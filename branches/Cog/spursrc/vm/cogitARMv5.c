/* Automatically generated by
	CCodeGenerator VMMaker.oscog-eem.1401 uuid: 036f0933-639a-49dd-8a1d-a03bcdcb0a0a
   from
	StackToRegisterMappingCogit VMMaker.oscog-eem.1401 uuid: 036f0933-639a-49dd-8a1d-a03bcdcb0a0a
 */
static char __buildInfo[] = "StackToRegisterMappingCogit VMMaker.oscog-eem.1401 uuid: 036f0933-639a-49dd-8a1d-a03bcdcb0a0a " __DATE__ ;
char *__cogitBuildInfo = __buildInfo;



#include <stddef.h>
#include "sq.h"
#include "sqCogStackAlignment.h"
#include "dispdbg.h"
#include "cogmethod.h"
#if COGMTVM
#include "cointerpmt.h"
#else
#include "cointerp.h"
#endif
#include "cogit.h"

typedef struct _AbstractInstruction {
	unsigned char	opcode;
	unsigned char	machineCodeSize;
	unsigned char	maxSize;
	unsigned char	annotation;
	unsigned char	conditionOrNil;
	unsigned long		operands [3];
	unsigned long	address;
	struct _AbstractInstruction *dependent;
	unsigned long		machineCode [5];
 } AbstractInstruction;

#define CogOutOfLineLiteralsARMCompiler AbstractInstruction
#define CogARMCompiler AbstractInstruction
#define CogAbstractInstruction AbstractInstruction


typedef struct {
	AbstractInstruction *fakeHeader;
	AbstractInstruction *fillInstruction;
	sqInt	numArgs;
	sqInt	numCopied;
	sqInt	numInitialNils;
	sqInt	startpc;
	AbstractInstruction *entryLabel;
	AbstractInstruction *stackCheckLabel;
	sqInt	span;
	sqInt	hasInstVarRef;
 } BlockStart;

#define CogBlockStart BlockStart


typedef struct _BytecodeDescriptor {
	sqInt (*generator )(void);
	sqInt (*spanFunction )(struct _BytecodeDescriptor *,sqInt,sqInt,sqInt);
	sqInt (*needsFrameFunction )(sqInt);
	signed char	stackDelta;
	unsigned char	opcode;
	unsigned char	numBytes;
	unsigned		isBranchTrue : 1;
	unsigned		isBranchFalse : 1;
	unsigned		isReturn : 1;
	unsigned		isBlockCreation : 1;
	unsigned		isMapped : 1;
	unsigned		isMappedInBlock : 1;
	unsigned		isExtension : 1;
	unsigned		isInstVarRef : 1;
 } BytecodeDescriptor;

#define CogBytecodeDescriptor BytecodeDescriptor


typedef struct {
	sqInt (*primitiveGenerator )(void);
	sqInt	primNumArgs;
	sqInt (*enabled )(sqInt);
 } PrimitiveDescriptor;

#define CogPrimitiveDescriptor PrimitiveDescriptor


typedef struct {
	AbstractInstruction *targetInstruction;
	sqInt	instructionIndex;
	sqInt	simStackPtr;
 } BytecodeFixup;

#define CogSSBytecodeFixup BytecodeFixup
#define CogBytecodeFixup BytecodeFixup


typedef struct {
	char	type;
	char	spilled;
	char	annotateUse;
	sqInt	registerr;
	sqInt	offset;
	sqInt	constant;
	sqInt	bcptr;
 } CogSimStackEntry;


typedef struct {
	sqInt	isReceiverResultRegLive;
	CogSimStackEntry *ssEntry;
 } CogSSOptStatus;



/*** Constants ***/
#define AddCqR 96
#define AddCwR 104
#define AddOpcode 4
#define AddRdRd 112
#define AddRR 89
#define AL 14
#define AlignmentNops 3
#define AltBlockCreationBytecodeSize 3
#define AltFirstSpecialSelector 80
#define AndCqR 98
#define AndCqRR 110
#define AndCwR 106
#define AndOpcode 0
#define AndRR 91
#define AnnotationShift 5
#define Arg0Reg -7
#define Arg1Reg -8
#define ArithmeticShiftRightCqR 82
#define ArithmeticShiftRightRR 83
#define BadRegisterSet 1
#define BicOpcode 14
#define BlockCreationBytecodeSize 4
#define BytecodeSetHasDirectedSuperSend 0
#define CArg0Reg 0
#define CArg1Reg 1
#define CArg2Reg 2
#define CArg3Reg 3
#define Call 10
#define CallFull 11
#define CC 3
#define ClassArrayCompactIndex 51
#define ClassBlockClosureCompactIndex 37
#define ClassFloatCompactIndex 34
#define ClassMethodContextCompactIndex 36
#define ClassReg -5
#define ClosureFirstCopiedValueIndex 3
#define ClosureIndex 4
#define ClosureNumArgsIndex 2
#define ClosureOuterContextIndex 0
#define ClosureStartPCIndex 1
#define CMBlock 3
#define CMClosedPIC 4
#define CMFree 1
#define CMMaxUsageCount 7
#define CMMethod 2
#define CMOpenPIC 5
#define CMPSMULL 123
#define CmpCqR 95
#define CmpCwR 103
#define CmpNotOpcode 11
#define CmpOpcode 10
#define CmpRdRd 111
#define CmpRR 88
#define ConcreteIPReg 12
#define ConcreteVarBaseReg 10
#define ConstZero 1
#define ConvertRRd 117
#define CS 2
#define D0 0
#define D1 1
#define D2 2
#define D3 3
#define D4 4
#define D5 5
#define D6 6
#define D7 7
#define Debug DEBUGVM
#define DisplacementMask 0x1F
#define DisplacementX2N 0
#define DivRdRd 115
#define DPFPReg0 -9
#define DPFPReg1 -10
#define DPFPReg2 -11
#define DPFPReg3 -12
#define DPFPReg4 -13
#define DPFPReg5 -14
#define DPFPReg6 -15
#define DPFPReg7 -16
#define EncounteredUnknownBytecode -6
#define EQ 0
#define Fill16 6
#define Fill32 7
#define FillFromWord 8
#define FirstAnnotation 64
#define FirstJump 15
#define FirstShortJump 19
#define FirstSpecialSelector 176
#define FoxCallerSavedIP 4
#define FoxMethod -4
#define FoxMFReceiver -12
#define FoxSavedFP 0
#define FoxThisContext -8
#define FPReg -1
#define GCModeBecome 8
#define GCModeFull 1
#define GCModeNewSpace 2
#define GE 10
#define GPRegMax -3
#define GPRegMin -8
#define GT 12
#define HasBytecodePC 4
#define HeaderIndex 0
#define HI 8
#define InstanceSpecificationIndex 2
#define InstructionPointerIndex 1
#define InsufficientCodeSpace -2
#define IsAbsPCReference 3
#define IsAnnotationExtension 1
#define IsDirectedSuperSend 9
#define IsDisplacementX2N 0
#define IsNSDynamicSuperSend null
#define IsNSSelfSend null
#define IsNSSendCall null
#define IsObjectReference 2
#define IsRelativeCall 5
#define IsSendCall 7
#define IsSuperSend 8
#define Jump 19
#define JumpAbove 34
#define JumpAboveOrEqual 33
#define JumpBelow 32
#define JumpBelowOrEqual 35
#define JumpCarry 26
#define JumpFPEqual 36
#define JumpFPGreater 40
#define JumpFPGreaterOrEqual 41
#define JumpFPLess 38
#define JumpFPLessOrEqual 39
#define JumpFPNotEqual 37
#define JumpFPOrdered 42
#define JumpFPUnordered 43
#define JumpFull 15
#define JumpGreater 30
#define JumpGreaterOrEqual 29
#define JumpLess 28
#define JumpLessOrEqual 31
#define JumpLong 16
#define JumpLongNonZero 18
#define JumpLongZero 17
#define JumpNegative 22
#define JumpNoCarry 27
#define JumpNonNegative 23
#define JumpNonZero 21
#define JumpNoOverflow 25
#define JumpOverflow 24
#define JumpR 13
#define JumpZero 20
#define Label 1
#define LargeContextSlots 62
#define LastJump 43
#define LE 13
#define LinkReg -17
#define Literal 2
#define LoadEffectiveAddressMwrR 79
#define LogicalShiftLeftCqR 86
#define LogicalShiftLeftRR 87
#define LogicalShiftRightCqR 84
#define LogicalShiftRightRR 85
#define LR 14
#define LS 9
#define LT 11
#define MapEnd 0
#define MaxCompiledPrimitiveIndex 222
#define MaxMethodSize 65535
#define MaxNegativeErrorCode -8
#define MaxNumArgs 15
#define MaxStackAllocSize 1572864
#define MaxStackCheckOffset 0xFFF
#define MaxX2NDisplacement 992
#define MethodCacheClass 2
#define MethodCacheMask 0xFFC
#define MethodCacheMethod 3
#define MethodCacheSelector 1
#define MethodIndex 3
#define MethodTooBig -4
#define MFMethodFlagHasContextFlag 1
#define MFMethodFlagIsBlockFlag 2
#define MI 4
#define MoveAwR 45
#define MoveCqR 67
#define MoveCwR 68
#define MoveM16rR 55
#define MoveM64rRd 72
#define MoveMbrR 63
#define MoveMwrR 49
#define MoveNotOpcode 15
#define MoveOpcode 13
#define MoveRAw 46
#define MoveRdM64r 73
#define MoveRdRd 71
#define MoveRMbr 64
#define MoveRMwr 50
#define MoveRR 44
#define MoveRXbrR 66
#define MoveRXwrR 52
#define MoveXbrRR 65
#define MoveXwrRR 51
#define MSR 119
#define MULTIPLEBYTECODESETS 0
#define MulRdRd 114
#define NE 1
#define NegateR 81
#define NewspeakVM 0
#define Nop 9
#define NotFullyInitialized -1
#define NumObjRefsInRuntime 0
#define NumOopsPerNSC 6
#define NumSendTrampolines 4
#define NumTrampolines 54
#define OrCqR 99
#define OrCwR 107
#define OrOpcode 12
#define OrRR 92
#define PC 15
#define PCReg -19
#define PL 5
#define PopR 74
#define PrefetchAw 78
#define PrimCallCollectsProfileSamples 8
#define PrimCallDoNotJIT 32
#define PrimCallMayCallBack 4
#define PrimCallNeedsNewMethod 1
#define PrimCallNeedsPrimitiveFunction 2
#define PrimErrWritePastObject 17
#define PushCq 76
#define PushCw 77
#define PushR 75
#define R0 0
#define R11 11
#define R4 4
#define R5 5
#define R6 6
#define R7 7
#define R8 8
#define ReceiverIndex 5
#define ReceiverResultReg -3
#define RetN 12
#define RISCTempReg -18
#define RsbOpcode 3
#define SelectorCannotInterpret 34
#define SelectorDoesNotUnderstand 20
#define SenderIndex 0
#define SendNumArgsReg -6
#define ShouldNotJIT -8
#define SistaVM 0
#define SMULL 118
#define SmallContextSlots 22
#define SP 13
#define SPReg -2
#define SqrtRd 116
#define SSBaseOffset 1
#define SSConstant 2
#define SSRegister 3
#define SSSpill 4
#define StackPointerIndex 2
#define Stop 14
#define SubCqR 97
#define SubCwR 105
#define SubOpcode 2
#define SubRdRd 113
#define SubRR 90
#define TempReg -4
#define TstCqR 100
#define TstOpcode 8
#define UnfailingPrimitive 3
#define UnimplementedPrimitive -7
#define ValueIndex 1
#define VarBaseReg -20
#define VC 7
#define VS 6
#define XorCqR 101
#define XorCwR 108
#define XorOpcode 1
#define XorRR 93
#define YoungSelectorInPIC -5


/*** Function Prototypes ***/


#if !PRODUCTION && defined(PlatformNoDbgRegParms)
# define NoDbgRegParms PlatformNoDbgRegParms
#endif

#if !defined(NoDbgRegParms)
# define NoDbgRegParms /*empty*/
#endif



#if !defined(NeverInline)
# define NeverInline /*empty*/
#endif

static AbstractInstruction * addDependent(AbstractInstruction * self_in_addDependent, AbstractInstruction *anInstruction) NoDbgRegParms;
static sqInt availableRegisterOrNilFor(AbstractInstruction * self_in_availableRegisterOrNilFor, sqInt liveRegsMask) NoDbgRegParms;
static AbstractInstruction * cloneLiteralFrom(AbstractInstruction * self_in_cloneLiteralFrom, AbstractInstruction *existingLiteral) NoDbgRegParms;
static AbstractInstruction * generateICacheFlush(AbstractInstruction * self_in_generateICacheFlush) NoDbgRegParms;
static AbstractInstruction * genWriteCResultIntoReg(AbstractInstruction * self_in_genWriteCResultIntoReg, sqInt abstractRegister) NoDbgRegParms;
static AbstractInstruction * getJmpTarget(AbstractInstruction * self_in_getJmpTarget) NoDbgRegParms;
static AbstractInstruction * initializeSharableLiteral(AbstractInstruction * self_in_initializeSharableLiteral, sqInt literal) NoDbgRegParms;
static AbstractInstruction * initializeUniqueLiteral(AbstractInstruction * self_in_initializeUniqueLiteral, sqInt literal) NoDbgRegParms;
static sqInt isAFixup(AbstractInstruction * self_in_isAFixup, void *fixupOrAddress) NoDbgRegParms;
static sqInt isAnInstruction(AbstractInstruction * self_in_isAnInstruction, AbstractInstruction *addressOrInstruction) NoDbgRegParms;
static sqInt isJump(AbstractInstruction * self_in_isJump) NoDbgRegParms;
static sqInt isLongJump(AbstractInstruction * self_in_isLongJump) NoDbgRegParms;
static AbstractInstruction * jmpTarget(AbstractInstruction * self_in_jmpTarget, AbstractInstruction *anAbstractInstruction) NoDbgRegParms;
static usqInt labelOffset(AbstractInstruction * self_in_labelOffset) NoDbgRegParms;
static sqInt numCheckFeaturesOpcodes(AbstractInstruction * self_in_numCheckFeaturesOpcodes) NoDbgRegParms;
static AbstractInstruction * relocateJumpLongBeforeFollowingAddressby(AbstractInstruction * self_in_relocateJumpLongBeforeFollowingAddressby, sqInt pc, sqInt delta) NoDbgRegParms;
static AbstractInstruction * resolveJumpTarget(AbstractInstruction * self_in_resolveJumpTarget) NoDbgRegParms;
static sqInt setLabelOffset(AbstractInstruction * self_in_setLabelOffset, sqInt aValue) NoDbgRegParms;
static sqInt abstractRegisterForConcreteRegister(AbstractInstruction * self_in_abstractRegisterForConcreteRegister, sqInt reg) NoDbgRegParms;
static sqInt addsrnimmror(AbstractInstruction * self_in_addsrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot) NoDbgRegParms;
static sqInt addrnimmror(AbstractInstruction * self_in_addrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot) NoDbgRegParms;
static sqInt addrnrm(AbstractInstruction * self_in_addrnrm, sqInt destReg, sqInt srcReg, sqInt addReg) NoDbgRegParms;
static sqInt andsrnimmror(AbstractInstruction * self_in_andsrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot) NoDbgRegParms;
static sqInt andrnimmror(AbstractInstruction * self_in_andrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot) NoDbgRegParms;
static sqInt bicsrnimmror(AbstractInstruction * self_in_bicsrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot) NoDbgRegParms;
static sqInt bl(AbstractInstruction * self_in_bl, sqInt offset) NoDbgRegParms;
static sqInt b(AbstractInstruction * self_in_b, sqInt offset) NoDbgRegParms;
static sqInt callerSavedRegisterMask(AbstractInstruction * self_in_callerSavedRegisterMask) NoDbgRegParms;
static sqInt callInstructionByteSize(AbstractInstruction * self_in_callInstructionByteSize) NoDbgRegParms;
static sqInt callTargetFromReturnAddress(AbstractInstruction * self_in_callTargetFromReturnAddress, sqInt callSiteReturnAddress) NoDbgRegParms;
static sqInt computeMaximumSize(AbstractInstruction * self_in_computeMaximumSize) NoDbgRegParms;
static sqInt concreteCalleeSavedRegisterMask(AbstractInstruction * self_in_concreteCalleeSavedRegisterMask) NoDbgRegParms;
static sqInt concreteCallerSavedRegisterMask(AbstractInstruction * self_in_concreteCallerSavedRegisterMask) NoDbgRegParms;
static sqInt concreteDPFPRegister(AbstractInstruction * self_in_concreteDPFPRegister, sqInt registerIndex) NoDbgRegParms;
static sqInt concreteRegister(AbstractInstruction * self_in_concreteRegister, sqInt registerIndex) NoDbgRegParms;
static sqInt concretizeAt(AbstractInstruction * self_in_concretizeAt, sqInt actualAddress) NoDbgRegParms;
static usqInt concretizeCMPSMULL(AbstractInstruction * self_in_concretizeCMPSMULL) NoDbgRegParms;
static void concretizeConditionalInstruction(AbstractInstruction * self_in_concretizeConditionalInstruction) NoDbgRegParms;
static AbstractInstruction * concretizeFill16(AbstractInstruction * self_in_concretizeFill16) NoDbgRegParms;
static usqInt concretizeFill32(AbstractInstruction * self_in_concretizeFill32) NoDbgRegParms;
static AbstractInstruction * concretizeFillFromWord(AbstractInstruction * self_in_concretizeFillFromWord) NoDbgRegParms;
static usqInt concretizeMSR(AbstractInstruction * self_in_concretizeMSR) NoDbgRegParms;
static usqInt concretizeSMULL(AbstractInstruction * self_in_concretizeSMULL) NoDbgRegParms;
static sqInt cResultRegister(AbstractInstruction * self_in_cResultRegister) NoDbgRegParms;
static sqInt dataOpTyperdrnrmlsr(AbstractInstruction * self_in_dataOpTyperdrnrmlsr, sqInt armOpcode, sqInt destReg, sqInt srcReg, sqInt addReg, sqInt shft) NoDbgRegParms;
static void dispatchConcretize(AbstractInstruction * self_in_dispatchConcretize) NoDbgRegParms;
static sqInt fmsrFromto(AbstractInstruction * self_in_fmsrFromto, sqInt regA, sqInt regB) NoDbgRegParms;
static sqInt fsitodFromto(AbstractInstruction * self_in_fsitodFromto, sqInt regA, sqInt regB) NoDbgRegParms;
static sqInt fullCallsAreRelative(AbstractInstruction * self_in_fullCallsAreRelative) NoDbgRegParms;
static sqInt genAlignCStackSavingRegistersnumArgswordAlignment(AbstractInstruction * self_in_genAlignCStackSavingRegistersnumArgswordAlignment, sqInt saveRegs, sqInt numArgs, sqInt alignment) NoDbgRegParms;
static AbstractInstruction * genDivRRQuoRem(AbstractInstruction * self_in_genDivRRQuoRem, sqInt abstractRegDivisor, sqInt abstractRegDividend, sqInt abstractRegQuotient, sqInt abstractRegRemainder) NoDbgRegParms;
static AbstractInstruction * genGetLeafCallStackPointerFunction(AbstractInstruction * self_in_genGetLeafCallStackPointerFunction) NoDbgRegParms;
static sqInt genLoadCStackPointer(AbstractInstruction * self_in_genLoadCStackPointer) NoDbgRegParms;
static sqInt genLoadCStackPointers(AbstractInstruction * self_in_genLoadCStackPointers) NoDbgRegParms;
static sqInt genLoadStackPointers(AbstractInstruction * self_in_genLoadStackPointers) NoDbgRegParms;
static AbstractInstruction * genMulRR(AbstractInstruction * self_in_genMulRR, sqInt regSource, sqInt regDest) NoDbgRegParms;
static sqInt genPassConstasArgument(AbstractInstruction * self_in_genPassConstasArgument, sqInt constant, sqInt zeroRelativeArgIndex) NoDbgRegParms;
static sqInt genPassRegasArgument(AbstractInstruction * self_in_genPassRegasArgument, sqInt abstractRegister, sqInt zeroRelativeArgIndex) NoDbgRegParms;
static AbstractInstruction * genPushRegisterArgsForAbortMissNumArgs(AbstractInstruction * self_in_genPushRegisterArgsForAbortMissNumArgs, sqInt numArgs) NoDbgRegParms;
static AbstractInstruction * genPushRegisterArgsForNumArgsscratchReg(AbstractInstruction * self_in_genPushRegisterArgsForNumArgsscratchReg, sqInt numArgs, sqInt ignored) NoDbgRegParms;
static sqInt genRemoveNArgsFromStack(AbstractInstruction * self_in_genRemoveNArgsFromStack, sqInt n) NoDbgRegParms;
static AbstractInstruction * genRestoreRegs(AbstractInstruction * self_in_genRestoreRegs) NoDbgRegParms;
static AbstractInstruction * genRestoreRegsExcept(AbstractInstruction * self_in_genRestoreRegsExcept, sqInt abstractReg) NoDbgRegParms;
static AbstractInstruction * genSaveRegisters(AbstractInstruction * self_in_genSaveRegisters) NoDbgRegParms;
static sqInt genSaveStackPointers(AbstractInstruction * self_in_genSaveStackPointers) NoDbgRegParms;
static AbstractInstruction * genSubstituteReturnAddress(AbstractInstruction * self_in_genSubstituteReturnAddress, sqInt retpc) NoDbgRegParms;
static sqInt hasLinkRegister(AbstractInstruction * self_in_hasLinkRegister) NoDbgRegParms;
static sqInt hasPCDependentInstruction(AbstractInstruction * self_in_hasPCDependentInstruction) NoDbgRegParms;
static sqInt hasPCRegister(AbstractInstruction * self_in_hasPCRegister) NoDbgRegParms;
static sqInt instructionBeforeAddress(AbstractInstruction * self_in_instructionBeforeAddress, sqInt followingAddress) NoDbgRegParms;
static sqInt instructionIsBLX(AbstractInstruction * self_in_instructionIsBLX, sqInt instr) NoDbgRegParms;
static sqInt instructionIsBL(AbstractInstruction * self_in_instructionIsBL, sqInt instr) NoDbgRegParms;
static sqInt instructionIsBX(AbstractInstruction * self_in_instructionIsBX, sqInt instr) NoDbgRegParms;
static sqInt instructionIsB(AbstractInstruction * self_in_instructionIsB, sqInt instr) NoDbgRegParms;
static sqInt instructionIsOR(AbstractInstruction * self_in_instructionIsOR, sqInt instr) NoDbgRegParms;
static sqInt instructionIsPush(AbstractInstruction * self_in_instructionIsPush, sqInt instr) NoDbgRegParms;
static sqInt instructionSizeAt(AbstractInstruction * self_in_instructionSizeAt, sqInt pc) NoDbgRegParms;
static sqInt inverseOpcodeFor(AbstractInstruction * self_in_inverseOpcodeFor, sqInt armOpcode) NoDbgRegParms;
static sqInt isAddressRelativeToVarBase(AbstractInstruction * self_in_isAddressRelativeToVarBase, usqInt varAddress) NoDbgRegParms;
static sqInt isCallPreceedingReturnPC(AbstractInstruction * self_in_isCallPreceedingReturnPC, sqInt mcpc) NoDbgRegParms;
static sqInt isInImmediateJumpRange(AbstractInstruction * self_in_isInImmediateJumpRange, unsigned long operand) NoDbgRegParms;
static sqInt isJumpAt(AbstractInstruction * self_in_isJumpAt, sqInt pc) NoDbgRegParms;
static sqInt isPCRelativeValueLoad(AbstractInstruction * self_in_isPCRelativeValueLoad, unsigned int instr) NoDbgRegParms;
static sqInt jumpLongByteSize(AbstractInstruction * self_in_jumpLongByteSize) NoDbgRegParms;
static sqInt jumpLongConditionalByteSize(AbstractInstruction * self_in_jumpLongConditionalByteSize) NoDbgRegParms;
static sqInt jumpLongTargetBeforeFollowingAddress(AbstractInstruction * self_in_jumpLongTargetBeforeFollowingAddress, sqInt mcpc) NoDbgRegParms;
static usqInt jumpTargetPCAt(AbstractInstruction * self_in_jumpTargetPCAt, sqInt pc) NoDbgRegParms;
static sqInt ldrbrnplusimm(AbstractInstruction * self_in_ldrbrnplusimm, sqInt destReg, sqInt baseReg, sqInt u, sqInt immediate12bitValue) NoDbgRegParms;
static sqInt ldrbrnrm(AbstractInstruction * self_in_ldrbrnrm, sqInt destReg, sqInt baseReg, sqInt offsetReg) NoDbgRegParms;
static sqInt ldrhrnplusimm(AbstractInstruction * self_in_ldrhrnplusimm, sqInt destReg, sqInt baseReg, sqInt u, sqInt immediate8bitValue) NoDbgRegParms;
static sqInt ldrhrnrm(AbstractInstruction * self_in_ldrhrnrm, sqInt destReg, sqInt baseReg, sqInt offsetReg) NoDbgRegParms;
static sqInt ldrrnplusImm(AbstractInstruction * self_in_ldrrnplusImm, sqInt destReg, sqInt baseReg, sqInt immediate12bitValue) NoDbgRegParms;
static sqInt ldrrnplusimm(AbstractInstruction * self_in_ldrrnplusimm, sqInt destReg, sqInt baseReg, sqInt u, sqInt immediate12bitValue) NoDbgRegParms;
static sqInt ldrrnrm(AbstractInstruction * self_in_ldrrnrm, sqInt destReg, sqInt baseReg, sqInt offsetReg) NoDbgRegParms;
static sqInt leafCallStackPointerDelta(AbstractInstruction * self_in_leafCallStackPointerDelta) NoDbgRegParms;
static sqInt loadCwInto(AbstractInstruction * self_in_loadCwInto, sqInt destReg) NoDbgRegParms;
static sqInt loadLiteralByteSize(AbstractInstruction * self_in_loadLiteralByteSize) NoDbgRegParms;
static sqInt loadPICLiteralByteSize(AbstractInstruction * self_in_loadPICLiteralByteSize) NoDbgRegParms;
static sqInt machineCodeBytes(AbstractInstruction * self_in_machineCodeBytes) NoDbgRegParms;
static sqInt machineCodeWords(AbstractInstruction * self_in_machineCodeWords) NoDbgRegParms;
static AbstractInstruction * maybeEstablishVarBase(AbstractInstruction * self_in_maybeEstablishVarBase) NoDbgRegParms;
static sqInt memM16xrregbasepuwloffset(AbstractInstruction * self_in_memM16xrregbasepuwloffset, sqInt cond, sqInt destReg, sqInt baseReg, sqInt postpreoffset, sqInt updown, sqInt weirdstuff, sqInt loadstore, sqInt offset8) NoDbgRegParms;
static sqInt memM16xrregbasepuwlrm(AbstractInstruction * self_in_memM16xrregbasepuwlrm, sqInt cond, sqInt destReg, sqInt baseReg, sqInt postpreoffset, sqInt updown, sqInt weirdstuff, sqInt loadstore, sqInt offsetReg) NoDbgRegParms;
static sqInt memMxrregbasepubwlimm(AbstractInstruction * self_in_memMxrregbasepubwlimm, sqInt cond, sqInt destReg, sqInt baseReg, sqInt postpreoffset, sqInt updown, sqInt byteword, sqInt weirdstuff, sqInt loadstore, sqInt offset) NoDbgRegParms;
static sqInt memMxrregbasepubwlrmLsl2(AbstractInstruction * self_in_memMxrregbasepubwlrmLsl2, sqInt cond, sqInt destReg, sqInt baseReg, sqInt postpreoffset, sqInt updown, sqInt byteword, sqInt weirdstuff, sqInt loadstore, sqInt offsetReg) NoDbgRegParms;
static sqInt memMxrregbasepubwlrm(AbstractInstruction * self_in_memMxrregbasepubwlrm, sqInt cond, sqInt destReg, sqInt baseReg, sqInt postpreoffset, sqInt updown, sqInt byteword, sqInt weirdstuff, sqInt loadstore, sqInt offsetReg) NoDbgRegParms;
static sqInt memMxrregbaseublimm(AbstractInstruction * self_in_memMxrregbaseublimm, sqInt cond, sqInt destReg, sqInt baseReg, sqInt updown, sqInt byteword, sqInt loadstore, sqInt immediate12bitValue) NoDbgRegParms;
static sqInt movsrn(AbstractInstruction * self_in_movsrn, sqInt destReg, sqInt srcReg) NoDbgRegParms;
static sqInt movimmror(AbstractInstruction * self_in_movimmror, sqInt destReg, sqInt immediate8bitValue, sqInt rot) NoDbgRegParms;
static sqInt movrn(AbstractInstruction * self_in_movrn, sqInt destReg, sqInt srcReg) NoDbgRegParms;
static sqInt msr(AbstractInstruction * self_in_msr, sqInt flags) NoDbgRegParms;
static sqInt mvnimmror(AbstractInstruction * self_in_mvnimmror, sqInt destReg, sqInt immediate8bitValue, sqInt rot) NoDbgRegParms;
static AbstractInstruction * nopsFromto(AbstractInstruction * self_in_nopsFromto, sqInt startAddr, sqInt endAddr) NoDbgRegParms;
static sqInt numICacheFlushOpcodes(AbstractInstruction * self_in_numICacheFlushOpcodes) NoDbgRegParms;
static sqInt orrimmror(AbstractInstruction * self_in_orrimmror, sqInt destReg, sqInt immediate8bitValue, sqInt rot) NoDbgRegParms;
static AbstractInstruction * padIfPossibleWithNopsFromto(AbstractInstruction * self_in_padIfPossibleWithNopsFromto, sqInt startAddr, sqInt endAddr) NoDbgRegParms;
static sqInt popR(AbstractInstruction * self_in_popR, sqInt dstReg) NoDbgRegParms;
static sqInt pushLinkRegisterByteSize(AbstractInstruction * self_in_pushLinkRegisterByteSize) NoDbgRegParms;
static sqInt pushR(AbstractInstruction * self_in_pushR, sqInt srcReg) NoDbgRegParms;
static AbstractInstruction * relocateCallBeforeReturnPCby(AbstractInstruction * self_in_relocateCallBeforeReturnPCby, sqInt retpc, sqInt delta) NoDbgRegParms;
static sqInt rewriteCallAttarget(AbstractInstruction * self_in_rewriteCallAttarget, usqInt callSiteReturnAddress, usqInt callTargetAddress) NoDbgRegParms;
static sqInt rewriteCallFullAttarget(AbstractInstruction * self_in_rewriteCallFullAttarget, sqInt callSiteReturnAddress, sqInt callTargetAddress) NoDbgRegParms;
static sqInt rewriteJumpFullAttarget(AbstractInstruction * self_in_rewriteJumpFullAttarget, sqInt callSiteReturnAddress, sqInt callTargetAddress) NoDbgRegParms;
static sqInt setsConditionCodesFor(AbstractInstruction * self_in_setsConditionCodesFor, sqInt aConditionalJumpOpcode) NoDbgRegParms;
static sqInt shiftSetsConditionCodesFor(AbstractInstruction * self_in_shiftSetsConditionCodesFor, sqInt aConditionalJumpOpcode) NoDbgRegParms;
static sqInt stackPageInterruptHeadroomBytes(AbstractInstruction * self_in_stackPageInterruptHeadroomBytes) NoDbgRegParms;
static sqInt strbrnplusimm(AbstractInstruction * self_in_strbrnplusimm, sqInt destReg, sqInt baseReg, sqInt u, sqInt immediate12bitValue) NoDbgRegParms;
static sqInt strbrnrm(AbstractInstruction * self_in_strbrnrm, sqInt srcReg, sqInt baseReg, sqInt offsetReg) NoDbgRegParms;
static sqInt strrnplusImm(AbstractInstruction * self_in_strrnplusImm, sqInt srcReg, sqInt baseReg, sqInt immediate12bitValue) NoDbgRegParms;
static sqInt strrnplusimm(AbstractInstruction * self_in_strrnplusimm, sqInt destReg, sqInt baseReg, sqInt u, sqInt immediate12bitValue) NoDbgRegParms;
static sqInt strrnrm(AbstractInstruction * self_in_strrnrm, sqInt srcReg, sqInt baseReg, sqInt offsetReg) NoDbgRegParms;
static sqInt subsrnimmror(AbstractInstruction * self_in_subsrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot) NoDbgRegParms;
static sqInt subrnimmror(AbstractInstruction * self_in_subrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot) NoDbgRegParms;
static sqInt tstrnimmror(AbstractInstruction * self_in_tstrnimmror, sqInt ignored, sqInt srcReg, sqInt immediate, sqInt rot) NoDbgRegParms;
static CogMethod * cmHomeMethod(CogBlockMethod * self_in_cmHomeMethod) NoDbgRegParms;
static sqInt isBranch(BytecodeDescriptor * self_in_isBranch) NoDbgRegParms;
static sqInt isUnconditionalBranch(BytecodeDescriptor * self_in_isUnconditionalBranch) NoDbgRegParms;
static AbstractInstruction * gAndCqR(sqInt quickConstant, sqInt reg) NoDbgRegParms;
static AbstractInstruction * gArithmeticShiftRightRR(sqInt reg1, sqInt reg2) NoDbgRegParms;
extern sqInt abortOffset(void);
static void addCleanBlockStarts(void);
extern void addCogMethodsToHeapMap(void);
static sqInt addressIsInCurrentCompilation(sqInt address) NoDbgRegParms;
static sqInt addressIsInFixups(AbstractInstruction *address) NoDbgRegParms;
static sqInt addressIsInInstructions(AbstractInstruction *address) NoDbgRegParms;
static sqInt addressOfEndOfCaseinCPIC(sqInt n, CogMethod *cPIC) NoDbgRegParms;
static sqInt alignUptoRoutineBoundary(sqInt anAddress) NoDbgRegParms;
static sqInt allMachineCodeObjectReferencesValid(void);
static sqInt allMethodsHaveCorrectHeader(void);
static AbstractInstruction * annotateAbsolutePCRef(AbstractInstruction *abstractInstruction) NoDbgRegParms;
static AbstractInstruction * annotateBytecode(AbstractInstruction *abstractInstruction) NoDbgRegParms;
static AbstractInstruction * annotateobjRef(AbstractInstruction *abstractInstruction, sqInt anOop) NoDbgRegParms;
static sqInt annotationForMcpcin(sqInt mcpc, CogMethod *cogHomeMethod) NoDbgRegParms;
static void assertSaneJumpTarget(AbstractInstruction *jumpTarget) NoDbgRegParms;
static sqInt blockCreationBytecodeSizeForHeader(sqInt methodHeader) NoDbgRegParms;
static sqInt blockDispatchTargetsForperformarg(CogMethod *cogMethod, usqInt (*binaryFunction)(sqInt mcpc, sqInt arg), sqInt arg) NoDbgRegParms;
extern sqInt bytecodePCForstartBcpcin(sqInt mcpc, sqInt startbcpc, CogBlockMethod *cogMethod);
static AbstractInstruction * CallRTregistersToBeSavedMask(sqInt callTarget, sqInt registersToBeSaved) NoDbgRegParms;
static AbstractInstruction * gCall(sqInt callTarget) NoDbgRegParms;
static AbstractInstruction * gCmpCqR(sqInt quickConstant, sqInt reg) NoDbgRegParms;
static AbstractInstruction * gCmpCwR(sqInt wordConstant, sqInt reg) NoDbgRegParms;
static AbstractInstruction * gCmpRR(sqInt reg1, sqInt reg2) NoDbgRegParms;
extern void callCogCodePopReceiver(void);
extern void callCogCodePopReceiverAndClassRegs(void);
extern sqInt ceCPICMissreceiver(CogMethod *cPIC, sqInt receiver);
extern sqInt ceSICMiss(sqInt receiver);
extern void checkAssertsEnabledInCogit(void);
static sqInt checkIfValidOopRefAndTargetpccogMethod(sqInt annotation, char *mcpc, sqInt cogMethod) NoDbgRegParms;
static sqInt checkIfValidOopRefpccogMethod(sqInt annotation, char *mcpc, sqInt cogMethod) NoDbgRegParms;
extern sqInt checkIntegrityOfObjectReferencesInCode(sqInt gcModes);
static sqInt checkMaybeObjRefInClosedPIC(sqInt maybeObject) NoDbgRegParms;
static sqInt checkValidObjectReferencesInClosedPIC(CogMethod *cPIC) NoDbgRegParms;
static sqInt closedPICRefersToUnmarkedObject(CogMethod *cPIC) NoDbgRegParms;
extern char * codeEntryFor(char *address);
extern char * codeEntryNameFor(char *address);
extern sqInt cogCodeBase(void);
extern sqInt cogCodeConstituents(void);
static sqInt cogExtendPICCaseNMethodtagisMNUCase(CogMethod *cPIC, sqInt caseNMethod, sqInt caseNTag, sqInt isMNUCase) NoDbgRegParms;
extern void cogitPostGCAction(sqInt gcMode);
extern sqInt cogMethodDoesntLookKosher(CogMethod *cogMethod);
extern CogMethod * cogMNUPICSelectorreceivermethodOperandnumArgs(sqInt selector, sqInt rcvr, sqInt methodOperand, sqInt numArgs);
static CogMethod * cogOpenPICSelectornumArgs(sqInt selector, sqInt numArgs) NoDbgRegParms;
static CogMethod * cogPICSelectornumArgsCase0MethodCase1MethodtagisMNUCase(sqInt selector, sqInt numArgs, CogMethod *case0CogMethod, sqInt case1MethodOrNil, sqInt case1Tag, sqInt isMNUCase) NoDbgRegParms;
extern CogMethod * cogselector(sqInt aMethodObj, sqInt aSelectorOop);
extern void compactCogCompiledCode(void);
static AbstractInstruction * compileAbort(void);
static sqInt compileBlockDispatchFromto(sqInt lowBlockStartIndex, sqInt highBlockStartIndex) NoDbgRegParms;
static void compileBlockEntry(BlockStart *blockStart) NoDbgRegParms;
static void compileCallFornumArgsargargargargresultRegsaveRegs(void *aRoutine, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt resultRegOrNil, sqInt saveRegs) NoDbgRegParms;
static AbstractInstruction * compileCPICEntry(void);
static sqInt compileCPICCase0Case1MethodtagisMNUCasenumArgs(CogMethod *cPIC, CogMethod *case0CogMethod, sqInt case1Method, sqInt case1Tag, sqInt isMNUCase, sqInt numArgs) NoDbgRegParms;
static void compileEntry(void);
static sqInt compileMethodBody(void);
static sqInt compileMNUCPICmethodOperandnumArgs(CogMethod *cPIC, sqInt methodOperand, sqInt numArgs) NoDbgRegParms;
static sqInt compilePICAbort(sqInt numArgs) NoDbgRegParms;
static sqInt compilePrimitive(void);
static void compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(void *aRoutine, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt saveRegs, sqInt pushLinkReg, sqInt resultRegOrNil) NoDbgRegParms;
static void computeEntryOffsets(void);
static void computeMaximumSizes(void);
static sqInt cPICHasForwardedClass(CogMethod *cPIC) NoDbgRegParms;
static sqInt cPICHasFreedTargets(CogMethod *cPIC) NoDbgRegParms;
static sqInt cPICPrototypeCaseOffset(void);
static sqInt cPICHasTarget(CogMethod *cPIC, CogMethod *targetMethod) NoDbgRegParms;
static AbstractInstruction * gDivRRQuoRem(sqInt rDivisor, sqInt rDividend, sqInt rQuotient, sqInt rRemainder) NoDbgRegParms;
extern sqInt defaultCogCodeSize(void);
static sqInt endPCOf(sqInt aMethod) NoDbgRegParms;
extern void enterCogCodePopReceiver(void);
static sqInt expectedClosedPICPrototype(CogMethod *cPIC) NoDbgRegParms;
static sqInt fillInBlockHeadersAt(sqInt startAddress) NoDbgRegParms;
static CogMethod * fillInMethodHeadersizeselector(CogMethod *method, sqInt size, sqInt selector) NoDbgRegParms;
static usqInt findBlockMethodWithEntrystartBcpc(sqInt blockEntryMcpc, sqInt startBcpc) NoDbgRegParms;
static sqInt findMapLocationForMcpcinMethod(sqInt targetMcpc, CogMethod *cogMethod) NoDbgRegParms;
extern CogBlockMethod * findMethodForStartBcpcinHomeMethod(sqInt startbcpc, CogMethod *cogMethod);
static sqInt findIsBackwardBranchMcpcBcpcMatchingMcpc(BytecodeDescriptor *descriptor, sqInt isBackwardBranch, char *mcpc, sqInt bcpc, void *targetMcpc) NoDbgRegParms;
extern void followForwardedLiteralsIn(CogMethod *cogMethod);
extern void followForwardedMethods(void);
static sqInt followMaybeObjRefInClosedPICAt(sqInt mcpc) NoDbgRegParms;
static sqInt followMethodReferencesInClosedPIC(CogMethod *cPIC) NoDbgRegParms;
static void freePICsWithFreedTargets(void);
extern void freeUnmarkedMachineCode(void);
static sqInt genCheckForInterruptsTrampoline(void);
static void (*genEnilopmartForandandforCallcalled(sqInt regArg1, sqInt regArg2, sqInt regArg3, sqInt forCall, char *trampolineName))(void)  NoDbgRegParms;
static void genEnilopmartReturn(sqInt forCall) NoDbgRegParms;
static void generateCaptureCStackPointers(sqInt captureFramePointer) NoDbgRegParms;
static void generateClosedPICPrototype(void);
static CogMethod * generateCogMethod(sqInt selector) NoDbgRegParms;
static sqInt generateInstructionsAt(sqInt eventualAbsoluteAddress) NoDbgRegParms;
static sqInt generateMapAtstart(sqInt addressOrNull, sqInt startAddress) NoDbgRegParms;
static void generateOpenPICPrototype(void);
static void generateRunTimeTrampolines(void);
static void generateStackPointerCapture(void);
static void generateTrampolines(void);
static void generateVMOwnerLockFunctions(void);
static sqInt genGetLeafCallStackPointer(void);
static sqInt genInnerPICAbortTrampoline(char *name) NoDbgRegParms;
static sqInt genLoadCStackPointersForPrimCall(void);
static sqInt genNonLocalReturnTrampoline(void);
static sqInt genReturnTrampolineForcalledarg(void *aRoutine, char *aString, sqInt regOrConst0) NoDbgRegParms;
static sqInt genSafeTrampolineForcalled(void *aRoutine, char *aString) NoDbgRegParms;
static sqInt genSafeTrampolineForcalledarg(void *aRoutine, char *aString, sqInt regOrConst0) NoDbgRegParms;
static sqInt genSafeTrampolineForcalledargarg(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1) NoDbgRegParms;
static sqInt genSmalltalkToCStackSwitch(sqInt pushLinkReg) NoDbgRegParms;
static sqInt genTrampolineForcalled(void *aRoutine, char *aString) NoDbgRegParms;
static sqInt genTrampolineForcalledargargargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt resultReg) NoDbgRegParms;
static sqInt genTrampolineForcalledargargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt resultReg) NoDbgRegParms;
static sqInt genTrampolineForcalledargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt resultReg) NoDbgRegParms;
static sqInt genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(void *aRoutine, char *trampolineName, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt saveRegs, sqInt pushLinkReg, sqInt resultRegOrNil, sqInt appendBoolean) NoDbgRegParms;
static AbstractInstruction * gen(sqInt opcode) NoDbgRegParms;
static AbstractInstruction * genoperand(sqInt opcode, sqInt operand) NoDbgRegParms;
static AbstractInstruction * genoperandoperand(sqInt opcode, sqInt operandOne, sqInt operandTwo) NoDbgRegParms;
static AbstractInstruction * genoperandoperandoperand(sqInt opcode, sqInt operandOne, sqInt operandTwo, sqInt operandThree) NoDbgRegParms;
static sqInt getLiteral(sqInt litIndex) NoDbgRegParms;
static sqInt getOpcodeIndex(void);
static sqInt incrementUsageOfTargetIfLinkedSendmcpcignored(sqInt annotation, char *mcpc, sqInt superfluity) NoDbgRegParms;
static sqInt initialClosedPICUsageCount(void);
static void initializeBackend(void);
extern void initializeCodeZoneFromupTo(sqInt startAddress, sqInt endAddress);
static sqInt initialMethodUsageCount(void);
static sqInt initialOpenPICUsageCount(void);
static sqInt inverseBranchFor(sqInt opcode) NoDbgRegParms;
static sqInt isBackwardBranchatextsin(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj) NoDbgRegParms;
static sqInt isPCMappedAnnotation(sqInt annotation) NoDbgRegParms;
extern sqInt isPCWithinMethodZone(void *address);
extern sqInt isSendReturnPC(sqInt retpc);
static AbstractInstruction * gJumpFPEqual(void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * gJumpFPGreaterOrEqual(void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * gJumpFPGreater(void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * gJumpFPLessOrEqual(void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * gJumpFPLess(void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * gJumpFPNotEqual(void *jumpTarget) NoDbgRegParms;
static AbstractInstruction * gLabel(void);
static AbstractInstruction * gLogicalShiftLeftCqR(sqInt quickConstant, sqInt reg) NoDbgRegParms;
static AbstractInstruction * lastOpcode(void);
extern void linkSendAtintooffsetreceiver(sqInt callSiteReturnAddress, CogMethod *sendingMethod, CogMethod *targetMethod, sqInt theEntryOffset, sqInt receiver);
static void loadSubsequentBytesForDescriptorat(BytecodeDescriptor *descriptor, sqInt pc) NoDbgRegParms;
static AbstractInstruction * gMoveAwR(sqInt address, sqInt reg) NoDbgRegParms;
static AbstractInstruction * gMoveCwR(sqInt wordConstant, sqInt reg) NoDbgRegParms;
static AbstractInstruction * gMoveMwrR(sqInt offset, sqInt baseReg, sqInt destReg) NoDbgRegParms;
static AbstractInstruction * gMoveRMwr(sqInt sourceReg, sqInt offset, sqInt baseReg) NoDbgRegParms;
static AbstractInstruction * gMoveRR(sqInt reg1, sqInt reg2) NoDbgRegParms;
static AbstractInstruction * gMulRR(sqInt reg1, sqInt reg2) NoDbgRegParms;
static sqInt mapEndFor(CogMethod *cogMethod) NoDbgRegParms;
static sqInt mapForperformUntilarg(CogMethod *cogMethod, int (*functionSymbol)(sqInt annotation, char *mcpc, sqInt arg), sqInt arg) NoDbgRegParms;
static sqInt mapObjectReferencesInClosedPIC(CogMethod *cPIC) NoDbgRegParms;
static void mapObjectReferencesInGeneratedRuntime(void);
static void mapObjectReferencesInMachineCodeForBecome(void);
static void mapObjectReferencesInMachineCodeForFullGC(void);
static void mapObjectReferencesInMachineCodeForYoungGC(void);
extern void mapObjectReferencesInMachineCode(sqInt gcMode);
extern void markAndTraceMachineCodeOfMarkedMethods(void);
static void markAndTraceObjectReferencesInGeneratedRuntime(void);
static sqInt markAndTraceOrFreeCogMethodfirstVisit(CogMethod *cogMethod, sqInt firstVisit) NoDbgRegParms;
static sqInt markLiteralsAndUnlinkIfUnmarkedSendpcmethod(sqInt annotation, char *mcpc, sqInt cogMethod) NoDbgRegParms;
static sqInt markLiteralspcmethod(sqInt annotation, char *mcpc, sqInt cogMethod) NoDbgRegParms;
extern void markMethodAndReferents(CogBlockMethod *aCogMethod);
extern usqInt maxCogMethodAddress(void);
static sqInt maybeAllocAndInitIRCs(void);
static sqInt maybeFreeCogMethodDoesntLookKosher(CogMethod *cogMethod) NoDbgRegParms;
static sqInt maybeGenerateCheckFeatures(void);
static sqInt maybeGenerateICacheFlush(void);
static void maybeMarkCountersIn(CogMethod *cogMethod) NoDbgRegParms;
static sqInt mclassIsSmallInteger(sqInt ignoredPrimIndex) NoDbgRegParms;
extern usqInt mcPCForBackwardBranchstartBcpcin(sqInt bcpc, sqInt startbcpc, CogBlockMethod *cogMethod);
static sqInt methodhasSameCodeAscheckPenultimate(sqInt methodA, sqInt methodB, sqInt comparePenultimateLiteral) NoDbgRegParms;
extern sqInt minCogMethodAddress(void);
extern sqInt mnuOffset(void);
static AbstractInstruction * gNegateR(sqInt reg) NoDbgRegParms;
static sqInt needsFrameIfInBlock(sqInt stackDelta) NoDbgRegParms;
static sqInt needsFrameNever(sqInt stackDelta) NoDbgRegParms;
static sqInt noAssertMethodClassAssociationOf(sqInt methodPointer) NoDbgRegParms;
static sqInt noCogMethodsMaximallyMarked(void);
static sqInt noTargetsFreeInClosedPIC(CogMethod *cPIC) NoDbgRegParms;
static sqInt outputInstructionsAt(sqInt startAddress) NoDbgRegParms;
static sqInt outputInstructionsForGeneratedRuntimeAt(sqInt startAddress) NoDbgRegParms;
static AbstractInstruction * gPopR(sqInt reg) NoDbgRegParms;
static AbstractInstruction * gPushCw(sqInt wordConstant) NoDbgRegParms;
extern sqInt patchToOpenPICFornumArgsreceiver(sqInt selector, sqInt numArgs, sqInt receiver);
static sqInt picAbortDiscriminatorValue(void);
static sqInt picInterpretAbortOffset(void);
static PrimitiveDescriptor * primitiveGeneratorOrNil(void);
extern void printCogMethodFor(void *address);
extern void printTrampolineTable(void);
static sqInt processorHasDivQuoRemAndMClassIsSmallInteger(sqInt ignoredPrimIndex) NoDbgRegParms;
static sqInt processorHasDivQuoRem(sqInt ignoredPrimIndex) NoDbgRegParms;
static sqInt processorHasDoublePrecisionFloatingPointSupport(sqInt ignoredPrimIndex) NoDbgRegParms;
static sqInt processorHasMultiplyAndMClassIsSmallInteger(sqInt ignoredPrimIndex) NoDbgRegParms;
static sqInt processorHasMultiply(sqInt ignoredPrimIndex) NoDbgRegParms;
static AbstractInstruction * gRetN(sqInt offset) NoDbgRegParms;
static void recordGeneratedRunTimeaddress(char *aString, sqInt address) NoDbgRegParms;
extern sqInt recordPrimTraceFunc(void);
static void recordRunTimeObjectReferences(void);
static sqInt registerMaskFor(sqInt reg) NoDbgRegParms;
static sqInt registerMaskForand(sqInt reg1, sqInt reg2) NoDbgRegParms;
static void relocateCallsAndSelfReferencesInMethod(CogMethod *cogMethod) NoDbgRegParms;
static void relocateCallsInClosedPIC(CogMethod *cPIC) NoDbgRegParms;
static sqInt relocateIfCallOrMethodReferencemcpcdelta(sqInt annotation, char *mcpc, sqInt delta) NoDbgRegParms;
static sqInt remapIfObjectRefpchasYoung(sqInt annotation, char *mcpc, sqInt hasYoungPtr) NoDbgRegParms;
static AbstractInstruction * gSubCwR(sqInt wordConstant, sqInt reg) NoDbgRegParms;
static sqInt scanForCleanBlocks(void);
extern void setBreakMethod(sqInt anObj);
extern void setPostCompileHook(void (*aFunction)(CogMethod *));
extern void setSelectorOfto(CogMethod *cogMethod, sqInt aSelectorOop);
static sqInt spanForCleanBlockStartingAt(sqInt startPC) NoDbgRegParms;
extern sqInt traceLinkedSendOffset(void);
static char * trampolineNamenumArgs(char *routinePrefix, sqInt numArgs) NoDbgRegParms;
static char * trampolineNamenumRegArgs(char *routinePrefix, sqInt numArgs) NoDbgRegParms;
static sqInt unimplementedPrimitive(void);
static sqInt unknownBytecode(void);
extern void unlinkAllSends(void);
static sqInt unlinkIfFreeOrLinkedSendpcof(sqInt annotation, char *mcpc, sqInt theSelector) NoDbgRegParms;
static sqInt unlinkIfInvalidClassSendpcignored(sqInt annotation, char *mcpc, sqInt superfluity) NoDbgRegParms;
static sqInt unlinkIfLinkedSendToFreepcignored(sqInt annotation, char *mcpc, sqInt superfluity) NoDbgRegParms;
static sqInt unlinkIfLinkedSendpcignored(sqInt annotation, char *mcpc, sqInt superfluity) NoDbgRegParms;
static sqInt unlinkIfLinkedSendpcto(sqInt annotation, char *mcpc, sqInt theCogMethod) NoDbgRegParms;
extern void unlinkSendsLinkedForInvalidClasses(void);
extern void unlinkSendsOfisMNUSelector(sqInt selector, sqInt isMNUSelector);
extern void unlinkSendsToFree(void);
extern void unlinkSendsToandFreeIf(sqInt targetMethodObject, sqInt freeIfTrue);
static sqInt updateMaybeClassRefInClosedPICAt(sqInt mcpc) NoDbgRegParms;
static sqInt updateMaybeObjRefInClosedPICAt(sqInt mcpc) NoDbgRegParms;
static AbstractInstruction * gXorCwR(sqInt wordConstant, sqInt reg) NoDbgRegParms;
static void zeroOpcodeIndex(void);
extern void addAllToYoungReferrers(void);
static void addToOpenPICList(CogMethod *anOpenPIC) NoDbgRegParms;
static void addToYoungReferrers(CogMethod *cogMethod) NoDbgRegParms;
static sqInt allocate(sqInt numBytes) NoDbgRegParms;
static void clearCogCompiledCode(void);
static void compactCompiledCode(void);
static void ensureInYoungReferrers(CogMethod *cogMethod) NoDbgRegParms;
extern void freeMethod(CogMethod *cogMethod);
static void freeOlderMethodsForCompaction(void);
static sqInt kosherYoungReferrers(void);
static void manageFromto(sqInt theStartAddress, sqInt theLimitAddress) NoDbgRegParms;
extern CogMethod * methodFor(void *address);
static sqInt numMethods(void);
extern sqInt numMethodsOfType(sqInt cogMethodType);
static sqInt occurrencesInYoungReferrers(CogMethod *cogMethod) NoDbgRegParms;
static CogMethod * openPICWithSelector(sqInt aSelector) NoDbgRegParms;
static void planCompaction(void);
extern void printCogMethods(void);
extern void printCogMethodsOfType(sqInt cmType);
extern void printCogMethodsWithMethod(sqInt methodOop);
extern void printCogMethodsWithPrimitive(sqInt primIdx);
extern void printCogMethodsWithSelector(sqInt selectorOop);
extern void printCogYoungReferrers(void);
extern void printOpenPICList(void);
static sqInt pruneYoungReferrers(void);
static sqInt relocateAndPruneYoungReferrers(void);
static sqInt relocateMethodsPreCompaction(void);
static sqInt removeFromOpenPICList(CogMethod *anOpenPIC) NoDbgRegParms;
static void voidYoungReferrersPostTenureAll(void);
extern char * whereIsMaybeCodeThing(sqInt anOop);
static sqInt checkValidObjectReference(sqInt anOop) NoDbgRegParms;
static AbstractInstruction * genCmpClassFloatCompactIndexR(sqInt reg) NoDbgRegParms;
static AbstractInstruction * genCmpClassMethodContextCompactIndexR(sqInt reg) NoDbgRegParms;
static sqInt genInnerPrimitiveNewMethod(sqInt retNoffset) NoDbgRegParms;
static AbstractInstruction * genJumpNotSmallIntegerscratchReg(sqInt aRegister, sqInt scratch) NoDbgRegParms;
static sqInt genLoadSlotsourceRegdestReg(sqInt index, sqInt sourceReg, sqInt destReg) NoDbgRegParms;
static sqInt isUnannotatableConstant(CogSimStackEntry *simStackEntry) NoDbgRegParms;
static sqInt genAddSmallIntegerTagsTo(sqInt aRegister) NoDbgRegParms;
static void genConvertCharacterToSmallIntegerInReg(sqInt reg) NoDbgRegParms;
static sqInt genConvertIntegerToSmallIntegerInReg(sqInt reg) NoDbgRegParms;
static void genConvertSmallIntegerToCharacterInReg(sqInt reg) NoDbgRegParms;
static sqInt genConvertSmallIntegerToIntegerInReg(sqInt reg) NoDbgRegParms;
static sqInt genCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(sqInt bcpc, sqInt numArgs, sqInt numCopied, sqInt ctxtNumArgs, sqInt isLargeCtxt, sqInt isInBlock) NoDbgRegParms;
static sqInt genFetchIndexRegisterfrominto(sqInt indexReg, sqInt tableObj, sqInt destReg) NoDbgRegParms;
static sqInt genGetActiveContextLargeinBlock(sqInt isLarge, sqInt isInBlock) NoDbgRegParms;
static AbstractInstruction * genGetClassTagOfintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg) NoDbgRegParms;
static sqInt genGetHashFieldNonImmOfasSmallIntegerInto(sqInt instReg, sqInt destReg) NoDbgRegParms;
static sqInt genGetHashFieldNonImmOfinto(sqInt instReg, sqInt destReg) NoDbgRegParms;
static AbstractInstruction * genGetInlineCacheClassTagFromintoforEntry(sqInt sourceReg, sqInt destReg, sqInt forEntry) NoDbgRegParms;
static sqInt genGetNumBytesOfinto(sqInt srcReg, sqInt destReg) NoDbgRegParms;
static sqInt genGetNumSlotsOfinto(sqInt srcReg, sqInt destReg) NoDbgRegParms;
static sqInt genGetOverflowSlotsOfinto(sqInt srcReg, sqInt destReg) NoDbgRegParms;
static sqInt genInnerPrimitiveAtPut(sqInt retNoffset) NoDbgRegParms;
static sqInt genInnerPrimitiveAt(sqInt retNoffset) NoDbgRegParms;
static sqInt genInnerPrimitiveIdentityHash(sqInt retNoffset) NoDbgRegParms;
static sqInt genInnerPrimitiveNewWithArg(sqInt retNoffset) NoDbgRegParms;
static sqInt genInnerPrimitiveNew(sqInt retNoffset) NoDbgRegParms;
static sqInt genInnerPrimitiveStringAtPut(sqInt retNoffset) NoDbgRegParms;
static sqInt genInnerPrimitiveStringAt(sqInt retNoffset) NoDbgRegParms;
static AbstractInstruction * genJumpNotSmallIntegerInScratchReg(sqInt aRegister) NoDbgRegParms;
static AbstractInstruction * genJumpNotSmallInteger(sqInt aRegister) NoDbgRegParms;
static AbstractInstruction * genJumpSmallInteger(sqInt aRegister) NoDbgRegParms;
static sqInt genNewArrayOfSizeinitialized(sqInt size, sqInt initialized) NoDbgRegParms;
static sqInt genNoPopCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(sqInt bcpc, sqInt numArgs, sqInt numCopied, sqInt ctxtNumArgs, sqInt isLargeCtxt, sqInt isInBlock) NoDbgRegParms;
static sqInt genRemoveSmallIntegerTagsInScratchReg(sqInt scratchReg) NoDbgRegParms;
static sqInt genSetSmallIntegerTagsIn(sqInt scratchReg) NoDbgRegParms;
static sqInt genShiftAwaySmallIntegerTagsInScratchReg(sqInt scratchReg) NoDbgRegParms;
static sqInt inlineCacheTagForInstance(sqInt oop) NoDbgRegParms;
static AbstractInstruction * jumpNotSmallIntegerUnsignedValueInRegister(sqInt reg) NoDbgRegParms;
static sqInt log2BytesPerWord(void);
static sqInt numCharacterBits(void);
static sqInt numSmallIntegerBits(void);
static sqInt numSmallIntegerTagBits(void);
static sqInt validInlineCacheTag(usqInt classIndexOrTagPattern) NoDbgRegParms;
static sqInt allYoungObjectsAgeInFullGC(void);
static sqInt cacheTagIsMarked(sqInt cacheTag) NoDbgRegParms;
static sqInt checkValidOopReference(sqInt anOop) NoDbgRegParms;
static sqInt couldBeObject(sqInt literal) NoDbgRegParms;
static sqInt createsClosuresInline(void);
static sqInt genActiveContextTrampolineLargeinBlockcalled(sqInt isLarge, sqInt isInBlock, char *aString) NoDbgRegParms;
static AbstractInstruction * genAllocFloatValueintoscratchRegscratchReg(sqInt dpreg, sqInt resultReg, sqInt scratch1, sqInt scratch2) NoDbgRegParms;
static sqInt genConvertCharacterToCodeInReg(sqInt reg) NoDbgRegParms;
static sqInt genConvertIntegerToCharacterInReg(sqInt reg) NoDbgRegParms;
static sqInt genEnsureObjInRegNotForwardedscratchReg(sqInt reg, sqInt scratch) NoDbgRegParms;
static sqInt genEnsureOopInRegNotForwardedscratchReg(sqInt reg, sqInt scratch) NoDbgRegParms;
static sqInt genEnsureOopInRegNotForwardedscratchRegjumpBackTo(sqInt reg, sqInt scratch, AbstractInstruction *instruction) NoDbgRegParms;
static sqInt genEnsureOopInRegNotForwardedscratchRegupdatingSlotin(sqInt reg, sqInt scratch, sqInt index, sqInt objReg) NoDbgRegParms;
static void generateObjectRepresentationTrampolines(void);
static sqInt genGetActiveContextNumArgslargeinBlock(sqInt numArgs, sqInt isLargeContext, sqInt isInBlock) NoDbgRegParms;
static sqInt genGetBitsofFormatByteOfintobaseHeaderIntoScratch(sqInt mask, sqInt sourceReg, sqInt destReg, sqInt scratchReg) NoDbgRegParms;
static sqInt genGetClassIndexOfNonImminto(sqInt sourceReg, sqInt destReg) NoDbgRegParms;
static sqInt genGetClassObjectOfClassIndexintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg) NoDbgRegParms;
static sqInt genGetClassObjectOfintoscratchReginstRegIsReceiver(sqInt instReg, sqInt destReg, sqInt scratchReg, sqInt instRegIsReceiver) NoDbgRegParms;
static sqInt genGetCompactClassIndexNonImmOfinto(sqInt instReg, sqInt destReg) NoDbgRegParms;
static sqInt genGetDoubleValueOfinto(sqInt srcReg, sqInt destFPReg) NoDbgRegParms;
static sqInt genGetFormatOfinto(sqInt srcReg, sqInt destReg) NoDbgRegParms;
static sqInt genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(sqInt sourceReg, sqInt destReg, sqInt scratchRegOrNil) NoDbgRegParms;
static sqInt genGetRawSlotSizeOfNonImminto(sqInt sourceReg, sqInt destReg) NoDbgRegParms;
static sqInt genInnerPrimitiveAsCharacterinReg(sqInt retNOffset, sqInt reg) NoDbgRegParms;
static sqInt genInnerPrimitiveCharacterValue(sqInt retNOffset) NoDbgRegParms;
static sqInt genInnerPrimitiveIdenticalorNotIf(sqInt retNoffset, sqInt orNot) NoDbgRegParms;
static sqInt genInnerPrimitiveSize(sqInt retNoffset) NoDbgRegParms;
static AbstractInstruction * genJumpImmediate(sqInt aRegister) NoDbgRegParms;
static AbstractInstruction * genJumpNotCharacterInScratchReg(sqInt reg) NoDbgRegParms;
static sqInt genStoreCheckContextReceiverTrampoline(void);
static sqInt genStoreCheckReceiverRegvalueRegscratchReginFrame(sqInt destReg, sqInt valueReg, sqInt scratchReg, sqInt inFrame) NoDbgRegParms;
static sqInt genStoreImmediateInSourceRegslotIndexdestReg(sqInt sourceReg, sqInt index, sqInt destReg) NoDbgRegParms;
static sqInt genStoreSourceRegslotIndexdestRegscratchReginFrame(sqInt sourceReg, sqInt index, sqInt destReg, sqInt scratchReg, sqInt inFrame) NoDbgRegParms;
static sqInt genStoreSourceRegslotIndexintoNewObjectInDestReg(sqInt sourceReg, sqInt index, sqInt destReg) NoDbgRegParms;
static sqInt getActiveContextAllocatesInMachineCode(void);
static sqInt hasSpurMemoryManagerAPI(void);
static sqInt inlineCacheTagIsYoung(sqInt cacheTag) NoDbgRegParms;
static sqInt isSmallIntegerTagNonZero(void);
static AbstractInstruction * jumpNotCharacterUnsignedValueInRegister(sqInt reg) NoDbgRegParms;
static sqInt markAndTraceCacheTagLiteralinatpc(sqInt literal, CogMethod *cogMethodOrNil, usqInt address) NoDbgRegParms;
static sqInt markAndTraceLiteralinatpc(sqInt literal, CogMethod *cogMethodOrNil, usqInt address) NoDbgRegParms;
static void markAndTraceLiteralinat(sqInt literal, CogMethod *cogMethod, sqInt *address) NoDbgRegParms;
static void markAndTraceUpdatedLiteralin(sqInt objOop, CogMethod *cogMethodOrNil) NoDbgRegParms;
static sqInt maybeCompileRetryonPrimitiveFail(AbstractInstruction *retryInst, sqInt primIndex) NoDbgRegParms;
extern sqInt numRegArgs(void);
static sqInt remapObject(sqInt objOop) NoDbgRegParms;
static sqInt remapOop(sqInt objOop) NoDbgRegParms;
static sqInt shouldAnnotateObjectReference(sqInt anOop) NoDbgRegParms;
static sqInt slotOffsetOfInstVarIndex(sqInt index) NoDbgRegParms;
static sqInt smallIntegerIsOnlyImmediateType(void);
static AbstractInstruction * concretizeLiteral(AbstractInstruction * self_in_concretizeLiteral) NoDbgRegParms;
static sqInt inlineCacheTagAt(AbstractInstruction * self_in_inlineCacheTagAt, sqInt followingAddress) NoDbgRegParms;
static sqInt isPCDependent(AbstractInstruction * self_in_isPCDependent) NoDbgRegParms;
static usqInt isSharable(AbstractInstruction * self_in_isSharable) NoDbgRegParms;
static sqInt literalLoadInstructionBytes(AbstractInstruction * self_in_literalLoadInstructionBytes) NoDbgRegParms;
static sqInt outOfLineLiteralOpcodeLimit(AbstractInstruction * self_in_outOfLineLiteralOpcodeLimit) NoDbgRegParms;
static sqInt pcRelativeAddressAt(AbstractInstruction * self_in_pcRelativeAddressAt, sqInt instrAddress) NoDbgRegParms;
static AbstractInstruction * relocateMethodReferenceBeforeAddressby(AbstractInstruction * self_in_relocateMethodReferenceBeforeAddressby, sqInt pc, sqInt delta) NoDbgRegParms;
static sqInt rewriteFullTransferAttargetexpectedInstruction(AbstractInstruction * self_in_rewriteFullTransferAttargetexpectedInstruction, usqInt callSiteReturnAddress, usqInt callTargetAddress, sqInt expectedInstruction) NoDbgRegParms;
static sqInt rewriteInlineCacheAttagtarget(AbstractInstruction * self_in_rewriteInlineCacheAttagtarget, usqInt callSiteReturnAddress, sqInt cacheTag, usqInt callTargetAddress) NoDbgRegParms;
static AbstractInstruction * rewriteInlineCacheTagat(AbstractInstruction * self_in_rewriteInlineCacheTagat, sqInt cacheTag, sqInt callSiteReturnAddress) NoDbgRegParms;
static usqInt sizePCDependentInstructionAt(AbstractInstruction * self_in_sizePCDependentInstructionAt, sqInt eventualAbsoluteAddress) NoDbgRegParms;
static AbstractInstruction * storeLiteralbeforeFollowingAddress(AbstractInstruction * self_in_storeLiteralbeforeFollowingAddress, sqInt literal, sqInt followingAddress) NoDbgRegParms;
static AbstractInstruction * updateLabel(AbstractInstruction * self_in_updateLabel, AbstractInstruction *labelInstruction) NoDbgRegParms;
static sqInt usesOutOfLineLiteral(AbstractInstruction * self_in_usesOutOfLineLiteral) NoDbgRegParms;
static CogSimStackEntry * ensureSpilledAtfrom(CogSimStackEntry * self_in_ensureSpilledAtfrom, sqInt baseOffset, sqInt baseRegister) NoDbgRegParms;
static CogSimStackEntry * mergeAtfrom(CogSimStackEntry * self_in_mergeAtfrom, sqInt baseOffset, sqInt baseRegister) NoDbgRegParms;
static CogSimStackEntry * popToReg(CogSimStackEntry * self_in_popToReg, sqInt reg) NoDbgRegParms;
static sqInt registerMask(CogSimStackEntry * self_in_registerMask) NoDbgRegParms;
static sqInt registerOrNil(CogSimStackEntry * self_in_registerOrNil) NoDbgRegParms;
static CogSimStackEntry * storeToReg(CogSimStackEntry * self_in_storeToReg, sqInt reg) NoDbgRegParms;
static AbstractInstruction * allocateLiteral(sqInt aLiteral) NoDbgRegParms;
static AbstractInstruction * checkLiteralforInstruction(sqInt literal, AbstractInstruction *anInstruction) NoDbgRegParms;
static AbstractInstruction * checkQuickConstantforInstruction(sqInt literal, AbstractInstruction *anInstruction) NoDbgRegParms;
static sqInt classRefInClosedPICAt(sqInt address) NoDbgRegParms;
static sqInt dumpLiterals(sqInt generateBranchAround) NoDbgRegParms;
static sqInt literalInstructionInRange(AbstractInstruction *litInst) NoDbgRegParms;
static AbstractInstruction * locateLiteral(sqInt aLiteral) NoDbgRegParms;
static sqInt mustDumpLiterals(sqInt currentOpcodeIndex) NoDbgRegParms;
static sqInt objRefInClosedPICAt(sqInt address) NoDbgRegParms;
static sqInt resetForBlockCompile(void);
static sqInt saveForBlockCompile(void);
static sqInt compileBlockDispatch(void);
static sqInt compileFallbackToInterpreterPrimitive(void);
static void compileGetErrorCode(void);
static sqInt compileInterpreterPrimitive(void (*primitiveRoutine)(void)) NoDbgRegParms;
static sqInt extendedPushBytecode(void);
static sqInt extendedStoreAndPopBytecode(void);
static sqInt extendedStoreBytecode(void);
static sqInt frameOffsetOfTemporary(sqInt index) NoDbgRegParms;
static sqInt genBlockReturn(void);
static AbstractInstruction * genDoubleFailIfZeroArgRcvrarg(sqInt rcvrReg, sqInt argReg) NoDbgRegParms;
static sqInt genExtendedSendBytecode(void);
static sqInt genExtendedSuperBytecode(void);
static sqInt genFastPrimFail(void);
static void genFastPrimTraceUsingand(sqInt r1, sqInt r2) NoDbgRegParms;
static sqInt genLongJumpIfFalse(void);
static sqInt genLongJumpIfTrue(void);
static sqInt genLongStoreAndPopTemporaryVariableBytecode(void);
static sqInt genLongUnconditionalBackwardJump(void);
static sqInt genLongUnconditionalForwardJump(void);
static AbstractInstruction * genMoveFalseR(sqInt reg) NoDbgRegParms;
static AbstractInstruction * genMoveTrueR(sqInt reg) NoDbgRegParms;
static sqInt genMustBeBooleanTrampolineForcalled(sqInt boolean, char *trampolineName) NoDbgRegParms;
static sqInt genPrimitiveEqual(void);
static sqInt genPrimitiveFloatAdd(void);
static sqInt genPrimitiveFloatDivide(void);
static sqInt genPrimitiveFloatEqual(void);
static sqInt genPrimitiveFloatGreaterOrEqual(void);
static sqInt genPrimitiveFloatGreaterThan(void);
static sqInt genPrimitiveFloatLessOrEqual(void);
static sqInt genPrimitiveFloatLessThan(void);
static sqInt genPrimitiveFloatMultiply(void);
static sqInt genPrimitiveFloatNotEqual(void);
static sqInt genPrimitiveFloatSubtract(void);
static sqInt genPrimitiveGreaterOrEqual(void);
static sqInt genPrimitiveGreaterThan(void);
static sqInt genPrimitiveLessOrEqual(void);
static sqInt genPrimitiveLessThan(void);
static sqInt genPrimitiveNotEqual(void);
static void genPrimReturnEnterCogCodeEnilopmart(sqInt profiling) NoDbgRegParms;
static sqInt genPushClosureTempsBytecode(void);
static sqInt genPushConstantFalseBytecode(void);
static sqInt genPushConstantNilBytecode(void);
static sqInt genPushConstantTrueBytecode(void);
static sqInt genPushLiteralConstantBytecode(void);
static sqInt genPushLiteralIndex(sqInt literalIndex) NoDbgRegParms;
static sqInt genPushLiteralVariableBytecode(void);
static sqInt genPushQuickIntegerConstantBytecode(void);
static sqInt genPushReceiverVariableBytecode(void);
static sqInt genPushTemporaryVariableBytecode(void);
extern sqInt genQuickReturnConst(void);
extern sqInt genQuickReturnInstVar(void);
extern sqInt genQuickReturnSelf(void);
static sqInt genReturnFalse(void);
static sqInt genReturnNil(void);
static sqInt genReturnTrue(void);
static sqInt genSecondExtendedSendBytecode(void);
static sqInt genSendLiteralSelector0ArgsBytecode(void);
static sqInt genSendLiteralSelector1ArgBytecode(void);
static sqInt genSendLiteralSelector2ArgsBytecode(void);
static sqInt genShortJumpIfFalse(void);
static sqInt genShortUnconditionalJump(void);
static sqInt genSpecialSelectorSend(void);
static sqInt genStoreAndPopReceiverVariableBytecode(void);
static sqInt genStoreAndPopRemoteTempLongBytecode(void);
static sqInt genStoreAndPopTemporaryVariableBytecode(void);
static sqInt genStoreRemoteTempLongBytecode(void);
static void maybeCompileAllocFillerCheck(void);
extern void recordCallOffsetIn(CogMethod *cogMethod);
static sqInt registerisInMask(sqInt reg, sqInt mask) NoDbgRegParms;
static sqInt returnRegForStoreCheck(void);
extern void rewritePrimInvocationInto(CogMethod *cogMethod, void (*primFunctionPointer)(void));
static sqInt v3BlockCodeSize(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj) NoDbgRegParms;
static sqInt v3LongForwardBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj) NoDbgRegParms;
static sqInt v3LongBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj) NoDbgRegParms;
static sqInt v3ShortForwardBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj) NoDbgRegParms;
extern void voidCogCompiledCode(void);
static BlockStart * addBlockStartAtnumArgsnumCopiedspan(sqInt bytecodepc, sqInt numArgs, sqInt numCopied, sqInt span) NoDbgRegParms;
static sqInt allocateRegForStackEntryAtnotConflictingWith(sqInt index, sqInt regMask) NoDbgRegParms;
static sqInt allocateRegNotConflictingWith(sqInt regMask) NoDbgRegParms;
static void annotateBytecodeIfAnnotated(CogSimStackEntry *aSimStackEntry) NoDbgRegParms;
static sqInt anyReferencesToRegisterinTopNItems(sqInt reg, sqInt n) NoDbgRegParms;
extern void callCogCodePopReceiverArg0Regs(void);
extern void callCogCodePopReceiverArg1Arg0Regs(void);
static sqInt compileAbstractInstructionsFromthrough(sqInt start, sqInt end) NoDbgRegParms;
static sqInt compileBlockBodies(void);
static void compileBlockFrameBuild(BlockStart *blockStart) NoDbgRegParms;
static void compileBlockFramelessEntry(BlockStart *blockStart) NoDbgRegParms;
static CogMethod * compileCogMethod(sqInt selector) NoDbgRegParms;
static sqInt compileEntireMethod(void);
static sqInt compileFrameBuild(void);
static void compileOpenPICnumArgs(sqInt selector, sqInt numArgs) NoDbgRegParms;
static sqInt cPICMissTrampolineFor(sqInt numArgs) NoDbgRegParms;
static sqInt doubleExtendedDoAnythingBytecode(void);
static sqInt duplicateTopBytecode(void);
static BytecodeFixup * ensureFixupAt(sqInt targetIndex) NoDbgRegParms;
static BytecodeFixup * ensureNonMergeFixupAt(sqInt targetIndex) NoDbgRegParms;
static void ensureReceiverResultRegContainsSelf(void);
static void evaluateat(BytecodeDescriptor *descriptor, sqInt pc) NoDbgRegParms;
static sqInt freeAnyRegNotConflictingWith(sqInt regMask) NoDbgRegParms;
static sqInt genBinaryConstOpVarInlinePrimitive(sqInt prim) NoDbgRegParms;
static sqInt genBinaryInlineComparisonopFalsedestReg(sqInt opTrue, sqInt opFalse, sqInt destReg) NoDbgRegParms;
static sqInt genBinaryVarOpConstInlinePrimitive(sqInt prim) NoDbgRegParms;
static sqInt genBinaryVarOpVarInlinePrimitive(sqInt prim) NoDbgRegParms;
static void (*genCallPICEnilopmartNumArgs(sqInt numArgs))(void)  NoDbgRegParms;
static sqInt genCallPrimitiveBytecode(void);
static sqInt genDoubleArithmeticpreOpCheck(sqInt arithmeticOperator, AbstractInstruction *(*preOpCheckOrNil)(int rcvrReg, int argReg)) NoDbgRegParms;
static sqInt genDoubleComparisoninvert(AbstractInstruction *(*jumpOpcodeGenerator)(void *), sqInt invertComparison) NoDbgRegParms;
static sqInt genEqualsEqualsNoBranchArgIsConstantrcvrIsConstantargRegrcvrReg(sqInt argIsConstant, sqInt rcvrIsConstant, sqInt argReg, sqInt rcvrReg) NoDbgRegParms;
static sqInt genExternalizePointersForPrimitiveCall(void);
static void generateEnilopmarts(void);
static void generateMissAbortTrampolines(void);
static void generateSendTrampolines(void);
static void generateTracingTrampolines(void);
static sqInt genJumpBackTo(sqInt targetBytecodePC) NoDbgRegParms;
static sqInt genJumpIfto(sqInt boolean, sqInt targetBytecodePC) NoDbgRegParms;
static sqInt genJumpTo(sqInt targetBytecodePC) NoDbgRegParms;
static sqInt genMarshalledSendnumArgssendTable(sqInt selector, sqInt numArgs, sqInt *sendTable) NoDbgRegParms;
static sqInt genMethodAbortTrampolineFor(sqInt numArgs) NoDbgRegParms;
static sqInt genNullaryInlinePrimitive(sqInt prim) NoDbgRegParms;
static sqInt genPICAbortTrampolineFor(sqInt numArgs) NoDbgRegParms;
static sqInt genPICMissTrampolineFor(sqInt numArgs) NoDbgRegParms;
static sqInt genPopStackBytecode(void);
static sqInt genPrimitiveAdd(void);
static sqInt genPrimitiveAsCharacter(void);
static sqInt genPrimitiveAsFloat(void);
static sqInt genPrimitiveAt(void);
static sqInt genPrimitiveAtPut(void);
static sqInt genPrimitiveBitAnd(void);
static sqInt genPrimitiveBitOr(void);
static sqInt genPrimitiveBitShift(void);
static sqInt genPrimitiveBitXor(void);
static sqInt genPrimitiveCharacterValue(void);
static sqInt genPrimitiveClass(void);
static sqInt genPrimitiveClosureValue(void);
static sqInt genPrimitiveDiv(void);
static sqInt genPrimitiveDivide(void);
static sqInt genPrimitiveFloatSquareRoot(void);
static sqInt genPrimitiveIdentical(void);
static sqInt genPrimitiveIdentityHash(void);
static sqInt genPrimitiveMod(void);
static sqInt genPrimitiveMultiply(void);
static sqInt genPrimitiveNew(void);
static sqInt genPrimitiveNewMethod(void);
static sqInt genPrimitiveNewWithArg(void);
static sqInt genPrimitiveNotIdentical(void);
static sqInt genPrimitiveQuo(void);
static sqInt genPrimitiveSize(void);
static sqInt genPrimitiveStringAt(void);
static sqInt genPrimitiveStringAtPut(void);
static sqInt genPrimitiveSubtract(void);
static sqInt genPushActiveContextBytecode(void);
static sqInt genPushClosureCopyCopiedValuesBytecode(void);
static sqInt genPushLiteralVariable(sqInt literalIndex) NoDbgRegParms;
static sqInt genPushLiteral(sqInt literal) NoDbgRegParms;
static sqInt genPushMaybeContextReceiverVariable(sqInt slotIndex) NoDbgRegParms;
static sqInt genPushNewArrayBytecode(void);
static sqInt genPushReceiverBytecode(void);
static sqInt genPushReceiverVariable(sqInt index) NoDbgRegParms;
static void genPushRegisterArgs(void);
static sqInt genPushRemoteTempLongBytecode(void);
static sqInt genPushTemporaryVariable(sqInt index) NoDbgRegParms;
static sqInt genReturnReceiver(void);
static sqInt genReturnTopFromBlock(void);
static sqInt genReturnTopFromMethod(void);
static sqInt genSendSupernumArgs(sqInt selector, sqInt numArgs) NoDbgRegParms;
static sqInt genSendTrampolineFornumArgscalledargargargarg(void *aRoutine, sqInt numArgs, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3) NoDbgRegParms;
static sqInt genSendnumArgs(sqInt selector, sqInt numArgs) NoDbgRegParms;
static sqInt genSmallIntegerComparison(sqInt jumpOpcode) NoDbgRegParms;
static sqInt genSmallIntegerComparisonorDoubleComparison(sqInt jumpOpcode, AbstractInstruction *(*jumpFPOpcodeGenerator)(void *)) NoDbgRegParms;
static sqInt genSpecialSelectorArithmetic(void);
static sqInt genSpecialSelectorClass(void);
static sqInt genSpecialSelectorComparison(void);
static sqInt genSpecialSelectorEqualsEquals(void);
static sqInt genSpecialSelectorEqualsEqualsWithForwarders(void);
static sqInt genStaticallyResolvedSpecialSelectorComparison(void);
static sqInt genStorePopLiteralVariable(sqInt popBoolean, sqInt litVarIndex) NoDbgRegParms;
static sqInt genStorePopMaybeContextReceiverVariable(sqInt popBoolean, sqInt slotIndex) NoDbgRegParms;
static sqInt genStorePopReceiverVariable(sqInt popBoolean, sqInt slotIndex) NoDbgRegParms;
static sqInt genStorePopRemoteTempAt(sqInt popBoolean, sqInt slotIndex, sqInt remoteTempIndex) NoDbgRegParms;
static sqInt genStorePopTemporaryVariable(sqInt popBoolean, sqInt tempIndex) NoDbgRegParms;
static sqInt genTrinaryInlinePrimitive(sqInt prim) NoDbgRegParms;
static sqInt genUnaryInlinePrimitive(sqInt prim) NoDbgRegParms;
static sqInt genUpArrowReturn(void);
static BytecodeFixup * initializeFixupAt(sqInt targetIndex) NoDbgRegParms;
static void initSimStackForFramefulMethod(sqInt startpc) NoDbgRegParms;
static void initSimStackForFramelessBlock(sqInt startpc) NoDbgRegParms;
static void initSimStackForFramelessMethod(sqInt startpc) NoDbgRegParms;
static sqInt liveRegisters(void);
static void marshallSendArguments(sqInt numArgs) NoDbgRegParms;
static void mergeafterContinuation(BytecodeFixup *fixup, sqInt mergeWithContinuation) NoDbgRegParms;
static sqInt methodAbortTrampolineFor(sqInt numArgs) NoDbgRegParms;
static sqInt needsFrameIfMod16GENumArgs(sqInt stackDelta) NoDbgRegParms;
static sqInt needsFrameIfStackGreaterThanOne(sqInt stackDelta) NoDbgRegParms;
static sqInt numberOfSpillsInTopNItems(sqInt n) NoDbgRegParms;
static sqInt picAbortTrampolineFor(sqInt numArgs) NoDbgRegParms;
static sqInt prevInstIsPCAnnotated(void);
static sqInt pushNilSizenumInitialNils(sqInt aMethodObj, sqInt numInitialNils) NoDbgRegParms;
static void reinitializeFixupsFromthrough(sqInt start, sqInt end) NoDbgRegParms;
static void scanBlock(BlockStart *blockStart) NoDbgRegParms;
static sqInt scanMethod(void);
static void ssAllocateCallReg(sqInt requiredReg) NoDbgRegParms;
static void ssAllocateCallRegand(sqInt requiredReg1, sqInt requiredReg2) NoDbgRegParms;
static void ssAllocateCallRegandand(sqInt requiredReg1, sqInt requiredReg2, sqInt requiredReg3) NoDbgRegParms;
static void ssAllocateRequiredRegMaskupThrough(sqInt requiredRegsMask, sqInt stackPtr) NoDbgRegParms;
static void ssAllocateRequiredReg(sqInt requiredReg) NoDbgRegParms;
static void ssAllocateRequiredRegand(sqInt requiredReg1, sqInt requiredReg2) NoDbgRegParms;
static void ssAllocateRequiredRegupThrough(sqInt requiredReg, sqInt stackPtr) NoDbgRegParms;
static void ssFlushTo(sqInt index) NoDbgRegParms;
static void ssFlushUpThroughReceiverVariable(sqInt slotIndex) NoDbgRegParms;
static void ssFlushUpThroughTemporaryVariable(sqInt tempIndex) NoDbgRegParms;
static void ssPop(sqInt n) NoDbgRegParms;
static sqInt ssPushAnnotatedConstant(sqInt literal) NoDbgRegParms;
static sqInt ssPushBaseoffset(sqInt reg, sqInt offset) NoDbgRegParms;
static sqInt ssPushConstant(sqInt literal) NoDbgRegParms;
static sqInt ssPushDesc(CogSimStackEntry simStackEntry) NoDbgRegParms;
static sqInt ssPushRegister(sqInt reg) NoDbgRegParms;
static void ssPush(sqInt n) NoDbgRegParms;
static sqInt ssStorePoptoPreferredReg(sqInt popBoolean, sqInt preferredReg) NoDbgRegParms;
static void ssStorePoptoReg(sqInt popBoolean, sqInt reg) NoDbgRegParms;
static CogSimStackEntry * ssTop(void);
static CogSimStackEntry ssTopDescriptor(void);
static CogSimStackEntry * ssValue(sqInt n) NoDbgRegParms;
static sqInt tryCollapseTempVectorInitializationOfSize(sqInt slots) NoDbgRegParms;
static void updateSimSpillBase(void);
static sqInt v3PushNilSizenumInitialNils(sqInt aMethodObj, sqInt numInitialNils) NoDbgRegParms;
static sqInt v3NumPushNils(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj) NoDbgRegParms;


/*** Variables ***/
static AbstractInstruction * abstractOpcodes;
static AbstractInstruction aMethodLabel;
static AbstractInstruction * const backEnd = &aMethodLabel;
static usqInt baseAddress;
static sqInt blockCount;
static AbstractInstruction * blockEntryLabel;
static AbstractInstruction * blockEntryNoContextSwitch;
sqInt blockNoContextSwitchOffset;
static BlockStart * blockStarts;
static sqInt breakBlock;
static sqInt breakMethod;
sqInt breakPC;
static sqInt byte0;
static sqInt byte1;
static sqInt byte2;
static sqInt byte3;
static sqInt bytecodePC;
static sqInt bytecodeSetOffset;
void * CFramePointer;
void * CStackPointer;
static sqInt callerSavedRegMask;
sqInt ceBaseFrameReturnTrampoline;
void (*ceCall0ArgsPIC)(void);
void (*ceCall1ArgsPIC)(void);
void (*ceCall2ArgsPIC)(void);
void (*ceCallCogCodePopReceiverAndClassRegs)(void);
void (*ceCallCogCodePopReceiverArg0Regs)(void);
void (*ceCallCogCodePopReceiverArg1Arg0Regs)(void);
void (*ceCallCogCodePopReceiverReg)(void);
sqInt ceCannotResumeTrampoline;
void (*ceCaptureCStackPointers)(void);
static unsigned long (*ceCheckFeaturesFunction)(void);
sqInt ceCheckForInterruptTrampoline;
static sqInt ceCPICMissTrampoline;
void (*ceEnterCogCodePopReceiverReg)(void);
static sqInt ceFetchContextInstVarTrampoline;
unsigned long (*ceGetSP)(void);
static sqInt ceLargeActiveContextInBlockTrampoline;
static sqInt ceLargeActiveContextInMethodTrampoline;
static sqInt ceMethodAbortTrampoline;
static sqInt ceNonLocalReturnTrampoline;
static sqInt cePICAbortTrampoline;
static sqInt cePrimReturnEnterCogCode;
static sqInt cePrimReturnEnterCogCodeProfiling;
sqInt ceReturnToInterpreterTrampoline;
static sqInt ceScheduleScavengeTrampoline;
static sqInt ceSendMustBeBooleanAddFalseTrampoline;
static sqInt ceSendMustBeBooleanAddTrueTrampoline;
static sqInt ceSmallActiveContextInBlockTrampoline;
static sqInt ceSmallActiveContextInMethodTrampoline;
static sqInt ceStoreCheckContextReceiverTrampoline;
static sqInt ceStoreCheckTrampoline;
static sqInt ceStoreContextInstVarTrampoline;
static sqInt ceTraceBlockActivationTrampoline;
static sqInt ceTraceLinkedSendTrampoline;
static sqInt ceTraceStoreTrampoline;
unsigned long (*ceTryLockVMOwner)(void);
void (*ceUnlockVMOwner)(void);
sqInt cFramePointerInUse;
static sqInt checkedEntryAlignment;
static sqInt closedPICSize;
sqInt cmEntryOffset;
sqInt cmNoCheckEntryOffset;
static sqInt codeBase;
static sqInt codeModified;
static sqInt compilationTrace;
static sqInt cPICCaseSize;
static sqInt cPICEndSize;
static sqInt deadCode;
static sqInt debugFixupBreaks;
unsigned long debugPrimCallStackOffset;
static sqInt directedSuperSendTrampolines[NumSendTrampolines];
static AbstractInstruction * endCPICCase0;
static AbstractInstruction * endCPICCase1;
static sqInt endPC;
static AbstractInstruction * entry;
static sqInt entryPointMask;
static sqInt expectedFPAlignment;
static sqInt expectedSPAlignment;
static sqInt extA;
static sqInt extB;
static sqInt externalPrimCallOffsets[MaxNumArgs + 1];
static sqInt externalPrimJumpOffsets[MaxNumArgs + 1];
static sqInt externalSetPrimOffsets[MaxNumArgs + 1];
static sqInt firstCPICCaseOffset;
static sqInt firstOpcodeIndex;
static sqInt firstSend;
static BytecodeFixup * fixups;
static BytecodeDescriptor generatorTable[256] = {
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushConstantTrueBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushConstantFalseBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushConstantNilBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushQuickIntegerConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushQuickIntegerConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushQuickIntegerConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushQuickIntegerConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genReturnReceiver, 0, needsFrameIfInBlock, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0 },
	{ genReturnTrue, 0, needsFrameIfInBlock, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0 },
	{ genReturnFalse, 0, needsFrameIfInBlock, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0 },
	{ genReturnNil, 0, needsFrameIfInBlock, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0 },
	{ genReturnTopFromMethod, 0, needsFrameIfInBlock, -1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0 },
	{ genReturnTopFromBlock, 0, needsFrameNever, -1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0 },
	{ unknownBytecode, 0, 0, 0, Nop, 1, 0, 0, 0, 0, 0, 0, 1, 0 },
	{ unknownBytecode, 0, 0, 0, Nop, 1, 0, 0, 0, 0, 0, 0, 1, 0 },
	{ extendedPushBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ extendedStoreBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ extendedStoreAndPopBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genExtendedSendBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ doubleExtendedDoAnythingBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genExtendedSuperBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1 },
	{ genSecondExtendedSendBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genPopStackBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ duplicateTopBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushActiveContextBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushNewArrayBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genCallPrimitiveBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushRemoteTempLongBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreRemoteTempLongBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopRemoteTempLongBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushClosureCopyCopiedValuesBytecode, v3BlockCodeSize, 0, 0, 0, 4, 0, 0, 0, 1, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genLongUnconditionalBackwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongUnconditionalBackwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongUnconditionalBackwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongUnconditionalBackwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongUnconditionalForwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genLongUnconditionalForwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genLongUnconditionalForwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genLongUnconditionalForwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genLongJumpIfTrue, v3LongForwardBranchDistance, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfTrue, v3LongForwardBranchDistance, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfTrue, v3LongForwardBranchDistance, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfTrue, v3LongForwardBranchDistance, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfFalse, v3LongForwardBranchDistance, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfFalse, v3LongForwardBranchDistance, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfFalse, v3LongForwardBranchDistance, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfFalse, v3LongForwardBranchDistance, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorArithmetic, 0, 0, 0, AddRR, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorArithmetic, 0, 0, 0, SubRR, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpLess, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpGreater, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpLessOrEqual, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpGreaterOrEqual, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpZero, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpNonZero, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorArithmetic, 0, 0, 0, AndRR, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorArithmetic, 0, 0, 0, OrRR, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorEqualsEquals, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genSpecialSelectorClass, 0, needsFrameIfStackGreaterThanOne, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 }
};
static sqInt guardPageSize;
static sqInt hasYoungReferent;
static sqInt inBlock;
static sqInt initialPC;
static int labelCounter;
static sqInt lastDumpedLiteralIndex;
static sqInt lastSend;
static usqInt limitAddress;
static AbstractInstruction * literals;
static sqInt literalsSize;
static sqInt maxLitIndex;
static sqInt methodAbortTrampolines[4];
static sqInt methodBytesFreedSinceLastCompaction;
static sqInt methodCount;
static AbstractInstruction * const methodLabel = &aMethodLabel;
static sqInt methodObj;
static sqInt methodOrBlockNumArgs;
static sqInt methodOrBlockNumTemps;
static sqInt methodZoneBase;
static unsigned long minValidCallAddress;
sqInt missOffset;
static usqInt mzFreeStart;
static sqInt needsFrame;
static sqInt nextLiteralIndex;
static AbstractInstruction * noCheckEntry;
static sqInt numAbstractOpcodes;
static sqInt numPICCases;
static usqInt objectReferencesInRuntime[NumObjRefsInRuntime];
static sqInt opcodeIndex;
static CogMethod *openPICList = 0;
static sqInt openPICSize;
static CogSSOptStatus optStatus;
static sqInt ordinarySendTrampolines[NumSendTrampolines];
static sqInt picAbortTrampolines[4];
static AbstractInstruction * picInterpretAbort;
static sqInt picMissTrampolines[4];
static AbstractInstruction * picMNUAbort;
static void (*postCompileHook)(CogMethod *);
static BytecodeDescriptor * prevBCDescriptor;
static AbstractInstruction * primInvokeLabel;
static sqInt primitiveIndex;
static AbstractInstruction * primSetFunctionLabel;
void (*realCECallCogCodePopReceiverAndClassRegs)(void);
void (*realCECallCogCodePopReceiverArg0Regs)(void);
void (*realCECallCogCodePopReceiverArg1Arg0Regs)(void);
void (*realCECallCogCodePopReceiverReg)(void);
void (*realCEEnterCogCodePopReceiverReg)(void);
static sqInt regArgsHaveBeenPushed;
static sqInt runtimeObjectRefIndex;
static sqInt savedFirstOpcodeIndex;
static sqInt savedLastDumpedLiteralIndex;
static sqInt savedNextLiteralIndex;
static AbstractInstruction * sendMiss;
static CogSimStackEntry simSelf;
static sqInt simSpillBase;
static CogSimStackEntry simStack[77];
static sqInt simStackPtr;
static AbstractInstruction * stackCheckLabel;
static AbstractInstruction * stackOverflowCall;
static sqInt superSendTrampolines[NumSendTrampolines];
int traceFlags = 8 /* prim trace log on by default */;
sqInt traceStores;
static char *trampolineAddresses[NumTrampolines*2];
static sqInt trampolineTableIndex;
static sqInt uncheckedEntryAlignment;
static usqInt unpairedMethodList;
static usqInt youngReferrers;


/*** Macros ***/
#define flushICacheFromto(me,startAddress,endAddress) __clear_cache((char*) startAddress, (char*) (endAddress ))
#define numberOfSaveableRegisters(self) 0
#define cPICNumCases stackCheckOffset
#define cPICNumCasesHack hack hack hack i.e. the getter macro does all the work
#define abstractInstructionAt(index) (&abstractOpcodes[index])
#define allocateBlockStarts(numBlocks) do { \
		blockStarts = (numBlocks) ? alloca(sizeof(BlockStart) * (numBlocks)) : 0; \
} while (0)
#define backEnd() backEnd
#define blockAlignment(self) 8
#define blockStartAt(index) (&blockStarts[index])
#define breakOnImplicitReceiver() (traceFlags & 64)
#define callerSavedRegMask() callerSavedRegMask
#define ceBaseFrameReturnPC() ceBaseFrameReturnTrampoline
#define ceCannotResumePC() ((usqInt)ceCannotResumeTrampoline)
#define ceCheckFeatures() ceCheckFeaturesFunction()
#define ceReturnToInterpreterPC() ((usqInt)ceReturnToInterpreterTrampoline)
#define cFramePointerAddress() ((unsigned long)&CFramePointer)
#define compileSendTrace() (traceFlags & 2)
#define cr() putchar('\n')
#define cStackPointerAddress() ((unsigned long)&CStackPointer)
#define entryOffset() cmEntryOffset
#define generatorAt(index) (&generatorTable[index])
#define getCFramePointer() CFramePointer
#define getCStackPointer() CStackPointer
#define getIsObjectReference() IsObjectReference
#define halt() warning("halt")
#define haltmsg(msg) warning("halt: " msg)
#define interpretOffset() missOffset
#define methodLabel() methodLabel
#define methodZoneBase() methodZoneBase
#define minCallAddress() minValidCallAddress
#define noCheckEntryOffset() cmNoCheckEntryOffset
#define noContextSwitchBlockEntryOffset() blockNoContextSwitchOffset
#define notYetImplemented() warning("not yet implemented")
#define printNum(n) printf("%ld", (long) n)
#define printOnTrace() (traceFlags & 1)
#define print(aString) printf(aString)
#define recordBlockTrace() (traceFlags & 4)
#define recordEventTrace() (traceFlags & 16)
#define recordOverflowTrace() (traceFlags & 32)
#define recordPrimTrace() (traceFlags & 8)
#define recordSendTrace() (traceFlags & 2)
#define reportError(n) warning("compilation error")
#define setCFramePointer(theFP) (CFramePointer = (void *)(theFP))
#define setCStackPointer(theSP) (CStackPointer = (void *)(theSP))
#define tryLockVMOwner() (ceTryLockVMOwner() != 0)
#define unlockVMOwner() ceUnlockVMOwner()
#define nextOpenPIC methodObject
#define nextOpenPICHack hack hack hack i.e. the getter macro does all the work
#define freeStart() mzFreeStart
#define limitZony() ((CogMethod *)mzFreeStart)
#define methodBytesFreedSinceLastCompaction() methodBytesFreedSinceLastCompaction
#define roundUpLength(numBytes) ((numBytes) + 7 & -8)
#define youngReferrers() youngReferrers
#define maybeConstant(sse) ((sse)->constant)
#define literalInstructionAt(index) (&literals[index])
#define fixupAt(index) (&fixups[index])
#define simStackAt(index) (simStack + (index))
#define traceDescriptor(ign) 0
#define traceFixup(ign) 0
#define traceMerge(ign) 0
#define traceSimStack() 0
#define traceSpill(ign) 0
#define allocatype(numElements, elementType) alloca((numElements)*sizeof(elementType))
#define numElementsIn(anArray) (sizeof(anArray)/sizeof(anArray[0]))
#define oopisGreaterThanOrEqualTo(anOop,otherOop) ((usqInt)(anOop) >= (usqInt)(otherOop))
#define oopisGreaterThanOrEqualToandLessThanOrEqualTo(anOop,baseOop,limitOop) ((usqInt)(anOop) >= (usqInt)(baseOop) && (usqInt)(anOop) <= (usqInt)(limitOop))
#define oopisGreaterThanOrEqualToandLessThan(anOop,baseOop,limitOop) ((usqInt)(anOop) >= (usqInt)(baseOop) && (usqInt)(anOop) < (usqInt)(limitOop))
#define oopisGreaterThan(anOop,otherOop) ((usqInt)(anOop) > (usqInt)(otherOop))
#define oopisGreaterThanandLessThan(anOop,baseOop,limitOop) ((usqInt)(anOop) > (usqInt)(baseOop) && (usqInt)(anOop) < (usqInt)(limitOop))
#define oopisLessThanOrEqualTo(anOop,otherOop) ((usqInt)(anOop) <= (usqInt)(otherOop))
#define oopisLessThan(anOop,otherOop) ((usqInt)(anOop) < (usqInt)(otherOop))


	/* CogAbstractInstruction>>#addDependent: */
static AbstractInstruction *
addDependent(AbstractInstruction * self_in_addDependent, AbstractInstruction *anInstruction)
{
	if (((self_in_addDependent->dependent)) != null) {
		(anInstruction->dependent = (self_in_addDependent->dependent));
	}
	return ((self_in_addDependent->dependent) = anInstruction);
}


/*	Answer an unused abstract register in the liveRegMask.
	Subclasses with more registers can override to answer them. */

	/* CogAbstractInstruction>>#availableRegisterOrNilFor: */
static sqInt
availableRegisterOrNilFor(AbstractInstruction * self_in_availableRegisterOrNilFor, sqInt liveRegsMask)
{
	flag("searching physical registers that are not assigned to abstract registers first will do a better job and allocate with fewer conflicts");
	if (!(liveRegsMask & (registerMaskFor(Arg1Reg)))) {
		return Arg1Reg;
	}
	if (!(liveRegsMask & (registerMaskFor(Arg0Reg)))) {
		return Arg0Reg;
	}
	if (!(liveRegsMask & (registerMaskFor(SendNumArgsReg)))) {
		return SendNumArgsReg;
	}
	if (!(liveRegsMask & (registerMaskFor(ClassReg)))) {
		return ClassReg;
	}
	if (!(liveRegsMask & (registerMaskFor(ReceiverResultReg)))) {
		return ReceiverResultReg;
	}
	return null;
}


/*	For out-of-line literal support, clone a literal from a literal. */

	/* CogAbstractInstruction>>#cloneLiteralFrom: */
static AbstractInstruction *
cloneLiteralFrom(AbstractInstruction * self_in_cloneLiteralFrom, AbstractInstruction *existingLiteral)
{
	assert((((existingLiteral->opcode)) == Literal)
	 && ((((self_in_cloneLiteralFrom->dependent)) == null)
	 && (((self_in_cloneLiteralFrom->address)) == null)));
	(self_in_cloneLiteralFrom->opcode) = Literal;
	(self_in_cloneLiteralFrom->annotation) = (existingLiteral->annotation);
	((self_in_cloneLiteralFrom->operands))[0] = (((existingLiteral->operands))[0]);
	((self_in_cloneLiteralFrom->operands))[1] = (((existingLiteral->operands))[1]);
	((self_in_cloneLiteralFrom->operands))[2] = (((existingLiteral->operands))[2]);
	return self_in_cloneLiteralFrom;
}


/*	A dummy routine.
	Processors that can generate code to flush the icache can override. */

	/* CogAbstractInstruction>>#generateICacheFlush */
static AbstractInstruction *
generateICacheFlush(AbstractInstruction * self_in_generateICacheFlush)
{
	return self_in_generateICacheFlush;
}

	/* CogAbstractInstruction>>#genWriteCResultIntoReg: */
static AbstractInstruction *
genWriteCResultIntoReg(AbstractInstruction * self_in_genWriteCResultIntoReg, sqInt abstractRegister)
{
    sqInt cResultReg;

	cResultReg = cResultRegister(self_in_genWriteCResultIntoReg);
	if (abstractRegister != cResultReg) {
		genoperandoperand(MoveRR, cResultReg, abstractRegister);
	}
	return self_in_genWriteCResultIntoReg;
}


/*	Get the target of a jump instruction. Jumps have the target in the first
	operand. 
 */

	/* CogAbstractInstruction>>#getJmpTarget */
static AbstractInstruction *
getJmpTarget(AbstractInstruction * self_in_getJmpTarget)
{
	return ((AbstractInstruction *) (((self_in_getJmpTarget->operands))[0]));
}


/*	For out-of-line literal support, initialize a sharable literal. */

	/* CogAbstractInstruction>>#initializeSharableLiteral: */
static AbstractInstruction *
initializeSharableLiteral(AbstractInstruction * self_in_initializeSharableLiteral, sqInt literal)
{
	(self_in_initializeSharableLiteral->opcode) = Literal;

	/* separate := nil for Slang */

	(self_in_initializeSharableLiteral->annotation) = null;
	(self_in_initializeSharableLiteral->address) = null;
	(self_in_initializeSharableLiteral->dependent) = null;
	((self_in_initializeSharableLiteral->operands))[0] = literal;
	((self_in_initializeSharableLiteral->operands))[1] = 1;
	((self_in_initializeSharableLiteral->operands))[2] = -1;
	return self_in_initializeSharableLiteral;
}


/*	For out-of-line literal support, initialize an unsharable literal. */

	/* CogAbstractInstruction>>#initializeUniqueLiteral: */
static AbstractInstruction *
initializeUniqueLiteral(AbstractInstruction * self_in_initializeUniqueLiteral, sqInt literal)
{
	(self_in_initializeUniqueLiteral->opcode) = Literal;

	/* separate := nil for Slang */

	(self_in_initializeUniqueLiteral->annotation) = null;
	(self_in_initializeUniqueLiteral->address) = null;
	(self_in_initializeUniqueLiteral->dependent) = null;
	((self_in_initializeUniqueLiteral->operands))[0] = literal;
	((self_in_initializeUniqueLiteral->operands))[1] = 0;
	((self_in_initializeUniqueLiteral->operands))[2] = -1;
	return self_in_initializeUniqueLiteral;
}

	/* CogAbstractInstruction>>#isAFixup: */
static sqInt
isAFixup(AbstractInstruction * self_in_isAFixup, void *fixupOrAddress)
{
	return addressIsInFixups(fixupOrAddress);
}

	/* CogAbstractInstruction>>#isAnInstruction: */
static sqInt
isAnInstruction(AbstractInstruction * self_in_isAnInstruction, AbstractInstruction *addressOrInstruction)
{
	return (addressIsInInstructions(addressOrInstruction))
	 || (addressOrInstruction == (methodLabel()));
}

	/* CogAbstractInstruction>>#isJump */
static sqInt
isJump(AbstractInstruction * self_in_isJump)
{
	return ((((self_in_isJump->opcode)) >= FirstJump) && (((self_in_isJump->opcode)) <= LastJump));
}

	/* CogAbstractInstruction>>#isLongJump */
static sqInt
isLongJump(AbstractInstruction * self_in_isLongJump)
{
	return ((((self_in_isLongJump->opcode)) >= FirstJump) && (((self_in_isLongJump->opcode)) <= (FirstShortJump - 1)));
}


/*	Set the target of a jump instruction. These all have the target in the
	first operand. */

	/* CogAbstractInstruction>>#jmpTarget: */
static AbstractInstruction *
jmpTarget(AbstractInstruction * self_in_jmpTarget, AbstractInstruction *anAbstractInstruction)
{
	null;
	((self_in_jmpTarget->operands))[0] = (((usqInt)anAbstractInstruction));
	return anAbstractInstruction;
}


/*	Hack: To arrange that the block method field pushed in a block entry has
	its MFMethodFlagIsBlockFlag bit set we provide labels with an offset. The
	offset for the fakeHeader reference is MFMethodFlagIsBlockFlag. See
	compileBlockFrameBuild: */

	/* CogAbstractInstruction>>#labelOffset */
static usqInt
labelOffset(AbstractInstruction * self_in_labelOffset)
{
	return ((self_in_labelOffset->operands))[1];
}


/*	If the priocessor has a feature check facility answer the number
	of opcodes required to compile an accessor for the feature. */

	/* CogAbstractInstruction>>#numCheckFeaturesOpcodes */
static sqInt
numCheckFeaturesOpcodes(AbstractInstruction * self_in_numCheckFeaturesOpcodes)
{
	return 0;
}


/*	We assume here that calls and jumps look the same as regards their
	displacement. This works on at least x86, ARM and x86_64. Processors on
	which that isn't the
	case can override as necessary. */

	/* CogAbstractInstruction>>#relocateJumpLongBeforeFollowingAddress:by: */
static AbstractInstruction *
relocateJumpLongBeforeFollowingAddressby(AbstractInstruction * self_in_relocateJumpLongBeforeFollowingAddressby, sqInt pc, sqInt delta)
{
	relocateCallBeforeReturnPCby(self_in_relocateJumpLongBeforeFollowingAddressby, pc, delta);
	return self_in_relocateJumpLongBeforeFollowingAddressby;
}

	/* CogAbstractInstruction>>#resolveJumpTarget */
static AbstractInstruction *
resolveJumpTarget(AbstractInstruction * self_in_resolveJumpTarget)
{
    BytecodeFixup *fixup;

	assert(isJump(self_in_resolveJumpTarget));
	fixup = ((BytecodeFixup *) (((self_in_resolveJumpTarget->operands))[0]));
	null;
	if (isAFixup(self_in_resolveJumpTarget, fixup)) {
		assert(addressIsInInstructions((fixup->targetInstruction)));
		jmpTarget(self_in_resolveJumpTarget, (fixup->targetInstruction));
	}
	return self_in_resolveJumpTarget;
}


/*	Hack: To arrange that the block method field pushed in a block entry has
	its MFMethodFlagIsBlockFlag bit set we provide labels with an offset. The
	offset for the fakeHeader reference is MFMethodFlagIsBlockFlag. See
	compileBlockFrameBuild: */

	/* CogAbstractInstruction>>#setLabelOffset: */
static sqInt
setLabelOffset(AbstractInstruction * self_in_setLabelOffset, sqInt aValue)
{
	return ((self_in_setLabelOffset->operands))[1] = aValue;
}

	/* CogARMCompiler>>#abstractRegisterForConcreteRegister: */
static sqInt
abstractRegisterForConcreteRegister(AbstractInstruction * self_in_abstractRegisterForConcreteRegister, sqInt reg)
{
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, TempReg)) == reg) {
		return TempReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, ReceiverResultReg)) == reg) {
		return ReceiverResultReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, ClassReg)) == reg) {
		return ClassReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, SendNumArgsReg)) == reg) {
		return SendNumArgsReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, Arg0Reg)) == reg) {
		return Arg0Reg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, Arg1Reg)) == reg) {
		return Arg1Reg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, FPReg)) == reg) {
		return FPReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, SPReg)) == reg) {
		return SPReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, LinkReg)) == reg) {
		return LinkReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, RISCTempReg)) == reg) {
		return RISCTempReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, PCReg)) == reg) {
		return PCReg;
	}
	if ((concreteRegister(self_in_abstractRegisterForConcreteRegister, VarBaseReg)) == reg) {
		return VarBaseReg;
	}
	error("could not find abstract register");
	return 0;
}


/*	Remember the ROR is doubled by the cpu so use 30>>1 etc
	ADDS destReg, srcREg, #immediate ROR #rot */

	/* CogARMCompiler>>#adds:rn:imm:ror: */
static sqInt
addsrnimmror(AbstractInstruction * self_in_addsrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot)
{
	return (((AL << 28) | ((1 << 25) | ((AddOpcode << 21) | (1 << 20)))) | ((srcReg << 16) | (destReg << 12))) | ((((((usqInt) rot) >> 1) << 8) | immediate) & 0xFFF);
}


/*	Remember the ROR is doubled by the cpu so use 30>>1 etc.
	ADD destReg, srcReg, #immediate ROR #rot */

	/* CogARMCompiler>>#add:rn:imm:ror: */
static sqInt
addrnimmror(AbstractInstruction * self_in_addrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot)
{
	return (((AL << 28) | ((1 << 25) | ((AddOpcode << 21) | (0 << 20)))) | ((srcReg << 16) | (destReg << 12))) | ((((((usqInt) rot) >> 1) << 8) | immediate) & 0xFFF);
}


/*	return an ADD destReg, srcReg, addReg instruction
	ADD destReg, srcReg, addReg */

	/* CogARMCompiler>>#add:rn:rm: */
static sqInt
addrnrm(AbstractInstruction * self_in_addrnrm, sqInt destReg, sqInt srcReg, sqInt addReg)
{
	return (((AL << 28) | ((0 << 25) | ((AddOpcode << 21) | (0 << 20)))) | ((srcReg << 16) | (destReg << 12))) | (addReg & 0xFFF);
}


/*	Remember the ROR is doubled by the cpu so use 30>>1 etc
	ANDS destReg, srcReg, #immediate ROR #rot */

	/* CogARMCompiler>>#ands:rn:imm:ror: */
static sqInt
andsrnimmror(AbstractInstruction * self_in_andsrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot)
{
	return (((AL << 28) | ((1 << 25) | ((AndOpcode << 21) | (1 << 20)))) | ((srcReg << 16) | (destReg << 12))) | ((((((usqInt) rot) >> 1) << 8) | immediate) & 0xFFF);
}


/*	Remember the ROR is doubled by the cpu so use 30>>1 etc
	AND destReg, srcReg, #immediate ROR #rot */

	/* CogARMCompiler>>#and:rn:imm:ror: */
static sqInt
andrnimmror(AbstractInstruction * self_in_andrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot)
{
	return (((AL << 28) | ((1 << 25) | ((AndOpcode << 21) | (0 << 20)))) | ((srcReg << 16) | (destReg << 12))) | ((((((usqInt) rot) >> 1) << 8) | immediate) & 0xFFF);
}


/*	Remember the ROR is doubled by the cpu so use 30>>1 etc
	BICS destReg, srcReg, #immediate ROR #rot */

	/* CogARMCompiler>>#bics:rn:imm:ror: */
static sqInt
bicsrnimmror(AbstractInstruction * self_in_bicsrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot)
{
	return (((AL << 28) | ((1 << 25) | ((BicOpcode << 21) | (1 << 20)))) | ((srcReg << 16) | (destReg << 12))) | ((((((usqInt) rot) >> 1) << 8) | immediate) & 0xFFF);
}


/*	return a BL offset instruction; offset is signed 24bits of WORD offset, so
	+_32Mbyte range. Return address is in LR
	BL offset
 */

	/* CogARMCompiler>>#bl: */
static sqInt
bl(AbstractInstruction * self_in_bl, sqInt offset)
{
	return (AL << 28) | (((10 | (1 & 1)) << 24) | ((((usqInt) offset) >> 2) & 0xFFFFFF));
}


/*	return a B offset instruction; offset is signed 24bits of WORD offset, so
	+_32Mbyte range
	B offset
 */

	/* CogARMCompiler>>#b: */
static sqInt
b(AbstractInstruction * self_in_b, sqInt offset)
{
	return (AL << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset) >> 2) & 0xFFFFFF));
}


/*	According to IHI0042E ARM Architecture Procedure Calling Standard, in
	section 5.1.1:
	A subroutine must preserve the contents of the registers r4-r8, r10, r11
	and SP (and r9 in PCS variants that designate r9 as v6).
	SP = r13, so the callee-saved regs are r4-r8 & r10-r12.
	The caller-saved registers are those that are not callee-saved and not
	reserved for hardware/abi uses,
	i..e r0-r3, r9 & r12. We can't name all the C argument registers. So... */

	/* CogARMCompiler>>#callerSavedRegisterMask */
static sqInt
callerSavedRegisterMask(AbstractInstruction * self_in_callerSavedRegisterMask)
{
	return registerMaskForand(abstractRegisterForConcreteRegister(self_in_callerSavedRegisterMask, 0), abstractRegisterForConcreteRegister(self_in_callerSavedRegisterMask, 12));
}


/*	ARM calls and jumps span +/- 32 mb, more than enough for intra-zone calls
	and jumps.
 */

	/* CogARMCompiler>>#callInstructionByteSize */
static sqInt
callInstructionByteSize(AbstractInstruction * self_in_callInstructionByteSize)
{
	return 4;
}


/*	Answer the address that the call immediately preceeding
	callSiteReturnAddress will jump to.
 */
/*	this is also used by #jumpLongTargetBeforeFollowingAddress:. */

	/* CogARMCompiler>>#callTargetFromReturnAddress: */
static sqInt
callTargetFromReturnAddress(AbstractInstruction * self_in_callTargetFromReturnAddress, sqInt callSiteReturnAddress)
{
    sqInt call;
    sqInt callDistance;
    sqInt relativeJump;

	call = longAt(callSiteReturnAddress - 4);
	assert((instructionIsB(self_in_callTargetFromReturnAddress, call))
	 || (instructionIsBL(self_in_callTargetFromReturnAddress, call)));
	/* begin extractOffsetFromBL: */
	relativeJump = call & 0xFFFFFF;
	relativeJump = (relativeJump & (1 << 23)
		? ((sqInt) ((relativeJump | 0x3F000000) << 2))
		: relativeJump << 2);
	callDistance = relativeJump;
	return (callSiteReturnAddress + 4) + (((sqInt) callDistance));
}


/*	Because we don't use Thumb, each ARM instruction has 4 bytes. Many
	abstract opcodes need more than one instruction. Instructions that refer
	to constants and/or literals depend on literals being stored in-line or
	out-of-line. 
	N.B. The ^N forms are to get around the bytecode compiler's long branch
	limits which are exceeded when each case jumps around the otherwise. */

	/* CogARMCompiler>>#computeMaximumSize */
static sqInt
computeMaximumSize(AbstractInstruction * self_in_computeMaximumSize)
{
    sqInt constant;
    sqInt constant1;
    sqInt constant2;
    sqInt constant3;
    sqInt constant4;
    sqInt constant5;
    sqInt constant6;
    sqInt constant7;
    sqInt i;
    sqInt i1;
    sqInt i2;
    sqInt i3;
    sqInt i4;
    sqInt i5;
    sqInt i6;
    sqInt n;
    sqInt r;
    sqInt u;
    sqInt value;
    sqInt value1;
    sqInt value2;
    sqInt value3;
    sqInt value4;

	
	switch ((self_in_computeMaximumSize->opcode)) {
	case Label:
		return 0;

	case Literal:
	case Fill16:
	case Fill32:
	case FillFromWord:
	case Nop:
	case Call:
	case JumpR:
	case Jump:
	case JumpLong:
	case JumpZero:
	case JumpNonZero:
	case JumpNegative:
	case JumpNonNegative:
	case JumpOverflow:
	case JumpNoOverflow:
	case JumpCarry:
	case JumpNoCarry:
	case JumpLess:
	case JumpGreaterOrEqual:
	case JumpGreater:
	case JumpLessOrEqual:
	case JumpBelow:
	case JumpAboveOrEqual:
	case JumpAbove:
	case JumpBelowOrEqual:
	case JumpLongZero:
	case JumpLongNonZero:
	case Stop:
	case AddRR:
	case AndRR:
	case CmpRR:
	case OrRR:
	case XorRR:
	case SubRR:
	case NegateR:
	case LogicalShiftLeftCqR:
	case LogicalShiftRightCqR:
	case ArithmeticShiftRightCqR:
	case LogicalShiftLeftRR:
	case LogicalShiftRightRR:
	case ArithmeticShiftRightRR:
	case AddRdRd:
	case CmpRdRd:
	case SubRdRd:
	case MulRdRd:
	case DivRdRd:
	case SqrtRd:
	case SMULL:
	case MSR:
	case CMPSMULL:
	case MoveRR:
	case MoveRdRd:
	case MoveXbrRR:
	case MoveRXbrR:
	case MoveXwrRR:
	case MoveRXwrR:
	case PopR:
	case PushR:
		return 4;

	case AlignmentNops:
		return (((self_in_computeMaximumSize->operands))[0]) - 4;

	case CallFull:
	case JumpFull:
	case AddCwR:
	case AndCwR:
	case CmpCwR:
	case OrCwR:
	case SubCwR:
	case XorCwR:
	case MoveRdM64r:
	case MoveM64rRd:
		return 4 + 4;

	case JumpFPEqual:
	case JumpFPNotEqual:
	case JumpFPLess:
	case JumpFPGreaterOrEqual:
	case JumpFPGreater:
	case JumpFPLessOrEqual:
	case JumpFPOrdered:
	case JumpFPUnordered:
	case ConvertRRd:
		return 8;

	case RetN:
		return ((((self_in_computeMaximumSize->operands))[0]) == 0
			? 4
			: 8);

	case AddCqR:
	case CmpCqR:
	case SubCqR:
		/* begin rotateable8bitSignedImmediate:ifTrue:ifFalse: */
		constant = ((self_in_computeMaximumSize->operands))[0];
		value = constant;
		while (1) {
			if ((value & 0xFF) == value) {
				return 4;

			}
			for (i1 = 2; i1 <= 30; i1 += 2) {
				if ((value & (((0xFF << i1) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i1)))) == value) {
					return 4;

				}
			}
			if (!((value == constant)
			 && (constant != 0))) break;
			value = -constant;
		}
		return 4 + 4;


	case AndCqR:
	case AndCqRR:
	case XorCqR:
		/* begin rotateable8bitBitwiseImmediate:ifTrue:ifFalse: */
		constant1 = ((self_in_computeMaximumSize->operands))[0];
		value1 = constant1;
		while (1) {
			if ((value1 & 0xFF) == value1) {
				return 4;

			}
			for (i2 = 2; i2 <= 30; i2 += 2) {
				if ((value1 & (((0xFF << i2) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i2)))) == value1) {
					return 4;

				}
			}
			if (!(value1 == constant1)) break;
			value1 = (constant1 < 0
				? -1 - constant1
				: (unsigned int)~constant1);
		}
		return 8;


	case OrCqR:
	case TstCqR:
	case LoadEffectiveAddressMwrR:
	case MoveM16rR:
		/* begin rotateable8bitImmediate:ifTrue:ifFalse: */
		constant2 = ((self_in_computeMaximumSize->operands))[0];
		if ((constant2 & 0xFF) == constant2) {
			return 4;

		}
		for (i3 = 2; i3 <= 30; i3 += 2) {
			if ((constant2 & (((0xFF << i3) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i3)))) == constant2) {
				return 4;

			}
		}
		return 4 + 4;


	case MoveCqR:
		return 4;

	case MoveCwR:
		return 4;

	case MoveAwR:
	case PrefetchAw:
		return (isAddressRelativeToVarBase(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[0])
			? 4
			: 4 + 4);

	case MoveRAw:
		return (isAddressRelativeToVarBase(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[1])
			? 4
			: 4 + 4);

	case MoveRMwr:
	case MoveRMbr:
		/* begin is12BitValue:ifTrue:ifFalse: */
		constant4 = ((self_in_computeMaximumSize->operands))[1];
		if ((abs(constant4)) <= 0xFFF) {

			/* (2 raisedTo: 12)-1 */

			if (constant4 >= 0) {
				return 4;

			}
			else {
				return 4;

			}
		}
		else {
			return 4 + 4;

		}

	case MoveMbrR:
	case MoveMwrR:
		/* begin is12BitValue:ifTrue:ifFalse: */
		constant5 = ((self_in_computeMaximumSize->operands))[0];
		if ((abs(constant5)) <= 0xFFF) {

			/* (2 raisedTo: 12)-1 */

			if (constant5 >= 0) {
				return 4;

			}
			else {
				return 4;

			}
		}
		else {
			return 4 + 4;

		}

	case PushCw:
		return 4 + 4;

	case PushCq:
		return 4 + 4;

	default:
		error("Case not found and no otherwise clause");
	}
	return 0;
}


/*	According to IHI0042E ARM Architecture Procedure Calling Standard, in
	section 5.1.1:
	A subroutine must preserve the contents of the registers r4-r8, r10, r11
	and SP (and r9 in PCS variants that designate r9 as v6).
	SP = r13, so... */

	/* CogARMCompiler>>#concreteCalleeSavedRegisterMask */
static sqInt
concreteCalleeSavedRegisterMask(AbstractInstruction * self_in_concreteCalleeSavedRegisterMask)
{
	return 3568;
}


/*	According to IHI0042E ARM Architecture Procedure Calling Standard, in
	section 5.1.1:
	A subroutine must preserve the contents of the registers r4-r8, r10, r11
	and SP (and r9 in PCS variants that designate r9 as v6).
	SP = r13, so the callee-saved regs are r4-r8 & r10-r12.
	The caller-saved registers are those that are not callee-saved and not
	reserved for hardware/abi uses,
	i..e r0-r3, r9 & r12. */

	/* CogARMCompiler>>#concreteCallerSavedRegisterMask */
static sqInt
concreteCallerSavedRegisterMask(AbstractInstruction * self_in_concreteCallerSavedRegisterMask)
{
	return 4623;
}


/*	Map a possibly abstract double-precision floating-point register into a
	concrete one.
	Abstract registers (defined in CogAbstractOpcodes) are all negative. If
	registerIndex is negative assume it is an abstract register. */

	/* CogARMCompiler>>#concreteDPFPRegister: */
static sqInt
concreteDPFPRegister(AbstractInstruction * self_in_concreteDPFPRegister, sqInt registerIndex)
{
	
	switch (registerIndex) {
	case DPFPReg0:
		return D0;

	case DPFPReg1:
		return D1;

	case DPFPReg2:
		return D2;

	case DPFPReg3:
		return D3;

	case DPFPReg4:
		return D4;

	case DPFPReg5:
		return D5;

	case DPFPReg6:
		return D6;

	case DPFPReg7:
		return D7;

	default:
		assert(((registerIndex >= D0) && (registerIndex <= D7)));
		return registerIndex;

	}
}


/*	Map a possibly abstract register into a concrete one. Abstract registers
	(defined in CogAbstractOpcodes) are all negative. If registerIndex is
	negative assume it is an abstract register. */
/*	N.B. According to BSABI, R0-R3 are caller-save, R4-R12 are callee save.
	Note that R9 might be a special register for the implementation. In some
	slides it is refered to as sb. R10 can contain the stack limit (sl), R11
	the fp. R12 is an
	intra-procedure scratch instruction pointer for link purposes. It can also
	be used.
	R10 is used as temporary inside a single abstract opcode implementation */
/*	R0-R3 are used when calling back to the interpreter. Using them would
	require saving and restoring their values, so they are omitted so far. R12
	is the only
	unused register at the moment.. */

	/* CogARMCompiler>>#concreteRegister: */
static sqInt
concreteRegister(AbstractInstruction * self_in_concreteRegister, sqInt registerIndex)
{
	
	switch (registerIndex) {
	case TempReg:
		return R0;

	case ClassReg:
		return R8;

	case ReceiverResultReg:
		return R7;

	case SendNumArgsReg:
		return R6;

	case SPReg:
		return SP;

	case FPReg:
		return R11;

	case Arg0Reg:
		return R4;

	case Arg1Reg:
		return R5;

	case VarBaseReg:
		return ConcreteVarBaseReg;

	case RISCTempReg:
		return ConcreteIPReg;

	case LinkReg:
		return LR;

	case PCReg:
		return PC;

	default:
		assert(((registerIndex >= R0) && (registerIndex <= PC)));
		return registerIndex;

	}
}


/*	Generate concrete machine code for the instruction at actualAddress,
	setting machineCodeSize, and answer the following address. */

	/* CogARMCompiler>>#concretizeAt: */
static sqInt
concretizeAt(AbstractInstruction * self_in_concretizeAt, sqInt actualAddress)
{
	assert((actualAddress % 4) == 0);
	(self_in_concretizeAt->address) = actualAddress;
	dispatchConcretize(self_in_concretizeAt);
	assert((((self_in_concretizeAt->maxSize)) == null)
	 || (((self_in_concretizeAt->maxSize)) >= ((self_in_concretizeAt->machineCodeSize))));
	return actualAddress + ((self_in_concretizeAt->machineCodeSize));
}


/*	Generate a CMP a, b, ASR #31 instruction, specifically for comparing the
	resutls of SMULLs in genMulR:R:
 */

	/* CogARMCompiler>>#concretizeCMPSMULL */
static usqInt
concretizeCMPSMULL(AbstractInstruction * self_in_concretizeCMPSMULL)
{
    sqInt hiReg;
    sqInt loReg;

	hiReg = concreteRegister(self_in_concretizeCMPSMULL, ((self_in_concretizeCMPSMULL->operands))[0]);
	loReg = concreteRegister(self_in_concretizeCMPSMULL, ((self_in_concretizeCMPSMULL->operands))[1]);
	/* begin machineCodeAt:put: */
	((self_in_concretizeCMPSMULL->machineCode))[0 / 4] = ((((((AL << 28) | ((0 << 25) | ((CmpOpcode << 21) | (1 << 20)))) | ((hiReg << 16) | (0 << 12))) + (0x1F << 7)) + (2 << 5)) + loReg);
	self_in_concretizeCMPSMULL;
	return ((self_in_concretizeCMPSMULL->machineCodeSize) = 4);
}


/*	Concretize the current instruction, but with a condition. */

	/* CogARMCompiler>>#concretizeConditionalInstruction */
static void
concretizeConditionalInstruction(AbstractInstruction * self_in_concretizeConditionalInstruction)
{
    sqInt aWord;
    sqInt i;
    sqInt instr;
    unsigned char savedCond;

	assert(((self_in_concretizeConditionalInstruction->conditionOrNil)) != null);
	savedCond = (self_in_concretizeConditionalInstruction->conditionOrNil);
	(self_in_concretizeConditionalInstruction->conditionOrNil) = null;
	dispatchConcretize(self_in_concretizeConditionalInstruction);
	(self_in_concretizeConditionalInstruction->conditionOrNil) = savedCond;
	for (i = 0; i < ((self_in_concretizeConditionalInstruction->machineCodeSize)); i += 4) {
		instr = (((((self_in_concretizeConditionalInstruction->machineCode))[i / 4]) | (15 << 28)) - (15 << 28));
		/* begin machineCodeAt:put: */
		aWord = instr | ((((self_in_concretizeConditionalInstruction->conditionOrNil)) & 15) << 28);
		((self_in_concretizeConditionalInstruction->machineCode))[i / 4] = aWord;
		self_in_concretizeConditionalInstruction;
	}
	return;
}


/*	fill with (operand 0 bitAnd: 16rFFFF) according to the processor's
	endianness 
 */

	/* CogARMCompiler>>#concretizeFill16 */
static AbstractInstruction *
concretizeFill16(AbstractInstruction * self_in_concretizeFill16)
{
	haltmsg("unused opcode?");
	return self_in_concretizeFill16;
}


/*	fill with operand 0 according to the processor's endianness */

	/* CogARMCompiler>>#concretizeFill32 */
static usqInt
concretizeFill32(AbstractInstruction * self_in_concretizeFill32)
{
    unsigned long word;

	word = ((self_in_concretizeFill32->operands))[0];
	/* begin machineCodeAt:put: */
	((self_in_concretizeFill32->machineCode))[0 / 4] = word;
	self_in_concretizeFill32;
	return ((self_in_concretizeFill32->machineCodeSize) = 4);
}

	/* CogARMCompiler>>#concretizeFillFromWord */
static AbstractInstruction *
concretizeFillFromWord(AbstractInstruction * self_in_concretizeFillFromWord)
{
	assert(0);
	notYetImplemented();
	return self_in_concretizeFillFromWord;
}


/*	Generate an MSR CPSR_f, #flags instruction.
	Note that we only have business with the NZCV flags so we use
	N -> 8
	Z -> 4
	C -> 2
	V -> 1.
	You don't want to mess with this too much.
 */

	/* CogARMCompiler>>#concretizeMSR */
static usqInt
concretizeMSR(AbstractInstruction * self_in_concretizeMSR)
{
    sqInt aWord;
    sqInt flags;

	flags = concreteRegister(self_in_concretizeMSR, ((self_in_concretizeMSR->operands))[0]);
	/* begin machineCodeAt:put: */
	aWord = msr(self_in_concretizeMSR, flags);
	((self_in_concretizeMSR->machineCode))[0 / 4] = aWord;
	self_in_concretizeMSR;
	return ((self_in_concretizeMSR->machineCodeSize) = 4);
}


/*	Generate an SMULL loResultReg, hiResultReg, srcA, srcB instruction */

	/* CogARMCompiler>>#concretizeSMULL */
static usqInt
concretizeSMULL(AbstractInstruction * self_in_concretizeSMULL)
{
    sqInt hiResultReg;
    sqInt loResultReg;
    sqInt srcA;
    sqInt srcB;


	/* NOTE: srcB contains the other mutiplicand at this point. It is OK to use it as the destination for the low part of the result and in fact this saves us moving it later */

	srcA = concreteRegister(self_in_concretizeSMULL, ((self_in_concretizeSMULL->operands))[0]);
	loResultReg = (srcB = concreteRegister(self_in_concretizeSMULL, ((self_in_concretizeSMULL->operands))[1]));
	hiResultReg = concreteRegister(self_in_concretizeSMULL, RISCTempReg);
	/* begin machineCodeAt:put: */
	((self_in_concretizeSMULL->machineCode))[0 / 4] = ((((((AL << 28) | ((0 << 25) | ((6 << 21) | (0 << 20)))) | ((hiResultReg << 16) | (loResultReg << 12))) + (srcA << 8)) + (9 << 4)) + srcB);
	self_in_concretizeSMULL;
	return ((self_in_concretizeSMULL->machineCodeSize) = 4);
}


/*	Answer the abstract register for the C result register.
	Only partially implemented. Works on x86 since TempReg = EAX = C result
	reg.  */

	/* CogARMCompiler>>#cResultRegister */
static sqInt
cResultRegister(AbstractInstruction * self_in_cResultRegister)
{
	return R0;
}


/*	return an {opcode} destReg, srcReg, addReg lsl #shft */
/*	important detail - a 0 shft requires setting the shift-type code to 0 to
	avoid potential instruction confusion
 */

	/* CogARMCompiler>>#dataOpType:rd:rn:rm:lsr: */
static sqInt
dataOpTyperdrnrmlsr(AbstractInstruction * self_in_dataOpTyperdrnrmlsr, sqInt armOpcode, sqInt destReg, sqInt srcReg, sqInt addReg, sqInt shft)
{
	if (shft == 0) {
		return (((AL << 28) | ((0 << 25) | ((armOpcode << 21) | (1 << 20)))) | ((srcReg << 16) | (destReg << 12))) | (addReg & 0xFFF);
	}
	else {
		return (((AL << 28) | ((0 << 25) | ((armOpcode << 21) | (1 << 20)))) | ((srcReg << 16) | (destReg << 12))) | ((((shft << 7) | 32) | addReg) & 0xFFF);
	}
}


/*	Attempt to generate concrete machine code for the instruction at address.
	This is the inner dispatch of concretizeAt: actualAddress which exists
	only to get around the branch size limits in the SqueakV3 (blue book
	derived) bytecode set. */

	/* CogARMCompiler>>#dispatchConcretize */
static void
dispatchConcretize(AbstractInstruction * self_in_dispatchConcretize)
{
    unsigned long addressOperand;
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord10;
    sqInt aWord11;
    sqInt aWord110;
    sqInt aWord111;
    sqInt aWord112;
    sqInt aWord113;
    sqInt aWord114;
    sqInt aWord115;
    sqInt aWord116;
    sqInt aWord117;
    sqInt aWord118;
    sqInt aWord119;
    sqInt aWord12;
    sqInt aWord120;
    sqInt aWord121;
    sqInt aWord122;
    sqInt aWord123;
    sqInt aWord13;
    sqInt aWord14;
    sqInt aWord15;
    sqInt aWord16;
    sqInt aWord17;
    sqInt aWord18;
    sqInt aWord19;
    sqInt aWord2;
    sqInt aWord20;
    sqInt aWord21;
    sqInt aWord210;
    sqInt aWord211;
    sqInt aWord212;
    sqInt aWord213;
    sqInt aWord22;
    sqInt aWord23;
    sqInt aWord24;
    sqInt aWord25;
    sqInt aWord26;
    sqInt aWord27;
    sqInt aWord28;
    sqInt aWord29;
    sqInt aWord3;
    sqInt aWord30;
    sqInt aWord31;
    sqInt aWord310;
    sqInt aWord311;
    sqInt aWord32;
    sqInt aWord33;
    sqInt aWord34;
    sqInt aWord35;
    sqInt aWord36;
    sqInt aWord37;
    sqInt aWord38;
    sqInt aWord39;
    sqInt aWord4;
    sqInt aWord40;
    sqInt aWord41;
    sqInt aWord42;
    sqInt aWord43;
    sqInt aWord44;
    sqInt aWord45;
    sqInt aWord46;
    sqInt aWord47;
    sqInt aWord48;
    sqInt aWord49;
    sqInt aWord5;
    sqInt aWord50;
    sqInt aWord51;
    sqInt aWord52;
    sqInt aWord53;
    sqInt aWord54;
    sqInt aWord55;
    sqInt aWord56;
    sqInt aWord57;
    sqInt aWord58;
    sqInt aWord59;
    sqInt aWord6;
    sqInt aWord60;
    sqInt aWord61;
    sqInt aWord62;
    sqInt aWord63;
    sqInt aWord64;
    sqInt aWord65;
    sqInt aWord7;
    sqInt aWord8;
    sqInt aWord9;
    sqInt base;
    sqInt base1;
    sqInt base2;
    sqInt base3;
    sqInt baseReg;
    sqInt baseReg1;
    usqInt constant;
    usqInt constant1;
    unsigned long constant10;
    unsigned long constant11;
    unsigned long constant12;
    unsigned long constant13;
    unsigned long constant14;
    unsigned long constant2;
    unsigned long constant3;
    unsigned long constant4;
    unsigned long constant5;
    unsigned long constant6;
    unsigned long constant7;
    unsigned long constant8;
    unsigned long constant9;
    AbstractInstruction *dependentChain;
    sqInt dest;
    sqInt dest1;
    unsigned long destAddr;
    sqInt destReg;
    sqInt destReg1;
    sqInt destReg10;
    sqInt destReg11;
    sqInt destReg2;
    sqInt destReg3;
    sqInt destReg4;
    sqInt destReg5;
    sqInt destReg6;
    sqInt destReg7;
    sqInt destReg8;
    sqInt destReg9;
    sqInt distance;
    sqInt distance1;
    sqInt distance2;
    sqInt distReg;
    sqInt distReg1;
    sqInt distReg2;
    sqInt dstReg;
    sqInt dstReg1;
    sqInt flagsOrOpcode;
    sqInt flagsOrOpcode1;
    sqInt flagsOrOpcode2;
    sqInt flagsOrOpcode3;
    sqInt flagsOrOpcode4;
    sqInt flagsOrOpcode5;
    sqInt flagsOrOpcode6;
    sqInt flagsOrOpcode7;
    sqInt fpReg;
    sqInt hb;
    sqInt hb1;
    sqInt hb2;
    sqInt hb3;
    sqInt hb4;
    sqInt hb5;
    sqInt hb6;
    sqInt hb7;
    sqInt i;
    sqInt i1;
    sqInt i10;
    sqInt i11;
    sqInt i12;
    sqInt i13;
    sqInt i14;
    sqInt i15;
    sqInt i2;
    sqInt i3;
    sqInt i4;
    sqInt i5;
    sqInt i6;
    sqInt i7;
    sqInt i8;
    sqInt i9;
    sqInt immediate;
    sqInt immediate1;
    sqInt immediate10;
    sqInt immediate11;
    sqInt immediate12;
    sqInt immediate13;
    sqInt immediate14;
    sqInt immediate15;
    sqInt immediate16;
    sqInt immediate17;
    sqInt immediate18;
    sqInt immediate19;
    sqInt immediate2;
    sqInt immediate3;
    sqInt immediate4;
    sqInt immediate5;
    sqInt immediate6;
    sqInt immediate7;
    sqInt immediate8;
    sqInt immediate9;
    sqInt index;
    sqInt index1;
    sqInt index2;
    sqInt index3;
    usqInt instrOffset;
    usqInt instrOffset1;
    usqInt instrOffset10;
    usqInt instrOffset11;
    usqInt instrOffset12;
    usqInt instrOffset13;
    usqInt instrOffset14;
    usqInt instrOffset15;
    usqInt instrOffset16;
    usqInt instrOffset17;
    usqInt instrOffset18;
    usqInt instrOffset19;
    usqInt instrOffset2;
    usqInt instrOffset20;
    usqInt instrOffset21;
    usqInt instrOffset22;
    usqInt instrOffset23;
    usqInt instrOffset24;
    usqInt instrOffset25;
    usqInt instrOffset26;
    usqInt instrOffset3;
    usqInt instrOffset4;
    sqInt instrOffset5;
    usqInt instrOffset6;
    usqInt instrOffset7;
    usqInt instrOffset8;
    usqInt instrOffset9;
    sqInt invert;
    sqInt invert1;
    sqInt invert2;
    sqInt invert3;
    sqInt invert4;
    sqInt invVal;
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    AbstractInstruction *jumpTarget10;
    AbstractInstruction *jumpTarget11;
    AbstractInstruction *jumpTarget110;
    AbstractInstruction *jumpTarget111;
    AbstractInstruction *jumpTarget112;
    AbstractInstruction *jumpTarget113;
    AbstractInstruction *jumpTarget114;
    AbstractInstruction *jumpTarget115;
    AbstractInstruction *jumpTarget116;
    AbstractInstruction *jumpTarget117;
    AbstractInstruction *jumpTarget118;
    AbstractInstruction *jumpTarget119;
    AbstractInstruction *jumpTarget12;
    AbstractInstruction *jumpTarget120;
    AbstractInstruction *jumpTarget121;
    AbstractInstruction *jumpTarget122;
    AbstractInstruction *jumpTarget123;
    AbstractInstruction *jumpTarget124;
    AbstractInstruction *jumpTarget13;
    AbstractInstruction *jumpTarget14;
    AbstractInstruction *jumpTarget15;
    AbstractInstruction *jumpTarget16;
    AbstractInstruction *jumpTarget17;
    AbstractInstruction *jumpTarget18;
    AbstractInstruction *jumpTarget19;
    AbstractInstruction *jumpTarget2;
    AbstractInstruction *jumpTarget20;
    AbstractInstruction *jumpTarget21;
    AbstractInstruction *jumpTarget22;
    AbstractInstruction *jumpTarget23;
    AbstractInstruction *jumpTarget24;
    AbstractInstruction *jumpTarget25;
    AbstractInstruction *jumpTarget26;
    AbstractInstruction *jumpTarget27;
    AbstractInstruction *jumpTarget28;
    AbstractInstruction *jumpTarget29;
    AbstractInstruction *jumpTarget3;
    AbstractInstruction *jumpTarget30;
    AbstractInstruction *jumpTarget31;
    AbstractInstruction *jumpTarget32;
    AbstractInstruction *jumpTarget33;
    AbstractInstruction *jumpTarget34;
    AbstractInstruction *jumpTarget4;
    AbstractInstruction *jumpTarget5;
    AbstractInstruction *jumpTarget6;
    AbstractInstruction *jumpTarget7;
    AbstractInstruction *jumpTarget8;
    AbstractInstruction *jumpTarget9;
    sqInt negate;
    sqInt negate1;
    sqInt offset;
    sqInt offset1;
    sqInt offset10;
    sqInt offset11;
    sqInt offset12;
    sqInt offset13;
    sqInt offset14;
    sqInt offset15;
    sqInt offset16;
    sqInt offset17;
    sqInt offset18;
    sqInt offset19;
    unsigned long offset2;
    sqInt offset20;
    sqInt offset21;
    sqInt offset22;
    sqInt offset23;
    sqInt offset24;
    sqInt offset25;
    sqInt offset26;
    sqInt offset27;
    sqInt offset28;
    sqInt offset29;
    sqInt offset3;
    sqInt offset30;
    sqInt offset31;
    sqInt offset32;
     long offset4;
    sqInt offset5;
    sqInt offset6;
     long offset7;
    sqInt offset8;
    sqInt offset9;
    sqInt p;
    sqInt rd;
    sqInt rd1;
    sqInt rd10;
    sqInt rd11;
    sqInt rd12;
    sqInt rd13;
    sqInt rd14;
    sqInt rd15;
    sqInt rd16;
    sqInt rd17;
    sqInt rd18;
    sqInt rd19;
    sqInt rd2;
    sqInt rd20;
    sqInt rd21;
    sqInt rd22;
    sqInt rd23;
    sqInt rd24;
    sqInt rd3;
    sqInt rd4;
    sqInt rd5;
    sqInt rd6;
    sqInt rd7;
    sqInt rd8;
    sqInt rd9;
    sqInt reg;
    sqInt reg1;
    sqInt reg2;
    sqInt reg3;
    sqInt reg4;
    sqInt reg5;
    sqInt reg6;
    sqInt reg7;
    sqInt regA;
    sqInt regB;
    sqInt regLHS;
    sqInt regLHS1;
    sqInt regLHS2;
    sqInt regLHS3;
    sqInt regLHS4;
    sqInt regRHS;
    sqInt regRHS1;
    sqInt regRHS2;
    sqInt regRHS3;
    sqInt rn;
    sqInt rn1;
    sqInt rn10;
    sqInt rn11;
    sqInt rn12;
    sqInt rn13;
    sqInt rn14;
    sqInt rn15;
    sqInt rn16;
    sqInt rn17;
    sqInt rn18;
    sqInt rn19;
    sqInt rn2;
    sqInt rn20;
    sqInt rn21;
    sqInt rn22;
    sqInt rn23;
    sqInt rn24;
    sqInt rn25;
    sqInt rn26;
    sqInt rn3;
    sqInt rn4;
    sqInt rn5;
    sqInt rn6;
    sqInt rn7;
    sqInt rn8;
    sqInt rn9;
    sqInt rot;
    sqInt rot1;
    sqInt rot10;
    sqInt rot11;
    sqInt rot12;
    sqInt rot13;
    sqInt rot2;
    sqInt rot3;
    sqInt rot4;
    sqInt rot5;
    sqInt rot6;
    sqInt rot7;
    sqInt rot8;
    sqInt rot9;
    sqInt src;
    sqInt src1;
    unsigned long srcAddr;
    sqInt srcReg;
    sqInt srcReg1;
    sqInt srcReg10;
    sqInt srcReg11;
    sqInt srcReg12;
    sqInt srcReg13;
    sqInt srcReg14;
    sqInt srcReg15;
    sqInt srcReg16;
    sqInt srcReg17;
    sqInt srcReg2;
    sqInt srcReg3;
    sqInt srcReg4;
    sqInt srcReg5;
    sqInt srcReg6;
    sqInt srcReg7;
    sqInt srcReg8;
    sqInt srcReg9;
    sqInt u;
    sqInt u1;
    sqInt u2;
    sqInt u3;
    sqInt u4;
    sqInt u5;
    sqInt u6;
     long val;
     long val1;
    unsigned long val2;
     long val3;
     long val4;
     long val5;
     long val6;
     long val7;
    sqInt value;
    sqInt value1;
    sqInt value2;
    sqInt value3;
    sqInt value4;
    sqInt value5;
    sqInt value6;
    sqInt word;
    unsigned long word1;
    sqInt word2;
    unsigned long word3;

	if (!(((self_in_dispatchConcretize->conditionOrNil)) == null)) {
		concretizeConditionalInstruction(self_in_dispatchConcretize);
		return;
	}
	
	switch ((self_in_dispatchConcretize->opcode)) {
	case Label:
		/* begin concretizeLabel */
		dependentChain = (self_in_dispatchConcretize->dependent);
		while (!(dependentChain == null)) {
			updateLabel(dependentChain, self_in_dispatchConcretize);
			dependentChain = (dependentChain->dependent);
		}
		((self_in_dispatchConcretize->machineCodeSize) = 0);
		return;

	case Literal:
		concretizeLiteral(self_in_dispatchConcretize);
		return;

	case AlignmentNops:
		/* begin concretizeAlignmentNops */
		assert((((self_in_dispatchConcretize->machineCodeSize)) % 4) == 0);
		for (p = 0; p < ((self_in_dispatchConcretize->machineCodeSize)); p += 4) {
			/* begin machineCodeAt:put: */
			((self_in_dispatchConcretize->machineCode))[p / 4] = 3785359360UL;
			self_in_dispatchConcretize;
		}
		return;

	case Fill16:
		concretizeFill16(self_in_dispatchConcretize);
		return;

	case Fill32:
		concretizeFill32(self_in_dispatchConcretize);
		return;

	case FillFromWord:
		concretizeFillFromWord(self_in_dispatchConcretize);
		return;

	case Nop:
		/* begin concretizeNop */
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = 3785359360UL;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case Call:
		/* begin concretizeCall */
		assert((((self_in_dispatchConcretize->operands))[0]) != 0);
		assert(((((self_in_dispatchConcretize->operands))[0]) % 4) == 0);

		/* normal pc offset */

		offset = (((sqInt) (((self_in_dispatchConcretize->operands))[0]))) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset));
		/* begin machineCodeAt:put: */
		aWord = bl(self_in_dispatchConcretize, offset);
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case CallFull:
		/* begin concretizeCallFull */
		/* begin longJumpTargetAddress */
		jumpTarget1 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		if ((addressIsInInstructions(jumpTarget1))
		 || (jumpTarget1 == (methodLabel()))) {
			jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
		}
		assert(jumpTarget1 != 0);
		jumpTarget = jumpTarget1;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord42 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord42;
		self_in_dispatchConcretize;
		instrOffset6 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset6 / 4] = ((AL << 28) | ((19922704 | ((1 & 1) << 5)) | ConcreteIPReg));
		self_in_dispatchConcretize;
		assert(instrOffset6 == (literalLoadInstructionBytes(self_in_dispatchConcretize)));
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset6 + 4);
		return;

	case JumpR:
		/* begin concretizeJumpR */

		/* bx reg */

		reg2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((AL << 28) | ((19922704 | ((0 & 1) << 5)) | reg2));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpFull:
		/* begin concretizeJumpFull */
		/* begin longJumpTargetAddress */
		jumpTarget11 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		if ((addressIsInInstructions(jumpTarget11))
		 || (jumpTarget11 == (methodLabel()))) {
			jumpTarget11 = ((AbstractInstruction *) ((jumpTarget11->address)));
		}
		assert(jumpTarget11 != 0);
		jumpTarget2 = jumpTarget11;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord43 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord43;
		self_in_dispatchConcretize;
		instrOffset7 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset7 / 4] = ((AL << 28) | ((19922704 | ((0 & 1) << 5)) | ConcreteIPReg));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset7 + 4);
		return;

	case JumpLong:
	case Jump:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget12 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget12);
		if ((addressIsInInstructions(jumpTarget12))
		 || (jumpTarget12 == (methodLabel()))) {
			jumpTarget12 = ((AbstractInstruction *) ((jumpTarget12->address)));
		}
		assert(jumpTarget12 != 0);
		jumpTarget3 = jumpTarget12;
		offset8 = (((sqInt) jumpTarget3)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset8));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((AL << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset8) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpLongZero:
	case JumpZero:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget13 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget13);
		if ((addressIsInInstructions(jumpTarget13))
		 || (jumpTarget13 == (methodLabel()))) {
			jumpTarget13 = ((AbstractInstruction *) ((jumpTarget13->address)));
		}
		assert(jumpTarget13 != 0);
		jumpTarget4 = jumpTarget13;
		offset9 = (((sqInt) jumpTarget4)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset9));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((EQ << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset9) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpLongNonZero:
	case JumpNonZero:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget14 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget14);
		if ((addressIsInInstructions(jumpTarget14))
		 || (jumpTarget14 == (methodLabel()))) {
			jumpTarget14 = ((AbstractInstruction *) ((jumpTarget14->address)));
		}
		assert(jumpTarget14 != 0);
		jumpTarget5 = jumpTarget14;
		offset10 = (((sqInt) jumpTarget5)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset10));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((NE << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset10) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpNegative:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget15 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget15);
		if ((addressIsInInstructions(jumpTarget15))
		 || (jumpTarget15 == (methodLabel()))) {
			jumpTarget15 = ((AbstractInstruction *) ((jumpTarget15->address)));
		}
		assert(jumpTarget15 != 0);
		jumpTarget6 = jumpTarget15;
		offset11 = (((sqInt) jumpTarget6)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset11));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((MI << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset11) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpNonNegative:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget16 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget16);
		if ((addressIsInInstructions(jumpTarget16))
		 || (jumpTarget16 == (methodLabel()))) {
			jumpTarget16 = ((AbstractInstruction *) ((jumpTarget16->address)));
		}
		assert(jumpTarget16 != 0);
		jumpTarget7 = jumpTarget16;
		offset12 = (((sqInt) jumpTarget7)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset12));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((PL << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset12) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpOverflow:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget17 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget17);
		if ((addressIsInInstructions(jumpTarget17))
		 || (jumpTarget17 == (methodLabel()))) {
			jumpTarget17 = ((AbstractInstruction *) ((jumpTarget17->address)));
		}
		assert(jumpTarget17 != 0);
		jumpTarget8 = jumpTarget17;
		offset13 = (((sqInt) jumpTarget8)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset13));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((VS << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset13) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpNoOverflow:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget18 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget18);
		if ((addressIsInInstructions(jumpTarget18))
		 || (jumpTarget18 == (methodLabel()))) {
			jumpTarget18 = ((AbstractInstruction *) ((jumpTarget18->address)));
		}
		assert(jumpTarget18 != 0);
		jumpTarget9 = jumpTarget18;
		offset14 = (((sqInt) jumpTarget9)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset14));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((VC << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset14) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpCarry:
	case JumpAboveOrEqual:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget19 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget19);
		if ((addressIsInInstructions(jumpTarget19))
		 || (jumpTarget19 == (methodLabel()))) {
			jumpTarget19 = ((AbstractInstruction *) ((jumpTarget19->address)));
		}
		assert(jumpTarget19 != 0);
		jumpTarget10 = jumpTarget19;
		offset15 = (((sqInt) jumpTarget10)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset15));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((CS << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset15) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpNoCarry:
	case JumpBelow:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget110 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget110);
		if ((addressIsInInstructions(jumpTarget110))
		 || (jumpTarget110 == (methodLabel()))) {
			jumpTarget110 = ((AbstractInstruction *) ((jumpTarget110->address)));
		}
		assert(jumpTarget110 != 0);
		jumpTarget20 = jumpTarget110;
		offset16 = (((sqInt) jumpTarget20)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset16));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((CC << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset16) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpLess:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget111 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget111);
		if ((addressIsInInstructions(jumpTarget111))
		 || (jumpTarget111 == (methodLabel()))) {
			jumpTarget111 = ((AbstractInstruction *) ((jumpTarget111->address)));
		}
		assert(jumpTarget111 != 0);
		jumpTarget21 = jumpTarget111;
		offset17 = (((sqInt) jumpTarget21)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset17));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((LT << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset17) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpGreaterOrEqual:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget112 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget112);
		if ((addressIsInInstructions(jumpTarget112))
		 || (jumpTarget112 == (methodLabel()))) {
			jumpTarget112 = ((AbstractInstruction *) ((jumpTarget112->address)));
		}
		assert(jumpTarget112 != 0);
		jumpTarget22 = jumpTarget112;
		offset18 = (((sqInt) jumpTarget22)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset18));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((GE << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset18) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpGreater:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget113 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget113);
		if ((addressIsInInstructions(jumpTarget113))
		 || (jumpTarget113 == (methodLabel()))) {
			jumpTarget113 = ((AbstractInstruction *) ((jumpTarget113->address)));
		}
		assert(jumpTarget113 != 0);
		jumpTarget23 = jumpTarget113;
		offset19 = (((sqInt) jumpTarget23)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset19));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((GT << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset19) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpLessOrEqual:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget114 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget114);
		if ((addressIsInInstructions(jumpTarget114))
		 || (jumpTarget114 == (methodLabel()))) {
			jumpTarget114 = ((AbstractInstruction *) ((jumpTarget114->address)));
		}
		assert(jumpTarget114 != 0);
		jumpTarget24 = jumpTarget114;
		offset20 = (((sqInt) jumpTarget24)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset20));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((LE << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset20) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpAbove:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget115 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget115);
		if ((addressIsInInstructions(jumpTarget115))
		 || (jumpTarget115 == (methodLabel()))) {
			jumpTarget115 = ((AbstractInstruction *) ((jumpTarget115->address)));
		}
		assert(jumpTarget115 != 0);
		jumpTarget25 = jumpTarget115;
		offset21 = (((sqInt) jumpTarget25)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset21));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((HI << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset21) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpBelowOrEqual:
		/* begin concretizeConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget116 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget116);
		if ((addressIsInInstructions(jumpTarget116))
		 || (jumpTarget116 == (methodLabel()))) {
			jumpTarget116 = ((AbstractInstruction *) ((jumpTarget116->address)));
		}
		assert(jumpTarget116 != 0);
		jumpTarget26 = jumpTarget116;
		offset22 = (((sqInt) jumpTarget26)) - (((sqInt) (((self_in_dispatchConcretize->address)) + 8)));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset22));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((LS << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset22) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case JumpFPEqual:
		/* begin concretizeFPConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget117 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget117);
		if ((addressIsInInstructions(jumpTarget117))
		 || (jumpTarget117 == (methodLabel()))) {
			jumpTarget117 = ((AbstractInstruction *) ((jumpTarget117->address)));
		}
		assert(jumpTarget117 != 0);
		jumpTarget27 = jumpTarget117;
		offset23 = (((sqInt) jumpTarget27)) - (((sqInt) (((self_in_dispatchConcretize->address)) + (8 + 4))));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset23));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = 4008835600UL;
		self_in_dispatchConcretize;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[4 / 4] = ((EQ << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset23) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 8);
		return;

	case JumpFPNotEqual:
		/* begin concretizeFPConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget118 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget118);
		if ((addressIsInInstructions(jumpTarget118))
		 || (jumpTarget118 == (methodLabel()))) {
			jumpTarget118 = ((AbstractInstruction *) ((jumpTarget118->address)));
		}
		assert(jumpTarget118 != 0);
		jumpTarget28 = jumpTarget118;
		offset24 = (((sqInt) jumpTarget28)) - (((sqInt) (((self_in_dispatchConcretize->address)) + (8 + 4))));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset24));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = 4008835600UL;
		self_in_dispatchConcretize;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[4 / 4] = ((NE << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset24) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 8);
		return;

	case JumpFPLess:
		/* begin concretizeFPConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget119 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget119);
		if ((addressIsInInstructions(jumpTarget119))
		 || (jumpTarget119 == (methodLabel()))) {
			jumpTarget119 = ((AbstractInstruction *) ((jumpTarget119->address)));
		}
		assert(jumpTarget119 != 0);
		jumpTarget29 = jumpTarget119;
		offset25 = (((sqInt) jumpTarget29)) - (((sqInt) (((self_in_dispatchConcretize->address)) + (8 + 4))));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset25));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = 4008835600UL;
		self_in_dispatchConcretize;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[4 / 4] = ((LT << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset25) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 8);
		return;

	case JumpFPGreaterOrEqual:
		/* begin concretizeFPConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget120 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget120);
		if ((addressIsInInstructions(jumpTarget120))
		 || (jumpTarget120 == (methodLabel()))) {
			jumpTarget120 = ((AbstractInstruction *) ((jumpTarget120->address)));
		}
		assert(jumpTarget120 != 0);
		jumpTarget30 = jumpTarget120;
		offset26 = (((sqInt) jumpTarget30)) - (((sqInt) (((self_in_dispatchConcretize->address)) + (8 + 4))));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset26));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = 4008835600UL;
		self_in_dispatchConcretize;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[4 / 4] = ((GE << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset26) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 8);
		return;

	case JumpFPGreater:
		/* begin concretizeFPConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget121 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget121);
		if ((addressIsInInstructions(jumpTarget121))
		 || (jumpTarget121 == (methodLabel()))) {
			jumpTarget121 = ((AbstractInstruction *) ((jumpTarget121->address)));
		}
		assert(jumpTarget121 != 0);
		jumpTarget31 = jumpTarget121;
		offset27 = (((sqInt) jumpTarget31)) - (((sqInt) (((self_in_dispatchConcretize->address)) + (8 + 4))));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset27));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = 4008835600UL;
		self_in_dispatchConcretize;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[4 / 4] = ((GT << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset27) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 8);
		return;

	case JumpFPLessOrEqual:
		/* begin concretizeFPConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget122 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget122);
		if ((addressIsInInstructions(jumpTarget122))
		 || (jumpTarget122 == (methodLabel()))) {
			jumpTarget122 = ((AbstractInstruction *) ((jumpTarget122->address)));
		}
		assert(jumpTarget122 != 0);
		jumpTarget32 = jumpTarget122;
		offset28 = (((sqInt) jumpTarget32)) - (((sqInt) (((self_in_dispatchConcretize->address)) + (8 + 4))));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset28));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = 4008835600UL;
		self_in_dispatchConcretize;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[4 / 4] = ((LE << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset28) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 8);
		return;

	case JumpFPOrdered:
		/* begin concretizeFPConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget123 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget123);
		if ((addressIsInInstructions(jumpTarget123))
		 || (jumpTarget123 == (methodLabel()))) {
			jumpTarget123 = ((AbstractInstruction *) ((jumpTarget123->address)));
		}
		assert(jumpTarget123 != 0);
		jumpTarget33 = jumpTarget123;
		offset29 = (((sqInt) jumpTarget33)) - (((sqInt) (((self_in_dispatchConcretize->address)) + (8 + 4))));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset29));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = 4008835600UL;
		self_in_dispatchConcretize;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[4 / 4] = ((VC << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset29) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 8);
		return;

	case JumpFPUnordered:
		/* begin concretizeFPConditionalJump: */
		/* begin computeJumpTargetOffsetPlus: */
		/* begin jumpTargetAddress */
		jumpTarget124 = ((AbstractInstruction *) (((self_in_dispatchConcretize->operands))[0]));
		assertSaneJumpTarget(jumpTarget124);
		if ((addressIsInInstructions(jumpTarget124))
		 || (jumpTarget124 == (methodLabel()))) {
			jumpTarget124 = ((AbstractInstruction *) ((jumpTarget124->address)));
		}
		assert(jumpTarget124 != 0);
		jumpTarget34 = jumpTarget124;
		offset30 = (((sqInt) jumpTarget34)) - (((sqInt) (((self_in_dispatchConcretize->address)) + (8 + 4))));
		assert(isInImmediateJumpRange(self_in_dispatchConcretize, offset30));
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = 4008835600UL;
		self_in_dispatchConcretize;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[4 / 4] = ((VS << 28) | (((10 | (0 & 1)) << 24) | ((((usqInt) offset30) >> 2) & 0xFFFFFF)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 8);
		return;

	case RetN:
		/* begin concretizeRetN */
		offset1 = ((self_in_dispatchConcretize->operands))[0];
		if (offset1 == 0) {
			/* begin machineCodeAt:put: */
			aWord3 = movrn(self_in_dispatchConcretize, PC, LR);
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord3;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;
		}
		assert(offset1 < 0xFF);
		/* begin machineCodeAt:put: */
		aWord1 = addrnimmror(self_in_dispatchConcretize, SP, SP, offset1, 0);
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord1;
		self_in_dispatchConcretize;
		/* begin machineCodeAt:put: */
		aWord2 = movrn(self_in_dispatchConcretize, PC, LR);
		((self_in_dispatchConcretize->machineCode))[4 / 4] = aWord2;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 8);
		return;

	case Stop:
		/* begin concretizeStop */
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((AL << 28) | ((66 << 20) | (7 << 4)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case AddCqR:
		/* begin concretizeNegateableDataOperationCqR: */
		val = ((self_in_dispatchConcretize->operands))[0];

		/* Extra note - if ever a version of this code wants to NOT set the Set flag
		   - Cmp must always have it set or it will pretend to be a SMALALBT and Very Bad Things might happen. */

		rn = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd = (((self_in_dispatchConcretize->opcode)) == CmpOpcode
			? 0
			: rn);
		/* begin rotateable8bitSignedImmediate:ifTrue:ifFalse: */
		value = val;
		while (1) {
			if ((value & 0xFF) == value) {
				negate = val != value;
				/* begin machineCodeAt:put: */
				/* begin type:op:set:rn:rd:shifterOperand: */
				flagsOrOpcode = (negate
					? inverseOpcodeFor(self_in_dispatchConcretize, AddOpcode)
					: AddOpcode);
				aWord4 = (((AL << 28) | ((1 << 25) | ((flagsOrOpcode << 21) | (1 << 20)))) | ((rn << 16) | (rd << 12))) | ((((((usqInt) 0) >> 1) << 8) | value) & 0xFFF);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord4;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l1;
			}
			for (i = 2; i <= 30; i += 2) {
				if ((value & (((0xFF << i) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i)))) == value) {
					rot = 32 - i;
					immediate = (((usqInt) value) >> i) | ((value << (32 - i)) & 0xFFFFFFFFUL);
					negate = val != value;
					/* begin machineCodeAt:put: */
					/* begin type:op:set:rn:rd:shifterOperand: */
					flagsOrOpcode1 = (negate
						? inverseOpcodeFor(self_in_dispatchConcretize, AddOpcode)
						: AddOpcode);
					aWord4 = (((AL << 28) | ((1 << 25) | ((flagsOrOpcode1 << 21) | (1 << 20)))) | ((rn << 16) | (rd << 12))) | ((((((usqInt) rot) >> 1) << 8) | immediate) & 0xFFF);
					((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord4;
					self_in_dispatchConcretize;
					((self_in_dispatchConcretize->machineCodeSize) = 4);
					return;

					goto l1;
				}
			}
			if (!((value == val)
			 && (val != 0))) break;
			value = -val;
		}
		
		/* let's try to see if the constant can be made from a simple shift of 0xFFFFFFFF */

		if (val > 0) {
			hb = highBit(val);
			if ((1 << hb) == (val + 1)) {

				/* MVN temp,  #0, making 0xffffffff */

				/* begin machineCodeAt:put: */
				aWord11 = mvnimmror(self_in_dispatchConcretize, ConcreteIPReg, 0, 0);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord11;
				self_in_dispatchConcretize;
				/* begin machineCodeAt:put: */
				aWord21 = dataOpTyperdrnrmlsr(self_in_dispatchConcretize, AddOpcode, rd, rn, ConcreteIPReg, 32 - hb);
				((self_in_dispatchConcretize->machineCode))[4 / 4] = aWord21;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 8);
				return;
			}
		}
		/* begin concretizeDataOperationCwR: */
		constant1 = ((self_in_dispatchConcretize->operands))[0];
		rn4 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd2 = rn4;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord44 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord44;
		self_in_dispatchConcretize;
		instrOffset8 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset8 / 4] = ((((AL << 28) | ((0 << 25) | ((AddOpcode << 21) | (1 << 20)))) | ((rn4 << 16) | (rd2 << 12))) | (ConcreteIPReg & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset8 + 4);
		return;

	l1:	/* end rotateable8bitSignedImmediate:ifTrue:ifFalse: */;
		return;

	case AndCqR:
		/* begin concretizeInvertibleDataOperationCqR: */
		val1 = ((self_in_dispatchConcretize->operands))[0];
		rn1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		assert(!((((self_in_dispatchConcretize->opcode)) == CmpOpcode)));
		/* begin rotateable8bitBitwiseImmediate:ifTrue:ifFalse: */
		value1 = val1;
		while (1) {
			if ((value1 & 0xFF) == value1) {
				invert = val1 != value1;
				/* begin machineCodeAt:put: */
				/* begin type:op:set:rn:rd:shifterOperand: */
				flagsOrOpcode2 = (invert
					? inverseOpcodeFor(self_in_dispatchConcretize, AndOpcode)
					: AndOpcode);
				aWord5 = (((AL << 28) | ((1 << 25) | ((flagsOrOpcode2 << 21) | (1 << 20)))) | ((rn1 << 16) | (rn1 << 12))) | ((((((usqInt) 0) >> 1) << 8) | value1) & 0xFFF);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord5;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l2;
			}
			for (i1 = 2; i1 <= 30; i1 += 2) {
				if ((value1 & (((0xFF << i1) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i1)))) == value1) {
					rot1 = 32 - i1;
					immediate1 = (((usqInt) value1) >> i1) | ((value1 << (32 - i1)) & 0xFFFFFFFFUL);
					invert = val1 != value1;
					/* begin machineCodeAt:put: */
					/* begin type:op:set:rn:rd:shifterOperand: */
					flagsOrOpcode3 = (invert
						? inverseOpcodeFor(self_in_dispatchConcretize, AndOpcode)
						: AndOpcode);
					aWord5 = (((AL << 28) | ((1 << 25) | ((flagsOrOpcode3 << 21) | (1 << 20)))) | ((rn1 << 16) | (rn1 << 12))) | ((((((usqInt) rot1) >> 1) << 8) | immediate1) & 0xFFF);
					((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord5;
					self_in_dispatchConcretize;
					((self_in_dispatchConcretize->machineCodeSize) = 4);
					return;

					goto l2;
				}
			}
			if (!(value1 == val1)) break;
			value1 = (val1 < 0
				? -1 - val1
				: (unsigned int)~val1);
		}
		
		/* let's try to see if the constant can be made from a simple shift of 0xFFFFFFFF */

		if (val1 > 0) {
			hb1 = highBit(val1);
			if ((1 << hb1) == (val1 + 1)) {

				/* MVN temp,  #0, making 0xffffffff */

				/* begin machineCodeAt:put: */
				aWord12 = mvnimmror(self_in_dispatchConcretize, ConcreteIPReg, 0, 0);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord12;
				self_in_dispatchConcretize;
				/* begin machineCodeAt:put: */
				aWord22 = dataOpTyperdrnrmlsr(self_in_dispatchConcretize, AndOpcode, rn1, rn1, ConcreteIPReg, 32 - hb1);
				((self_in_dispatchConcretize->machineCode))[4 / 4] = aWord22;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 8);
				return;
			}
		}
		/* begin concretizeDataOperationCqR: */
		val5 = ((self_in_dispatchConcretize->operands))[0];
		rn5 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);

		/* Extra note - if ever a version of this code wants to NOT set the Set flag - Cmp must always have it set or it will pretend to be a SMALALBT and Very Bad Things might happen */

		rd3 = (((self_in_dispatchConcretize->opcode)) == CmpOpcode
			? 0
			: rn5);
		/* begin rotateable8bitImmediate:ifTrue:ifFalse: */
		if ((val5 & 0xFF) == val5) {
			/* begin machineCodeAt:put: */
			((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((1 << 25) | ((AndOpcode << 21) | (1 << 20)))) | ((rn5 << 16) | (rd3 << 12))) | ((((((usqInt) 0) >> 1) << 8) | val5) & 0xFFF));
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;

			goto l21;
		}
		for (i13 = 2; i13 <= 30; i13 += 2) {
			if ((val5 & (((0xFF << i13) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i13)))) == val5) {
				rot11 = 32 - i13;
				immediate14 = (((usqInt) val5) >> i13) | ((val5 << (32 - i13)) & 0xFFFFFFFFUL);
				/* begin machineCodeAt:put: */
				((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((1 << 25) | ((AndOpcode << 21) | (1 << 20)))) | ((rn5 << 16) | (rd3 << 12))) | ((((((usqInt) rot11) >> 1) << 8) | immediate14) & 0xFFF));
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l21;
			}
		}
		
		/* let's try to see if the constant can be made from a simple shift of 0xFFFFFFFF */

		if (val5 > 0) {
			hb5 = highBit(val5);
			if ((1 << hb5) == (val5 + 1)) {

				/* MVN temp,  #0, making 0xffffffff */

				/* begin machineCodeAt:put: */
				aWord45 = mvnimmror(self_in_dispatchConcretize, ConcreteIPReg, 0, 0);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord45;
				self_in_dispatchConcretize;
				/* begin machineCodeAt:put: */
				aWord116 = dataOpTyperdrnrmlsr(self_in_dispatchConcretize, AndOpcode, rd3, rn5, ConcreteIPReg, 32 - hb5);
				((self_in_dispatchConcretize->machineCode))[4 / 4] = aWord116;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 8);
				return;
			}
		}
		/* begin concretizeDataOperationCwR: */
		constant12 = ((self_in_dispatchConcretize->operands))[0];
		rn24 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd22 = rn24;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord63 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord63;
		self_in_dispatchConcretize;
		instrOffset24 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset24 / 4] = ((((AL << 28) | ((0 << 25) | ((AndOpcode << 21) | (1 << 20)))) | ((rn24 << 16) | (rd22 << 12))) | (ConcreteIPReg & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset24 + 4);
		return;

	l21:	/* end rotateable8bitImmediate:ifTrue:ifFalse: */;
		return;

	l2:	/* end rotateable8bitBitwiseImmediate:ifTrue:ifFalse: */;
		return;

	case AndCqRR:
		/* begin concretizeAndCqRR */
		val2 = ((self_in_dispatchConcretize->operands))[0];
		srcReg = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		dstReg = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		/* begin rotateable8bitBitwiseImmediate:ifTrue:ifFalse: */
		value2 = val2;
		while (1) {
			if ((value2 & 0xFF) == value2) {
				invert1 = val2 != value2;
				/* begin machineCodeAt:put: */
				aWord6 = (invert1
					? bicsrnimmror(self_in_dispatchConcretize, dstReg, srcReg, value2, 0)
					: andsrnimmror(self_in_dispatchConcretize, dstReg, srcReg, value2, 0));
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord6;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l3;
			}
			for (i2 = 2; i2 <= 30; i2 += 2) {
				if ((value2 & (((0xFF << i2) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i2)))) == value2) {
					rot2 = 32 - i2;
					immediate2 = (((usqInt) value2) >> i2) | ((value2 << (32 - i2)) & 0xFFFFFFFFUL);
					invert1 = val2 != value2;
					/* begin machineCodeAt:put: */
					aWord6 = (invert1
						? bicsrnimmror(self_in_dispatchConcretize, dstReg, srcReg, immediate2, rot2)
						: andsrnimmror(self_in_dispatchConcretize, dstReg, srcReg, immediate2, rot2));
					((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord6;
					self_in_dispatchConcretize;
					((self_in_dispatchConcretize->machineCodeSize) = 4);
					return;

					goto l3;
				}
			}
			if (!(value2 == val2)) break;
			value2 = (val2 < 0
				? -1 - val2
				: (unsigned int)~val2);
		}
		
		/* let's try to see if the constant can be made from a simple shift of 0xFFFFFFFF */

		hb2 = highBit(((self_in_dispatchConcretize->operands))[0]);
		if ((1 << hb2) == (val2 + 1)) {

			/* MVN temp reg, 0, making 0xffffffff */

			/* begin machineCodeAt:put: */
			aWord13 = mvnimmror(self_in_dispatchConcretize, ConcreteIPReg, 0, 0);
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord13;
			self_in_dispatchConcretize;
			/* begin machineCodeAt:put: */
			aWord23 = dataOpTyperdrnrmlsr(self_in_dispatchConcretize, AndOpcode, dstReg, srcReg, ConcreteIPReg, 32 - hb2);
			((self_in_dispatchConcretize->machineCode))[4 / 4] = aWord23;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = 8);
			return;
		}
		else {
			/* begin concretizeDataOperationCwR: */
			constant2 = ((self_in_dispatchConcretize->operands))[0];
			rn6 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
			rd4 = rn6;
			/* begin moveCw:intoR: */
			assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
			assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
			/* begin machineCodeAt:put: */
			aWord46 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
				? 1
				: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord46;
			self_in_dispatchConcretize;
			instrOffset9 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
			/* begin machineCodeAt:put: */
			((self_in_dispatchConcretize->machineCode))[instrOffset9 / 4] = ((((AL << 28) | ((0 << 25) | ((AndOpcode << 21) | (1 << 20)))) | ((rn6 << 16) | (rd4 << 12))) | (ConcreteIPReg & 0xFFF));
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = instrOffset9 + 4);
			return;
		}

	l3:	/* end rotateable8bitBitwiseImmediate:ifTrue:ifFalse: */;
		return;

	case CmpCqR:
		/* begin concretizeNegateableDataOperationCqR: */
		val3 = ((self_in_dispatchConcretize->operands))[0];

		/* Extra note - if ever a version of this code wants to NOT set the Set flag
		   - Cmp must always have it set or it will pretend to be a SMALALBT and Very Bad Things might happen. */

		rn2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd1 = (((self_in_dispatchConcretize->opcode)) == CmpOpcode
			? 0
			: rn2);
		/* begin rotateable8bitSignedImmediate:ifTrue:ifFalse: */
		value3 = val3;
		while (1) {
			if ((value3 & 0xFF) == value3) {
				negate1 = val3 != value3;
				/* begin machineCodeAt:put: */
				/* begin type:op:set:rn:rd:shifterOperand: */
				flagsOrOpcode4 = (negate1
					? inverseOpcodeFor(self_in_dispatchConcretize, CmpOpcode)
					: CmpOpcode);
				aWord7 = (((AL << 28) | ((1 << 25) | ((flagsOrOpcode4 << 21) | (1 << 20)))) | ((rn2 << 16) | (rd1 << 12))) | ((((((usqInt) 0) >> 1) << 8) | value3) & 0xFFF);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord7;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l4;
			}
			for (i3 = 2; i3 <= 30; i3 += 2) {
				if ((value3 & (((0xFF << i3) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i3)))) == value3) {
					rot3 = 32 - i3;
					immediate3 = (((usqInt) value3) >> i3) | ((value3 << (32 - i3)) & 0xFFFFFFFFUL);
					negate1 = val3 != value3;
					/* begin machineCodeAt:put: */
					/* begin type:op:set:rn:rd:shifterOperand: */
					flagsOrOpcode5 = (negate1
						? inverseOpcodeFor(self_in_dispatchConcretize, CmpOpcode)
						: CmpOpcode);
					aWord7 = (((AL << 28) | ((1 << 25) | ((flagsOrOpcode5 << 21) | (1 << 20)))) | ((rn2 << 16) | (rd1 << 12))) | ((((((usqInt) rot3) >> 1) << 8) | immediate3) & 0xFFF);
					((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord7;
					self_in_dispatchConcretize;
					((self_in_dispatchConcretize->machineCodeSize) = 4);
					return;

					goto l4;
				}
			}
			if (!((value3 == val3)
			 && (val3 != 0))) break;
			value3 = -val3;
		}
		
		/* let's try to see if the constant can be made from a simple shift of 0xFFFFFFFF */

		if (val3 > 0) {
			hb3 = highBit(val3);
			if ((1 << hb3) == (val3 + 1)) {

				/* MVN temp,  #0, making 0xffffffff */

				/* begin machineCodeAt:put: */
				aWord14 = mvnimmror(self_in_dispatchConcretize, ConcreteIPReg, 0, 0);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord14;
				self_in_dispatchConcretize;
				/* begin machineCodeAt:put: */
				aWord24 = dataOpTyperdrnrmlsr(self_in_dispatchConcretize, CmpOpcode, rd1, rn2, ConcreteIPReg, 32 - hb3);
				((self_in_dispatchConcretize->machineCode))[4 / 4] = aWord24;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 8);
				return;
			}
		}
		/* begin concretizeDataOperationCwR: */
		constant3 = ((self_in_dispatchConcretize->operands))[0];
		rn7 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd5 = 0;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord47 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord47;
		self_in_dispatchConcretize;
		instrOffset10 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset10 / 4] = ((((AL << 28) | ((0 << 25) | ((CmpOpcode << 21) | (1 << 20)))) | ((rn7 << 16) | (rd5 << 12))) | (ConcreteIPReg & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset10 + 4);
		return;

	l4:	/* end rotateable8bitSignedImmediate:ifTrue:ifFalse: */;
		return;

	case OrCqR:
		/* begin concretizeDataOperationCqR: */
		val6 = ((self_in_dispatchConcretize->operands))[0];
		rn8 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);

		/* Extra note - if ever a version of this code wants to NOT set the Set flag - Cmp must always have it set or it will pretend to be a SMALALBT and Very Bad Things might happen */

		rd6 = (((self_in_dispatchConcretize->opcode)) == CmpOpcode
			? 0
			: rn8);
		/* begin rotateable8bitImmediate:ifTrue:ifFalse: */
		if ((val6 & 0xFF) == val6) {
			/* begin machineCodeAt:put: */
			((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((1 << 25) | ((OrOpcode << 21) | (1 << 20)))) | ((rn8 << 16) | (rd6 << 12))) | ((((((usqInt) 0) >> 1) << 8) | val6) & 0xFFF));
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;

			goto l17;
		}
		for (i14 = 2; i14 <= 30; i14 += 2) {
			if ((val6 & (((0xFF << i14) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i14)))) == val6) {
				rot12 = 32 - i14;
				immediate15 = (((usqInt) val6) >> i14) | ((val6 << (32 - i14)) & 0xFFFFFFFFUL);
				/* begin machineCodeAt:put: */
				((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((1 << 25) | ((OrOpcode << 21) | (1 << 20)))) | ((rn8 << 16) | (rd6 << 12))) | ((((((usqInt) rot12) >> 1) << 8) | immediate15) & 0xFFF));
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l17;
			}
		}
		
		/* let's try to see if the constant can be made from a simple shift of 0xFFFFFFFF */

		if (val6 > 0) {
			hb6 = highBit(val6);
			if ((1 << hb6) == (val6 + 1)) {

				/* MVN temp,  #0, making 0xffffffff */

				/* begin machineCodeAt:put: */
				aWord48 = mvnimmror(self_in_dispatchConcretize, ConcreteIPReg, 0, 0);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord48;
				self_in_dispatchConcretize;
				/* begin machineCodeAt:put: */
				aWord117 = dataOpTyperdrnrmlsr(self_in_dispatchConcretize, OrOpcode, rd6, rn8, ConcreteIPReg, 32 - hb6);
				((self_in_dispatchConcretize->machineCode))[4 / 4] = aWord117;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 8);
				return;
			}
		}
		/* begin concretizeDataOperationCwR: */
		constant13 = ((self_in_dispatchConcretize->operands))[0];
		rn25 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd23 = rn25;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord64 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord64;
		self_in_dispatchConcretize;
		instrOffset25 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset25 / 4] = ((((AL << 28) | ((0 << 25) | ((OrOpcode << 21) | (1 << 20)))) | ((rn25 << 16) | (rd23 << 12))) | (ConcreteIPReg & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset25 + 4);
		return;

	l17:	/* end rotateable8bitImmediate:ifTrue:ifFalse: */;
		return;

	case SubCqR:
		/* begin concretizeSubCqR */
		word = ((self_in_dispatchConcretize->operands))[0];
		/* begin rotateable8bitImmediate:ifTrue:ifFalse: */
		if ((word & 0xFF) == word) {
			reg = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
			/* begin machineCodeAt:put: */
			aWord8 = subsrnimmror(self_in_dispatchConcretize, reg, reg, word, 0);
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord8;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;

			goto l6;
		}
		for (i11 = 2; i11 <= 30; i11 += 2) {
			if ((word & (((0xFF << i11) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i11)))) == word) {
				rot4 = 32 - i11;
				immediate4 = (((usqInt) word) >> i11) | ((word << (32 - i11)) & 0xFFFFFFFFUL);
				reg = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
				/* begin machineCodeAt:put: */
				aWord8 = subsrnimmror(self_in_dispatchConcretize, reg, reg, immediate4, rot4);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord8;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l6;
			}
		}
		
		/* before building a full load of a big constant, see if we can do an add of the constant negated */

		/* begin rotateable8bitImmediate:ifTrue:ifFalse: */
		if (((-word) & 0xFF) == (-word)) {
			immediate4 = -word;
			reg = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
			/* begin machineCodeAt:put: */
			aWord15 = addsrnimmror(self_in_dispatchConcretize, reg, reg, immediate4, 0);
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord15;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;

			goto l22;
		}
		for (i4 = 2; i4 <= 30; i4 += 2) {
			if (((-word) & (((0xFF << i4) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i4)))) == (-word)) {
				rot4 = 32 - i4;
				immediate4 = (((usqInt) (-word)) >> i4) | (((-word) << (32 - i4)) & 0xFFFFFFFFUL);
				reg = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
				/* begin machineCodeAt:put: */
				aWord15 = addsrnimmror(self_in_dispatchConcretize, reg, reg, immediate4, rot4);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord15;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l22;
			}
		}
		/* begin concretizeDataOperationCwR: */
		constant4 = ((self_in_dispatchConcretize->operands))[0];
		rn9 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd7 = rn9;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord49 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord49;
		self_in_dispatchConcretize;
		instrOffset11 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset11 / 4] = ((((AL << 28) | ((0 << 25) | ((SubOpcode << 21) | (1 << 20)))) | ((rn9 << 16) | (rd7 << 12))) | (ConcreteIPReg & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset11 + 4);
		return;

	l22:	/* end rotateable8bitImmediate:ifTrue:ifFalse: */;

	l6:	/* end rotateable8bitImmediate:ifTrue:ifFalse: */;
		return;

	case TstCqR:
		/* begin concretizeTstCqR */
		/* begin rotateable8bitImmediate:ifTrue:ifFalse: */
		constant = ((self_in_dispatchConcretize->operands))[0];
		if ((constant & 0xFF) == constant) {
			reg1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
			/* begin machineCodeAt:put: */
			aWord9 = tstrnimmror(self_in_dispatchConcretize, reg1, reg1, constant, 0);
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord9;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;

			goto l7;
		}
		for (i5 = 2; i5 <= 30; i5 += 2) {
			if ((constant & (((0xFF << i5) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i5)))) == constant) {
				rot5 = 32 - i5;
				immediate5 = (((usqInt) constant) >> i5) | ((constant << (32 - i5)) & 0xFFFFFFFFUL);
				reg1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
				/* begin machineCodeAt:put: */
				aWord9 = tstrnimmror(self_in_dispatchConcretize, reg1, reg1, immediate5, rot5);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord9;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l7;
			}
		}
		/* begin concretizeDataOperationCwR: */
		constant5 = ((self_in_dispatchConcretize->operands))[0];
		rn10 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd8 = rn10;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord50 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord50;
		self_in_dispatchConcretize;
		instrOffset12 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset12 / 4] = ((((AL << 28) | ((0 << 25) | ((TstOpcode << 21) | (1 << 20)))) | ((rn10 << 16) | (rd8 << 12))) | (ConcreteIPReg & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset12 + 4);
		return;

	l7:	/* end rotateable8bitImmediate:ifTrue:ifFalse: */;
		return;

	case XorCqR:
		/* begin concretizeInvertibleDataOperationCqR: */
		val4 = ((self_in_dispatchConcretize->operands))[0];
		rn3 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		assert(!((((self_in_dispatchConcretize->opcode)) == CmpOpcode)));
		/* begin rotateable8bitBitwiseImmediate:ifTrue:ifFalse: */
		value4 = val4;
		while (1) {
			if ((value4 & 0xFF) == value4) {
				invert2 = val4 != value4;
				/* begin machineCodeAt:put: */
				/* begin type:op:set:rn:rd:shifterOperand: */
				flagsOrOpcode6 = (invert2
					? inverseOpcodeFor(self_in_dispatchConcretize, XorOpcode)
					: XorOpcode);
				aWord10 = (((AL << 28) | ((1 << 25) | ((flagsOrOpcode6 << 21) | (1 << 20)))) | ((rn3 << 16) | (rn3 << 12))) | ((((((usqInt) 0) >> 1) << 8) | value4) & 0xFFF);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord10;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l8;
			}
			for (i6 = 2; i6 <= 30; i6 += 2) {
				if ((value4 & (((0xFF << i6) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i6)))) == value4) {
					rot6 = 32 - i6;
					immediate6 = (((usqInt) value4) >> i6) | ((value4 << (32 - i6)) & 0xFFFFFFFFUL);
					invert2 = val4 != value4;
					/* begin machineCodeAt:put: */
					/* begin type:op:set:rn:rd:shifterOperand: */
					flagsOrOpcode7 = (invert2
						? inverseOpcodeFor(self_in_dispatchConcretize, XorOpcode)
						: XorOpcode);
					aWord10 = (((AL << 28) | ((1 << 25) | ((flagsOrOpcode7 << 21) | (1 << 20)))) | ((rn3 << 16) | (rn3 << 12))) | ((((((usqInt) rot6) >> 1) << 8) | immediate6) & 0xFFF);
					((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord10;
					self_in_dispatchConcretize;
					((self_in_dispatchConcretize->machineCodeSize) = 4);
					return;

					goto l8;
				}
			}
			if (!(value4 == val4)) break;
			value4 = (val4 < 0
				? -1 - val4
				: (unsigned int)~val4);
		}
		
		/* let's try to see if the constant can be made from a simple shift of 0xFFFFFFFF */

		if (val4 > 0) {
			hb4 = highBit(val4);
			if ((1 << hb4) == (val4 + 1)) {

				/* MVN temp,  #0, making 0xffffffff */

				/* begin machineCodeAt:put: */
				aWord16 = mvnimmror(self_in_dispatchConcretize, ConcreteIPReg, 0, 0);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord16;
				self_in_dispatchConcretize;
				/* begin machineCodeAt:put: */
				aWord25 = dataOpTyperdrnrmlsr(self_in_dispatchConcretize, XorOpcode, rn3, rn3, ConcreteIPReg, 32 - hb4);
				((self_in_dispatchConcretize->machineCode))[4 / 4] = aWord25;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 8);
				return;
			}
		}
		/* begin concretizeDataOperationCqR: */
		val7 = ((self_in_dispatchConcretize->operands))[0];
		rn11 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);

		/* Extra note - if ever a version of this code wants to NOT set the Set flag - Cmp must always have it set or it will pretend to be a SMALALBT and Very Bad Things might happen */

		rd9 = (((self_in_dispatchConcretize->opcode)) == CmpOpcode
			? 0
			: rn11);
		/* begin rotateable8bitImmediate:ifTrue:ifFalse: */
		if ((val7 & 0xFF) == val7) {
			/* begin machineCodeAt:put: */
			((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((1 << 25) | ((XorOpcode << 21) | (1 << 20)))) | ((rn11 << 16) | (rd9 << 12))) | ((((((usqInt) 0) >> 1) << 8) | val7) & 0xFFF));
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;

			goto l23;
		}
		for (i15 = 2; i15 <= 30; i15 += 2) {
			if ((val7 & (((0xFF << i15) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i15)))) == val7) {
				rot13 = 32 - i15;
				immediate16 = (((usqInt) val7) >> i15) | ((val7 << (32 - i15)) & 0xFFFFFFFFUL);
				/* begin machineCodeAt:put: */
				((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((1 << 25) | ((XorOpcode << 21) | (1 << 20)))) | ((rn11 << 16) | (rd9 << 12))) | ((((((usqInt) rot13) >> 1) << 8) | immediate16) & 0xFFF));
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l23;
			}
		}
		
		/* let's try to see if the constant can be made from a simple shift of 0xFFFFFFFF */

		if (val7 > 0) {
			hb7 = highBit(val7);
			if ((1 << hb7) == (val7 + 1)) {

				/* MVN temp,  #0, making 0xffffffff */

				/* begin machineCodeAt:put: */
				aWord51 = mvnimmror(self_in_dispatchConcretize, ConcreteIPReg, 0, 0);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord51;
				self_in_dispatchConcretize;
				/* begin machineCodeAt:put: */
				aWord118 = dataOpTyperdrnrmlsr(self_in_dispatchConcretize, XorOpcode, rd9, rn11, ConcreteIPReg, 32 - hb7);
				((self_in_dispatchConcretize->machineCode))[4 / 4] = aWord118;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 8);
				return;
			}
		}
		/* begin concretizeDataOperationCwR: */
		constant14 = ((self_in_dispatchConcretize->operands))[0];
		rn26 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd24 = rn26;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord65 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord65;
		self_in_dispatchConcretize;
		instrOffset26 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset26 / 4] = ((((AL << 28) | ((0 << 25) | ((XorOpcode << 21) | (1 << 20)))) | ((rn26 << 16) | (rd24 << 12))) | (ConcreteIPReg & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset26 + 4);
		return;

	l23:	/* end rotateable8bitImmediate:ifTrue:ifFalse: */;
		return;

	l8:	/* end rotateable8bitBitwiseImmediate:ifTrue:ifFalse: */;
		return;

	case AddCwR:
		/* begin concretizeDataOperationCwR: */
		constant6 = ((self_in_dispatchConcretize->operands))[0];
		rn12 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd10 = rn12;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord52 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord52;
		self_in_dispatchConcretize;
		instrOffset13 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset13 / 4] = ((((AL << 28) | ((0 << 25) | ((AddOpcode << 21) | (1 << 20)))) | ((rn12 << 16) | (rd10 << 12))) | (ConcreteIPReg & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset13 + 4);
		return;

	case AndCwR:
		/* begin concretizeDataOperationCwR: */
		constant7 = ((self_in_dispatchConcretize->operands))[0];
		rn13 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd11 = rn13;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord53 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord53;
		self_in_dispatchConcretize;
		instrOffset14 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset14 / 4] = ((((AL << 28) | ((0 << 25) | ((AndOpcode << 21) | (1 << 20)))) | ((rn13 << 16) | (rd11 << 12))) | (ConcreteIPReg & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset14 + 4);
		return;

	case CmpCwR:
		/* begin concretizeDataOperationCwR: */
		constant8 = ((self_in_dispatchConcretize->operands))[0];
		rn14 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd12 = 0;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord54 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord54;
		self_in_dispatchConcretize;
		instrOffset15 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset15 / 4] = ((((AL << 28) | ((0 << 25) | ((CmpOpcode << 21) | (1 << 20)))) | ((rn14 << 16) | (rd12 << 12))) | (ConcreteIPReg & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset15 + 4);
		return;

	case OrCwR:
		/* begin concretizeDataOperationCwR: */
		constant9 = ((self_in_dispatchConcretize->operands))[0];
		rn15 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd13 = rn15;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord55 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord55;
		self_in_dispatchConcretize;
		instrOffset16 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset16 / 4] = ((((AL << 28) | ((0 << 25) | ((OrOpcode << 21) | (1 << 20)))) | ((rn15 << 16) | (rd13 << 12))) | (ConcreteIPReg & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset16 + 4);
		return;

	case SubCwR:
		/* begin concretizeDataOperationCwR: */
		constant10 = ((self_in_dispatchConcretize->operands))[0];
		rn16 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd14 = rn16;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord56 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord56;
		self_in_dispatchConcretize;
		instrOffset17 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset17 / 4] = ((((AL << 28) | ((0 << 25) | ((SubOpcode << 21) | (1 << 20)))) | ((rn16 << 16) | (rd14 << 12))) | (ConcreteIPReg & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset17 + 4);
		return;

	case XorCwR:
		/* begin concretizeDataOperationCwR: */
		constant11 = ((self_in_dispatchConcretize->operands))[0];
		rn17 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd15 = rn17;
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord57 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord57;
		self_in_dispatchConcretize;
		instrOffset18 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset18 / 4] = ((((AL << 28) | ((0 << 25) | ((XorOpcode << 21) | (1 << 20)))) | ((rn17 << 16) | (rd15 << 12))) | (ConcreteIPReg & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset18 + 4);
		return;

	case AddRR:
		/* begin concretizeDataOperationRR: */
		srcReg9 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		rn18 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd16 = rn18;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((0 << 25) | ((AddOpcode << 21) | (1 << 20)))) | ((rn18 << 16) | (rd16 << 12))) | (srcReg9 & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case AndRR:
		/* begin concretizeDataOperationRR: */
		srcReg10 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		rn19 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd17 = rn19;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((0 << 25) | ((AndOpcode << 21) | (1 << 20)))) | ((rn19 << 16) | (rd17 << 12))) | (srcReg10 & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case CmpRR:
		/* begin concretizeDataOperationRR: */
		srcReg11 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		rn20 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd18 = 0;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((0 << 25) | ((CmpOpcode << 21) | (1 << 20)))) | ((rn20 << 16) | (rd18 << 12))) | (srcReg11 & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case OrRR:
		/* begin concretizeDataOperationRR: */
		srcReg12 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		rn21 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd19 = rn21;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((0 << 25) | ((OrOpcode << 21) | (1 << 20)))) | ((rn21 << 16) | (rd19 << 12))) | (srcReg12 & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case SubRR:
		/* begin concretizeDataOperationRR: */
		srcReg13 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		rn22 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd20 = rn22;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((0 << 25) | ((SubOpcode << 21) | (1 << 20)))) | ((rn22 << 16) | (rd20 << 12))) | (srcReg13 & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case XorRR:
		/* begin concretizeDataOperationRR: */
		srcReg14 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		rn23 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		rd21 = rn23;
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((0 << 25) | ((XorOpcode << 21) | (1 << 20)))) | ((rn23 << 16) | (rd21 << 12))) | (srcReg14 & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case AddRdRd:
		/* begin concretizeAddRdRd */
		regRHS = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regLHS = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = (((3996125952UL | (regLHS << 16)) | (regLHS << 12)) | regRHS);
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case CmpRdRd:
		/* begin concretizeCmpRdRd */
		regA = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regB = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = ((4004776768UL | (regB << 12)) | regA);
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case DivRdRd:
		/* begin concretizeDivRdRd */
		regRHS1 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regLHS1 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = (((4001368832UL | (regLHS1 << 16)) | (regLHS1 << 12)) | regRHS1);
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case MulRdRd:
		/* begin concretizeMulRdRd */
		regRHS2 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regLHS2 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = (((3995077376UL | (regLHS2 << 16)) | (regLHS2 << 12)) | regRHS2);
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case SubRdRd:
		/* begin concretizeSubRdRd */
		regRHS3 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		regLHS3 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = (((3996126016UL | (regLHS3 << 16)) | (regLHS3 << 12)) | regRHS3);
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case SqrtRd:
		/* begin concretizeSqrtRd */
		regLHS4 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = ((4004580288UL | (regLHS4 << 12)) | regLHS4);
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case NegateR:
		/* begin concretizeNegateR */

		/* RSB destReg, srcReg, #0 */

		reg4 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = (((AL << 28) | ((1 << 25) | ((RsbOpcode << 21) | (0 << 20)))) | ((reg4 << 16) | (reg4 << 12)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case LoadEffectiveAddressMwrR:
		/* begin concretizeLoadEffectiveAddressMwrR */
		offset2 = ((self_in_dispatchConcretize->operands))[0];
		srcReg1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		destReg = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		/* begin rotateable8bitImmediate:ifTrue:ifFalse: */
		if ((offset2 & 0xFF) == offset2) {
			/* begin machineCodeAt:put: */
			aWord18 = addrnimmror(self_in_dispatchConcretize, destReg, srcReg1, offset2, 0 << 1);
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord18;
			self_in_dispatchConcretize;
			(self_in_dispatchConcretize->machineCodeSize) = 4;

			goto l9;
		}
		for (i7 = 2; i7 <= 30; i7 += 2) {
			if ((offset2 & (((0xFF << i7) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i7)))) == offset2) {
				rot7 = 32 - i7;
				immediate7 = (((usqInt) offset2) >> i7) | ((offset2 << (32 - i7)) & 0xFFFFFFFFUL);
				/* begin machineCodeAt:put: */
				aWord18 = addrnimmror(self_in_dispatchConcretize, destReg, srcReg1, immediate7, rot7 << 1);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord18;
				self_in_dispatchConcretize;
				(self_in_dispatchConcretize->machineCodeSize) = 4;

				goto l9;
			}
		}
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord35 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord35;
		self_in_dispatchConcretize;
		instrOffset = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		aWord17 = addrnrm(self_in_dispatchConcretize, destReg, srcReg1, ConcreteIPReg);
		((self_in_dispatchConcretize->machineCode))[16 / 4] = aWord17;
		self_in_dispatchConcretize;
		(self_in_dispatchConcretize->machineCodeSize) = instrOffset + 4;

	l9:	/* end rotateable8bitImmediate:ifTrue:ifFalse: */;
		(self_in_dispatchConcretize->machineCodeSize);
		return;

	case ArithmeticShiftRightCqR:
		/* begin concretizeArithmeticShiftRightCqR */
		distance = (((((self_in_dispatchConcretize->operands))[0]) < 0x1F) ? (((self_in_dispatchConcretize->operands))[0]) : 0x1F);

		/* cond 000 1101 0 0000 dest dist -100 srcR */

		reg5 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((0 << 25) | ((MoveOpcode << 21) | (1 << 20)))) | ((0 << 16) | (reg5 << 12))) | (((distance << 7) | (64 | reg5)) & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case LogicalShiftRightCqR:
		/* begin concretizeLogicalShiftRightCqR */
		distance1 = (((((self_in_dispatchConcretize->operands))[0]) < 0x1F) ? (((self_in_dispatchConcretize->operands))[0]) : 0x1F);

		/* cond 000 1101 0 0000 dest dist -010 srcR */

		reg6 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((0 << 25) | ((MoveOpcode << 21) | (1 << 20)))) | ((0 << 16) | (reg6 << 12))) | (((distance1 << 7) | (32 | reg6)) & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case LogicalShiftLeftCqR:
		/* begin concretizeLogicalShiftLeftCqR */
		distance2 = (((((self_in_dispatchConcretize->operands))[0]) < 0x1F) ? (((self_in_dispatchConcretize->operands))[0]) : 0x1F);

		/* cond 000 1101 0 0000 dest dista 000 srcR */

		reg7 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((0 << 25) | ((MoveOpcode << 21) | (1 << 20)))) | ((0 << 16) | (reg7 << 12))) | (((distance2 << 7) | reg7) & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case ArithmeticShiftRightRR:
		/* begin concretizeArithmeticShiftRightRR */
		distReg = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);

		/* cond 000 1101 0 0000 destR distR 0101 srcR */

		destReg7 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((0 << 25) | ((MoveOpcode << 21) | (1 << 20)))) | ((0 << 16) | (destReg7 << 12))) | (((distReg << 8) | (80 | destReg7)) & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case LogicalShiftLeftRR:
		/* begin concretizeLogicalShiftLeftRR */
		distReg1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);

		/* cond 000 1101 0 0000 dest dist 0001 srcR */

		destReg8 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((0 << 25) | ((MoveOpcode << 21) | (1 << 20)))) | ((0 << 16) | (destReg8 << 12))) | (((distReg1 << 8) | (16 | destReg8)) & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case LogicalShiftRightRR:
		/* begin concretizeLogicalShiftRightRR */
		distReg2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);

		/* cond 000 1101 0 0000 dest dist 0011 srcR */

		destReg9 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[0 / 4] = ((((AL << 28) | ((0 << 25) | ((MoveOpcode << 21) | (1 << 20)))) | ((0 << 16) | (destReg9 << 12))) | (((distReg2 << 8) | (48 | destReg9)) & 0xFFF));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case SMULL:
		concretizeSMULL(self_in_dispatchConcretize);
		return;

	case CMPSMULL:
		concretizeCMPSMULL(self_in_dispatchConcretize);
		return;

	case MSR:
		concretizeMSR(self_in_dispatchConcretize);
		return;

	case MoveCqR:
		/* begin concretizeMoveCqR */
		word2 = ((self_in_dispatchConcretize->operands))[0];
		reg3 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		/* begin rotateable8bitImmediate:ifTrue:ifFalse: */
		if ((word2 & 0xFF) == word2) {
			/* begin machineCodeAt:put: */
			aWord36 = movimmror(self_in_dispatchConcretize, reg3, word2, 0);
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord36;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;

			goto l14;
		}
		for (i12 = 2; i12 <= 30; i12 += 2) {
			if ((word2 & (((0xFF << i12) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i12)))) == word2) {
				rot9 = 32 - i12;
				immediate12 = (((usqInt) word2) >> i12) | ((word2 << (32 - i12)) & 0xFFFFFFFFUL);
				/* begin machineCodeAt:put: */
				aWord36 = movimmror(self_in_dispatchConcretize, reg3, immediate12, rot9);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord36;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l14;
			}
		}
		if (word2 < 0) {
			invVal = -1 - word2;
		}
		else {
			invVal = (unsigned int)~word2;
		}
		/* begin rotateable8bitImmediate:ifTrue:ifFalse: */
		if ((invVal & 0xFF) == invVal) {
			/* begin machineCodeAt:put: */
			aWord114 = mvnimmror(self_in_dispatchConcretize, reg3, invVal, 0);
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord114;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;

			goto l24;
		}
		for (i9 = 2; i9 <= 30; i9 += 2) {
			if ((invVal & (((0xFF << i9) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i9)))) == invVal) {
				rot9 = 32 - i9;
				immediate12 = (((usqInt) invVal) >> i9) | ((invVal << (32 - i9)) & 0xFFFFFFFFUL);
				/* begin machineCodeAt:put: */
				aWord114 = mvnimmror(self_in_dispatchConcretize, reg3, immediate12, rot9);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord114;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l24;
			}
		}
		((self_in_dispatchConcretize->machineCodeSize) = loadCwInto(self_in_dispatchConcretize, concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1])));
		return;

	l24:	/* end rotateable8bitImmediate:ifTrue:ifFalse: */;

	l14:	/* end rotateable8bitImmediate:ifTrue:ifFalse: */;
		return;

	case MoveCwR:
		((self_in_dispatchConcretize->machineCodeSize) = loadCwInto(self_in_dispatchConcretize, concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1])));
		return;

	case MoveRR:
		/* begin concretizeMoveRR */
		srcReg2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);

		/* cond 000 1101 0 0000 dest 0000 0000 srcR */

		destReg1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		/* begin machineCodeAt:put: */
		aWord19 = movrn(self_in_dispatchConcretize, destReg1, srcReg2);
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord19;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case MoveAwR:
		/* begin concretizeMoveAwR */
		srcAddr = ((self_in_dispatchConcretize->operands))[0];
		destReg10 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		if ((srcAddr != null)
		 && ((srcAddr >= (varBaseAddress()))
		 && ((srcAddr - (varBaseAddress())) < (1 << 12)))) {
			/* begin machineCodeAt:put: */
			aWord58 = ldrrnplusImm(self_in_dispatchConcretize, destReg10, ConcreteVarBaseReg, srcAddr - (varBaseAddress()));
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord58;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;
		}
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord210 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord210;
		self_in_dispatchConcretize;
		instrOffset19 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		aWord119 = ldrrnplusImm(self_in_dispatchConcretize, destReg10, ConcreteIPReg, 0);
		((self_in_dispatchConcretize->machineCode))[instrOffset19 / 4] = aWord119;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset19 + 4);
		return;

	case MoveRAw:
		/* begin concretizeMoveRAw */
		srcReg15 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		destAddr = ((self_in_dispatchConcretize->operands))[1];
		if ((destAddr != null)
		 && ((destAddr >= (varBaseAddress()))
		 && ((destAddr - (varBaseAddress())) < (1 << 12)))) {
			/* begin machineCodeAt:put: */
			aWord59 = strrnplusImm(self_in_dispatchConcretize, srcReg15, ConcreteVarBaseReg, destAddr - (varBaseAddress()));
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord59;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;
		}
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord211 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord211;
		self_in_dispatchConcretize;
		instrOffset20 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		aWord120 = strrnplusImm(self_in_dispatchConcretize, srcReg15, ConcreteIPReg, 0);
		((self_in_dispatchConcretize->machineCode))[instrOffset20 / 4] = aWord120;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset20 + 4);
		return;

	case MoveMbrR:
		/* begin concretizeMoveMbrR */
		offset31 = ((self_in_dispatchConcretize->operands))[0];
		srcReg16 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		destReg11 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		/* begin is12BitValue:ifTrue:ifFalse: */
		if ((abs(offset31)) <= 0xFFF) {

			/* (2 raisedTo: 12)-1 */

			if (offset31 >= 0) {
				/* begin machineCodeAt:put: */
				aWord60 = ldrbrnplusimm(self_in_dispatchConcretize, destReg11, srcReg16, 1, offset31);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord60;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l19;
			}
			else {
				immediate17 = abs(offset31);
				/* begin machineCodeAt:put: */
				aWord60 = ldrbrnplusimm(self_in_dispatchConcretize, destReg11, srcReg16, 0, immediate17);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord60;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l19;
			}
		}
		else {
			if ((offset31 != null)
			 && ((offset31 >= (varBaseAddress()))
			 && ((offset31 - (varBaseAddress())) < (1 << 12)))) {
				/* begin machineCodeAt:put: */
				aWord121 = addsrnimmror(self_in_dispatchConcretize, ConcreteIPReg, ConcreteVarBaseReg, offset31 - (varBaseAddress()), 0);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord121;
				self_in_dispatchConcretize;
				instrOffset21 = 4;
			}
			else {
				/* begin moveCw:intoR: */
				assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
				assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
				/* begin machineCodeAt:put: */
				aWord310 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
					? 1
					: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord310;
				self_in_dispatchConcretize;
				instrOffset21 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
			}
			/* begin machineCodeAt:put: */
			aWord212 = ldrbrnrm(self_in_dispatchConcretize, destReg11, srcReg16, ConcreteIPReg);
			((self_in_dispatchConcretize->machineCode))[instrOffset21 / 4] = aWord212;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = instrOffset21 + 4);
			return;

			goto l19;
		}
	l19:	/* end is12BitValue:ifTrue:ifFalse: */;
		return;

	case MoveRMbr:
		/* begin concretizeMoveRMbr */
		srcReg17 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		offset32 = ((self_in_dispatchConcretize->operands))[1];
		baseReg1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		/* begin is12BitValue:ifTrue:ifFalse: */
		if ((abs(offset32)) <= 0xFFF) {

			/* (2 raisedTo: 12)-1 */

			if (offset32 >= 0) {
				/* begin machineCodeAt:put: */
				aWord61 = strbrnplusimm(self_in_dispatchConcretize, srcReg17, baseReg1, 1, offset32);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord61;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l20;
			}
			else {
				immediate18 = abs(offset32);
				/* begin machineCodeAt:put: */
				aWord61 = strbrnplusimm(self_in_dispatchConcretize, srcReg17, baseReg1, 0, immediate18);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord61;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l20;
			}
		}
		else {
			if ((offset32 != null)
			 && ((offset32 >= (varBaseAddress()))
			 && ((offset32 - (varBaseAddress())) < (1 << 12)))) {
				/* begin machineCodeAt:put: */
				aWord122 = addsrnimmror(self_in_dispatchConcretize, ConcreteIPReg, ConcreteVarBaseReg, offset32 - (varBaseAddress()), 0);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord122;
				self_in_dispatchConcretize;
				instrOffset22 = 4;
			}
			else {
				/* begin moveCw:intoR: */
				assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
				assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
				/* begin machineCodeAt:put: */
				aWord311 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
					? 1
					: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord311;
				self_in_dispatchConcretize;
				instrOffset22 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
			}
			/* begin machineCodeAt:put: */
			aWord213 = strbrnrm(self_in_dispatchConcretize, srcReg17, baseReg1, ConcreteIPReg);
			((self_in_dispatchConcretize->machineCode))[instrOffset22 / 4] = aWord213;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = instrOffset22 + 4);
			return;

			goto l20;
		}
	l20:	/* end is12BitValue:ifTrue:ifFalse: */;
		return;

	case MoveM16rR:
		/* begin concretizeMoveM16rR */
		offset3 = ((self_in_dispatchConcretize->operands))[0];
		srcReg3 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		destReg2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		/* begin is8BitValue:ifTrue:ifFalse: */
		if ((abs(offset3)) <= 0xFF) {

			/* (2 raisedTo: 8)-1 */

			if (offset3 >= 0) {
				/* begin machineCodeAt:put: */
				aWord20 = ldrhrnplusimm(self_in_dispatchConcretize, destReg2, srcReg3, 1, offset3);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord20;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

			}
			else {
				immediate8 = abs(offset3);
				/* begin machineCodeAt:put: */
				aWord20 = ldrhrnplusimm(self_in_dispatchConcretize, destReg2, srcReg3, 0, immediate8);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord20;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

			}
		}
		else {
			/* begin moveCw:intoR: */
			assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
			assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
			/* begin machineCodeAt:put: */
			aWord37 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
				? 1
				: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord37;
			self_in_dispatchConcretize;
			instrOffset1 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
			/* begin machineCodeAt:put: */
			aWord110 = ldrhrnrm(self_in_dispatchConcretize, destReg2, srcReg3, ConcreteIPReg);
			((self_in_dispatchConcretize->machineCode))[instrOffset1 / 4] = aWord110;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = instrOffset1 + 4);
			return;
		}
		self_in_dispatchConcretize;
		return;

	case MoveM64rRd:
		/* begin concretizeMoveM64rRd */
		offset4 = ((self_in_dispatchConcretize->operands))[0];
		u1 = (offset4 > 0
			? 1
			: 0);
		srcReg4 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		destReg3 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		((self_in_dispatchConcretize->machineCode))[0] = ((((3977251584UL | (srcReg4 << 16)) | (destReg3 << 12)) | (u1 << 23)) | (((usqInt) offset4) >> 2));
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case MoveMwrR:
		/* begin concretizeMoveMwrR */
		offset5 = ((self_in_dispatchConcretize->operands))[0];
		srcReg5 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		destReg4 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		/* begin is12BitValue:ifTrue:ifFalse: */
		if ((abs(offset5)) <= 0xFFF) {

			/* (2 raisedTo: 12)-1 */

			if (offset5 >= 0) {
				/* begin machineCodeAt:put: */
				aWord26 = ldrrnplusimm(self_in_dispatchConcretize, destReg4, srcReg5, 1, offset5);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord26;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l10;
			}
			else {
				immediate9 = abs(offset5);
				/* begin machineCodeAt:put: */
				aWord26 = ldrrnplusimm(self_in_dispatchConcretize, destReg4, srcReg5, 0, immediate9);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord26;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l10;
			}
		}
		else {
			/* begin moveCw:intoR: */
			assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
			assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
			/* begin machineCodeAt:put: */
			aWord38 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
				? 1
				: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord38;
			self_in_dispatchConcretize;
			instrOffset2 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
			/* begin machineCodeAt:put: */
			aWord111 = ldrrnrm(self_in_dispatchConcretize, destReg4, srcReg5, ConcreteIPReg);
			((self_in_dispatchConcretize->machineCode))[instrOffset2 / 4] = aWord111;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = instrOffset2 + 4);
			return;

			goto l10;
		}
	l10:	/* end is12BitValue:ifTrue:ifFalse: */;
		return;

	case MoveXbrRR:
		/* begin concretizeMoveXbrRR */

		/* index is number of *bytes* */

		index = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		base = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);

		/* LDRB	dest, [base, +index, LSL #0] */
		/* cond 011 1100 1 base dest 00000 00 0 inde */

		dest = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		/* begin machineCodeAt:put: */
		aWord27 = ldrbrnrm(self_in_dispatchConcretize, dest, base, index);
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord27;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case MoveRXbrR:
		/* begin concretizeMoveRXbrR */
		src = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		index1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);

		/* str	b	src, [base, +index, LSL #0] */
		/* cond 011 1100 0 base srcR 00000 00 0 index */

		base1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		/* begin machineCodeAt:put: */
		aWord28 = strbrnrm(self_in_dispatchConcretize, src, base1, index1);
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord28;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case MoveXwrRR:
		/* begin concretizeMoveXwrRR */
		index2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		base2 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);

		/* LDR	dest, [base, +index, LSL #2] */
		/* cond 011 1100 1 base dest 00010 00 0 inde bulit by lowest level generator so we can do the lsl #2 on the index register */

		dest1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		/* begin machineCodeAt:put: */
		aWord29 = memMxrregbasepubwlrmLsl2(self_in_dispatchConcretize, AL, dest1, base2, 1, 1, 0, 0, 1, index2);
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord29;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case MoveRXwrR:
		/* begin concretizeMoveRXwrR */
		src1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);

		/* index is number of *words* = 4* bytes */

		index3 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);

		/* str		src, [base, +index, LSL #2] */
		/* cond 011 1100 0 base srcR 00010 00 0 inde */

		base3 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		/* begin machineCodeAt:put: */
		aWord30 = memMxrregbasepubwlrmLsl2(self_in_dispatchConcretize, AL, src1, base3, 1, 1, 0, 0, 0, index3);
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord30;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case MoveRMwr:
		/* begin concretizeMoveRMwr */
		srcReg6 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		offset6 = ((self_in_dispatchConcretize->operands))[1];
		baseReg = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		/* begin is12BitValue:ifTrue:ifFalse: */
		if ((abs(offset6)) <= 0xFFF) {

			/* (2 raisedTo: 12)-1 */

			if (offset6 >= 0) {
				/* begin machineCodeAt:put: */
				aWord31 = strrnplusimm(self_in_dispatchConcretize, srcReg6, baseReg, 1, offset6);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord31;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l11;
			}
			else {
				immediate10 = abs(offset6);
				/* begin machineCodeAt:put: */
				aWord31 = strrnplusimm(self_in_dispatchConcretize, srcReg6, baseReg, 0, immediate10);
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord31;
				self_in_dispatchConcretize;
				((self_in_dispatchConcretize->machineCodeSize) = 4);
				return;

				goto l11;
			}
		}
		else {
			/* begin moveCw:intoR: */
			assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
			assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
			/* begin machineCodeAt:put: */
			aWord39 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
				? 1
				: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord39;
			self_in_dispatchConcretize;
			instrOffset3 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
			/* begin machineCodeAt:put: */
			aWord112 = strrnrm(self_in_dispatchConcretize, srcReg6, baseReg, ConcreteIPReg);
			((self_in_dispatchConcretize->machineCode))[instrOffset3 / 4] = aWord112;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = instrOffset3 + 4);
			return;

			goto l11;
		}
	l11:	/* end is12BitValue:ifTrue:ifFalse: */;
		return;

	case MoveRdM64r:
		/* begin concretizeMoveRdM64r */
		offset7 = ((self_in_dispatchConcretize->operands))[1];
		u4 = (offset7 > 0
			? 1
			: 0);
		dstReg1 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[2]);
		fpReg = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		((self_in_dispatchConcretize->machineCode))[0] = ((((3976203008UL | (dstReg1 << 16)) | (fpReg << 12)) | (u4 << 23)) | (((usqInt) offset7) >> 2));
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case PopR:
		/* begin concretizePopR */

		/* LDR destReg, [SP], #4 */

		destReg5 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		/* begin machineCodeAt:put: */
		aWord32 = popR(self_in_dispatchConcretize, destReg5);
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord32;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case PushR:
		/* begin concretizePushR */

		/* cond | 010 | 1001 | 0 | -Rn- | -Rd- | 0000 0000 0100 */
		/* STR srcReg, [sp, #-4] */

		srcReg7 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		/* begin machineCodeAt:put: */
		aWord33 = pushR(self_in_dispatchConcretize, srcReg7);
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord33;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = 4);
		return;

	case PushCq:
		/* begin concretizePushCq */
		word1 = ((self_in_dispatchConcretize->operands))[0];
		/* begin rotateable8bitBitwiseImmediate:ifTrue:ifFalse: */
		value5 = word1;
		while (1) {
			if ((value5 & 0xFF) == value5) {
				invert3 = word1 != value5;
				/* begin machineCodeAt:put: */
				aWord34 = (invert3
					? mvnimmror(self_in_dispatchConcretize, ConcreteIPReg, value5, 0)
					: movimmror(self_in_dispatchConcretize, ConcreteIPReg, value5, 0));
				((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord34;
				self_in_dispatchConcretize;
				instrOffset4 = 4;

				goto l12;
			}
			for (i8 = 2; i8 <= 30; i8 += 2) {
				if ((value5 & (((0xFF << i8) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i8)))) == value5) {
					rot8 = 32 - i8;
					immediate11 = (((usqInt) value5) >> i8) | ((value5 << (32 - i8)) & 0xFFFFFFFFUL);
					invert3 = word1 != value5;
					/* begin machineCodeAt:put: */
					aWord34 = (invert3
						? mvnimmror(self_in_dispatchConcretize, ConcreteIPReg, immediate11, rot8)
						: movimmror(self_in_dispatchConcretize, ConcreteIPReg, immediate11, rot8));
					((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord34;
					self_in_dispatchConcretize;
					instrOffset4 = 4;

					goto l12;
				}
			}
			if (!(value5 == word1)) break;
			value5 = (word1 < 0
				? -1 - word1
				: (unsigned int)~word1);
		}
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord40 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord40;
		self_in_dispatchConcretize;
		instrOffset4 = ((self_in_dispatchConcretize->machineCodeSize) = 4);

	l12:	/* end rotateable8bitBitwiseImmediate:ifTrue:ifFalse: */;
		/* begin machineCodeAt:put: */
		aWord113 = pushR(self_in_dispatchConcretize, ConcreteIPReg);
		((self_in_dispatchConcretize->machineCode))[instrOffset4 / 4] = aWord113;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset4 + 4);
		return;

	case PushCw:
		/* begin concretizePushCw */
		word3 = ((self_in_dispatchConcretize->operands))[0];
		if (((addressIsInInstructions(((AbstractInstruction *) word3)))
		 || ((((AbstractInstruction *) word3)) == (methodLabel())))
		 || (addressIsInCurrentCompilation(word3))) {
			instrOffset5 = loadCwInto(self_in_dispatchConcretize, ConcreteIPReg);
		}
		else {
			/* begin rotateable8bitBitwiseImmediate:ifTrue:ifFalse: */
			value6 = word3;
			while (1) {
				if ((value6 & 0xFF) == value6) {
					invert4 = word3 != value6;
					/* begin machineCodeAt:put: */
					aWord41 = (invert4
						? mvnimmror(self_in_dispatchConcretize, ConcreteIPReg, value6, 0)
						: movimmror(self_in_dispatchConcretize, ConcreteIPReg, value6, 0));
					((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord41;
					self_in_dispatchConcretize;
					instrOffset5 = 4;

					goto l15;
				}
				for (i10 = 2; i10 <= 30; i10 += 2) {
					if ((value6 & (((0xFF << i10) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i10)))) == value6) {
						rot10 = 32 - i10;
						immediate13 = (((usqInt) value6) >> i10) | ((value6 << (32 - i10)) & 0xFFFFFFFFUL);
						invert4 = word3 != value6;
						/* begin machineCodeAt:put: */
						aWord41 = (invert4
							? mvnimmror(self_in_dispatchConcretize, ConcreteIPReg, immediate13, rot10)
							: movimmror(self_in_dispatchConcretize, ConcreteIPReg, immediate13, rot10));
						((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord41;
						self_in_dispatchConcretize;
						instrOffset5 = 4;

						goto l15;
					}
				}
				if (!(value6 == word3)) break;
				value6 = (word3 < 0
					? -1 - word3
					: (unsigned int)~word3);
			}
			instrOffset5 = loadCwInto(self_in_dispatchConcretize, ConcreteIPReg);

		l15:	/* end rotateable8bitBitwiseImmediate:ifTrue:ifFalse: */;
		}
		/* begin machineCodeAt:put: */
		aWord115 = pushR(self_in_dispatchConcretize, ConcreteIPReg);
		((self_in_dispatchConcretize->machineCode))[instrOffset5 / 4] = aWord115;
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset5 + 4);
		return;

	case PrefetchAw:
		/* begin concretizePrefetchAw */
		addressOperand = ((self_in_dispatchConcretize->operands))[0];
		if ((addressOperand != null)
		 && ((addressOperand >= (varBaseAddress()))
		 && ((addressOperand - (varBaseAddress())) < (1 << 12)))) {
			/* begin machineCodeAt:put: */
			/* begin pld:plus:offset: */
			immediate19 = addressOperand - (varBaseAddress());
			aWord62 = 4115722240UL | ((ConcreteVarBaseReg << 16) | ((1 << 23) | immediate19));
			((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord62;
			self_in_dispatchConcretize;
			((self_in_dispatchConcretize->machineCodeSize) = 4);
			return;
		}
		/* begin moveCw:intoR: */
		assert(addressIsInCurrentCompilation((((self_in_dispatchConcretize->dependent))->address)));
		assert((abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8))) < (1 << 12));
		/* begin machineCodeAt:put: */
		aWord123 = ldrrnplusimm(self_in_dispatchConcretize, ConcreteIPReg, PC, (((((self_in_dispatchConcretize->dependent))->address)) >= (((self_in_dispatchConcretize->address)) + 8)
			? 1
			: 0), abs(((((self_in_dispatchConcretize->dependent))->address)) - (((self_in_dispatchConcretize->address)) + 8)));
		((self_in_dispatchConcretize->machineCode))[0 / 4] = aWord123;
		self_in_dispatchConcretize;
		instrOffset23 = ((self_in_dispatchConcretize->machineCodeSize) = 4);
		/* begin machineCodeAt:put: */
		((self_in_dispatchConcretize->machineCode))[instrOffset23 / 4] = (4115722240UL | ((ConcreteIPReg << 16) | ((1 << 23) | 0)));
		self_in_dispatchConcretize;
		((self_in_dispatchConcretize->machineCodeSize) = instrOffset23 + 4);
		return;

	case ConvertRRd:
		/* begin concretizeConvertRRd */
		srcReg8 = concreteRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[0]);
		destReg6 = concreteDPFPRegister(self_in_dispatchConcretize, ((self_in_dispatchConcretize->operands))[1]);
		((self_in_dispatchConcretize->machineCode))[0] = (fmsrFromto(self_in_dispatchConcretize, srcReg8, 9));
		((self_in_dispatchConcretize->machineCode))[1] = (fsitodFromto(self_in_dispatchConcretize, 9, destReg6));
		((self_in_dispatchConcretize->machineCodeSize) = 8);
		return;

	default:
		error("Case not found and no otherwise clause");
	}
	return;
}


/*	FMSR or VMSR instruction to move a value from an ARM reg to an fpu double
	register ready for conversion
	ARM_ARM v5 DDI 01001.pdf pp. C4-68
 */
/*	the dest reg bits are spread out a little */

	/* CogARMCompiler>>#fmsrFrom:to: */
static sqInt
fmsrFromto(AbstractInstruction * self_in_fmsrFromto, sqInt regA, sqInt regB)
{
    sqInt destReg;

	destReg = ((((usqInt) regB) >> 1) << 16) | ((regB & 1) << 7);
	return (3992979984UL | (regA << 12)) | destReg;
}


/*	FSITOD or VCVT instruction to move convert an integer value to an fpu
	double ARM_ARM v5 DDI 01001.pdf pp. C4-95
 */
/*	the src reg bits are spread out a little */

	/* CogARMCompiler>>#fsitodFrom:to: */
static sqInt
fsitodFromto(AbstractInstruction * self_in_fsitodFromto, sqInt regA, sqInt regB)
{
    sqInt srcReg;

	srcReg = (((usqInt) regA) >> 1) | ((regA & 1) << 5);
	return (4005039040UL | srcReg) | (regB << 12);
}


/*	Answer if CallFull and/or JumpFull are relative and hence need relocating
	on method
	compation. If so, they are annotated with IsRelativeCall in methods and
	relocated in
	relocateIfCallOrMethodReference:mcpc:delta: */

	/* CogARMCompiler>>#fullCallsAreRelative */
static sqInt
fullCallsAreRelative(AbstractInstruction * self_in_fullCallsAreRelative)
{
	return 0;
}


/*	ARM doesn't push the first 4 arguments. Now, currently Cog doesn't use
	more than 4 args so we should never need to push any - but just in case
	we'll check for it
 */

	/* CogARMCompiler>>#genAlignCStackSavingRegisters:numArgs:wordAlignment: */
static sqInt
genAlignCStackSavingRegistersnumArgswordAlignment(AbstractInstruction * self_in_genAlignCStackSavingRegistersnumArgswordAlignment, sqInt saveRegs, sqInt numArgs, sqInt alignment)
{
    sqInt delta;
    sqInt wordsPushedModAlignment;

	wordsPushedModAlignment = (((saveRegs
	? numberOfSaveableRegisters(self_in_genAlignCStackSavingRegistersnumArgswordAlignment)
	: 0)) + ((numArgs > 4
	? numArgs - 4
	: 0))) % alignment;
	if (wordsPushedModAlignment != 0) {
		delta = alignment - wordsPushedModAlignment;
		/* begin SubCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(delta * 4, genoperandoperand(SubCqR, delta * 4, SPReg));
	}
	return 0;
}


/*	Currently no instruction level support for divide on ARM. See also
	#canDivQuoRem 
 */

	/* CogARMCompiler>>#genDivR:R:Quo:Rem: */
static AbstractInstruction *
genDivRRQuoRem(AbstractInstruction * self_in_genDivRRQuoRem, sqInt abstractRegDivisor, sqInt abstractRegDividend, sqInt abstractRegQuotient, sqInt abstractRegRemainder)
{
	return self_in_genDivRRQuoRem;
}


/*	create a tiny leaf function that just returns the SP in r0 */

	/* CogARMCompiler>>#genGetLeafCallStackPointerFunction */
static AbstractInstruction *
genGetLeafCallStackPointerFunction(AbstractInstruction * self_in_genGetLeafCallStackPointerFunction)
{
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SP, R0);
	/* begin RetN: */
	genoperand(RetN, 0);
	return self_in_genGetLeafCallStackPointerFunction;
}


/*	Load the stack pointer register with that of the C stack, effecting
	a switch to the C stack. Used when machine code calls into the
	CoInterpreter run-time (e.g. to invoke interpreter primitives). */

	/* CogARMCompiler>>#genLoadCStackPointer */
static sqInt
genLoadCStackPointer(AbstractInstruction * self_in_genLoadCStackPointer)
{
    sqInt address;

	/* begin MoveAw:R: */
	address = cStackPointerAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, SPReg));
	return 0;
}


/*	Load the frame and stack pointer registers with those of the C stack,
	effecting a switch to the C stack. Used when machine code calls into
	the CoInterpreter run-time (e.g. to invoke interpreter primitives). */

	/* CogARMCompiler>>#genLoadCStackPointers */
static sqInt
genLoadCStackPointers(AbstractInstruction * self_in_genLoadCStackPointers)
{
    sqInt address;
    sqInt address1;

	/* begin MoveAw:R: */
	address = cStackPointerAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, SPReg));
	/* begin MoveAw:R: */
	address1 = cFramePointerAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address1, genoperandoperand(MoveAwR, address1, FPReg));
	return 0;
}


/*	Switch back to the Smalltalk stack. Assign SPReg first
	because typically it is used immediately afterwards. */

	/* CogARMCompiler>>#genLoadStackPointers */
static sqInt
genLoadStackPointers(AbstractInstruction * self_in_genLoadStackPointers)
{
    sqInt address;
    sqInt address1;

	/* begin MoveAw:R: */
	address = stackPointerAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, SPReg));
	/* begin MoveAw:R: */
	address1 = framePointerAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address1, genoperandoperand(MoveAwR, address1, FPReg));
	return 0;
}


/*	Use SMULL to produce a 64-bit result, explicitly in RISCTempReg,regDest.
	By comparing RISCTempReg with regDest ASR 31(which effectively makes it 0
	or -1) we know that the result being EQ means the hi reg and the top bit
	of the lo reg are the same - ie no overflow. The condition code can then
	be forced to oVerflow by use of MSR APSR_nzcvq, #1, lsl 28
 */

	/* CogARMCompiler>>#genMulR:R: */
static AbstractInstruction *
genMulRR(AbstractInstruction * self_in_genMulRR, sqInt regSource, sqInt regDest)
{
	genoperandoperand(SMULL, regSource, regDest);
	genoperandoperand(CMPSMULL, RISCTempReg, regDest);
	genoperand(MSR, 1);
	return self_in_genMulRR;
}

	/* CogARMCompiler>>#genPassConst:asArgument: */
static sqInt
genPassConstasArgument(AbstractInstruction * self_in_genPassConstasArgument, sqInt constant, sqInt zeroRelativeArgIndex)
{
	
	switch (zeroRelativeArgIndex) {
	case 0:
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, CArg0Reg));
		break;
	case 1:
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, CArg1Reg));
		break;
	case 2:
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, CArg2Reg));
		break;
	case 3:
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, CArg3Reg));
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	return 0;
}

	/* CogARMCompiler>>#genPassReg:asArgument: */
static sqInt
genPassRegasArgument(AbstractInstruction * self_in_genPassRegasArgument, sqInt abstractRegister, sqInt zeroRelativeArgIndex)
{
	
	switch (zeroRelativeArgIndex) {
	case 0:
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, abstractRegister, CArg0Reg);
		break;
	case 1:
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, abstractRegister, CArg1Reg);
		break;
	case 2:
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, abstractRegister, CArg2Reg);
		break;
	case 3:
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, abstractRegister, CArg3Reg);
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	return 0;
}


/*	Ensure that the register args are pushed before the outer and
	inner retpcs at an entry miss for arity <= self numRegArgs. The
	outer retpc is that of a call at a send site. The inner is the call
	from a method or PIC abort/miss to the trampoline. */
/*	Putting the receiver and args above the return address means the
	CoInterpreter has a single machine-code frame format which saves
	us a lot of work. */
/*	Iff there are register args convert
	sp		->	outerRetpc			(send site retpc)
	linkReg = innerRetpc			(PIC abort/miss retpc)
	to
	base	->	receiver
	(arg0)
	(arg1)
	sp		->	outerRetpc			(send site retpc)
	sp		->	linkReg/innerRetpc	(PIC abort/miss retpc) */

	/* CogARMCompiler>>#genPushRegisterArgsForAbortMissNumArgs: */
static AbstractInstruction *
genPushRegisterArgsForAbortMissNumArgs(AbstractInstruction * self_in_genPushRegisterArgsForAbortMissNumArgs, sqInt numArgs)
{
	if (numArgs <= 2) {
		assert((numRegArgs()) <= 2);
		/* begin MoveMw:r:R: */
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveMwrR, 0, SPReg, TempReg));
		/* begin MoveR:Mw:r: */
		/* begin gen:operand:quickConstant:operand: */
		checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveRMwr, ReceiverResultReg, 0, SPReg));
		if (numArgs > 0) {
			/* begin PushR: */
			genoperand(PushR, Arg0Reg);
			if (numArgs > 1) {
				/* begin PushR: */
				genoperand(PushR, Arg1Reg);
			}
		}
		/* begin PushR: */
		genoperand(PushR, TempReg);
	}
	/* begin PushR: */
	genoperand(PushR, LinkReg);
	return self_in_genPushRegisterArgsForAbortMissNumArgs;
}


/*	Ensure that the register args are pushed before the retpc for arity <=
	self numRegArgs.
 */
/*	This is easy on a RISC like ARM because the return address is in the link
	register. Putting
	the receiver and args above the return address means the CoInterpreter has
	a single
	machine-code frame format which saves us a lot of work
	NOTA BENE: we do NOT push the return address here, which means it must be
	dealt with later. */

	/* CogARMCompiler>>#genPushRegisterArgsForNumArgs:scratchReg: */
static AbstractInstruction *
genPushRegisterArgsForNumArgsscratchReg(AbstractInstruction * self_in_genPushRegisterArgsForNumArgsscratchReg, sqInt numArgs, sqInt ignored)
{
	if (numArgs <= 2) {
		assert((numRegArgs()) <= 2);
		/* begin PushR: */
		genoperand(PushR, ReceiverResultReg);
		if (numArgs > 0) {
			/* begin PushR: */
			genoperand(PushR, Arg0Reg);
			if (numArgs > 1) {
				/* begin PushR: */
				genoperand(PushR, Arg1Reg);
			}
		}
	}
	return self_in_genPushRegisterArgsForNumArgsscratchReg;
}


/*	This is a no-op on ARM since the ABI passes up to 4 args in registers and
	trampolines currently observe that limit.
 */

	/* CogARMCompiler>>#genRemoveNArgsFromStack: */
static sqInt
genRemoveNArgsFromStack(AbstractInstruction * self_in_genRemoveNArgsFromStack, sqInt n)
{
	assert(n <= 4);
	return 0;
}


/*	Restore the general purpose registers for a trampoline call. */
/*	Restore none, because the ARM ABI only defines callee saved registers, no
	caller-saved regs.
 */
/*	cogit gen: LDMFD operand: 16r7F */

	/* CogARMCompiler>>#genRestoreRegs */
static AbstractInstruction *
genRestoreRegs(AbstractInstruction * self_in_genRestoreRegs)
{
	return self_in_genRestoreRegs;
}


/*	Restore the general purpose registers except for abstractReg for a
	trampoline call.
 */
/*	Restore none, because the ARM ABI only defines callee saved registers, no
	caller-saved regs.
 */

	/* CogARMCompiler>>#genRestoreRegsExcept: */
static AbstractInstruction *
genRestoreRegsExcept(AbstractInstruction * self_in_genRestoreRegsExcept, sqInt abstractReg)
{
	return self_in_genRestoreRegsExcept;
}


/*	Save the general purpose registers for a trampoline call. */
/*	Save none, because the ARM ABI only defines callee saved registers, no
	caller-saved regs.
 */
/*	cogit gen: STMFD operand: 16r7F */

	/* CogARMCompiler>>#genSaveRegisters */
static AbstractInstruction *
genSaveRegisters(AbstractInstruction * self_in_genSaveRegisters)
{
	return self_in_genSaveRegisters;
}


/*	Save the frame and stack pointer registers to the framePointer
	and stackPointer variables. Used to save the machine code frame
	for use by the run-time when calling into the CoInterpreter run-time. */

	/* CogARMCompiler>>#genSaveStackPointers */
static sqInt
genSaveStackPointers(AbstractInstruction * self_in_genSaveStackPointers)
{
    sqInt address;
    sqInt address1;

	/* begin MoveR:Aw: */
	address = framePointerAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address, genoperandoperand(MoveRAw, FPReg, address));
	/* begin MoveR:Aw: */
	address1 = stackPointerAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address1, genoperandoperand(MoveRAw, SPReg, address1));
	return 0;
}

	/* CogARMCompiler>>#genSubstituteReturnAddress: */
static AbstractInstruction *
genSubstituteReturnAddress(AbstractInstruction * self_in_genSubstituteReturnAddress, sqInt retpc)
{
	/* begin MoveCw:R: */
	/* begin gen:literal:operand: */
	return checkLiteralforInstruction(retpc, genoperandoperand(MoveCwR, retpc, LR));
}

	/* CogARMCompiler>>#hasLinkRegister */
static sqInt
hasLinkRegister(AbstractInstruction * self_in_hasLinkRegister)
{
	return 1;
}


/*	e.g. B, BL: Branch, Branch and Link */

	/* CogARMCompiler>>#hasPCDependentInstruction */
static sqInt
hasPCDependentInstruction(AbstractInstruction * self_in_hasPCDependentInstruction)
{
	return 1;
}


/*	Answer if the processor has a generally addressable pc register, which ARM
	does. 
 */

	/* CogARMCompiler>>#hasPCRegister */
static sqInt
hasPCRegister(AbstractInstruction * self_in_hasPCRegister)
{
	return 1;
}


/*	Answer the instruction immediately preceeding followingAddress. */

	/* CogARMCompiler>>#instructionBeforeAddress: */
static sqInt
instructionBeforeAddress(AbstractInstruction * self_in_instructionBeforeAddress, sqInt followingAddress)
{
	return longAt(followingAddress - 4);
}


/*	is this a BLX <targetReg> instruction? */

	/* CogARMCompiler>>#instructionIsBLX: */
static sqInt
instructionIsBLX(AbstractInstruction * self_in_instructionIsBLX, sqInt instr)
{
	return ((((usqInt) instr) >> 28) < 15)
	 && ((instr & 0xFFFFFF0) == 19922736);
}


/*	is this a BL <offset> instruction? */

	/* CogARMCompiler>>#instructionIsBL: */
static sqInt
instructionIsBL(AbstractInstruction * self_in_instructionIsBL, sqInt instr)
{
	return ((((usqInt) instr) >> 28) < 15)
	 && ((instr & (15 << 24)) == (11 << 24));
}


/*	is this a BX <targetReg> instruction? */

	/* CogARMCompiler>>#instructionIsBX: */
static sqInt
instructionIsBX(AbstractInstruction * self_in_instructionIsBX, sqInt instr)
{
	return ((((usqInt) instr) >> 28) < 15)
	 && ((instr & 0xFFFFFF0) == 19922704);
}


/*	is this a B <offset> instruction? */

	/* CogARMCompiler>>#instructionIsB: */
static sqInt
instructionIsB(AbstractInstruction * self_in_instructionIsB, sqInt instr)
{
	return ((((usqInt) instr) >> 28) < 15)
	 && ((instr & (15 << 24)) == (10 << 24));
}


/*	is this an ORR instruction? */

	/* CogARMCompiler>>#instructionIsOR: */
static sqInt
instructionIsOR(AbstractInstruction * self_in_instructionIsOR, sqInt instr)
{
	return ((((usqInt) instr) >> 21) & 15) == 12;
}


/*	is this a push -str r??, [sp, #-4] - instruction? */

	/* CogARMCompiler>>#instructionIsPush: */
static sqInt
instructionIsPush(AbstractInstruction * self_in_instructionIsPush, sqInt instr)
{
	return ((((usqInt) instr) >> 28) < 15)
	 && ((instr & 268374015) == 86835204);
}


/*	Answer the instruction size at pc.Simple on ARM ;-) */

	/* CogARMCompiler>>#instructionSizeAt: */
static sqInt
instructionSizeAt(AbstractInstruction * self_in_instructionSizeAt, sqInt pc)
{
	return 4;
}


/*	Several of the opcodes are inverses. Answer the inverse for an opcode if
	it has one.
	See Table A3-2 in sec A3.4 Data-processing instructions of the AARM. */

	/* CogARMCompiler>>#inverseOpcodeFor: */
static sqInt
inverseOpcodeFor(AbstractInstruction * self_in_inverseOpcodeFor, sqInt armOpcode)
{
	
	switch (armOpcode) {
	case AddOpcode:
		return SubOpcode;

	case AndOpcode:
		return BicOpcode;

	case BicOpcode:
		return AndOpcode;

	case CmpOpcode:
		return CmpNotOpcode;

	case MoveOpcode:
		return MoveNotOpcode;

	case MoveNotOpcode:
		return MoveOpcode;

	case SubOpcode:
		return AddOpcode;

	default:
		error("opcode has no inverse");
		return -1;

	}
}


/*	Support for addressing variables off the dedicated VarBaseReg */

	/* CogARMCompiler>>#isAddressRelativeToVarBase: */
static sqInt
isAddressRelativeToVarBase(AbstractInstruction * self_in_isAddressRelativeToVarBase, usqInt varAddress)
{
	return (varAddress != null)
	 && ((varAddress >= (varBaseAddress()))
	 && ((varAddress - (varBaseAddress())) < (1 << 12)));
}


/*	Assuming mcpc is a return pc answer if the instruction before it is a
	call. 
 */
/*	There are two types of calls: BL and/BLX encoding */

	/* CogARMCompiler>>#isCallPreceedingReturnPC: */
static sqInt
isCallPreceedingReturnPC(AbstractInstruction * self_in_isCallPreceedingReturnPC, sqInt mcpc)
{
    sqInt call;

	call = longAt(mcpc - 4);
	return (instructionIsBL(self_in_isCallPreceedingReturnPC, call))
	 || (instructionIsBLX(self_in_isCallPreceedingReturnPC, call));
}


/*	ARM calls and jumps span +/- 32 mb, more than enough for intra-zone calls
	and jumps.
 */

	/* CogARMCompiler>>#isInImmediateJumpRange: */
static sqInt
isInImmediateJumpRange(AbstractInstruction * self_in_isInImmediateJumpRange, unsigned long operand)
{
	return (((((sqInt) operand)) >= -33554432) && ((((sqInt) operand)) <= 0x1FFFFFC));
}

	/* CogARMCompiler>>#isJumpAt: */
static sqInt
isJumpAt(AbstractInstruction * self_in_isJumpAt, sqInt pc)
{
    sqInt instr;

	instr = long32At(pc);
	return (instructionIsB(self_in_isJumpAt, instr))
	 || (instructionIsBX(self_in_isJumpAt, instr));
}


/*	add xx, pc, blah or sub xx, pc, blah */

	/* CogARMCompiler>>#isPCRelativeValueLoad: */
static sqInt
isPCRelativeValueLoad(AbstractInstruction * self_in_isPCRelativeValueLoad, unsigned int instr)
{
	return ((((usqInt) instr) >> 16) == 57999)
	 || ((((usqInt) instr) >> 16) == 57935);
}


/*	Branch/Call ranges. Jump[Cond] can be generated as short as possible.
	Call/Jump[Cond]Long must be generated
	in the same number of bytes irrespective of displacement since their
	targets may be updated, but they need only
	span 16Mb, the maximum size of the code zone. This allows e.g. ARM to use
	single-word call and jump instructions
	for most calls and jumps. CallFull/JumpFull must also be generated in the
	same number of bytes irrespective of
	displacement for the same reason, but they must be able to span the full
	(32-bit or 64-bit) address space because
	they are used to call code in the C runtime, which may be distant from the
	code zone
 */

	/* CogARMCompiler>>#jumpLongByteSize */
static sqInt
jumpLongByteSize(AbstractInstruction * self_in_jumpLongByteSize)
{
	return 4;
}

	/* CogARMCompiler>>#jumpLongConditionalByteSize */
static sqInt
jumpLongConditionalByteSize(AbstractInstruction * self_in_jumpLongConditionalByteSize)
{
	return jumpLongByteSize(self_in_jumpLongConditionalByteSize);
}


/*	Answer the target address for the long jump immediately preceeding mcpc */

	/* CogARMCompiler>>#jumpLongTargetBeforeFollowingAddress: */
static sqInt
jumpLongTargetBeforeFollowingAddress(AbstractInstruction * self_in_jumpLongTargetBeforeFollowingAddress, sqInt mcpc)
{
	return callTargetFromReturnAddress(self_in_jumpLongTargetBeforeFollowingAddress, mcpc);
}

	/* CogARMCompiler>>#jumpTargetPCAt: */
static usqInt
jumpTargetPCAt(AbstractInstruction * self_in_jumpTargetPCAt, sqInt pc)
{
    sqInt operand;
    sqInt word;

	word = long32At(pc);
	operand = word & 0xFFFFFF;
	if (operand & 0x800000) {
		operand -= 0x1000000;
	}
	return ((operand * 4) + pc) + 8;
}


/*	LDRB destReg, [baseReg, 'u' immediate12bitValue] u=0 -> subtract imm; =1
	-> add imm 
	Note that this is a very low level interface that does not check the sign
	of the immediate, nor validity. See for example #concretizeMoveMbrR
 */

	/* CogARMCompiler>>#ldrb:rn:plus:imm: */
static sqInt
ldrbrnplusimm(AbstractInstruction * self_in_ldrbrnplusimm, sqInt destReg, sqInt baseReg, sqInt u, sqInt immediate12bitValue)
{
	return memMxrregbaseublimm(self_in_ldrbrnplusimm, AL, destReg, baseReg, u, 1, 1, immediate12bitValue);
}


/*	LDR destReg, [baseReg, + offsetReg] 
	The contents of offsetReg are assumed to be correctly signed */

	/* CogARMCompiler>>#ldrb:rn:rm: */
static sqInt
ldrbrnrm(AbstractInstruction * self_in_ldrbrnrm, sqInt destReg, sqInt baseReg, sqInt offsetReg)
{
	return memMxrregbasepubwlrm(self_in_ldrbrnrm, AL, destReg, baseReg, 1, 1, 1, 0, 1, offsetReg);
}


/*	LDRH destReg, [baseReg, 'u' immediate8bitValue] u=0 -> subtract imm; =1 ->
	add imm */

	/* CogARMCompiler>>#ldrh:rn:plus:imm: */
static sqInt
ldrhrnplusimm(AbstractInstruction * self_in_ldrhrnplusimm, sqInt destReg, sqInt baseReg, sqInt u, sqInt immediate8bitValue)
{
	return memM16xrregbasepuwloffset(self_in_ldrhrnplusimm, AL, destReg, baseReg, 1, u, 0, 1, immediate8bitValue);
}


/*	LDRH destReg, [baseReg, +offsetReg]
	The contents of offsetReg are assumed to be correctly signed */

	/* CogARMCompiler>>#ldrh:rn:rm: */
static sqInt
ldrhrnrm(AbstractInstruction * self_in_ldrhrnrm, sqInt destReg, sqInt baseReg, sqInt offsetReg)
{
	return memM16xrregbasepuwlrm(self_in_ldrhrnrm, AL, destReg, baseReg, 1, 1, 0, 1, offsetReg);
}


/*	LDR destReg, [baseReg, +immediate12bitValue] */

	/* CogARMCompiler>>#ldr:rn:plusImm: */
static sqInt
ldrrnplusImm(AbstractInstruction * self_in_ldrrnplusImm, sqInt destReg, sqInt baseReg, sqInt immediate12bitValue)
{
	return memMxrregbaseublimm(self_in_ldrrnplusImm, AL, destReg, baseReg, 1, 0, 1, immediate12bitValue);
}


/*	LDR destReg, [baseReg, immediate12bitValue] u=0 -> subtract imm; =1 -> add
	imm  */

	/* CogARMCompiler>>#ldr:rn:plus:imm: */
static sqInt
ldrrnplusimm(AbstractInstruction * self_in_ldrrnplusimm, sqInt destReg, sqInt baseReg, sqInt u, sqInt immediate12bitValue)
{
	return memMxrregbaseublimm(self_in_ldrrnplusimm, AL, destReg, baseReg, u, 0, 1, immediate12bitValue);
}


/*	LDR destReg, [baseReg, + offsetReg]
	The contents of offsetReg are assumed to be correctly signed */

	/* CogARMCompiler>>#ldr:rn:rm: */
static sqInt
ldrrnrm(AbstractInstruction * self_in_ldrrnrm, sqInt destReg, sqInt baseReg, sqInt offsetReg)
{
	return memMxrregbasepubwlrm(self_in_ldrrnrm, AL, destReg, baseReg, 1, 1, 0, 0, 1, offsetReg);
}


/*	Answer the delta from the stack pointer after a call to the stack pointer
	immediately prior to the call. This is used to compute the stack pointer
	immediately prior to call from within a leaf routine, which in turn is
	used to capture the c stack pointer to use in trampolines back into the C
	run-time.  */
/*	This might actually be false, since directly after a call, lr, fp and
	variable registers need be pushed onto the stack. It depends on the
	implementation of call.
 */

	/* CogARMCompiler>>#leafCallStackPointerDelta */
static sqInt
leafCallStackPointerDelta(AbstractInstruction * self_in_leafCallStackPointerDelta)
{
	return 0;
}


/*	Load the operand into the destination register, answering
	the size of the instructions generated to do so. */

	/* CogARMCompiler>>#loadCwInto: */
static sqInt
loadCwInto(AbstractInstruction * self_in_loadCwInto, sqInt destReg)
{
    sqInt aWord;
    sqInt aWord1;
    unsigned long distance;
    sqInt i;
    sqInt immediate;
    sqInt negate;
    unsigned long operand;
    sqInt rot;
    sqInt value;

	operand = ((self_in_loadCwInto->operands))[0];
	null;
	if ((addressIsInInstructions(((AbstractInstruction *) operand)))
	 || ((((AbstractInstruction *) operand)) == (methodLabel()))) {
		operand = ((((AbstractInstruction *) operand))->address);
	}
	if (addressIsInCurrentCompilation(operand)) {
		distance = operand - (((self_in_loadCwInto->address)) + 8);
		/* begin rotateable8bitSignedImmediate:ifTrue:ifFalse: */
		value = distance;
		while (1) {
			if ((value & 0xFF) == value) {
				negate = distance != value;
				/* begin machineCodeAt:put: */
				aWord = (negate
					? subrnimmror(self_in_loadCwInto, destReg, PC, value, 0)
					: addrnimmror(self_in_loadCwInto, destReg, PC, value, 0));
				((self_in_loadCwInto->machineCode))[0 / 4] = aWord;
				self_in_loadCwInto;
				return 4;

				goto l1;
			}
			for (i = 2; i <= 30; i += 2) {
				if ((value & (((0xFF << i) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i)))) == value) {
					rot = 32 - i;
					immediate = (((usqInt) value) >> i) | ((value << (32 - i)) & 0xFFFFFFFFUL);
					negate = distance != value;
					/* begin machineCodeAt:put: */
					aWord = (negate
						? subrnimmror(self_in_loadCwInto, destReg, PC, immediate, rot)
						: addrnimmror(self_in_loadCwInto, destReg, PC, immediate, rot));
					((self_in_loadCwInto->machineCode))[0 / 4] = aWord;
					self_in_loadCwInto;
					return 4;

					goto l1;
				}
			}
			if (!((value == distance)
			 && (distance != 0))) break;
			value = -distance;
		}
		assert(!((isAnInstruction(self_in_loadCwInto, ((AbstractInstruction *) (((self_in_loadCwInto->operands))[0]))))));

	l1:	/* end rotateable8bitSignedImmediate:ifTrue:ifFalse: */;
	}
	/* begin moveCw:intoR: */
	assert(addressIsInCurrentCompilation((((self_in_loadCwInto->dependent))->address)));
	assert((abs(((((self_in_loadCwInto->dependent))->address)) - (((self_in_loadCwInto->address)) + 8))) < (1 << 12));
	/* begin machineCodeAt:put: */
	aWord1 = ldrrnplusimm(self_in_loadCwInto, destReg, PC, (((((self_in_loadCwInto->dependent))->address)) >= (((self_in_loadCwInto->address)) + 8)
		? 1
		: 0), abs(((((self_in_loadCwInto->dependent))->address)) - (((self_in_loadCwInto->address)) + 8)));
	((self_in_loadCwInto->machineCode))[0 / 4] = aWord1;
	self_in_loadCwInto;
	return ((usqInt) (((self_in_loadCwInto->machineCodeSize) = 4)));
}


/*	Answer the byte size of a MoveCwR opcode's corresponding machine code */

	/* CogARMCompiler>>#loadLiteralByteSize */
static sqInt
loadLiteralByteSize(AbstractInstruction * self_in_loadLiteralByteSize)
{
	return 16;
}


/*	Answer the byte size of a MoveCwR opcode's corresponding machine code
	when the argument is a PIC. This is for the self-reference at the end of a
	closed PIC. On ARM this is a single instruction pc-relative register load. */

	/* CogARMCompiler>>#loadPICLiteralByteSize */
static sqInt
loadPICLiteralByteSize(AbstractInstruction * self_in_loadPICLiteralByteSize)
{
	return 4;
}


/*	Answer the maximum number of bytes of machine code generated for any
	abstract instruction.
	e.g. CmpCwR =>
	mov R3, #<addressByte1>, 12
	orr R3, R3, #<addressByte2>, 8
	orr R3, R3, #<addressByte3>, 4
	orr R3, R3, #<addressByte4>, 0
	cmp R?, R3 */

	/* CogARMCompiler>>#machineCodeBytes */
static sqInt
machineCodeBytes(AbstractInstruction * self_in_machineCodeBytes)
{
	return 20;
}


/*	Answer the maximum number of words of machine code generated for any
	abstract instruction.
	e.g. CmpCwR =>
	mov R3, #<addressByte1>, 12
	orr R3, R3, #<addressByte2>, 8
	orr R3, R3, #<addressByte3>, 4
	orr R3, R3, #<addressByte4>, 0
	cmp R?, R3 */

	/* CogARMCompiler>>#machineCodeWords */
static sqInt
machineCodeWords(AbstractInstruction * self_in_machineCodeWords)
{
	return 5;
}


/*	The receiver has a VarBaseReg; generate the code to set it to its value. */

	/* CogARMCompiler>>#maybeEstablishVarBase */
static AbstractInstruction *
maybeEstablishVarBase(AbstractInstruction * self_in_maybeEstablishVarBase)
{
    sqInt quickConstant;

	/* begin MoveCq:R: */
	quickConstant = varBaseAddress();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(MoveCqR, quickConstant, VarBaseReg));
	return self_in_maybeEstablishVarBase;
}


/*	build an ARM [base +/- offset8] half-word memory instruction
	p -> pre-index (1) or post-index (0) the offset. Combines with W to do
	some odd things.
	u -> up (1) or down (0) ie + or - for the offset
	b -> byte(1) or word (0)
	w -> write-back (1) if pre-indexing. 
	l -> load (1) or store (0) */

	/* CogARMCompiler>>#memM16xr:reg:base:p:u:w:l:offset: */
static sqInt
memM16xrregbasepuwloffset(AbstractInstruction * self_in_memM16xrregbasepuwloffset, sqInt cond, sqInt destReg, sqInt baseReg, sqInt postpreoffset, sqInt updown, sqInt weirdstuff, sqInt loadstore, sqInt offset8)
{
	return (cond << 28) | ((0 << 25) | ((postpreoffset << 24) | ((updown << 23) | ((1 << 22) | ((weirdstuff << 21) | ((loadstore << 20) | ((baseReg << 16) | ((destReg << 12) | (((offset8 & 240) << 4) | ((11 << 4) | (offset8 & 15)))))))))));
}


/*	build an ARM [base +/- offsetReg] memory instruction
	p -> pre-index (1) or post-index (0) the offset. Combines with W to do
	some odd things.
	u -> up (1) or down (0) ie + or - for the offset
	b -> byte(1) or word (0)
	w -> write-back (1) if pre-indexing. 
	l -> load (1) or store (0)
 */

	/* CogARMCompiler>>#memM16xr:reg:base:p:u:w:l:rm: */
static sqInt
memM16xrregbasepuwlrm(AbstractInstruction * self_in_memM16xrregbasepuwlrm, sqInt cond, sqInt destReg, sqInt baseReg, sqInt postpreoffset, sqInt updown, sqInt weirdstuff, sqInt loadstore, sqInt offsetReg)
{
	return (cond << 28) | ((0 << 25) | ((postpreoffset << 24) | ((updown << 23) | ((0 << 22) | ((weirdstuff << 21) | ((loadstore << 20) | ((baseReg << 16) | ((destReg << 12) | (176 | offsetReg)))))))));
}


/*	build an ARM [base +/- offset] memory instruction
	p -> pre-index (1) or post-index (0) the offset. Combines with W to do
	some odd things.
	u -> up (1) or down (0) ie + or - for the offset
	b -> byte(1) or word (0)
	w -> write-back (1) if pre-indexing. 
	l -> load (1) or store (0)
 */

	/* CogARMCompiler>>#memMxr:reg:base:p:u:b:w:l:imm: */
static sqInt
memMxrregbasepubwlimm(AbstractInstruction * self_in_memMxrregbasepubwlimm, sqInt cond, sqInt destReg, sqInt baseReg, sqInt postpreoffset, sqInt updown, sqInt byteword, sqInt weirdstuff, sqInt loadstore, sqInt offset)
{
	return (cond << 28) | ((2 << 25) | ((postpreoffset << 24) | ((updown << 23) | ((byteword << 22) | ((weirdstuff << 21) | ((loadstore << 20) | ((baseReg << 16) | ((destReg << 12) | offset))))))));
}


/*	build an ARM [base +/- offsetReg lsl #2] memory instruction - see also
	#memMxr:reg:base:p:u:b:w:l:rm: and keep them correlated properly
	p -> pre-index (1) or post-index (0) the offset. Combines with W to do
	some odd things.
	u -> up (1) or down (0) ie + or - for the offset
	b -> byte(1) or word (0)
	w -> write-back (1) if pre-indexing. 
	l -> load (1) or store (0)
 */

	/* CogARMCompiler>>#memMxr:reg:base:p:u:b:w:l:rmLsl2: */
static sqInt
memMxrregbasepubwlrmLsl2(AbstractInstruction * self_in_memMxrregbasepubwlrmLsl2, sqInt cond, sqInt destReg, sqInt baseReg, sqInt postpreoffset, sqInt updown, sqInt byteword, sqInt weirdstuff, sqInt loadstore, sqInt offsetReg)
{
	return ((cond & 15) << 28) | ((3 << 25) | (((postpreoffset & 1) << 24) | (((updown & 1) << 23) | (((byteword & 1) << 22) | (((weirdstuff & 1) << 21) | (((loadstore & 1) << 20) | (((baseReg & 15) << 16) | (((destReg & 15) << 12) | (256 | (offsetReg & 15))))))))));
}


/*	build an ARM [base +/- offsetReg] memory instruction
	p -> pre-index (1) or post-index (0) the offset. Combines with W to do
	some odd things.
	u -> up (1) or down (0) ie + or - for the offset
	b -> byte(1) or word (0)
	w -> write-back (1) if pre-indexing. 
	l -> load (1) or store (0)
 */

	/* CogARMCompiler>>#memMxr:reg:base:p:u:b:w:l:rm: */
static sqInt
memMxrregbasepubwlrm(AbstractInstruction * self_in_memMxrregbasepubwlrm, sqInt cond, sqInt destReg, sqInt baseReg, sqInt postpreoffset, sqInt updown, sqInt byteword, sqInt weirdstuff, sqInt loadstore, sqInt offsetReg)
{
	return ((cond & 15) << 28) | ((3 << 25) | (((postpreoffset & 1) << 24) | (((updown & 1) << 23) | (((byteword & 1) << 22) | (((weirdstuff & 1) << 21) | (((loadstore & 1) << 20) | (((baseReg & 15) << 16) | (((destReg & 15) << 12) | (offsetReg & 15)))))))));
}


/*	This is the lowest level build of an ARM [base +/- immediate 12bit offset]
	memory instruction
	u -> up (1) or down (0) ie + or - for the offset
	b -> byte(1) or word (0)
	l -> load (1) or store (0)
 */

	/* CogARMCompiler>>#memMxr:reg:base:u:b:l:imm: */
static sqInt
memMxrregbaseublimm(AbstractInstruction * self_in_memMxrregbaseublimm, sqInt cond, sqInt destReg, sqInt baseReg, sqInt updown, sqInt byteword, sqInt loadstore, sqInt immediate12bitValue)
{
	return ((cond & 15) << 28) | ((5 << 24) | (((updown & 1) << 23) | (((byteword & 1) << 22) | (((loadstore & 1) << 20) | (((baseReg & 15) << 16) | (((destReg & 15) << 12) | (immediate12bitValue & 0xFFF)))))));
}


/*	MOVS destReg, srcReg */

	/* CogARMCompiler>>#movs:rn: */
static sqInt
movsrn(AbstractInstruction * self_in_movsrn, sqInt destReg, sqInt srcReg)
{
	return (((AL << 28) | ((0 << 25) | ((MoveOpcode << 21) | (1 << 20)))) | ((0 << 16) | (destReg << 12))) | (srcReg & 0xFFF);
}


/*	Remember the ROR is doubled by the cpu so use 30>>1 etc.
	MOV destReg, #immediate8BitValue ROR rot */

	/* CogARMCompiler>>#mov:imm:ror: */
static sqInt
movimmror(AbstractInstruction * self_in_movimmror, sqInt destReg, sqInt immediate8bitValue, sqInt rot)
{
	return (((AL << 28) | ((1 << 25) | ((MoveOpcode << 21) | (0 << 20)))) | ((0 << 16) | (destReg << 12))) | ((((((usqInt) rot) >> 1) << 8) | immediate8bitValue) & 0xFFF);
}


/*	MOV destReg, srcReg */

	/* CogARMCompiler>>#mov:rn: */
static sqInt
movrn(AbstractInstruction * self_in_movrn, sqInt destReg, sqInt srcReg)
{
	return (((AL << 28) | ((0 << 25) | ((MoveOpcode << 21) | (0 << 20)))) | ((0 << 16) | (destReg << 12))) | (srcReg & 0xFFF);
}


/*	Generate an MSR CPSR_f, #flags instruction.
	Note that 
	a) CPSR_f is equivalent to APSR_nzcvq (ARM ARM DDI0406A p A8-209 & A2-14)
	b) We only have business with the NZCV flags so the generated instruction
	shifts the flags value <<28 - which is a ROR 4
 */

	/* CogARMCompiler>>#msr: */
static sqInt
msr(AbstractInstruction * self_in_msr, sqInt flags)
{
	return (321449984 + (2 << 8)) + (flags & 15);
}


/*	Remember the ROR is doubled by the cpu so use 30>>1 etc.
	MVN destReg, #immediate8BitValue ROR rot */

	/* CogARMCompiler>>#mvn:imm:ror: */
static sqInt
mvnimmror(AbstractInstruction * self_in_mvnimmror, sqInt destReg, sqInt immediate8bitValue, sqInt rot)
{
	return (((AL << 28) | ((1 << 25) | ((MoveNotOpcode << 21) | (0 << 20)))) | ((0 << 16) | (destReg << 12))) | ((((((usqInt) rot) >> 1) << 8) | immediate8bitValue) & 0xFFF);
}


/*	fill with MOV R0, R0 no-op instructions */

	/* CogARMCompiler>>#nopsFrom:to: */
static AbstractInstruction *
nopsFromto(AbstractInstruction * self_in_nopsFromto, sqInt startAddr, sqInt endAddr)
{
    sqInt p;

	assert((((endAddr - startAddr) + 1) % 4) == 0);
	for (p = startAddr; p <= endAddr; p += 4) {
		byteAtput(p, 0);
		byteAtput(p + 1, 0);
		byteAtput(p + 2, 160);
		byteAtput(p + 3, 225);
	}
	return self_in_nopsFromto;
}


/*	ARM needs to do icache flushing when code is written */
/*	for now return 0 to skip it and probably blow up */

	/* CogARMCompiler>>#numICacheFlushOpcodes */
static sqInt
numICacheFlushOpcodes(AbstractInstruction * self_in_numICacheFlushOpcodes)
{
	return 0;
}


/*	Remember the ROR is doubled by the cpu so use 30>>1 etc.
	ORR destReg, #immediate8BitValue ROR rot */

	/* CogARMCompiler>>#orr:imm:ror: */
static sqInt
orrimmror(AbstractInstruction * self_in_orrimmror, sqInt destReg, sqInt immediate8bitValue, sqInt rot)
{
	return (((AL << 28) | ((1 << 25) | ((OrOpcode << 21) | (0 << 20)))) | ((destReg << 16) | (destReg << 12))) | ((((((usqInt) rot) >> 1) << 8) | immediate8bitValue) & 0xFFF);
}

	/* CogARMCompiler>>#padIfPossibleWithNopsFrom:to: */
static AbstractInstruction *
padIfPossibleWithNopsFromto(AbstractInstruction * self_in_padIfPossibleWithNopsFromto, sqInt startAddr, sqInt endAddr)
{
    sqInt nullBytes;
    sqInt p;

	nullBytes = ((endAddr - startAddr) + 1) % 4;
	nopsFromto(self_in_padIfPossibleWithNopsFromto, startAddr, endAddr - nullBytes);
	for (p = ((endAddr - nullBytes) + 1); p <= endAddr; p += 1) {
		byteAtput(p, 0);
	}
	return self_in_padIfPossibleWithNopsFromto;
}


/*	pop word off TOS
	LDR srcReg, [sp] #4 */

	/* CogARMCompiler>>#popR: */
static sqInt
popR(AbstractInstruction * self_in_popR, sqInt dstReg)
{
	return memMxrregbasepubwlimm(self_in_popR, AL, dstReg, SP, 0, 1, 0, 0, 1, 4);
}

	/* CogARMCompiler>>#pushLinkRegisterByteSize */
static sqInt
pushLinkRegisterByteSize(AbstractInstruction * self_in_pushLinkRegisterByteSize)
{
	return 4;
}


/*	push word to TOS 
	STR srcReg, [sp, #-4]! */

	/* CogARMCompiler>>#pushR: */
static sqInt
pushR(AbstractInstruction * self_in_pushR, sqInt srcReg)
{
	return memMxrregbasepubwlimm(self_in_pushR, AL, srcReg, SP, 1, 0, 0, 1, 0, 4);
}

	/* CogARMCompiler>>#relocateCallBeforeReturnPC:by: */
static AbstractInstruction *
relocateCallBeforeReturnPCby(AbstractInstruction * self_in_relocateCallBeforeReturnPCby, sqInt retpc, sqInt delta)
{
    sqInt distanceDiv4;
    sqInt instr;

	assert((delta % 4) == 0);
	if (delta != 0) {
		instr = longAt(retpc - 4);
		assert((instructionIsB(self_in_relocateCallBeforeReturnPCby, instr))
		 || (instructionIsBL(self_in_relocateCallBeforeReturnPCby, instr)));
		distanceDiv4 = instr & 0xFFFFFF;
		distanceDiv4 += delta / 4;
		longAtput(retpc - 4, (instr & 0xFF000000UL) | (distanceDiv4 & 0xFFFFFF));
	}
	return self_in_relocateCallBeforeReturnPCby;
}


/*	Rewrite a call instruction to call a different target. This variant is
	used to link PICs
	in ceSendMiss et al, and to rewrite cached primitive calls. Answer the
	extent of
	the code change which is used to compute the range of the icache to flush. */
/*	self cCode: ''
	inSmalltalk: [cogit disassembleFrom: callSiteReturnAddress - 10 to:
	callSiteReturnAddress - 1]. */

	/* CogARMCompiler>>#rewriteCallAt:target: */
static sqInt
rewriteCallAttarget(AbstractInstruction * self_in_rewriteCallAttarget, usqInt callSiteReturnAddress, usqInt callTargetAddress)
{
    sqInt call;
    usqInt callDistance;

	if (!(callTargetAddress >= (minCallAddress()))) {
		error("linking callsite to invalid address");
	}


	/* pc offset */
	/* return offset */

	callDistance = ((usqInt) (callTargetAddress - ((callSiteReturnAddress + 8) - 4)));
	assert(isInImmediateJumpRange(self_in_rewriteCallAttarget, callDistance));
	call = bl(self_in_rewriteCallAttarget, callDistance);
	longAtput(callSiteReturnAddress - 4, call);
	assert((((usqInt) (callTargetFromReturnAddress(self_in_rewriteCallAttarget, callSiteReturnAddress)))) == callTargetAddress);
	return 4;
}


/*	Rewrite a callFull instruction to jump to a different target. This variant
	is used to rewrite cached primitive calls. Answer the extent of the
	code change which is used to compute the range of the icache to flush. */

	/* CogARMCompiler>>#rewriteCallFullAt:target: */
static sqInt
rewriteCallFullAttarget(AbstractInstruction * self_in_rewriteCallFullAttarget, sqInt callSiteReturnAddress, sqInt callTargetAddress)
{
	return rewriteFullTransferAttargetexpectedInstruction(self_in_rewriteCallFullAttarget, callSiteReturnAddress, callTargetAddress, 3778019132UL);
}


/*	Rewrite a full jump instruction to jump to a different target. This
	variant is used to rewrite cached primitive calls. Answer the extent of
	the code change which is used to compute the range of the icache to flush. */

	/* CogARMCompiler>>#rewriteJumpFullAt:target: */
static sqInt
rewriteJumpFullAttarget(AbstractInstruction * self_in_rewriteJumpFullAttarget, sqInt callSiteReturnAddress, sqInt callTargetAddress)
{
	return rewriteFullTransferAttargetexpectedInstruction(self_in_rewriteJumpFullAttarget, callSiteReturnAddress, callTargetAddress, 3778019100UL);
}


/*	to save Slang from having to be a real compiler (it can't inline switches
	that return)
 */
/*	Answer if the receiver's opcode sets the condition codes correctly for the
	given conditional jump opcode.
	ARM has to check carefully since the V flag is not affected by
	non-comparison instructions
 */

	/* CogARMCompiler>>#setsConditionCodesFor: */
static sqInt
setsConditionCodesFor(AbstractInstruction * self_in_setsConditionCodesFor, sqInt aConditionalJumpOpcode)
{
	
	switch ((self_in_setsConditionCodesFor->opcode)) {
	case ArithmeticShiftRightCqR:
	case ArithmeticShiftRightRR:
	case LogicalShiftLeftCqR:
	case LogicalShiftLeftRR:
		return shiftSetsConditionCodesFor(self_in_setsConditionCodesFor, aConditionalJumpOpcode);

	case XorRR:
		return 1;

	default:
		haltmsg("unhandled opcode in setsConditionCodesFor:");
		return 0;

	}
}


/*	check what flags the opcdoe needs setting - ARM doesn't set V when simply
	MOVing 
 */

	/* CogARMCompiler>>#shiftSetsConditionCodesFor: */
static sqInt
shiftSetsConditionCodesFor(AbstractInstruction * self_in_shiftSetsConditionCodesFor, sqInt aConditionalJumpOpcode)
{
	
	switch (aConditionalJumpOpcode) {
	case JumpNegative:
	case JumpZero:
		return 1;

	default:
		haltmsg("unhandled opcode in setsConditionCodesFor:");
		return 0;

	}
}


/*	Return a minimum amount of headroom for each stack page (in bytes). In a
	JIT the stack has to have room for interrupt handlers which will run on
	the stack.
	According to ARM architecture v5 reference manual chapter A2.6, the basic
	interrupt procedure does not push anything onto the stack. It uses
	SPSR_err and R14_err to preserve state. Afterwards, it calls an interrupt
	procedure. So leave some room.
 */

	/* CogARMCompiler>>#stackPageInterruptHeadroomBytes */
static sqInt
stackPageInterruptHeadroomBytes(AbstractInstruction * self_in_stackPageInterruptHeadroomBytes)
{
	return 128;
}


/*	STRB destReg, [baseReg, 'u' immediate12bitValue] u=0 -> subtract imm; =1
	-> add imm */

	/* CogARMCompiler>>#strb:rn:plus:imm: */
static sqInt
strbrnplusimm(AbstractInstruction * self_in_strbrnplusimm, sqInt destReg, sqInt baseReg, sqInt u, sqInt immediate12bitValue)
{
	return memMxrregbaseublimm(self_in_strbrnplusimm, AL, destReg, baseReg, u, 1, 0, immediate12bitValue);
}


/*	STRB srcReg, [baseReg, + offsetReg] 
	The contents of offsetReg are assumed to be correctly signed */

	/* CogARMCompiler>>#strb:rn:rm: */
static sqInt
strbrnrm(AbstractInstruction * self_in_strbrnrm, sqInt srcReg, sqInt baseReg, sqInt offsetReg)
{
	return memMxrregbasepubwlrm(self_in_strbrnrm, AL, srcReg, baseReg, 1, 1, 1, 0, 0, offsetReg);
}


/*	STR srcReg, [baseReg, +immediate12bitValue] */

	/* CogARMCompiler>>#str:rn:plusImm: */
static sqInt
strrnplusImm(AbstractInstruction * self_in_strrnplusImm, sqInt srcReg, sqInt baseReg, sqInt immediate12bitValue)
{
	return memMxrregbaseublimm(self_in_strrnplusImm, AL, srcReg, baseReg, 1, 0, 0, immediate12bitValue);
}


/*	STR destReg, [baseReg, 'u' immediate12bitValue] u=0 -> subtract imm; =1 ->
	add imm */

	/* CogARMCompiler>>#str:rn:plus:imm: */
static sqInt
strrnplusimm(AbstractInstruction * self_in_strrnplusimm, sqInt destReg, sqInt baseReg, sqInt u, sqInt immediate12bitValue)
{
	return memMxrregbaseublimm(self_in_strrnplusimm, AL, destReg, baseReg, u, 0, 0, immediate12bitValue);
}


/*	STR srcReg, [baseReg, + offsetReg] 
	The contents of offsetReg are assumed to be correctly signed */

	/* CogARMCompiler>>#str:rn:rm: */
static sqInt
strrnrm(AbstractInstruction * self_in_strrnrm, sqInt srcReg, sqInt baseReg, sqInt offsetReg)
{
	return memMxrregbasepubwlrm(self_in_strrnrm, AL, srcReg, baseReg, 1, 1, 0, 0, 0, offsetReg);
}


/*	Remember the ROR is doubled by the cpu so use 30>>1 etc
	SUBS destReg, srcReg, #immediate ROR rot */

	/* CogARMCompiler>>#subs:rn:imm:ror: */
static sqInt
subsrnimmror(AbstractInstruction * self_in_subsrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot)
{
	return (((AL << 28) | ((1 << 25) | ((SubOpcode << 21) | (1 << 20)))) | ((srcReg << 16) | (destReg << 12))) | ((((((usqInt) rot) >> 1) << 8) | immediate) & 0xFFF);
}


/*	Remember the ROR is doubled by the cpu so use 30>>1 etc
	SUB destReg, srcReg, #immediate ROR rot */

	/* CogARMCompiler>>#sub:rn:imm:ror: */
static sqInt
subrnimmror(AbstractInstruction * self_in_subrnimmror, sqInt destReg, sqInt srcReg, sqInt immediate, sqInt rot)
{
	return (((AL << 28) | ((1 << 25) | ((SubOpcode << 21) | (0 << 20)))) | ((srcReg << 16) | (destReg << 12))) | ((((((usqInt) rot) >> 1) << 8) | immediate) & 0xFFF);
}


/*	Remember the ROR is doubled by the cpu so use 30>>1 etc */
/*	also note that TST has no destReg
	TST srcReg, #immediate ROR rot */

	/* CogARMCompiler>>#tst:rn:imm:ror: */
static sqInt
tstrnimmror(AbstractInstruction * self_in_tstrnimmror, sqInt ignored, sqInt srcReg, sqInt immediate, sqInt rot)
{
	return (((AL << 28) | ((1 << 25) | ((TstOpcode << 21) | (1 << 20)))) | ((srcReg << 16) | (0 << 12))) | ((((((usqInt) rot) >> 1) << 8) | immediate) & 0xFFF);
}

	/* CogBlockMethod>>#cmHomeMethod */
static CogMethod *
cmHomeMethod(CogBlockMethod * self_in_cmHomeMethod)
{
	return ((CogMethod *) ((((usqInt)self_in_cmHomeMethod)) - ((self_in_cmHomeMethod->homeOffset))));
}

	/* CogBytecodeDescriptor>>#isBranch */
static sqInt
isBranch(BytecodeDescriptor * self_in_isBranch)
{
	return (((self_in_isBranch->spanFunction)) != null)
	 && (!((self_in_isBranch->isBlockCreation)));
}

	/* CogBytecodeDescriptor>>#isUnconditionalBranch */
static sqInt
isUnconditionalBranch(BytecodeDescriptor * self_in_isUnconditionalBranch)
{
	return (isBranch(self_in_isUnconditionalBranch))
	 && (!(((self_in_isUnconditionalBranch->isBranchTrue))
 || ((self_in_isUnconditionalBranch->isBranchFalse))));
}

	/* Cogit>>#AndCq:R: */
static AbstractInstruction *
gAndCqR(sqInt quickConstant, sqInt reg)
{
	/* begin gen:quickConstant:operand: */
	return checkQuickConstantforInstruction(quickConstant, genoperandoperand(AndCqR, quickConstant, reg));
}

	/* Cogit>>#ArithmeticShiftRightR:R: */
static AbstractInstruction *
gArithmeticShiftRightRR(sqInt reg1, sqInt reg2)
{
	return genoperandoperand(ArithmeticShiftRightRR, reg1, reg2);
}

	/* Cogit>>#abortOffset */
sqInt
abortOffset(void)
{
	return missOffset;
}

	/* Cogit>>#addCleanBlockStarts */
static void
addCleanBlockStarts(void)
{
    sqInt i;
    sqInt iLimiT;
    sqInt lit;
    sqInt startPCOrNil;

	for (i = 1, iLimiT = (literalCountOf(methodObj)); i <= iLimiT; i += 1) {
		lit = fetchPointerofObject(i, methodObj);
		startPCOrNil = startPCOrNilOfLiteralin(lit, methodObj);
		if (!(startPCOrNil == null)) {
			maxLitIndex = ((maxLitIndex < i) ? i : maxLitIndex);
			addBlockStartAtnumArgsnumCopiedspan(startPCOrNil - 1, argumentCountOfClosure(lit), copiedValueCountOfClosure(lit), spanForCleanBlockStartingAt(startPCOrNil - 1));
		}
	}
}


/*	Perform an integrity/leak check using the heapMap.
	Set a bit at each cog method's header. */

	/* Cogit>>#addCogMethodsToHeapMap */
void
addCogMethodsToHeapMap(void)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			heapMapAtWordPut(cogMethod, 1);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* Cogit>>#addressIsInCurrentCompilation: */
static sqInt
addressIsInCurrentCompilation(sqInt address)
{
	return ((((usqInt)address)) >= ((methodLabel->address)))
	 && ((((usqInt)address)) < (youngReferrers()));
}

	/* Cogit>>#addressIsInFixups: */
static sqInt
addressIsInFixups(AbstractInstruction *address)
{
	return address >= (AbstractInstruction *)&fixups[0] && address < (AbstractInstruction *)&fixups[numAbstractOpcodes];
}

	/* Cogit>>#addressIsInInstructions: */
static sqInt
addressIsInInstructions(AbstractInstruction *address)
{
	return address >= &abstractOpcodes[0] && address < &abstractOpcodes[opcodeIndex];
}


/*	N.B. zero-relative */

	/* Cogit>>#addressOfEndOfCase:inCPIC: */
static sqInt
addressOfEndOfCaseinCPIC(sqInt n, CogMethod *cPIC)
{
	return ((((sqInt)cPIC)) + firstCPICCaseOffset) + (n * cPICCaseSize);
}

	/* Cogit>>#alignUptoRoutineBoundary: */
static sqInt
alignUptoRoutineBoundary(sqInt anAddress)
{
	return (((anAddress + 7) | 7) - 7);
}


/*	Check that all methods have valid selectors, and that all linked sends are
	to valid targets and have valid cache tags
 */

	/* Cogit>>#allMachineCodeObjectReferencesValid */
static sqInt
allMachineCodeObjectReferencesValid(void)
{
    CogMethod *cogMethod;
    sqInt ok;

	ok = 1;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			if (!(asserta(checkValidOopReference((cogMethod->selector))))) {
				ok = 0;
			}
			if (!(asserta((cogMethodDoesntLookKosher(cogMethod)) == 0))) {
				ok = 0;
			}
		}
		if ((((cogMethod->cmType)) == CMMethod)
		 || (((cogMethod->cmType)) == CMOpenPIC)) {
			if (!(asserta((mapForperformUntilarg(cogMethod, checkIfValidOopRefAndTargetpccogMethod, ((sqInt)cogMethod))) == 0))) {
				ok = 0;
			}
		}
		if (((cogMethod->cmType)) == CMClosedPIC) {
			if (!(asserta(noTargetsFreeInClosedPIC(cogMethod)))) {
				ok = 0;
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return ok;
}

	/* Cogit>>#allMethodsHaveCorrectHeader */
static sqInt
allMethodsHaveCorrectHeader(void)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			if (!(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()))) {
				return 0;
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return 1;
}

	/* Cogit>>#annotateAbsolutePCRef: */
static AbstractInstruction *
annotateAbsolutePCRef(AbstractInstruction *abstractInstruction)
{
	(abstractInstruction->annotation = IsAbsPCReference);
	return abstractInstruction;
}

	/* Cogit>>#annotateBytecode: */
static AbstractInstruction *
annotateBytecode(AbstractInstruction *abstractInstruction)
{
	(abstractInstruction->annotation = HasBytecodePC);
	return abstractInstruction;
}

	/* Cogit>>#annotate:objRef: */
static AbstractInstruction *
annotateobjRef(AbstractInstruction *abstractInstruction, sqInt anOop)
{
	if (shouldAnnotateObjectReference(anOop)) {
		if (isYoungObject(anOop)) {
			hasYoungReferent = 1;
		}
		(abstractInstruction->annotation = IsObjectReference);
	}
	return abstractInstruction;
}


/*	Answer the annotation for mcpc in cogHomeMethod's map, or 0 if no entry
	exists. 
 */

	/* Cogit>>#annotationForMcpc:in: */
static sqInt
annotationForMcpcin(sqInt mcpc, CogMethod *cogHomeMethod)
{
    sqInt annotation;
    sqInt mapByte;
    sqInt mapLocation;

	mapLocation = findMapLocationForMcpcinMethod(mcpc, cogHomeMethod);
	if (mapLocation == 0) {
		return 0;
	}
	mapByte = byteAt(mapLocation);
	annotation = ((usqInt) mapByte) >> AnnotationShift;
	if (annotation == IsSendCall) {
		mapByte = byteAt(mapLocation - 1);
		if ((((usqInt) mapByte) >> AnnotationShift) == IsAnnotationExtension) {
			annotation += mapByte & DisplacementMask;
		}
	}
	return annotation;
}

	/* Cogit>>#assertSaneJumpTarget: */
static void
assertSaneJumpTarget(AbstractInstruction *jumpTarget)
{
	assert((closedPICSize == null)
	 || ((openPICSize == null)
	 || ((addressIsInInstructions(jumpTarget))
	 || ((((((usqInt)jumpTarget)) >= codeBase) && ((((usqInt)jumpTarget)) <= ((((sqInt)(limitZony()))) + (((closedPICSize < openPICSize) ? openPICSize : closedPICSize)))))))));
}

	/* Cogit>>#blockCreationBytecodeSizeForHeader: */
static sqInt
blockCreationBytecodeSizeForHeader(sqInt methodHeader)
{
	return BlockCreationBytecodeSize;
}


/*	Evaluate binaryFunction with the block start mcpc and supplied arg for
	each entry in the block dispatch. If the function answers non-zero answer
	the value
	it answered. Used to update back-references to the home method in
	compaction.  */

	/* Cogit>>#blockDispatchTargetsFor:perform:arg: */
static sqInt
blockDispatchTargetsForperformarg(CogMethod *cogMethod, usqInt (*binaryFunction)(sqInt mcpc, sqInt arg), sqInt arg)
{
    sqInt blockEntry;
    sqInt end;
    sqInt pc;
    sqInt result;
    usqInt targetpc;

	if (((cogMethod->blockEntryOffset)) == 0) {
		return null;
	}
	blockEntry = ((cogMethod->blockEntryOffset)) + (((sqInt)cogMethod));
	pc = blockEntry;
	end = (mapEndFor(cogMethod)) - 1;
	while (pc < end) {
		if (isJumpAt(backEnd, pc)) {
			targetpc = jumpTargetPCAt(backEnd, pc);
			if (targetpc < blockEntry) {
				result = binaryFunction(targetpc, arg);
				if (result != 0) {
					return result;
				}
			}
		}
		pc += instructionSizeAt(backEnd, pc);
	}
	return 0;
}


/*	Answer the zero-relative bytecode pc matching the machine code pc argument
	in cogMethod, given the start of the bytecodes for cogMethod's block or
	method object. */

	/* Cogit>>#bytecodePCFor:startBcpc:in: */
sqInt
bytecodePCForstartBcpcin(sqInt mcpc, sqInt startbcpc, CogBlockMethod *cogMethod)
{
    sqInt aMethodObj;
    sqInt annotation;
    sqInt bcpc;
    sqInt bsOffset;
    sqInt byte;
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt endbcpc;
    CogMethod *homeMethod;
    sqInt isBackwardBranch;
    sqInt isInBlock;
    sqInt latestContinuation;
    sqInt map;
    sqInt mapByte;
    usqInt mcpc1;
    sqInt methodHeader;
    sqInt methodHeader1;
    sqInt nExts;
    sqInt nextBcpc;
    sqInt result;
    sqInt targetPC;

	latestContinuation = 0;
	/* begin mapFor:bcpc:performUntil:arg: */
	assert(((cogMethod->stackCheckOffset)) > 0);
	if (((cogMethod->cmType)) == CMMethod) {
		isInBlock = 0;
		homeMethod = ((CogMethod *) cogMethod);
		assert(startbcpc == (startPCOfMethodHeader((homeMethod->methodHeader))));
		map = ((((usqInt)homeMethod)) + ((homeMethod->blockSize))) - 1;
		assert(((((usqInt) (byteAt(map))) >> AnnotationShift) == IsAbsPCReference)
		 || (((((usqInt) (byteAt(map))) >> AnnotationShift) == IsObjectReference)
		 || (((((usqInt) (byteAt(map))) >> AnnotationShift) == IsRelativeCall)
		 || ((((usqInt) (byteAt(map))) >> AnnotationShift) == IsDisplacementX2N))));
		latestContinuation = startbcpc;
		aMethodObj = (homeMethod->methodObject);
		endbcpc = (numBytesOf(aMethodObj)) - 1;
		/* begin bytecodeSetOffsetForHeader: */
		methodHeader = (homeMethod->methodHeader);
		bsOffset = 0;
	}
	else {
		isInBlock = 1;
		homeMethod = cmHomeMethod(cogMethod);
		map = findMapLocationForMcpcinMethod((((usqInt)cogMethod)) + (sizeof(CogBlockMethod)), homeMethod);
		assert(map != 0);
		assert(((((usqInt) (byteAt(map))) >> AnnotationShift) == HasBytecodePC)
		 || ((((usqInt) (byteAt(map))) >> AnnotationShift) == IsDisplacementX2N));
		while ((((usqInt) (byteAt(map))) >> AnnotationShift) != HasBytecodePC) {
			map -= 1;
		}

		/* skip fiducial; i.e. the map entry for the pc immediately following the method header. */

		map -= 1;
		aMethodObj = (homeMethod->methodObject);
		bcpc = startbcpc - (blockCreationBytecodeSizeForHeader((homeMethod->methodHeader)));
		/* begin bytecodeSetOffsetForHeader: */
		methodHeader1 = (homeMethod->methodHeader);
		bsOffset = 0;
		byte = (fetchByteofObject(bcpc, aMethodObj)) + bsOffset;
		descriptor = generatorAt(byte);
		endbcpc = (bcpc + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bcpc, -1, aMethodObj)
	: 0));
	}
	bcpc = startbcpc;
	mcpc1 = (((usqInt)cogMethod)) + ((cogMethod->stackCheckOffset));

	/* The stack check maps to the start of the first bytecode,
	   the first bytecode being effectively after frame build. */

	nExts = 0;
	result = findIsBackwardBranchMcpcBcpcMatchingMcpc(null, 0, (((char *) mcpc1)), startbcpc, (((void *)mcpc)));
	if (result != 0) {
		return result;
	}
	while ((((usqInt) (byteAt(map))) >> AnnotationShift) != HasBytecodePC) {
		map -= 1;
	}
	map -= 1;
	while (((mapByte = byteAt(map))) != MapEnd) {

		/* defensive; we exit on bcpc */

		if (mapByte >= FirstAnnotation) {
			annotation = ((usqInt) mapByte) >> AnnotationShift;
			mcpc1 += (mapByte & DisplacementMask) * 4;
			if ((annotation >= IsSendCall)
			 || ((annotation == HasBytecodePC)
			 || (0))) {
				while (1) {
					byte = (fetchByteofObject(bcpc, aMethodObj)) + bsOffset;
					descriptor = generatorAt(byte);
					if (isInBlock) {
						if (bcpc >= endbcpc) {
							return 0;
						}
					}
					else {
						if (((descriptor->isReturn))
						 && (bcpc >= latestContinuation)) {
							return 0;
						}
						if ((isBranch(descriptor))
						 || ((descriptor->isBlockCreation))) {
							/* begin latestContinuationPCFor:at:exts:in: */
							distance = ((descriptor->spanFunction))(descriptor, bcpc, nExts, aMethodObj);
							targetPC = (bcpc + ((descriptor->numBytes))) + (((distance < 0) ? 0 : distance));
							latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
						}
					}
					nextBcpc = (bcpc + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bcpc, nExts, aMethodObj)
	: 0));
					if (((descriptor->isMapped))
					 || (isInBlock
					 && ((descriptor->isMappedInBlock)))) break;
					bcpc = nextBcpc;
					nExts = ((descriptor->isExtension)
						? nExts + 1
						: 0);
				}
				isBackwardBranch = (isBranch(descriptor))
				 && (isBackwardBranchatextsin(descriptor, bcpc, nExts, aMethodObj));
				result = findIsBackwardBranchMcpcBcpcMatchingMcpc(descriptor, isBackwardBranch, (((char *) mcpc1)), bcpc, (((void *)mcpc)));
				if (result != 0) {
					return result;
				}
				bcpc = nextBcpc;
				nExts = ((descriptor->isExtension)
					? nExts + 1
					: 0);
			}
		}
		else {
			assert(((((usqInt) mapByte) >> AnnotationShift) == IsDisplacementX2N)
			 || ((((usqInt) mapByte) >> AnnotationShift) == IsAnnotationExtension));
			if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
				mcpc1 += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
			}
		}
		map -= 1;
	}
	return 0;
}

	/* Cogit>>#CallRT:registersToBeSavedMask: */
static AbstractInstruction *
CallRTregistersToBeSavedMask(sqInt callTarget, sqInt registersToBeSaved)
{
    AbstractInstruction *abstractInstruction;
    sqInt callerSavedRegsToBeSaved;
    AbstractInstruction *lastInst;
    sqInt reg;

	callerSavedRegsToBeSaved = callerSavedRegMask & registersToBeSaved;
	for (reg = GPRegMax; reg >= GPRegMin; reg += -1) {
		if ((reg != TempReg)
		 && (callerSavedRegsToBeSaved & (registerMaskFor(reg)))) {
			/* begin PushR: */
			genoperand(PushR, reg);
		}
	}
	/* begin CallRT: */
	/* begin annotateCall: */
	/* begin Call: */
	abstractInstruction = genoperand(Call, callTarget);
	(abstractInstruction->annotation = IsRelativeCall);
	lastInst = abstractInstruction;
	for (reg = GPRegMin; reg <= GPRegMax; reg += 1) {
		if ((reg != TempReg)
		 && (callerSavedRegsToBeSaved & (registerMaskFor(reg)))) {
			/* begin PopR: */
			lastInst = genoperand(PopR, reg);
		}
	}
	return lastInst;
}

	/* Cogit>>#Call: */
static AbstractInstruction *
gCall(sqInt callTarget)
{
	return genoperand(Call, callTarget);
}

	/* Cogit>>#CmpCq:R: */
static AbstractInstruction *
gCmpCqR(sqInt quickConstant, sqInt reg)
{
	/* begin gen:quickConstant:operand: */
	return checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, reg));
}

	/* Cogit>>#CmpCw:R: */
static AbstractInstruction *
gCmpCwR(sqInt wordConstant, sqInt reg)
{
	/* begin gen:literal:operand: */
	return checkLiteralforInstruction(wordConstant, genoperandoperand(CmpCwR, wordConstant, reg));
}

	/* Cogit>>#CmpR:R: */
static AbstractInstruction *
gCmpRR(sqInt reg1, sqInt reg2)
{
	return genoperandoperand(CmpRR, reg1, reg2);
}


/*	This is a static version of ceCallCogCodePopReceiverReg
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

	/* Cogit>>#callCogCodePopReceiver */
void
callCogCodePopReceiver(void)
{
	realCECallCogCodePopReceiverReg();
	error("what??");

}


/*	This is a static version of ceCallCogCodePopReceiverAndClassRegs
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

	/* Cogit>>#callCogCodePopReceiverAndClassRegs */
void
callCogCodePopReceiverAndClassRegs(void)
{
	realCECallCogCodePopReceiverAndClassRegs();
}


/*	Code entry closed PIC miss. A send has fallen
	through a closed (finite) polymorphic inline cache.
	Either extend it or patch the send site to an open PIC.
	The stack looks like:
	receiver
	args
	sp=>	sender return address */

	/* Cogit>>#ceCPICMiss:receiver: */
sqInt
ceCPICMissreceiver(CogMethod *cPIC, sqInt receiver)
{
    sqInt cacheTag;
    sqInt errorSelectorOrNil;
    sqInt errsel;
    sqInt method;
    sqInt methodOrSelectorIndex;
    sqInt newTargetMethodOrNil;
    sqInt outerReturn;
    sqInt result;
    sqInt selector;

	
	if (isOopForwarded(receiver)) {
		return ceSendFromInLineCacheMiss(cPIC);
	}
	outerReturn = stackTop();
	assert(!(((inlineCacheTagAt(backEnd, outerReturn)) == (picAbortDiscriminatorValue()))));
	if (((cPIC->cPICNumCases)) < numPICCases) {
		/* begin lookup:for:methodAndErrorSelectorInto: */
		selector = (cPIC->selector);
		methodOrSelectorIndex = lookupOrdinaryreceiver(selector, receiver);
		if ((((usqInt)methodOrSelectorIndex)) > (maxLookupNoMNUErrorCode())) {
			if (!(isOopCompiledMethod(methodOrSelectorIndex))) {
				newTargetMethodOrNil = methodOrSelectorIndex;
				errorSelectorOrNil = SelectorCannotInterpret;

				goto l1;
			}
			if ((!(methodHasCogMethod(methodOrSelectorIndex)))
			 && (methodShouldBeCogged(methodOrSelectorIndex))) {

				/* We assume cog:selector: will *not* reclaim the method zone */

				cogselector(methodOrSelectorIndex, selector);
			}
			newTargetMethodOrNil = methodOrSelectorIndex;
			errorSelectorOrNil = null;

			goto l1;
		}
		if (methodOrSelectorIndex == SelectorDoesNotUnderstand) {
			methodOrSelectorIndex = lookupMNUreceiver(splObj(SelectorDoesNotUnderstand), receiver);
			if ((((usqInt)methodOrSelectorIndex)) > (maxLookupNoMNUErrorCode())) {
				assert(isOopCompiledMethod(methodOrSelectorIndex));
				if ((!(methodHasCogMethod(methodOrSelectorIndex)))
				 && (methodShouldBeCogged(methodOrSelectorIndex))) {

					/* We assume cog:selector: will *not* reclaim the method zone */

					cogselector(methodOrSelectorIndex, splObj(SelectorDoesNotUnderstand));
				}
				newTargetMethodOrNil = methodOrSelectorIndex;
				errorSelectorOrNil = SelectorDoesNotUnderstand;

				goto l1;
			}
			newTargetMethodOrNil = null;
			errorSelectorOrNil = SelectorDoesNotUnderstand;

			goto l1;
		}
		newTargetMethodOrNil = null;
		errorSelectorOrNil = methodOrSelectorIndex;

	l1:	/* end lookup:for:methodAndErrorSelectorInto: */;
	}
	else {
		newTargetMethodOrNil = (errorSelectorOrNil = null);
	}
	assert(outerReturn == (stackTop()));
	cacheTag = inlineCacheTagForInstance(receiver);
	if ((((cPIC->cPICNumCases)) >= numPICCases)
	 || (((errorSelectorOrNil != null)
	 && (errorSelectorOrNil != SelectorDoesNotUnderstand))
	 || ((newTargetMethodOrNil == null)
	 || (isYoung(newTargetMethodOrNil))))) {
		result = patchToOpenPICFornumArgsreceiver((cPIC->selector), (cPIC->cmNumArgs), receiver);
		assert(!result);
		return ceSendFromInLineCacheMiss(cPIC);
	}
	cogExtendPICCaseNMethodtagisMNUCase(cPIC, newTargetMethodOrNil, cacheTag, errorSelectorOrNil == SelectorDoesNotUnderstand);
	executeCogPICfromLinkedSendWithReceiverandCacheTag(cPIC, receiver, inlineCacheTagAt(backEnd, outerReturn));
	return null;
}


/*	An in-line cache check in a method has failed. The failing entry check has
	jumped to the ceMethodAbort abort call at the start of the method which
	has called this routine.
	If possible allocate a closed PIC for the current and existing classes.
	The stack looks like:
	receiver
	args
	sender return address
	sp=>	ceMethodAbort call return address
	So we can find the method that did the failing entry check at
	ceMethodAbort call return address - missOffset
	and we can find the send site from the outer return address. */

	/* Cogit>>#ceSICMiss: */
sqInt
ceSICMiss(sqInt receiver)
{
    sqInt cacheTag;
    sqInt entryPoint;
    sqInt errorSelectorOrNil;
    sqInt errsel;
    sqInt extent;
    usqInt innerReturn;
    sqInt method;
    sqInt methodOrSelectorIndex;
    sqInt newTargetMethodOrNil;
    usqInt outerReturn;
    CogMethod *pic;
    sqInt result;
    sqInt selector;
    CogMethod *targetMethod;


	/* Whether we can relink to a PIC or not we need to pop off the inner return and identify the target method. */

	innerReturn = ((usqInt)(popStack()));
	targetMethod = ((CogMethod *) (innerReturn - missOffset));
	if (isOopForwarded(receiver)) {
		return ceSendFromInLineCacheMiss(targetMethod);
	}
	outerReturn = ((usqInt)(stackTop()));
	assert(((outerReturn >= methodZoneBase) && (outerReturn <= (freeStart()))));
	entryPoint = callTargetFromReturnAddress(backEnd, outerReturn);
	assert(((targetMethod->selector)) != (nilObject()));
	
	assert(((((sqInt)targetMethod)) + cmEntryOffset) == entryPoint);
	/* begin lookup:for:methodAndErrorSelectorInto: */
	selector = (targetMethod->selector);
	methodOrSelectorIndex = lookupOrdinaryreceiver(selector, receiver);
	if ((((usqInt)methodOrSelectorIndex)) > (maxLookupNoMNUErrorCode())) {
		if (!(isOopCompiledMethod(methodOrSelectorIndex))) {
			newTargetMethodOrNil = methodOrSelectorIndex;
			errorSelectorOrNil = SelectorCannotInterpret;

			goto l1;
		}
		if ((!(methodHasCogMethod(methodOrSelectorIndex)))
		 && (methodShouldBeCogged(methodOrSelectorIndex))) {

			/* We assume cog:selector: will *not* reclaim the method zone */

			cogselector(methodOrSelectorIndex, selector);
		}
		newTargetMethodOrNil = methodOrSelectorIndex;
		errorSelectorOrNil = null;

		goto l1;
	}
	if (methodOrSelectorIndex == SelectorDoesNotUnderstand) {
		methodOrSelectorIndex = lookupMNUreceiver(splObj(SelectorDoesNotUnderstand), receiver);
		if ((((usqInt)methodOrSelectorIndex)) > (maxLookupNoMNUErrorCode())) {
			assert(isOopCompiledMethod(methodOrSelectorIndex));
			if ((!(methodHasCogMethod(methodOrSelectorIndex)))
			 && (methodShouldBeCogged(methodOrSelectorIndex))) {

				/* We assume cog:selector: will *not* reclaim the method zone */

				cogselector(methodOrSelectorIndex, splObj(SelectorDoesNotUnderstand));
			}
			newTargetMethodOrNil = methodOrSelectorIndex;
			errorSelectorOrNil = SelectorDoesNotUnderstand;

			goto l1;
		}
		newTargetMethodOrNil = null;
		errorSelectorOrNil = SelectorDoesNotUnderstand;

		goto l1;
	}
	newTargetMethodOrNil = null;
	errorSelectorOrNil = methodOrSelectorIndex;

l1:	/* end lookup:for:methodAndErrorSelectorInto: */;
	assert(outerReturn == (stackTop()));
	cacheTag = inlineCacheTagForInstance(receiver);
	if (((errorSelectorOrNil != null)
	 && (errorSelectorOrNil != SelectorDoesNotUnderstand))
	 || (((inlineCacheTagAt(backEnd, outerReturn)) == 0)
	 || ((newTargetMethodOrNil == null)
	 || (isYoung(newTargetMethodOrNil))))) {
		result = patchToOpenPICFornumArgsreceiver((targetMethod->selector), (targetMethod->cmNumArgs), receiver);
		assert(!result);
		return ceSendFromInLineCacheMiss(targetMethod);
	}
	pic = openPICWithSelector((targetMethod->selector));
	if (pic == null) {

		/* otherwise attempt to create a closed PIC for the two cases. */

		pic = cogPICSelectornumArgsCase0MethodCase1MethodtagisMNUCase((targetMethod->selector), (targetMethod->cmNumArgs), targetMethod, newTargetMethodOrNil, cacheTag, errorSelectorOrNil == SelectorDoesNotUnderstand);
		if ((((((sqInt)pic)) >= MaxNegativeErrorCode) && ((((sqInt)pic)) <= -1))) {

			/* For some reason the PIC couldn't be generated, most likely a lack of code memory.
			   Continue as if this is an unlinked send. */

			if ((((sqInt)pic)) == InsufficientCodeSpace) {
				callForCogCompiledCodeCompaction();
			}
			return ceSendFromInLineCacheMiss(targetMethod);
		}
		flushICacheFromto(processor, ((usqInt)pic), (((usqInt)pic)) + closedPICSize);
	}
	extent = (((pic->cmType)) == CMOpenPIC
		? rewriteInlineCacheAttagtarget(backEnd, outerReturn, (targetMethod->selector), (((sqInt)pic)) + cmEntryOffset)
		: rewriteCallAttarget(backEnd, outerReturn, (((sqInt)pic)) + cmEntryOffset));
	flushICacheFromto(processor, (((usqInt)outerReturn)) - extent, ((usqInt)outerReturn));
	executeCogPICfromLinkedSendWithReceiverandCacheTag(pic, receiver, inlineCacheTagAt(backEnd, outerReturn));
	return null;
}

	/* Cogit>>#checkAssertsEnabledInCogit */
void
checkAssertsEnabledInCogit(void)
{
    sqInt assertsAreEnabledInCogit;

	assertsAreEnabledInCogit = 0;
	assert(assertsAreEnabledInCogit);
}


/*	Check for a valid object reference, if any, at a map entry. Answer a code
	unique to each error for debugging. */

	/* Cogit>>#checkIfValidOopRefAndTarget:pc:cogMethod: */
static sqInt
checkIfValidOopRefAndTargetpccogMethod(sqInt annotation, char *mcpc, sqInt cogMethod)
{
    sqInt cacheTag;
    sqInt cacheTag1;
    sqInt entryPoint;
    sqInt entryPoint1;
    sqInt literal;
    sqInt offset;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt tagCouldBeObj;
    sqInt tagCouldBeObject;
    sqInt targetMethod;
    CogMethod *targetMethod1;

	if (annotation == IsObjectReference) {
		literal = longAt(((usqInt)mcpc));
		if (!(asserta(checkValidOopReference(literal)))) {
			return 1;
		}
		if ((couldBeObject(literal))
		 && (isReallyYoungObject(literal))) {
			if (!(asserta(((((CogMethod *) cogMethod))->cmRefersToYoung)))) {
				return 2;
			}
		}
	}
	
	if (annotation >= IsSendCall) {
		if (!(asserta((((((CogMethod *) cogMethod))->cmType)) == CMMethod))) {
			return 3;
		}
		/* begin offsetCacheTagAndCouldBeObjectAt:annotation:into: */
		cacheTag1 = inlineCacheTagAt(backEnd, ((sqInt)mcpc));

		/* in-line cache tags are the selectors of sends if sends are unlinked,
		   the selectors of super sends (entry offset = cmNoCheckEntryOffset),
		   the selectors of open PIC sends (entry offset = cmEntryOffset, target is an Open PIC)
		   or in-line cache tags (classes, class indices, immediate bit patterns, etc).
		   Note that selectors can be immediate so there is no guarantee that they
		   are markable/remappable objects. */

		entryPoint1 = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		tagCouldBeObj = (entryPoint1 < methodZoneBase)
		 || (((entryPoint1 & entryPointMask) == uncheckedEntryAlignment)
		 || (((entryPoint1 & entryPointMask) == checkedEntryAlignment)
		 && ((((((CogMethod *) (entryPoint1 - cmEntryOffset)))->cmType)) == CMOpenPIC)));
		if (tagCouldBeObj) {
			if (couldBeObject(cacheTag1)) {
				if (!(asserta(checkValidOopReference(cacheTag1)))) {
					return 4;
				}
			}
			else {
				if (!(asserta(validInlineCacheTag(cacheTag1)))) {
					return 5;
				}
			}
			if ((couldBeObject(cacheTag1))
			 && (isReallyYoungObject(cacheTag1))) {
				if (!(asserta(((((CogMethod *) cogMethod))->cmRefersToYoung)))) {
					return 6;
				}
			}
		}
		else {
			if (!(asserta(validInlineCacheTag(cacheTag1)))) {
				return 7;
			}
		}

		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send; find which kind. */

			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if (!(asserta((((targetMethod1->cmType)) == CMMethod)
				 || ((((targetMethod1->cmType)) == CMClosedPIC)
				 || (((targetMethod1->cmType)) == CMOpenPIC))))) {
				return 8;
			}

		}
	}
	return 0;
}


/*	Check for a valid object reference, if any, at a map entry. Answer a code
	unique to each error for debugging. */

	/* Cogit>>#checkIfValidOopRef:pc:cogMethod: */
static sqInt
checkIfValidOopRefpccogMethod(sqInt annotation, char *mcpc, sqInt cogMethod)
{
    sqInt entryPoint;
    sqInt literal;
    sqInt off;
    sqInt offset;
    sqInt offset1;
    sqInt selectorOrCacheTag;
    sqInt *sendTable;
    sqInt table;

	if (annotation == IsObjectReference) {
		literal = longAt(((usqInt)mcpc));
		if (!(checkValidOopReference(literal))) {
			print("object ref leak in CM ");
			printHex(((sqInt)cogMethod));
			print(" @ ");
			printHex(((sqInt)mcpc));
			cr();
			return 1;
		}
	}
	
	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint <= methodZoneBase) {
			offset = entryPoint;
		}
		else {
			/* begin offsetAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				offset1 = cmEntryOffset;
				sendTable = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				offset1 = cmNoCheckEntryOffset;
				sendTable = superSendTrampolines;



			}
			offset = offset1;

		}
		selectorOrCacheTag = inlineCacheTagAt(backEnd, ((sqInt)mcpc));
		if ((entryPoint > methodZoneBase)
		 && ((offset != cmNoCheckEntryOffset)
		 && ((((((CogMethod *) (entryPoint - offset)))->cmType)) != CMOpenPIC))) {

			/* linked non-super send, cacheTag is a cacheTag */

			if (!(validInlineCacheTag(selectorOrCacheTag))) {
				print("cache tag leak in CM ");
				printHex(((sqInt)cogMethod));
				print(" @ ");
				printHex(((sqInt)mcpc));
				cr();
				return 1;
			}
		}
		else {

			/* unlinked send or super send; cacheTag is a selector */

			if (!(checkValidOopReference(selectorOrCacheTag))) {
				print("selector leak in CM ");
				printHex(((sqInt)cogMethod));
				print(" @ ");
				printHex(((sqInt)mcpc));
				cr();
				return 1;
			}
		}
	}
	return 0;
}


/*	Answer if all references to objects in machine-code are valid. */

	/* Cogit>>#checkIntegrityOfObjectReferencesInCode: */
sqInt
checkIntegrityOfObjectReferencesInCode(sqInt gcModes)
{
    CogMethod *cogMethod;
    sqInt count;
    sqInt ok;

	cogMethod = ((CogMethod *) methodZoneBase);
	ok = 1;
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			if ((cogMethod->cmRefersToYoung)) {
				if (((count = occurrencesInYoungReferrers(cogMethod))) != 1) {
					print("young referrer CM ");
					printHex(((sqInt)cogMethod));
					if (count == 0) {
						print(" is not in youngReferrers");
						cr();
					}
					else {
						print(" is in youngReferrers ");
						printNum(count);
						print(" times!");
						cr();
					}
					ok = 0;
				}
			}
			if (!(checkValidOopReference((cogMethod->selector)))) {
				print("object leak in CM ");
				printHex(((sqInt)cogMethod));
				print(" selector");
				cr();
				ok = 0;
			}
			if (((cogMethod->cmType)) == CMMethod) {
				assert(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()));
				if (!(checkValidObjectReference((cogMethod->methodObject)))) {
					print("object leak in CM ");
					printHex(((sqInt)cogMethod));
					print(" methodObject");
					cr();
					ok = 0;
				}
				if (!(isOopCompiledMethod((cogMethod->methodObject)))) {
					print("non-method in CM ");
					printHex(((sqInt)cogMethod));
					print(" methodObject");
					cr();
					ok = 0;
				}
				if ((mapForperformUntilarg(cogMethod, checkIfValidOopRefpccogMethod, ((sqInt)cogMethod))) != 0) {
					ok = 0;
				}
				if (((isYoungObject((cogMethod->methodObject)))
				 || (isYoung((cogMethod->selector))))
				 && (!((cogMethod->cmRefersToYoung)))) {
					print("CM ");
					printHex(((sqInt)cogMethod));
					print(" refers to young but not marked as such");
					cr();
					ok = 0;
				}

			}
			else {
				if (((cogMethod->cmType)) == CMClosedPIC) {
					if (!(checkValidObjectReferencesInClosedPIC(cogMethod))) {
						ok = 0;
					}
				}
				else {
					if (((cogMethod->cmType)) == CMOpenPIC) {
						if ((mapForperformUntilarg(cogMethod, checkIfValidOopRefpccogMethod, ((sqInt)cogMethod))) != 0) {
							ok = 0;
						}
					}
				}
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return ok;
}

	/* Cogit>>#checkMaybeObjRefInClosedPIC: */
static sqInt
checkMaybeObjRefInClosedPIC(sqInt maybeObject)
{
	if (maybeObject == 0) {
		return 1;
	}
	if (!(couldBeObject(maybeObject))) {
		return 1;
	}
	return checkValidObjectReference(maybeObject);
}

	/* Cogit>>#checkValidObjectReferencesInClosedPIC: */
static sqInt
checkValidObjectReferencesInClosedPIC(CogMethod *cPIC)
{
    sqInt i;
    sqInt ok;
    sqInt pc;

	ok = 1;
	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	if (!(checkMaybeObjRefInClosedPIC(objRefInClosedPICAt(pc - (jumpLongByteSize(backEnd)))))) {
		print("object leak in CPIC ");
		printHex(((sqInt)cPIC));
		print(" @ ");
		printHex(pc - (jumpLongByteSize(backEnd)));
		cr();
		ok = 0;
	}
	pc += cPICCaseSize;
	for (i = 2; i <= ((cPIC->cPICNumCases)); i += 1) {
		;
		if (!(checkMaybeObjRefInClosedPIC(objRefInClosedPICAt(pc - (jumpLongConditionalByteSize(backEnd)))))) {
			print("object leak in CPIC ");
			printHex(((sqInt)cPIC));
			print(" @ ");
			printHex(pc - (jumpLongConditionalByteSize(backEnd)));
			cr();
			ok = 0;
		}
		pc += cPICCaseSize;
	}
	return ok;
}


/*	Answer if the ClosedPIC refers to any unmarked objects or freed/freeable
	target methods,
	applying markAndTraceOrFreeCogMethod:firstVisit: to those targets to
	determine if freed/freeable.
 */

	/* Cogit>>#closedPICRefersToUnmarkedObject: */
static sqInt
closedPICRefersToUnmarkedObject(CogMethod *cPIC)
{
    sqInt entryPoint;
    sqInt i;
    sqInt object;
    sqInt offsetToLiteral;
    sqInt pc;
    CogMethod *targetMethod;

	if (!(isImmediate((cPIC->selector)))) {
		if (!(isMarked((cPIC->selector)))) {
			return 1;
		}
	}

	/* First jump is unconditional; subsequent ones are conditional */

	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	offsetToLiteral = jumpLongByteSize(backEnd);
	for (i = 1; i <= ((cPIC->cPICNumCases)); i += 1) {
		;
		object = longAt(pc - offsetToLiteral);
		if ((couldBeObject(object))
		 && (!(isMarked(object)))) {
			return 1;
		}
		offsetToLiteral = jumpLongConditionalByteSize(backEnd);

		/* Find target from jump.  Ignore jumps to the interpret and MNU calls within this PIC */

		entryPoint = jumpLongTargetBeforeFollowingAddress(backEnd(), pc - ((i <= 1
	? BytesPerOop
	: BytesPerOop + 4)));
		assert((entryPoint > methodZoneBase)
		 && (entryPoint < (freeStart())));
		if (!(((((usqInt)cPIC)) <= (((usqInt)entryPoint)))
			 && (((((usqInt)cPIC)) + ((cPIC->blockSize))) >= (((usqInt)entryPoint))))) {
			targetMethod = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
			assert((((targetMethod->cmType)) == CMMethod)
			 || (((targetMethod->cmType)) == CMFree));
			if (markAndTraceOrFreeCogMethodfirstVisit(targetMethod, (((usqInt)targetMethod)) > (((usqInt)pc)))) {
				return 1;
			}
		}
		pc += cPICCaseSize;
	}
	return 0;
}

	/* Cogit>>#codeEntryFor: */
char *
codeEntryFor(char *address)
{
    sqInt i;

	for (i = 0; i <= (trampolineTableIndex - 3); i += 2) {
		if (((address >= (trampolineAddresses[i + 1])) && (address <= ((trampolineAddresses[i + 3]) - 1)))) {
			return trampolineAddresses[i + 1];
		}
	}
	return null;
}

	/* Cogit>>#codeEntryNameFor: */
char *
codeEntryNameFor(char *address)
{
    sqInt i;

	for (i = 0; i <= (trampolineTableIndex - 3); i += 2) {
		if (((address >= (trampolineAddresses[i + 1])) && (address <= ((trampolineAddresses[i + 3]) - 1)))) {
			return trampolineAddresses[i];
		}
	}
	return null;
}

	/* Cogit>>#cogCodeBase */
sqInt
cogCodeBase(void)
{
	return codeBase;
}


/*	Answer the contents of the code zone as an array of pair-wise element,
	address in ascending address order.
	Answer a string for a runtime routine or abstract label (beginning, end,
	etc), a CompiledMethod for a CMMethod,
	or a selector (presumably a Symbol) for a PIC. */

	/* Cogit>>#cogCodeConstituents */
sqInt
cogCodeConstituents(void)
{
    CogMethod *cogMethod;
    sqInt constituents;
    sqInt count;
    sqInt i;
    sqInt label;
    sqInt value;


	/* + 3 for start, freeStart and end */

	count = (trampolineTableIndex / 2) + 3;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			count += 1;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	constituents = instantiateClassindexableSize(classArray(), count * 2);
	if (constituents == null) {
		return constituents;
	}
	pushRemappableOop(constituents);
	if ((((label = stringForCString("CogCode"))) == null)
	 || (((value = positive32BitIntegerFor(codeBase))) == null)) {
		return null;
	}
	storePointerUncheckedofObjectwithValue(0, topRemappableOop(), label);
	storePointerUncheckedofObjectwithValue(1, topRemappableOop(), value);
	for (i = 0; i < trampolineTableIndex; i += 2) {
		if ((((label = stringForCString(trampolineAddresses[i]))) == null)
		 || (((value = positive32BitIntegerFor(((usqInt)(trampolineAddresses[i + 1]))))) == null)) {
			popRemappableOop();
			return null;
		}
		storePointerUncheckedofObjectwithValue(2 + i, topRemappableOop(), label);
		storePointerUncheckedofObjectwithValue(3 + i, topRemappableOop(), value);
	}
	count = trampolineTableIndex + 2;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			storePointerUncheckedofObjectwithValue(count, topRemappableOop(), (((cogMethod->cmType)) == CMMethod
				? (cogMethod->methodObject)
				: (cogMethod->selector)));
			if (((value = positive32BitIntegerFor(((usqInt)cogMethod)))) == null) {
				popRemappableOop();
				return null;
			}
			storePointerUncheckedofObjectwithValue(count + 1, topRemappableOop(), value);
			count += 2;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if ((((label = stringForCString("CCFree"))) == null)
	 || (((value = positive32BitIntegerFor(mzFreeStart))) == null)) {
		popRemappableOop();
		return null;
	}
	storePointerUncheckedofObjectwithValue(count, topRemappableOop(), label);
	storePointerUncheckedofObjectwithValue(count + 1, topRemappableOop(), value);
	if ((((label = stringForCString("CCEnd"))) == null)
	 || (((value = positive32BitIntegerFor(limitAddress))) == null)) {
		popRemappableOop();
		return null;
	}
	storePointerUncheckedofObjectwithValue(count + 2, topRemappableOop(), label);
	storePointerUncheckedofObjectwithValue(count + 3, topRemappableOop(), value);
	constituents = popRemappableOop();
	beRootIfOld(constituents);
	return constituents;
}


/*	Extend the cPIC with the supplied case. If caseNMethod is cogged dispatch
	direct to
	its unchecked entry-point. If caseNMethod is not cogged, jump to the fast
	interpreter dispatch, and if isMNUCase then dispatch to fast MNU
	invocation and mark the cPIC as
	having the MNU case for cache flushing. */
/*	stack allocate the various collections so that they
	are effectively garbage collected on return. */

	/* Cogit>>#cogExtendPIC:CaseNMethod:tag:isMNUCase: */
static sqInt
cogExtendPICCaseNMethodtagisMNUCase(CogMethod *cPIC, sqInt caseNMethod, sqInt caseNTag, sqInt isMNUCase)
{
    sqInt address;
    AbstractInstruction *anInstruction;
    sqInt end;
    sqInt fixupSize;
    AbstractInstruction *inst;
    sqInt jumpTarget;
    sqInt opcodeSize;
    sqInt operand;
    sqInt size;
    sqInt target;
    sqInt wordConstant;

	compilationBreakpointisMNUCase((cPIC->selector), numBytesOf((cPIC->selector)), isMNUCase);
	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = 8;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	(methodLabel->address = ((usqInt)cPIC));
	(methodLabel->dependent = null);
	assert(!(inlineCacheTagIsYoung(caseNTag)));
	assert((caseNMethod != null)
	 && (!(isYoung(caseNMethod))));
	if ((!isMNUCase)
	 && (methodHasCogMethod(caseNMethod))) {
		operand = 0;
		target = (((sqInt)(cogMethodOf(caseNMethod)))) + cmNoCheckEntryOffset;
	}
	else {
		operand = caseNMethod;
		if (isMNUCase) {
			(cPIC->cpicHasMNUCase = 1);
			target = (((sqInt)cPIC)) + (sizeof(CogMethod));
		}
		else {
			target = (((sqInt)cPIC)) + (picInterpretAbortOffset());
		}
	}
	/* begin CmpCw:R: */
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(caseNTag, genoperandoperand(CmpCwR, caseNTag, TempReg));
	/* begin MoveUniqueCw:R: */
	/* begin gen:uniqueLiteral:operand: */
	/* begin uniqueLiteral:forInstruction: */
	anInstruction = genoperandoperand(MoveCwR, operand, SendNumArgsReg);
	assert(usesOutOfLineLiteral(anInstruction));
	(anInstruction->dependent = allocateLiteral(operand));
	anInstruction;
	/* begin DumpJumpLongZero: */
	inst = genoperand(JumpLongZero, ((sqInt)target));
	dumpLiterals(0);
	inst;
	/* begin MoveCw:R: */
	wordConstant = ((usqInt)cPIC);
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(wordConstant, genoperandoperand(MoveCwR, wordConstant, ClassReg));
	/* begin JumpLong: */
	jumpTarget = cPICMissTrampolineFor((cPIC->cmNumArgs));
	genoperand(JumpLong, jumpTarget);
	computeMaximumSizes();
	address = addressOfEndOfCaseinCPIC(((cPIC->cPICNumCases)) - 1, cPIC);
	size = generateInstructionsAt(address);
	end = outputInstructionsAt(address);
	flushICacheFromto(processor, ((usqInt)cPIC), (((usqInt)cPIC)) + closedPICSize);
	(cPIC->cPICNumCases = ((cPIC->cPICNumCases)) + 1);
	return 0;
}

	/* Cogit>>#cogitPostGCAction: */
void
cogitPostGCAction(sqInt gcMode)
{
	;
	assert(allMethodsHaveCorrectHeader());
	assert(((gcMode & (GCModeFull + GCModeNewSpace)) == 0)
	 || (kosherYoungReferrers()));
}


/*	Check that the header fields onf a non-free method are consistent with
	the type. Answer 0 if it is ok, otherwise answer a code for the error. */

	/* Cogit>>#cogMethodDoesntLookKosher: */
sqInt
cogMethodDoesntLookKosher(CogMethod *cogMethod)
{
	if (((((cogMethod->blockSize)) & (BytesPerWord - 1)) != 0)
	 || ((((cogMethod->blockSize)) < (sizeof(CogMethod)))
	 || (((cogMethod->blockSize)) >= 32768))) {
		return 1;
	}
	if (((cogMethod->cmType)) == CMFree) {
		return 2;
	}
	if (((cogMethod->cmType)) == CMMethod) {
		if (!((((cogMethod->methodHeader)) & 1))) {
			return 11;
		}
		if (!(couldBeObject((cogMethod->methodObject)))) {
			return 12;
		}
		if ((((cogMethod->stackCheckOffset)) > 0)
		 && (((cogMethod->stackCheckOffset)) < cmNoCheckEntryOffset)) {
			return 13;
		}
		return 0;
	}
	if (((cogMethod->cmType)) == CMOpenPIC) {
		if (((cogMethod->blockSize)) != openPICSize) {
			return 21;
		}
		if (((cogMethod->methodHeader)) != 0) {
			return 22;
		}
		if (((cogMethod->objectHeader)) >= 0) {
			if ((((cogMethod->methodObject)) != 0)
			 && ((((cogMethod->methodObject)) < methodZoneBase)
			 || ((((cogMethod->methodObject)) > ((freeStart()) - openPICSize))
			 || (((((cogMethod->methodObject)) & (BytesPerWord - 1)) != 0)
			 || ((((((CogMethod *) ((cogMethod->methodObject))))->cmType)) != CMOpenPIC))))) {
				return 23;
			}
		}
		if (((cogMethod->stackCheckOffset)) != 0) {
			return 24;
		}
		return 0;
	}
	if (((cogMethod->cmType)) == CMClosedPIC) {
		if (((cogMethod->blockSize)) != closedPICSize) {
			return 0x1F;
		}
		if (!(((((cogMethod->cPICNumCases)) >= 1) && (((cogMethod->cPICNumCases)) <= numPICCases)))) {
			return 32;
		}
		if (((cogMethod->methodHeader)) != 0) {
			return 33;
		}
		if (((cogMethod->methodObject)) != 0) {
			return 34;
		}
		return 0;
	}
	return 9;
}


/*	Attempt to create a one-case PIC for an MNU.
	The tag for the case is at the send site and so doesn't need to be
	generated. 
 */

	/* Cogit>>#cogMNUPICSelector:receiver:methodOperand:numArgs: */
CogMethod *
cogMNUPICSelectorreceivermethodOperandnumArgs(sqInt selector, sqInt rcvr, sqInt methodOperand, sqInt numArgs)
{
    sqInt end;
    sqInt fixupSize;
    sqInt opcodeSize;
    CogMethod *pic;
    sqInt size;
    sqInt startAddress;

	if ((isYoung(selector))
	 || ((inlineCacheTagForInstance(rcvr)) == 0)) {
		return 0;
	}
	compilationBreakpointisMNUCase(selector, numBytesOf(selector), 1);
	assert(endCPICCase0 != null);
	startAddress = allocate(closedPICSize);
	if (startAddress == 0) {
		callForCogCompiledCodeCompaction();
		return 0;
	}
	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = numPICCases * 9;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	(methodLabel->address = startAddress);
	(methodLabel->dependent = null);
	compileMNUCPICmethodOperandnumArgs(((CogMethod *) startAddress), methodOperand, numArgs);
	computeMaximumSizes();
	size = generateInstructionsAt(startAddress + (sizeof(CogMethod)));

	/* The missOffset is the same as the interpretOffset. On RISCs it includes an additional instruction. */

	end = outputInstructionsAt(startAddress + (sizeof(CogMethod)));
	assert(missOffset == ((((callInstructionByteSize(backEnd)) + ((picInterpretAbort->address))) + ((picInterpretAbort->machineCodeSize))) - startAddress));
	assert((startAddress + cmEntryOffset) == ((entry->address)));
	/* begin fillInCPICHeader:numArgs:numCases:hasMNUCase:selector: */
	pic = ((CogMethod *) startAddress);
	assert(!(isYoung(selector)));
	(pic->cmType = CMClosedPIC);
	(pic->objectHeader = 0);
	(pic->blockSize = closedPICSize);
	(pic->methodObject = 0);
	(pic->methodHeader = 0);
	(pic->selector = selector);
	(pic->cmNumArgs = numArgs);
	(pic->cmRefersToYoung = 0);
	(pic->cmUsageCount = initialClosedPICUsageCount());
	(pic->cpicHasMNUCase = 1);
	(pic->cPICNumCases = 1);
	(pic->blockEntryOffset = 0);
	assert(((pic->cmType)) == CMClosedPIC);
	assert(((pic->selector)) == selector);
	assert(((pic->cmNumArgs)) == numArgs);
	assert(((pic->cPICNumCases)) == 1);
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)pic)) + missOffset)) == (picAbortTrampolineFor(numArgs)));
	assert(closedPICSize == (roundUpLength(closedPICSize)));
	flushICacheFromto(processor, ((usqInt)pic), (((usqInt)pic)) + closedPICSize);
	return pic;
}


/*	Create an Open PIC. Temporarily create a direct call of
	ceSendFromOpenPIC:. Should become a probe of the first-level method lookup
	cache followed by a
	call of ceSendFromOpenPIC: if the probe fails. */

	/* Cogit>>#cogOpenPICSelector:numArgs: */
static CogMethod *
cogOpenPICSelectornumArgs(sqInt selector, sqInt numArgs)
{
    sqInt codeSize;
    sqInt end;
    sqInt fixupSize;
    sqInt mapSize;
    sqInt opcodeSize;
    CogMethod *pic;
    sqInt startAddress;

	compilationBreakpointisMNUCase(selector, numBytesOf(selector), 0);
	startAddress = allocate(openPICSize);
	if (startAddress == 0) {
		return ((CogMethod *) InsufficientCodeSpace);
	}
	(methodLabel->address = startAddress);
	(methodLabel->dependent = null);
	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = 100;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	compileOpenPICnumArgs(selector, numArgs);
	computeMaximumSizes();
	concretizeAt(methodLabel, startAddress);
	codeSize = generateInstructionsAt(startAddress + (sizeof(CogMethod)));
	mapSize = generateMapAtstart((startAddress + openPICSize) - 1, startAddress + cmNoCheckEntryOffset);
	assert((((entry->address)) - startAddress) == cmEntryOffset);
	assert(((roundUpLength((sizeof(CogMethod)) + codeSize)) + (roundUpLength(mapSize))) <= openPICSize);
	end = outputInstructionsAt(startAddress + (sizeof(CogMethod)));
	/* begin fillInOPICHeader:numArgs:selector: */
	pic = ((CogMethod *) startAddress);
	(pic->cmType = CMOpenPIC);
	(pic->objectHeader = 0);
	(pic->blockSize = openPICSize);
	addToOpenPICList(pic);
	(pic->methodHeader = 0);
	(pic->selector = selector);
	(pic->cmNumArgs = numArgs);
	if ((pic->cmRefersToYoung = isYoung(selector))) {
		addToYoungReferrers(pic);
	}
	(pic->cmUsageCount = initialOpenPICUsageCount());
	(pic->cpicHasMNUCase = 0);
	(pic->cPICNumCases = 0);
	(pic->blockEntryOffset = 0);
	assert(((pic->cmType)) == CMOpenPIC);
	assert(((pic->selector)) == selector);
	assert(((pic->cmNumArgs)) == numArgs);
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)pic)) + missOffset)) == (picAbortTrampolineFor(numArgs)));
	assert(openPICSize == (roundUpLength(openPICSize)));
	flushICacheFromto(processor, ((usqInt)pic), (((usqInt)pic)) + openPICSize);
	return pic;
}


/*	Attempt to create a two-case PIC for case0CogMethod and
	case1Method,case1Tag. The tag for case0CogMethod is at the send site and
	so doesn't need to be generated.
	case1Method may be any of
	- a Cog method; link to its unchecked entry-point
	- a CompiledMethod; link to ceInterpretMethodFromPIC:
	- a CompiledMethod; link to ceMNUFromPICMNUMethod:receiver: */

	/* Cogit>>#cogPICSelector:numArgs:Case0Method:Case1Method:tag:isMNUCase: */
static CogMethod *
cogPICSelectornumArgsCase0MethodCase1MethodtagisMNUCase(sqInt selector, sqInt numArgs, CogMethod *case0CogMethod, sqInt case1MethodOrNil, sqInt case1Tag, sqInt isMNUCase)
{
    sqInt end;
    sqInt fixupSize;
    sqInt opcodeSize;
    CogMethod *pic;
    sqInt size;
    sqInt startAddress;

	if (isYoung(selector)) {
		return ((CogMethod *) YoungSelectorInPIC);
	}
	compilationBreakpointisMNUCase(selector, numBytesOf(selector), isMNUCase);
	startAddress = allocate(closedPICSize);
	if (startAddress == 0) {
		return ((CogMethod *) InsufficientCodeSpace);
	}
	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = numPICCases * 9;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	(methodLabel->address = startAddress);
	(methodLabel->dependent = null);
	compileCPICCase0Case1MethodtagisMNUCasenumArgs(((CogMethod *) startAddress), case0CogMethod, case1MethodOrNil, case1Tag, isMNUCase, numArgs);
	computeMaximumSizes();
	size = generateInstructionsAt(startAddress + (sizeof(CogMethod)));

	/* The missOffset is the same as the interpretOffset. On RISCs it includes an additional instruction. */

	end = outputInstructionsAt(startAddress + (sizeof(CogMethod)));
	assert(missOffset == ((((callInstructionByteSize(backEnd)) + ((picInterpretAbort->address))) + ((picInterpretAbort->machineCodeSize))) - startAddress));
	assert((startAddress + cmEntryOffset) == ((entry->address)));
	assert(((endCPICCase0->address)) == (startAddress + firstCPICCaseOffset));
	assert(((endCPICCase1->address)) == ((startAddress + firstCPICCaseOffset) + cPICCaseSize));
	/* begin fillInCPICHeader:numArgs:numCases:hasMNUCase:selector: */
	pic = ((CogMethod *) startAddress);
	assert(!(isYoung(selector)));
	(pic->cmType = CMClosedPIC);
	(pic->objectHeader = 0);
	(pic->blockSize = closedPICSize);
	(pic->methodObject = 0);
	(pic->methodHeader = 0);
	(pic->selector = selector);
	(pic->cmNumArgs = numArgs);
	(pic->cmRefersToYoung = 0);
	(pic->cmUsageCount = initialClosedPICUsageCount());
	(pic->cpicHasMNUCase = isMNUCase);
	(pic->cPICNumCases = 2);
	(pic->blockEntryOffset = 0);
	assert(((pic->cmType)) == CMClosedPIC);
	assert(((pic->selector)) == selector);
	assert(((pic->cmNumArgs)) == numArgs);
	assert(((pic->cPICNumCases)) == 2);
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)pic)) + missOffset)) == (picAbortTrampolineFor(numArgs)));
	assert(closedPICSize == (roundUpLength(closedPICSize)));
	flushICacheFromto(processor, ((usqInt)pic), (((usqInt)pic)) + closedPICSize);
	return pic;
}


/*	Attempt to produce a machine code method for the bytecode method
	object aMethodObj. N.B. If there is no code memory available do *NOT*
	attempt to reclaim the method zone. Certain clients (e.g. ceSICMiss:)
	depend on the zone remaining constant across method generation. */

	/* Cogit>>#cog:selector: */
CogMethod *
cogselector(sqInt aMethodObj, sqInt aSelectorOop)
{
    CogMethod *cogMethod;


	/* In Newspeak we support annonymous accessors and hence tolerate the same
	   method being cogged multiple times.  But only if the method class association is nil. */

	assert(!((methodHasCogMethod(aMethodObj))));

	compilationBreakpointisMNUCase(aSelectorOop, lengthOf(aSelectorOop), 0);
	if (aMethodObj == breakMethod) {
		haltmsg("Compilation of breakMethod");
	}
	
	if (methodUsesAlternateBytecodeSet(aMethodObj)) {
		if ((numElementsIn(generatorTable)) <= 256) {
			return null;
		}
		bytecodeSetOffset = 256;
	}
	else {
		bytecodeSetOffset = 0;
	}
	ensureNoForwardedLiteralsIn(aMethodObj);
	methodObj = aMethodObj;
	cogMethod = compileCogMethod(aSelectorOop);
	if ((((((sqInt)cogMethod)) >= MaxNegativeErrorCode) && ((((sqInt)cogMethod)) <= -1))) {
		if ((((sqInt)cogMethod)) == InsufficientCodeSpace) {
			callForCogCompiledCodeCompaction();
		}
		/* begin maybeFreeCounters */
		return null;
	}
	return cogMethod;
}

	/* Cogit>>#compactCogCompiledCode */
void
compactCogCompiledCode(void)
{
	assert(noCogMethodsMaximallyMarked());
	markActiveMethodsAndReferents();
	freeOlderMethodsForCompaction();
	freePICsWithFreedTargets();
	planCompaction();
	updateStackZoneReferencesToCompiledCodePreCompaction();
	relocateMethodsPreCompaction();
	compactCompiledCode();
	assert(allMethodsHaveCorrectHeader());
	assert(kosherYoungReferrers());
	flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(freeStart())));
}


/*	The start of a CogMethod has a call to a run-time abort routine that
	either handles an in-line cache failure or a stack overflow. The routine
	selects the
	path depending on ReceiverResultReg; if zero it takes the stack overflow
	path; if nonzero the in-line cache miss path. Neither of these paths
	returns. The abort routine must be called; In the callee the method is
	located by
	adding the relevant offset to the return address of the call.
	
	N.B. This code must match that in compilePICAbort: so that the offset of
	the return address of the call is the same in methods and closed PICs. */

	/* Cogit>>#compileAbort */
static AbstractInstruction *
compileAbort(void)
{
    sqInt callTarget;

	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	stackOverflowCall = checkQuickConstantforInstruction(0, genoperandoperand(MoveCqR, 0, ReceiverResultReg));
	
	/* If there is a link register it must be saved (pushed onto the stack) before it
	   is smashed by the abort call, and hence needs to be manually handled here */

	/* begin PushR: */
	sendMiss = genoperand(PushR, LinkReg);
	/* begin Call: */
	callTarget = methodAbortTrampolineFor(methodOrBlockNumArgs);
	return genoperand(Call, callTarget);

}

	/* Cogit>>#compileBlockDispatchFrom:to: */
static sqInt
compileBlockDispatchFromto(sqInt lowBlockStartIndex, sqInt highBlockStartIndex)
{
    BlockStart *blockStart;
    sqInt halfWay;
    AbstractInstruction *jmp;
    void *jumpTarget;
    void *jumpTarget1;
    void *jumpTarget2;
    sqInt quickConstant;

	if (lowBlockStartIndex == highBlockStartIndex) {
		blockStart = blockStartAt(lowBlockStartIndex);
		/* begin Jump: */
		jumpTarget = (blockStart->entryLabel);
		genoperand(Jump, ((sqInt)jumpTarget));
		return null;
	}
	halfWay = (highBlockStartIndex + lowBlockStartIndex) / 2;
	assert(((halfWay >= lowBlockStartIndex) && (halfWay <= highBlockStartIndex)));

	/* N.B. FLAGS := TempReg - startpc */

	blockStart = blockStartAt(halfWay);
	/* begin CmpCq:R: */
	quickConstant = (((((blockStart->startpc)) + 1) << 1) | 1);
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, TempReg));
	if (lowBlockStartIndex == halfWay) {
		/* begin JumpLessOrEqual: */
		jumpTarget1 = (blockStart->entryLabel);
		genoperand(JumpLessOrEqual, ((sqInt)jumpTarget1));
		compileBlockDispatchFromto(halfWay + 1, highBlockStartIndex);
		return null;
	}
	if ((halfWay + 1) == highBlockStartIndex) {
		blockStart = blockStartAt(highBlockStartIndex);
		/* begin JumpGreater: */
		jumpTarget2 = (blockStart->entryLabel);
		genoperand(JumpGreater, ((sqInt)jumpTarget2));
		return compileBlockDispatchFromto(lowBlockStartIndex, halfWay);
	}
	/* begin JumpGreater: */
	jmp = genoperand(JumpGreater, ((sqInt)0));
	compileBlockDispatchFromto(lowBlockStartIndex, halfWay);
	if (halfWay == highBlockStartIndex) {
		blockStart = blockStartAt(highBlockStartIndex);
		jmpTarget(jmp, (blockStart->entryLabel));
	}
	else {
		jmpTarget(jmp, gLabel());
		compileBlockDispatchFromto(halfWay + 1, highBlockStartIndex);
	}
}


/*	Compile a block's entry. This looks like a dummy CogBlockMethod header
	(for frame parsing)
	followed by either a frame build, if a frame is required, or nothing. The
	CogMethodHeader's objectHeader field is a back pointer to the method, but
	this can't be filled in until code generation. */

	/* Cogit>>#compileBlockEntry: */
static void
compileBlockEntry(BlockStart *blockStart)
{
    AbstractInstruction *abstractInstruction;
    sqInt alignment;

	/* begin AlignmentNops: */
	alignment = blockAlignment();
	genoperand(AlignmentNops, alignment);
	(blockStart->fakeHeader = gLabel());
	
	switch (sizeof(CogBlockMethod)) {
	case 2 * BytesPerWord:
		/* begin Fill32: */
		genoperand(Fill32, 0);
		/* begin Fill32: */
		genoperand(Fill32, 0);
		break;
	case 3 * BytesPerWord:
		/* begin Fill32: */
		genoperand(Fill32, 0);
		/* begin Fill32: */
		genoperand(Fill32, 0);
		/* begin Fill32: */
		genoperand(Fill32, 0);
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	(blockStart->entryLabel = gLabel());
	if (needsFrame) {
		compileBlockFrameBuild(blockStart);
		if (recordBlockTrace()) {
			/* begin CallRT: */
			/* begin annotateCall: */
			/* begin Call: */
			abstractInstruction = genoperand(Call, ceTraceBlockActivationTrampoline);
			(abstractInstruction->annotation = IsRelativeCall);
			abstractInstruction;
		}
	}
	else {
		compileBlockFramelessEntry(blockStart);
	}
}


/*	Generate a call to aRoutine with up to 4 arguments. If resultRegOrNil is
	non-zero assign the C result to resultRegOrNil. If saveRegs, save all
	registers. Hack: a negative arg value indicates an abstract register, a
	non-negative value
	indicates a constant. */

	/* Cogit>>#compileCallFor:numArgs:arg:arg:arg:arg:resultReg:saveRegs: */
static void
compileCallFornumArgsargargargargresultRegsaveRegs(void *aRoutine, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt resultRegOrNil, sqInt saveRegs)
{
    AbstractInstruction *abstractInstruction;
    sqInt callTarget;
    const int cStackAlignment = STACK_ALIGN_BYTES;

	if (cStackAlignment > BytesPerWord) {
		genAlignCStackSavingRegistersnumArgswordAlignment(backEnd, saveRegs, numArgs, cStackAlignment / BytesPerWord);
	}
	if (saveRegs) {
		genSaveRegisters(backEnd);
	}
	if (numArgs > 0) {
		if (numArgs > 1) {
			if (numArgs > 2) {
				if (numArgs > 3) {
					if (regOrConst3 < 0) {
						genPassRegasArgument(backEnd, regOrConst3, 3);
					}
					else {
						genPassConstasArgument(backEnd, regOrConst3, 3);
					}
				}
				if (regOrConst2 < 0) {
					genPassRegasArgument(backEnd, regOrConst2, 2);
				}
				else {
					genPassConstasArgument(backEnd, regOrConst2, 2);
				}
			}
			if (regOrConst1 < 0) {
				genPassRegasArgument(backEnd, regOrConst1, 1);
			}
			else {
				genPassConstasArgument(backEnd, regOrConst1, 1);
			}
		}
		if (regOrConst0 < 0) {
			genPassRegasArgument(backEnd, regOrConst0, 0);
		}
		else {
			genPassConstasArgument(backEnd, regOrConst0, 0);
		}
	}
	/* begin CallFullRT: */
	callTarget = ((usqInt)aRoutine);
	/* begin CallFull: */
	/* begin gen:literal: */
	checkLiteralforInstruction(callTarget, genoperand(CallFull, callTarget));

	if (!(resultRegOrNil == null)) {
		genWriteCResultIntoReg(backEnd, resultRegOrNil);
	}
	if (saveRegs) {
		if (numArgs > 0) {
			genRemoveNArgsFromStack(backEnd, numArgs);
		}
		if (resultRegOrNil == null) {
			genRestoreRegs(backEnd);
		}
		else {
			genRestoreRegsExcept(backEnd, resultRegOrNil);
		}
	}
}


/*	Compile the cache tag computation and the first comparison. Answer the
	address of that comparison. */

	/* Cogit>>#compileCPICEntry */
static AbstractInstruction *
compileCPICEntry(void)
{
	entry = genGetInlineCacheClassTagFromintoforEntry(ReceiverResultReg, TempReg, 1);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, ClassReg, TempReg);
	/* begin JumpNonZero: */
	return genoperand(JumpNonZero, ((sqInt)0));
}


/*	Compile the code for a two-case PIC for case0CogMethod and
	case1Method,case1Tag. The tag for case0CogMethod is at the send site and
	so doesn't need to be generated.
	case1Method may be any of
	- a Cog method; jump to its unchecked entry-point
	- a CompiledMethod; jump to the ceInterpretFromPIC trampoline
	- nil; call ceMNUFromPIC */

	/* Cogit>>#compileCPIC:Case0:Case1Method:tag:isMNUCase:numArgs: */
static sqInt
compileCPICCase0Case1MethodtagisMNUCasenumArgs(CogMethod *cPIC, CogMethod *case0CogMethod, sqInt case1Method, sqInt case1Tag, sqInt isMNUCase, sqInt numArgs)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *inst;
    AbstractInstruction *inst1;
    AbstractInstruction *jumpNext;
    sqInt jumpTarget;
    sqInt jumpTarget1;
    sqInt operand;
    void *targetEntry;
    sqInt wordConstant;

	assert(case1Method != null);
	compilePICAbort(numArgs);
	assert(!(inlineCacheTagIsYoung(case1Tag)));
	if ((!isMNUCase)
	 && (methodHasCogMethod(case1Method))) {
		operand = 0;
		targetEntry = ((void *)((((sqInt)(cogMethodOf(case1Method)))) + cmNoCheckEntryOffset));
	}
	else {

		/* We do not scavenge PICs, hence we cannot cache the MNU method if it is in new space. */

		operand = ((case1Method == null)
		 || (isYoungObject(case1Method))
			? 0
			: case1Method);
		targetEntry = (case1Method == null
			? picMNUAbort
			: picInterpretAbort);
	}
	jumpNext = compileCPICEntry();
	/* begin MoveUniqueCw:R: */
	/* begin gen:uniqueLiteral:operand: */
	/* begin uniqueLiteral:forInstruction: */
	anInstruction = genoperandoperand(MoveCwR, 0, SendNumArgsReg);
	assert(usesOutOfLineLiteral(anInstruction));
	(anInstruction->dependent = allocateLiteral(0));
	anInstruction;
	/* begin DumpJumpLong: */
	inst = genoperand(JumpLong, ((sqInt)((((sqInt)case0CogMethod)) + cmNoCheckEntryOffset)));
	dumpLiterals(0);
	inst;
	/* begin CmpCw:R: */
	/* begin gen:literal:operand: */
	endCPICCase0 = checkLiteralforInstruction(case1Tag, genoperandoperand(CmpCwR, case1Tag, TempReg));
	jmpTarget(jumpNext, endCPICCase0);
	/* begin MoveUniqueCw:R: */
	/* begin gen:uniqueLiteral:operand: */
	/* begin uniqueLiteral:forInstruction: */
	anInstruction1 = genoperandoperand(MoveCwR, operand, SendNumArgsReg);
	assert(usesOutOfLineLiteral(anInstruction1));
	(anInstruction1->dependent = allocateLiteral(operand));
	anInstruction1;
	/* begin DumpJumpLongZero: */
	jumpTarget = ((sqInt)((isMNUCase
	? picMNUAbort
	: targetEntry)));
	inst1 = genoperand(JumpLongZero, ((sqInt)jumpTarget));
	dumpLiterals(0);
	inst1;
	/* begin MoveCw:R: */
	wordConstant = ((usqInt)cPIC);
	/* begin gen:literal:operand: */
	endCPICCase1 = checkLiteralforInstruction(wordConstant, genoperandoperand(MoveCwR, wordConstant, ClassReg));
	/* begin JumpLong: */
	jumpTarget1 = cPICMissTrampolineFor(numArgs);
	genoperand(JumpLong, jumpTarget1);
	return 0;
}


/*	The entry code to a method checks that the class of the current receiver
	matches that in the inline cache. Other non-obvious elements are that its
	alignment must be
	different from the alignment of the noCheckEntry so that the method map
	machinery can distinguish normal and super sends (super sends bind to the
	noCheckEntry).  */

	/* Cogit>>#compileEntry */
static void
compileEntry(void)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction * inst;

	entry = genGetInlineCacheClassTagFromintoforEntry(ReceiverResultReg, TempReg, 1);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, ClassReg, TempReg);
	/* begin JumpNonZero: */
	genoperand(JumpNonZero, ((sqInt)sendMiss));
	/* begin Label */
	noCheckEntry = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	if (compileSendTrace()) {
		/* begin saveAndRestoreLinkRegAround: */
		/* begin PushR: */
		inst = genoperand(PushR, LinkReg);
		/* begin CallRT: */
		/* begin annotateCall: */
		/* begin Call: */
		abstractInstruction = genoperand(Call, ceTraceLinkedSendTrampoline);
		(abstractInstruction->annotation = IsRelativeCall);
		abstractInstruction;

		/* begin PopR: */
		genoperand(PopR, LinkReg);
		inst;
	}
}


/*	Compile the top-level method body. */

	/* Cogit>>#compileMethodBody */
static sqInt
compileMethodBody(void)
{
	if (endPC < initialPC) {
		return 0;
	}
	return compileAbstractInstructionsFromthrough(initialPC, endPC);
}


/*	Compile the code for a one-case MNU PIC that calls ceMNUFromPIC for
	case0Tag The tag for case0 is at the send site and so doesn't need to be
	generated. 
 */

	/* Cogit>>#compileMNUCPIC:methodOperand:numArgs: */
static sqInt
compileMNUCPICmethodOperandnumArgs(CogMethod *cPIC, sqInt methodOperand, sqInt numArgs)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *inst;
    AbstractInstruction *jumpNext;
    sqInt jumpTarget;
    sqInt operand;

	compilePICAbort(numArgs);

	/* We do not scavenge PICs, hence we cannot cache the MNU method if it is in new space. */

	jumpNext = compileCPICEntry();
	operand = ((methodOperand == null)
	 || (isYoungObject(methodOperand))
		? 0
		: methodOperand);
	/* begin MoveUniqueCw:R: */
	/* begin gen:uniqueLiteral:operand: */
	/* begin uniqueLiteral:forInstruction: */
	anInstruction = genoperandoperand(MoveCwR, operand, SendNumArgsReg);
	assert(usesOutOfLineLiteral(anInstruction));
	(anInstruction->dependent = allocateLiteral(operand));
	anInstruction;
	/* begin DumpJumpLong: */
	inst = genoperand(JumpLong, ((sqInt)(((sqInt)picMNUAbort))));
	dumpLiterals(0);
	inst;
	jmpTarget(jumpNext, gMoveCwR(((usqInt)cPIC), ClassReg));
	/* begin JumpLong: */
	jumpTarget = cPICMissTrampolineFor(numArgs);
	genoperand(JumpLong, jumpTarget);
	return 0;
}


/*	The start of a PIC has a call to a run-time abort routine that either
	handles a dispatch to an
	interpreted method or a dispatch of an MNU case. The routine selects the
	path by testing
	ClassReg, which holds the inline cache tag; if equal to the
	picAbortDiscriminatorValue (zero)
	it takes the MNU path; if nonzero the dispatch to interpreter path.
	Neither of these paths
	returns. The abort routine must be called; In the callee the PIC is
	located by adding the
	relevant offset to the return address of the call.
	
	N.B. This code must match that in compileAbort so that the offset of the
	return address of
	the call is the same in methods and closed PICs. */

	/* Cogit>>#compilePICAbort: */
static sqInt
compilePICAbort(sqInt numArgs)
{
    sqInt callTarget;
    sqInt callTarget1;

	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	picMNUAbort = checkQuickConstantforInstruction(0, genoperandoperand(MoveCqR, 0, ClassReg));
	
	/* If there is a link register it must be saved (pushed onto the stack) before it
	   is smashed by the abort call, and hence needs to be manually handled here */

	null;
	/* begin PushR: */
	picInterpretAbort = genoperand(PushR, LinkReg);
	/* begin Call: */
	callTarget = picAbortTrampolineFor(numArgs);
	genoperand(Call, callTarget);

	return 0;
}


/*	Compile a primitive. If possible, performance-critical primtiives will
	be generated by their own routines (primitiveGenerator). Otherwise,
	if there is a primitive at all, we call the C routine with the usual
	stack-switching dance, test the primFailCode and then either return
	on success or continue to the method body. */

	/* Cogit>>#compilePrimitive */
static sqInt
compilePrimitive(void)
{
    PrimitiveDescriptor *primitiveDescriptor;
    void (*primitiveRoutine)(void);

	if (primitiveIndex == 0) {
		return 0;
	}
	if ((((primitiveDescriptor = primitiveGeneratorOrNil())) != null)
	 && ((((primitiveDescriptor->primitiveGenerator)) != null)
	 && (((((primitiveDescriptor->primNumArgs)) < 0)
	 || (((primitiveDescriptor->primNumArgs)) == (argumentCountOf(methodObj))))
	 && ((((primitiveDescriptor->enabled)) == null)
	 || (((primitiveDescriptor->enabled))(primitiveIndex)))))) {
		return ((primitiveDescriptor->primitiveGenerator))();
	}
	if ((((primitiveRoutine = functionPointerForCompiledMethodprimitiveIndex(methodObj, primitiveIndex))) == null)
	 || (primitiveRoutine == (functionPointerForinClass(0, null)))) {
		return genFastPrimFail();
	}
	minValidCallAddress = ((minValidCallAddress < (((usqInt)primitiveRoutine))) ? minValidCallAddress : (((usqInt)primitiveRoutine)));
	return compileInterpreterPrimitive(primitiveRoutine);
}


/*	Generate a trampoline with up to four arguments. Generate either a call or
	a jump to aRoutine
	as requested by callJumpBar. If generating a call and resultRegOrNil is
	non-zero pass the C result
	back in resultRegOrNil.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

	/* Cogit>>#compileTrampolineFor:numArgs:arg:arg:arg:arg:saveRegs:pushLinkReg:resultReg: */
static void
compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(void *aRoutine, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt saveRegs, sqInt pushLinkReg, sqInt resultRegOrNil)
{
	genSmalltalkToCStackSwitch(pushLinkReg);
	compileCallFornumArgsargargargargresultRegsaveRegs(aRoutine, numArgs, regOrConst0, regOrConst1, regOrConst2, regOrConst3, resultRegOrNil, saveRegs);
	genLoadStackPointers(backEnd);
	if (pushLinkReg
	 && (hasLinkRegister(backEnd))) {
		/* begin PopR: */
		genoperand(PopR, PCReg);
	}
	else {
		/* begin RetN: */
		genoperand(RetN, 0);
	}
}


/*	Generate the entry code for a method to determine cmEntryOffset and
	cmNoCheckEntryOffset. We
	need cmNoCheckEntryOffset up front to be able to generate the map starting
	from cmNoCheckEntryOffset */
/*	stack allocate the various collections so that they
	are effectively garbage collected on return. */

	/* Cogit>>#computeEntryOffsets */
static void
computeEntryOffsets(void)
{
    sqInt fixupSize;
    sqInt opcodeSize;
    AbstractInstruction *sendMissCall;

	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = 24;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	methodOrBlockNumArgs = 0;
	sendMissCall = compileAbort();
	compileEntry();
	computeMaximumSizes();
	generateInstructionsAt(methodZoneBase + (sizeof(CogMethod)));
	cmEntryOffset = ((entry->address)) - methodZoneBase;
	cmNoCheckEntryOffset = ((noCheckEntry->address)) - methodZoneBase;
	missOffset = (((sendMissCall->address)) + ((sendMissCall->machineCodeSize))) - methodZoneBase;
	entryPointMask = BytesPerWord - 1;
	while ((cmEntryOffset & entryPointMask) == (cmNoCheckEntryOffset & entryPointMask)) {
		entryPointMask = (entryPointMask + entryPointMask) + 1;
	}
	if (entryPointMask >= (roundUpLength(1))) {
		error("cannot differentiate checked and unchecked entry-points with current cog method alignment");
	}
	checkedEntryAlignment = cmEntryOffset & entryPointMask;
	uncheckedEntryAlignment = cmNoCheckEntryOffset & entryPointMask;
	assert(checkedEntryAlignment != uncheckedEntryAlignment);
}


/*	This pass assigns maximum sizes to all abstract instructions and
	eliminates jump fixups.
	It hence assigns the maximum address an instruction will occur at which
	allows the next
	pass to conservatively size jumps. */

	/* Cogit>>#computeMaximumSizes */
static void
computeMaximumSizes(void)
{
    AbstractInstruction *abstractInstruction;
    sqInt i;
    sqInt relativeAddress;

	dumpLiterals(0);
	relativeAddress = 0;
	for (i = 0; i < opcodeIndex; i += 1) {
		abstractInstruction = abstractInstructionAt(i);
		(abstractInstruction->address = relativeAddress);
		(abstractInstruction->maxSize = computeMaximumSize(abstractInstruction));
		relativeAddress += (abstractInstruction->maxSize);
	}
}

	/* Cogit>>#cPICHasForwardedClass: */
static sqInt
cPICHasForwardedClass(CogMethod *cPIC)
{
    sqInt classIndex;
    sqInt i;
    sqInt pc;

	pc = (((((usqInt)cPIC)) + firstCPICCaseOffset) + cPICCaseSize) - (jumpLongConditionalByteSize(backEnd));
	for (i = 2; i <= ((cPIC->cPICNumCases)); i += 1) {
		classIndex = longAt(pc - BytesPerOop);
		if (isForwardedClassIndex(classIndex)) {
			return 1;
		}
		pc += cPICCaseSize;
	}
	return 0;
}

	/* Cogit>>#cPICHasFreedTargets: */
static sqInt
cPICHasFreedTargets(CogMethod *cPIC)
{
    sqInt entryPoint;
    sqInt i;
    sqInt pc;
    CogMethod *targetMethod;

	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	for (i = 1; i <= ((cPIC->cPICNumCases)); i += 1) {

		/* Find target from jump.  Ignore jumps to the interpret and MNU calls within this PIC */

		entryPoint = jumpLongTargetBeforeFollowingAddress(backEnd(), pc - ((i <= 1
	? BytesPerOop
	: BytesPerOop + 4)));
		if (!(((((usqInt)cPIC)) <= (((usqInt)entryPoint)))
			 && (((((usqInt)cPIC)) + ((cPIC->blockSize))) >= (((usqInt)entryPoint))))) {
			targetMethod = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
			assert((((targetMethod->cmType)) == CMMethod)
			 || (((targetMethod->cmType)) == CMFree));
			if (((targetMethod->cmType)) == CMFree) {
				return 1;
			}
		}
		pc += cPICCaseSize;
	}
	return 0;
}


/*	Whimsey; we want 16rCA5E10 + cPICPrototypeCaseOffset to be somewhere in
	the middle of the zone.
 */

	/* Cogit>>#cPICPrototypeCaseOffset */
static sqInt
cPICPrototypeCaseOffset(void)
{
	return ((methodZoneBase + (youngReferrers())) / 2) - 13262352;
}

	/* Cogit>>#cPIC:HasTarget: */
static sqInt
cPICHasTarget(CogMethod *cPIC, CogMethod *targetMethod)
{
    sqInt i;
    sqInt pc;
    usqInt target;

	target = (((usqInt)targetMethod)) + cmNoCheckEntryOffset;
	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	for (i = 1; i <= ((cPIC->cPICNumCases)); i += 1) {
		if (target == (jumpLongTargetBeforeFollowingAddress(backEnd(), pc - ((i <= 1
	? BytesPerOop
	: BytesPerOop + 4))))) {
			return 1;
		}
		pc += cPICCaseSize;
	}
	return 0;
}


/*	Division is a little weird on some processors. Defer to the backEnd
	to allow it to generate any special code it may need to. */

	/* Cogit>>#DivR:R:Quo:Rem: */
static AbstractInstruction *
gDivRRQuoRem(sqInt rDivisor, sqInt rDividend, sqInt rQuotient, sqInt rRemainder)
{
	genDivRRQuoRem(backEnd, rDivisor, rDividend, rQuotient, rRemainder);
	return abstractInstructionAt(opcodeIndex - 1);
}


/*	Return the default number of bytes to allocate for native code at startup.
	The actual value can be set via vmParameterAt: and/or a preference in the
	ini file. */

	/* Cogit>>#defaultCogCodeSize */
sqInt
defaultCogCodeSize(void)
{
	return 1024 * 1280;
}

	/* Cogit>>#endPCOf: */
static sqInt
endPCOf(sqInt aMethod)
{
    sqInt bsOffset;
    sqInt byte;
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt end;
    sqInt latestContinuation;
    sqInt nExts;
    sqInt pc;
    sqInt prim;
    sqInt targetPC;

	pc = (latestContinuation = startPCOfMethod(aMethod));
	if (((prim = primitiveIndexOf(aMethod))) > 0) {
		if (isQuickPrimitiveIndex(prim)) {
			return pc - 1;
		}
	}
	bsOffset = 0;
	nExts = 0;
	end = numBytesOf(aMethod);
	while (pc <= end) {
		byte = fetchByteofObject(pc, aMethod);
		descriptor = generatorAt(byte + bsOffset);
		if (((descriptor->isReturn))
		 && (pc >= latestContinuation)) {
			end = pc;
		}
		if ((isBranch(descriptor))
		 || ((descriptor->isBlockCreation))) {
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, aMethod);
			targetPC = (pc + ((descriptor->numBytes))) + distance;
			latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
			if ((descriptor->isBlockCreation)) {
				pc += distance;
			}
		}
		nExts = ((descriptor->isExtension)
			? nExts + 1
			: 0);
		pc += (descriptor->numBytes);
	}
	return end;
}


/*	This is a static version of ceEnterCogCodePopReceiverReg
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

	/* Cogit>>#enterCogCodePopReceiver */
void
enterCogCodePopReceiver(void)
{
	realCEEnterCogCodePopReceiverReg();
	error("what??");

}


/*	Answer 0 if the ClosedPIC is as expected from compileClosedPICPrototype,
	otherwise answer an error code identifying the first discrepancy found. */

	/* Cogit>>#expectedClosedPICPrototype: */
static sqInt
expectedClosedPICPrototype(CogMethod *cPIC)
{
    sqInt entryPoint;
    sqInt i;
    sqInt object;
    sqInt offsetToLiteral;
    sqInt pc;


	/* First jump is unconditional; subsequent ones are conditional */

	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	offsetToLiteral = jumpLongByteSize(backEnd);
	for (i = 1; i <= numPICCases; i += 1) {
		if (i > 1) {
			object = longAt((pc - offsetToLiteral) - BytesPerOop);
			if (!(object == ((3133021973UL + i) - 1))) {
				return 1;
			}
		}
		object = longAt(pc - offsetToLiteral);
		if (!(object == ((i == 1
	? 99282957
	: (195929424 + i) - 1)))) {
			return 2;
		}
		offsetToLiteral = jumpLongConditionalByteSize(backEnd);
		entryPoint = jumpLongTargetBeforeFollowingAddress(backEnd(), pc - ((i <= 1
	? BytesPerOop
	: BytesPerOop + 4)));
		if (!(entryPoint == (((cPICPrototypeCaseOffset()) + 13262352) + ((i - 1) * 16)))) {
			return 3;
		}
		pc += cPICCaseSize;
	}
	pc -= cPICCaseSize;
	entryPoint = jumpLongTargetBeforeFollowingAddress(backEnd, pc + cPICEndSize);
	if (!(entryPoint == (cPICMissTrampolineFor(0)))) {
		return 4;
	}
	return 0;
}


/*	Fill in the block headers now we know the exact layout of the code. */

	/* Cogit>>#fillInBlockHeadersAt: */
static sqInt
fillInBlockHeadersAt(sqInt startAddress)
{
    CogBlockMethod *blockHeader;
    BlockStart *blockStart;
    sqInt i;

	if (!(needsFrame
		 && (blockCount > 0))) {
		return null;
	}
	if (blockNoContextSwitchOffset == null) {
		blockNoContextSwitchOffset = ((blockEntryLabel->address)) - ((blockEntryNoContextSwitch->address));
	}
	else {
		assert(blockNoContextSwitchOffset == (((blockEntryLabel->address)) - ((blockEntryNoContextSwitch->address))));
	}
	for (i = 0; i < blockCount; i += 1) {
		blockStart = blockStartAt(i);
		blockHeader = ((CogBlockMethod *) ((((blockStart->fakeHeader))->address)));
		(blockHeader->homeOffset = ((((blockStart->fakeHeader))->address)) - startAddress);
		(blockHeader->startpc = (blockStart->startpc));
		(blockHeader->cmType = CMBlock);
		(blockHeader->cmNumArgs = (blockStart->numArgs));
		(blockHeader->cbUsesInstVars = (blockStart->hasInstVarRef));
		(blockHeader->stackCheckOffset = (((blockStart->stackCheckLabel)) == null
			? 0
			: ((((blockStart->stackCheckLabel))->address)) - ((((blockStart->fakeHeader))->address))));
	}
}

	/* Cogit>>#fillInMethodHeader:size:selector: */
static CogMethod *
fillInMethodHeadersizeselector(CogMethod *method, sqInt size, sqInt selector)
{
    sqInt methodHeader;
    CogMethod *originalMethod;

	(method->cmType = CMMethod);
	(method->objectHeader = nullHeaderForMachineCodeMethod());
	(method->blockSize = size);
	(method->methodObject = methodObj);

	/* If the method has already been cogged (e.g. Newspeak accessors) then
	   leave the original method attached to its cog method, but get the right header. */

	methodHeader = rawHeaderOf(methodObj);
	if (isCogMethodReference(methodHeader)) {
		originalMethod = ((CogMethod *) methodHeader);
		assert(((originalMethod->blockSize)) == size);
		methodHeader = (originalMethod->methodHeader);
		
	}
	else {
		rawHeaderOfput(methodObj, ((sqInt)method));
		
	}
	(method->methodHeader = methodHeader);
	(method->selector = selector);
	(method->cmNumArgs = argumentCountOfMethodHeader(methodHeader));
	if ((method->cmRefersToYoung = hasYoungReferent)) {
		addToYoungReferrers(method);
	}
	(method->cmUsageCount = initialMethodUsageCount());
	(method->cpicHasMNUCase = 0);
	(method->cmUsesPenultimateLit = maxLitIndex >= ((literalCountOfMethodHeader(methodHeader)) - 2));
	(method->blockEntryOffset = (blockEntryLabel != null
		? ((blockEntryLabel->address)) - (((sqInt)method))
		: 0));
	if (needsFrame) {
		if (!((((stackCheckLabel->address)) - (((sqInt)method))) <= MaxStackCheckOffset)) {
			error("too much code for stack check offset");
		}
	}
	(method->stackCheckOffset = (needsFrame
		? ((stackCheckLabel->address)) - (((sqInt)method))
		: 0));
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)method)) + missOffset)) == (methodAbortTrampolineFor((method->cmNumArgs))));
	assert(size == (roundUpLength(size)));
	flushICacheFromto(processor, ((usqInt)method), (((usqInt)method)) + size);
	return method;
}

	/* Cogit>>#findBlockMethodWithEntry:startBcpc: */
static usqInt
findBlockMethodWithEntrystartBcpc(sqInt blockEntryMcpc, sqInt startBcpc)
{
    CogBlockMethod *cogBlockMethod;

	cogBlockMethod = ((CogBlockMethod *) (blockEntryMcpc - (sizeof(CogBlockMethod))));
	if (((cogBlockMethod->startpc)) == startBcpc) {
		return ((usqInt)cogBlockMethod);
	}
	return 0;
}

	/* Cogit>>#findMapLocationForMcpc:inMethod: */
static sqInt
findMapLocationForMcpcinMethod(sqInt targetMcpc, CogMethod *cogMethod)
{
    sqInt annotation;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;

	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	if (mcpc == targetMcpc) {
		return map;
	}
	while (((mapByte = byteAt(map))) != MapEnd) {
		annotation = ((usqInt) mapByte) >> AnnotationShift;
		if (annotation != IsAnnotationExtension) {
			mcpc += 4 * ((annotation == IsDisplacementX2N
	? (mapByte - DisplacementX2N) << AnnotationShift
	: mapByte & DisplacementMask));
		}
		if (mcpc >= targetMcpc) {
			assert(mcpc == targetMcpc);
			if (annotation == IsDisplacementX2N) {
				map -= 1;
				mapByte = byteAt(map);
				annotation = ((usqInt) mapByte) >> AnnotationShift;
				assert(annotation > IsAnnotationExtension);
			}
			return map;
		}
		map -= 1;
	}
	return 0;
}


/*	Find the CMMethod or CMBlock that has zero-relative startbcpc as its first
	bytecode pc.
	As this is for cannot resume processing and/or conversion to machine-code
	on backward
	branch, it doesn't have to be fast. Enumerate block returns and map to
	bytecode pcs. */

	/* Cogit>>#findMethodForStartBcpc:inHomeMethod: */
CogBlockMethod *
findMethodForStartBcpcinHomeMethod(sqInt startbcpc, CogMethod *cogMethod)
{
	assert(((cogMethod->cmType)) == CMMethod);
	if (startbcpc == (startPCOfMethodHeader((cogMethod->methodHeader)))) {
		return ((CogBlockMethod *) cogMethod);
	}
	assert(((cogMethod->blockEntryOffset)) != 0);
	return ((CogBlockMethod *) (blockDispatchTargetsForperformarg(cogMethod, findBlockMethodWithEntrystartBcpc, startbcpc)));
}


/*	Machine code addresses map to the following bytecode for all bytecodes
	except backward branches, where they map to the backward branch itself.
	This is so that loops continue, rather than terminate prematurely. */

	/* Cogit>>#find:IsBackwardBranch:Mcpc:Bcpc:MatchingMcpc: */
static sqInt
findIsBackwardBranchMcpcBcpcMatchingMcpc(BytecodeDescriptor *descriptor, sqInt isBackwardBranch, char *mcpc, sqInt bcpc, void *targetMcpc)
{
	return (targetMcpc == mcpc
		? ((descriptor == null)
			 || (isBackwardBranch)
				? bcpc
				: bcpc + ((descriptor->numBytes)))
		: 0);
}

	/* Cogit>>#followForwardedLiteralsIn: */
void
followForwardedLiteralsIn(CogMethod *cogMethod)
{
    sqInt annotation;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	assert(!(isForwarded((cogMethod->methodObject))));
	if (shouldRemapOop((cogMethod->selector))) {
		(cogMethod->selector = remapObj((cogMethod->selector)));
		if (isYoung((cogMethod->selector))) {
			ensureInYoungReferrers(cogMethod);
		}
	}
	/* begin mapFor:performUntil:arg: */
	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while (((mapByte = byteAt(map))) != MapEnd) {
		if (mapByte >= FirstAnnotation) {

			/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

			mcpc += (mapByte & DisplacementMask) * 4;
			if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
			 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
				annotation += mapByte & DisplacementMask;
				map -= 1;
			}
			result = remapIfObjectRefpchasYoung(annotation, (((char *) mcpc)), 0);
			if (result != 0) {
				result;
				goto l1;
			}
		}
		else {
			if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
				mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
			}
		}
		map -= 1;
	}
	0;
l1:	/* end mapFor:performUntil:arg: */;
}

	/* Cogit>>#followForwardedMethods */
void
followForwardedMethods(void)
{
    CogMethod *cogMethod;
    sqInt freedPIC;

	freedPIC = 0;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			if (isForwarded((cogMethod->methodObject))) {
				(cogMethod->methodObject = followForwarded((cogMethod->methodObject)));
				if (isYoungObject((cogMethod->methodObject))) {
					ensureInYoungReferrers(cogMethod);
				}
			}
		}
		if (((cogMethod->cmType)) == CMClosedPIC) {
			if (followMethodReferencesInClosedPIC(cogMethod)) {
				freedPIC = 1;
				freeMethod(cogMethod);
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (freedPIC) {
		unlinkSendsToFree();
	}
}


/*	Follow a potential object reference from a closed PIC.
	This may be a method reference or null.
	Answer if the followed literal is young. */

	/* Cogit>>#followMaybeObjRefInClosedPICAt: */
static sqInt
followMaybeObjRefInClosedPICAt(sqInt mcpc)
{
    sqInt object;
    sqInt subject;

	object = longAt(mcpc);
	if (!(couldBeObject(object))) {
		return 0;
	}
	if (!(isForwarded(object))) {
		return isYoungObject(object);
	}
	subject = followForwarded(object);
	/* begin storeObjRef:inClosedPICAt: */
	longAtput(mcpc, subject);
	codeModified = 1;
	return isYoungObject(subject);
}


/*	Remap all object references in the closed PIC. Answer if any references
	are young.
	Set codeModified if any modifications are made. */

	/* Cogit>>#followMethodReferencesInClosedPIC: */
static sqInt
followMethodReferencesInClosedPIC(CogMethod *cPIC)
{
    sqInt i;
    sqInt pc;
    sqInt refersToYoung;

	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	refersToYoung = followMaybeObjRefInClosedPICAt(pc - (jumpLongByteSize(backEnd)));
	pc += cPICCaseSize;
	for (i = 2; i <= ((cPIC->cPICNumCases)); i += 1) {
		if (followMaybeObjRefInClosedPICAt(pc - (jumpLongConditionalByteSize(backEnd)))) {
			refersToYoung = 1;
		}
		pc += cPICCaseSize;
	}
	return refersToYoung;
}

	/* Cogit>>#freePICsWithFreedTargets */
static void
freePICsWithFreedTargets(void)
{
    CogMethod *cogMethod;
    sqInt count;

	cogMethod = ((CogMethod *) methodZoneBase);
	count = 0;
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) == CMClosedPIC)
		 && (cPICHasFreedTargets(cogMethod))) {
			(cogMethod->cmType = CMFree);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		count += 1;
	}
	assert(count == (numMethods()));
}


/*	Free machine-code methods whose compiled methods are unmarked
	and open PICs whose selectors are not marked, and closed PICs that
	refer to unmarked objects. */

	/* Cogit>>#freeUnmarkedMachineCode */
void
freeUnmarkedMachineCode(void)
{
    CogMethod *cogMethod;
    sqInt freedMethod;

	freedMethod = 0;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) == CMMethod)
		 && (!(isMarked((cogMethod->methodObject))))) {
			freedMethod = 1;
			freeMethod(cogMethod);
		}
		if ((((cogMethod->cmType)) == CMOpenPIC)
		 && ((!(isImmediate((cogMethod->selector))))
		 && (!(isMarked((cogMethod->selector)))))) {
			freedMethod = 1;
			freeMethod(cogMethod);
		}
		if ((((cogMethod->cmType)) == CMClosedPIC)
		 && (closedPICRefersToUnmarkedObject(cogMethod))) {
			freedMethod = 1;
			freeMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (freedMethod) {
		unlinkSendsToFree();
	}
}

	/* Cogit>>#genCheckForInterruptsTrampoline */
static sqInt
genCheckForInterruptsTrampoline(void)
{
    sqInt address;
    sqInt address1;

	zeroOpcodeIndex();
	/* begin MoveR:Aw: */
	address = instructionPointerAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address, genoperandoperand(MoveRAw, LinkReg, address));

	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceCheckForInterrupts, "ceCheckForInterruptsTrampoline", 0, null, null, null, null, 0, 0, null, 1);
}


/*	An enilopmart (the reverse of a trampoline) is a piece of code that makes
	the system-call-like transition from the C runtime into generated machine
	code. The desired arguments and entry-point are pushed on a stackPage's
	stack. The enilopmart pops off the values to be loaded into registers and
	then executes a return instruction to pop off the entry-point and jump to
	it. 
	BEFORE				AFTER			(stacks grow down)
	whatever			stackPointer ->	whatever
	target address =>	reg1 = reg1val, etc
	reg1val				pc = target address
	reg2val
	stackPointer ->	reg3val */

	/* Cogit>>#genEnilopmartFor:and:and:forCall:called: */
static void (*genEnilopmartForandandforCallcalled(sqInt regArg1, sqInt regArg2, sqInt regArg3, sqInt forCall, char *trampolineName))(void)

{
    sqInt endAddress;
    sqInt enilopmart;
    sqInt size;

	zeroOpcodeIndex();
	maybeEstablishVarBase(backEnd);
	genLoadStackPointers(backEnd);
	if (!(regArg3 == null)) {
		/* begin PopR: */
		genoperand(PopR, regArg3);
	}
	if (!(regArg2 == null)) {
		/* begin PopR: */
		genoperand(PopR, regArg2);
	}
	/* begin PopR: */
	genoperand(PopR, regArg1);
	genEnilopmartReturn(forCall);
	computeMaximumSizes();
	size = generateInstructionsAt(methodZoneBase);
	endAddress = outputInstructionsAt(methodZoneBase);
	assert((methodZoneBase + size) == endAddress);
	enilopmart = methodZoneBase;
	methodZoneBase = alignUptoRoutineBoundary(endAddress);
	nopsFromto(backEnd, endAddress, methodZoneBase - 1);
	recordGeneratedRunTimeaddress(trampolineName, enilopmart);
	return ((void (*)(void)) enilopmart);
}


/*	An enilopmart (the reverse of a trampoline) is a piece of code that makes
	the system-call-like transition from the C runtime into generated machine
	code. At the point the enilopmart enters machine code via a return
	instruction, any argument registers have been loaded with their values and
	the stack, if
	for call, looks like
	ret pc
	stackPointer ->	target address
	
	and if not for call, looks like
	whatever
	stackPointer ->	target address
	
	If forCall and running on a CISC, ret pc must be left on the stack. If
	forCall and
	running on a RISC, ret pc must be popped into LinkReg. In either case,
	target address must be removed from the stack and jumped/returned to. */

	/* Cogit>>#genEnilopmartReturn: */
static void
genEnilopmartReturn(sqInt forCall)
{
	if (forCall) {
		/* begin PopR: */
		genoperand(PopR, RISCTempReg);
		/* begin PopR: */
		genoperand(PopR, LinkReg);
		/* begin JumpR: */
		genoperand(JumpR, RISCTempReg);
	}
	else {
		/* begin PopR: */
		genoperand(PopR, PCReg);

	}

}


/*	Generate the routine that writes the current values of the C frame and
	stack pointers into
	variables. These are used to establish the C stack in trampolines back
	into the C run-time.
	
	This is a presumptuous quick hack for x86. It is presumptuous for two
	reasons. Firstly
	the system's frame and stack pointers may differ from those we use in
	generated code,
	e.g. on register-rich RISCs. Secondly the ABI may not support a simple
	frameless call
	as written here (for example 128-bit stack alignment on Mac OS X). */

	/* Cogit>>#generateCaptureCStackPointers: */
static void
generateCaptureCStackPointers(sqInt captureFramePointer)
{
    sqInt address;
    sqInt address1;
    sqInt address2;
    sqInt fixupSize;
    sqInt opcodeSize;
    sqInt quickConstant;
    sqInt startAddress;

	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = 32;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	startAddress = methodZoneBase;
	if (captureFramePointer) {
		/* begin MoveR:Aw: */
		address = cFramePointerAddress();
		/* begin gen:operand:literal: */
		checkLiteralforInstruction(address, genoperandoperand(MoveRAw, FPReg, address));
	}
	/* begin MoveR:Aw: */
	address1 = cStackPointerAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address1, genoperandoperand(MoveRAw, SPReg, address1));

	/* begin RetN: */
	genoperand(RetN, 0);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	flushICacheFromto(processor, ((usqInt)startAddress), ((usqInt)methodZoneBase));
	recordGeneratedRunTimeaddress("ceCaptureCStackPointers", startAddress);
	ceCaptureCStackPointers = ((void (*)(void)) startAddress);
}


/*	Generate the prototype ClosedPIC to determine how much space as full PIC
	takes. When we first allocate a closed PIC it only has one or two cases
	and we want to grow it.
	So we have to determine how big a full one is before hand. */

	/* Cogit>>#generateClosedPICPrototype */
static void
generateClosedPICPrototype(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    CogMethod *cPIC;
    sqInt fixupSize;
    sqInt h;
    AbstractInstruction *inst;
    AbstractInstruction *inst1;
    AbstractInstruction *jumpNext;
    sqInt jumpTarget;
    sqInt jumpTarget1;
    sqInt jumpTarget2;
    sqInt numArgs;
    sqInt opcodeSize;
    sqInt wordConstant;


	/* stack allocate the various collections so that they
	   are effectively garbage collected on return. */

	numPICCases = 6;
	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = numPICCases * 9;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	(methodLabel->address = methodZoneBase);
	(methodLabel->dependent = null);
	/* begin compileClosedPICPrototype */
	numArgs = 0;
	compilePICAbort(numArgs);
	jumpNext = compileCPICEntry();
	/* begin MoveUniqueCw:R: */
	/* begin gen:uniqueLiteral:operand: */
	/* begin uniqueLiteral:forInstruction: */
	anInstruction1 = genoperandoperand(MoveCwR, 99282957, SendNumArgsReg);
	assert(usesOutOfLineLiteral(anInstruction1));
	(anInstruction1->dependent = allocateLiteral(99282957));
	anInstruction1;
	/* begin DumpJumpLong: */
	jumpTarget1 = (cPICPrototypeCaseOffset()) + 13262352;
	inst1 = genoperand(JumpLong, ((sqInt)jumpTarget1));
	dumpLiterals(0);
	inst1;
	jmpTarget(jumpNext, (endCPICCase0 = gLabel()));
	for (h = 1; h < numPICCases; h += 1) {
		/* begin CmpCw:R: */
		/* begin gen:literal:operand: */
		checkLiteralforInstruction(3133021973UL + h, genoperandoperand(CmpCwR, 3133021973UL + h, TempReg));
		/* begin MoveUniqueCw:R: */
		/* begin gen:uniqueLiteral:operand: */
		/* begin uniqueLiteral:forInstruction: */
		anInstruction = genoperandoperand(MoveCwR, 195929424 + h, SendNumArgsReg);
		assert(usesOutOfLineLiteral(anInstruction));
		(anInstruction->dependent = allocateLiteral(195929424 + h));
		anInstruction;
		/* begin DumpJumpLongZero: */
		jumpTarget = ((cPICPrototypeCaseOffset()) + 13262352) + (h * 16);
		inst = genoperand(JumpLongZero, ((sqInt)jumpTarget));
		dumpLiterals(0);
		inst;
		if (h == 1) {
			/* begin Label */
			endCPICCase1 = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		}
	}
	/* begin MoveCw:R: */
	wordConstant = (methodLabel->address);
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(wordConstant, genoperandoperand(MoveCwR, wordConstant, ClassReg));
	/* begin JumpLong: */
	jumpTarget2 = cPICMissTrampolineFor(numArgs);
	genoperand(JumpLong, jumpTarget2);
	0;
	computeMaximumSizes();
	cPIC = ((CogMethod *) methodZoneBase);
	closedPICSize = (sizeof(CogMethod)) + (generateInstructionsAt(methodZoneBase + (sizeof(CogMethod))));
	outputInstructionsAt(methodZoneBase + (sizeof(CogMethod)));
	firstCPICCaseOffset = ((endCPICCase0->address)) - methodZoneBase;
	cPICCaseSize = ((endCPICCase1->address)) - ((endCPICCase0->address));
	cPICEndSize = closedPICSize - (((numPICCases - 1) * cPICCaseSize) + firstCPICCaseOffset);
	closedPICSize = roundUpLength(closedPICSize);
	assert(((picInterpretAbort->address)) == (((methodLabel->address)) + (picInterpretAbortOffset())));
	assert((expectedClosedPICPrototype(cPIC)) == 0);
}


/*	We handle jump sizing simply. First we make a pass that asks each
	instruction to compute its maximum size. Then we make a pass that
	sizes jumps based on the maxmimum sizes. Then we make a pass
	that fixes up jumps. When fixing up a jump the jump is not allowed to
	choose a smaller offset but must stick to the size set in the second pass. */

	/* Cogit>>#generateCogMethod: */
static CogMethod *
generateCogMethod(sqInt selector)
{
    sqInt codeSize;
    sqInt headerSize;
    sqInt mapSize;
    CogMethod *method;
    sqInt result;
    sqInt startAddress;
    sqInt totalSize;

	headerSize = sizeof(CogMethod);
	(methodLabel->address = freeStart());
	computeMaximumSizes();
	concretizeAt(methodLabel, freeStart());
	codeSize = generateInstructionsAt(((methodLabel->address)) + headerSize);
	mapSize = generateMapAtstart(null, ((methodLabel->address)) + cmNoCheckEntryOffset);
	totalSize = roundUpLength((headerSize + codeSize) + mapSize);
	if (totalSize > MaxMethodSize) {
		return ((CogMethod *) MethodTooBig);
	}
	startAddress = allocate(totalSize);
	if (startAddress == 0) {
		return ((CogMethod *) InsufficientCodeSpace);
	}
	assert((startAddress + cmEntryOffset) == ((entry->address)));
	assert((startAddress + cmNoCheckEntryOffset) == ((noCheckEntry->address)));
	result = outputInstructionsAt(startAddress + headerSize);
	assert(((startAddress + headerSize) + codeSize) == result);
	padIfPossibleWithNopsFromto(backEnd, result, (startAddress + totalSize) - mapSize);
	generateMapAtstart((startAddress + totalSize) - 1, startAddress + cmNoCheckEntryOffset);
	fillInBlockHeadersAt(startAddress);
	method = fillInMethodHeadersizeselector(((CogMethod *) startAddress), totalSize, selector);
	if (!(postCompileHook == null)) {
		postCompileHook(method);
		postCompileHook = null;
	}
	return method;
}


/*	Size pc-dependent instructions and assign eventual addresses to all
	instructions. Answer the size of the code.
	Compute forward branches based on virtual address (abstract code starts at
	0), assuming that any branches branched over are long.
	Compute backward branches based on actual address.
	Reuse the fixups array to record the pc-dependent instructions that need
	to have
	their code generation postponed until after the others. */

	/* Cogit>>#generateInstructionsAt: */
static sqInt
generateInstructionsAt(sqInt eventualAbsoluteAddress)
{
    sqInt absoluteAddress;
    AbstractInstruction *abstractInstruction;
    BytecodeFixup *fixup;
    sqInt i;
    sqInt j;
    sqInt pcDependentIndex;

	absoluteAddress = eventualAbsoluteAddress;
	pcDependentIndex = 0;
	for (i = 0; i < opcodeIndex; i += 1) {
		if (breakPC == absoluteAddress) {
			haltmsg("breakPC reached in generateInstructionsAt:");
		}
		abstractInstruction = abstractInstructionAt(i);
		if (isPCDependent(abstractInstruction)) {
			sizePCDependentInstructionAt(abstractInstruction, absoluteAddress);
			fixup = fixupAt(pcDependentIndex);
			pcDependentIndex += 1;
			(fixup->instructionIndex = i);
			absoluteAddress += (abstractInstruction->machineCodeSize);
		}
		else {
			absoluteAddress = concretizeAt(abstractInstruction, absoluteAddress);
		}
	}
	for (j = 0; j < pcDependentIndex; j += 1) {
		fixup = fixupAt(j);
		abstractInstruction = abstractInstructionAt((fixup->instructionIndex));
		if (breakPC == absoluteAddress) {
			haltmsg("breakPC reached in generateInstructionsAt:");
		}
		concretizeAt(abstractInstruction, (abstractInstruction->address));
	}
	
	return absoluteAddress - eventualAbsoluteAddress;
}


/*	Generate the method map at addressrNull (or compute it if addressOrNull is
	null). Answer the length of the map in byes. Each entry in the map is in
	two parts. In the
	least signficant bits are a displacement of how far from the start or
	previous entry,
	unless it is an IsAnnotationExtension byte, in which case those bits are
	the extension.
	In the most signficant bits are the type of annotation at the point
	reached. A null
	byte ends the map. */

	/* Cogit>>#generateMapAt:start: */
static sqInt
generateMapAtstart(sqInt addressOrNull, sqInt startAddress)
{
    unsigned char annotation;
    usqInt delta;
    sqInt i;
    AbstractInstruction *instruction;
    sqInt length;
    usqInt location;
    usqInt mapEntry;
    sqInt maxDelta;
    usqInt mcpc;

	length = 0;
	location = startAddress;
	for (i = 0; i < opcodeIndex; i += 1) {
		instruction = abstractInstructionAt(i);
		annotation = (instruction->annotation);
		if (!(annotation == null)) {
			/* begin assertValidAnnotation:for: */
			assert((annotation != (getIsObjectReference()))
			 || (((instruction->opcode)) == Literal));
			mcpc = (((instruction->opcode)) == Literal
				? (instruction->address)
				: ((instruction->address)) + ((instruction->machineCodeSize)));
			while (((delta = (mcpc - location) / 4)) > DisplacementMask) {
				maxDelta = (((((delta < MaxX2NDisplacement) ? delta : MaxX2NDisplacement)) | DisplacementMask) - DisplacementMask);
				assert((((usqInt) maxDelta) >> AnnotationShift) <= DisplacementMask);
				if (!(addressOrNull == null)) {
					/* begin addToMap:instruction:byte:at:for: */
					byteAtput(addressOrNull - length, (((usqInt) maxDelta) >> AnnotationShift) + DisplacementX2N);
					null;
				}
				location += maxDelta * 4;
				length += 1;
			}
			if (!(addressOrNull == null)) {
				mapEntry = delta + ((((annotation < IsSendCall) ? annotation : IsSendCall)) << AnnotationShift);
				/* begin addToMap:instruction:byte:at:for: */
				byteAtput(addressOrNull - length, mapEntry);
				null;
			}
			location += delta * 4;
			length += 1;
			if (annotation > IsSendCall) {

				/* Add the necessary IsAnnotationExtension */

				if (!(addressOrNull == null)) {
					mapEntry = (IsAnnotationExtension << AnnotationShift) + (annotation - IsSendCall);
					/* begin addToMap:instruction:byte:at:for: */
					byteAtput(addressOrNull - length, mapEntry);
					null;
				}
				length += 1;
			}
		}
	}
	if (!(addressOrNull == null)) {
		/* begin addToMap:instruction:byte:at:for: */
		byteAtput(addressOrNull - length, MapEnd);
		null;
	}
	return length + 1;
}


/*	Generate the prototype ClosedPIC to determine how much space as full PIC
	takes. When we first allocate a closed PIC it only has one or two cases
	and we want to grow it.
	So we have to determine how big a full one is before hand. */
/*	stack allocate the various collections so that they
	are effectively garbage collected on return. */

	/* Cogit>>#generateOpenPICPrototype */
static void
generateOpenPICPrototype(void)
{
    sqInt codeSize;
    sqInt fixupSize;
    sqInt mapSize;
    sqInt opcodeSize;

	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = 100;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	(methodLabel->address = methodZoneBase);
	(methodLabel->dependent = null);
	compileOpenPICnumArgs(specialSelector(0), 2);
	computeMaximumSizes();
	concretizeAt(methodLabel, methodZoneBase);
	codeSize = generateInstructionsAt(methodZoneBase + (sizeof(CogMethod)));
	mapSize = generateMapAtstart(null, methodZoneBase + cmNoCheckEntryOffset);
	openPICSize = (roundUpLength((sizeof(CogMethod)) + codeSize)) + (roundUpLength(mapSize));
}


/*	Generate the run-time entries at the base of the native code zone and
	update the base.
 */

	/* Cogit>>#generateRunTimeTrampolines */
static void
generateRunTimeTrampolines(void)
{
	ceSendMustBeBooleanAddFalseTrampoline = genMustBeBooleanTrampolineForcalled(falseObject(), "ceSendMustBeBooleanAddFalseTrampoline");
	ceSendMustBeBooleanAddTrueTrampoline = genMustBeBooleanTrampolineForcalled(trueObject(), "ceSendMustBeBooleanAddTrueTrampoline");
	ceNonLocalReturnTrampoline = genNonLocalReturnTrampoline();
	ceCheckForInterruptTrampoline = genCheckForInterruptsTrampoline();
	ceFetchContextInstVarTrampoline = genTrampolineForcalledargargresult(ceContextinstVar, "ceFetchContextInstVarTrampoline", ReceiverResultReg, SendNumArgsReg, SendNumArgsReg);
	ceStoreContextInstVarTrampoline = genTrampolineForcalledargargargresult(ceContextinstVarvalue, "ceStoreContextInstVarTrampoline", ReceiverResultReg, SendNumArgsReg, ClassReg, ReceiverResultReg);

	/* These two are unusual; they are reached by return instructions. */

	ceCannotResumeTrampoline = genTrampolineForcalled(ceCannotResume, "ceCannotResumeTrampoline");
	ceBaseFrameReturnTrampoline = genReturnTrampolineForcalledarg(ceBaseFrameReturn, "ceBaseFrameReturnTrampoline", ReceiverResultReg);
	ceReturnToInterpreterTrampoline = genReturnTrampolineForcalledarg(ceReturnToInterpreter, "ceReturnToInterpreterTrampoline", ReceiverResultReg);
}


/*	Generate a routine ceCaptureCStackPointers that will capture the C stack
	pointer, and, if it is in use, the C frame pointer. These are used in
	trampolines to call
	run-time routines in the interpreter from machine-code. */

	/* Cogit>>#generateStackPointerCapture */
static void
generateStackPointerCapture(void)
{
    sqInt oldMethodZoneBase;
    sqInt oldTrampolineTableIndex;


	/* For the benefit of the following assert, assume the minimum at first. */

	cFramePointerInUse = 0;
	assertCStackWellAligned();
	oldMethodZoneBase = methodZoneBase;
	oldTrampolineTableIndex = trampolineTableIndex;
	generateCaptureCStackPointers(1);
	ceCaptureCStackPointers();
	if (!((cFramePointerInUse = isCFramePointerInUse()))) {
		methodZoneBase = oldMethodZoneBase;
		trampolineTableIndex = oldTrampolineTableIndex;
		generateCaptureCStackPointers(0);
	}
	assertCStackWellAligned();
}


/*	Generate the run-time entries and exits at the base of the native code
	zone and update the base.
	Read the class-side method trampolines for documentation on the various
	trampolines 
 */

	/* Cogit>>#generateTrampolines */
static void
generateTrampolines(void)
{
    sqInt fixupSize;
    sqInt methodZoneStart;
    sqInt opcodeSize;

	methodZoneStart = methodZoneBase;
	(methodLabel->address = methodZoneStart);
	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = 80;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	hasYoungReferent = 0;
	generateSendTrampolines();
	generateMissAbortTrampolines();
	generateObjectRepresentationTrampolines();
	generateRunTimeTrampolines();
	
	
	generateEnilopmarts();
	generateTracingTrampolines();
	recordGeneratedRunTimeaddress("methodZoneBase", methodZoneBase);
	flushICacheFromto(processor, ((usqInt)methodZoneStart), ((usqInt)methodZoneBase));
}

	/* Cogit>>#generateVMOwnerLockFunctions */
static void
generateVMOwnerLockFunctions(void)
{
    sqInt fixupSize;
    sqInt numberOfAbstractOpcodes;
    sqInt opcodeSize;
    sqInt startAddress;

	
#  if COGMTVM
	/* begin allocateOpcodes:bytecodes: */
	numberOfAbstractOpcodes = numLowLevelLockOpcodes(backEnd);
	numAbstractOpcodes = numberOfAbstractOpcodes;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	zeroOpcodeIndex();
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	startAddress = methodZoneBase;
	generateLowLevelTryLock(backEnd, vmOwnerLockAddress());
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceTryLockVMOwner", startAddress);
	ceTryLockVMOwner = ((unsigned long (*)(void)) startAddress);
	zeroOpcodeIndex();
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	startAddress = methodZoneBase;
	generateLowLevelUnlock(backEnd, vmOwnerLockAddress());
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceUnlockVMOwner", startAddress);
	ceUnlockVMOwner = ((void (*)(void)) startAddress);

#  endif /* COGMTVM */

}


/*	Generate a routine that answers the stack pointer immedately
	after a leaf call, used for checking stack pointer alignment. */

	/* Cogit>>#genGetLeafCallStackPointer */
static sqInt
genGetLeafCallStackPointer(void)
{
    sqInt fixupSize;
    sqInt opcodeSize;
    sqInt startAddress;

	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = 32;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	startAddress = methodZoneBase;
	genGetLeafCallStackPointerFunction(backEnd);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceGetSP", startAddress);
	return startAddress;
}


/*	Generate the abort for a PIC. This abort performs either a call of
	ceInterpretMethodFromPIC:receiver: to handle invoking an uncogged target
	or a call of ceMNUFromPICMNUMethod:receiver: to handle an MNU dispatch
	in a closed PIC. It distinguishes the two by testing ClassReg. If the
	register is zero then this is an MNU.
	
	This poses a problem in 32-bit Spur, where zero is the cache tag for
	immediate characters (tag pattern 2r10) because SmallIntegers have tag
	patterns 2r11
	and 2r01, so anding with 1 reduces these to 0 & 1. We solve the ambiguity
	by patching send sites with a 0 cache tag to open PICs instead of closed
	PICs.  */

	/* Cogit>>#genInnerPICAbortTrampoline: */
static sqInt
genInnerPICAbortTrampoline(char *name)
{
    AbstractInstruction *jumpMNUCase;

	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, ClassReg));
	/* begin JumpZero: */
	jumpMNUCase = genoperand(JumpZero, ((sqInt)0));
	compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(ceInterpretMethodFromPICreceiver, 2, SendNumArgsReg, ReceiverResultReg, null, null, 0, 0, null);
	jmpTarget(jumpMNUCase, gLabel());
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceMNUFromPICMNUMethodreceiver, name, 2, SendNumArgsReg, ReceiverResultReg, null, null, 0, 0, null, 1);
}

	/* Cogit>>#genLoadCStackPointersForPrimCall */
static sqInt
genLoadCStackPointersForPrimCall(void)
{
    sqInt address;
    sqInt address1;
    sqInt address2;

	if (debugPrimCallStackOffset == 0) {
		/* begin MoveAw:R: */
		address = cStackPointerAddress();
		/* begin gen:literal:operand: */
		checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, SPReg));
	}
	else {
		/* begin MoveAw:R: */
		address1 = cStackPointerAddress();
		/* begin gen:literal:operand: */
		checkLiteralforInstruction(address1, genoperandoperand(MoveAwR, address1, TempReg));
		/* begin SubCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(debugPrimCallStackOffset, genoperandoperand(SubCqR, debugPrimCallStackOffset, TempReg));
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, TempReg, SPReg);
	}
	if (cFramePointerInUse) {
		/* begin MoveAw:R: */
		address2 = cFramePointerAddress();
		/* begin gen:literal:operand: */
		checkLiteralforInstruction(address2, genoperandoperand(MoveAwR, address2, FPReg));
	}
	return 0;
}

	/* Cogit>>#genNonLocalReturnTrampoline */
static sqInt
genNonLocalReturnTrampoline(void)
{
    sqInt address;
    sqInt address1;

	zeroOpcodeIndex();
	/* begin MoveR:Aw: */
	address = instructionPointerAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address, genoperandoperand(MoveRAw, LinkReg, address));

	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceNonLocalReturn, "ceNonLocalReturnTrampoline", 1, ReceiverResultReg, null, null, null, 0, 0, null, 1);
}


/*	Generate a trampoline for a routine used as a return address, that has one
	argument. Hack: a negative value indicates an abstract register, a
	non-negative value indicates a constant. */

	/* Cogit>>#genReturnTrampolineFor:called:arg: */
static sqInt
genReturnTrampolineForcalledarg(void *aRoutine, char *aString, sqInt regOrConst0)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 1, regOrConst0, null, null, null, 0, 0, null, 0);
}


/*	Generate a trampoline with no arguments that will
	save and restore all registers around the call */

	/* Cogit>>#genSafeTrampolineFor:called: */
static sqInt
genSafeTrampolineForcalled(void *aRoutine, char *aString)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 0, null, null, null, null, 1, 1, null, 0);
}


/*	Generate a trampoline with one argument that will
	save and restore all registers around the call */

	/* Cogit>>#genSafeTrampolineFor:called:arg: */
static sqInt
genSafeTrampolineForcalledarg(void *aRoutine, char *aString, sqInt regOrConst0)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 1, regOrConst0, null, null, null, 1, 1, null, 0);
}


/*	Generate a trampoline with two arguments that
	will save and restore all registers around the call */

	/* Cogit>>#genSafeTrampolineFor:called:arg:arg: */
static sqInt
genSafeTrampolineForcalledargarg(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 2, regOrConst0, regOrConst1, null, null, 1, 1, null, 0);
}


/*	If the client requires, then on an ARM-like RISC processor, the return
	address needs to
	be pushed to the stack so that the interpreter sees the same stack layout
	as on CISC.
 */

	/* Cogit>>#genSmalltalkToCStackSwitch: */
static sqInt
genSmalltalkToCStackSwitch(sqInt pushLinkReg)
{
	if (pushLinkReg) {
		/* begin PushR: */
		genoperand(PushR, LinkReg);
	}
	genSaveStackPointers(backEnd);
	if (cFramePointerInUse) {
		genLoadCStackPointers(backEnd);
	}
	else {
		genLoadCStackPointer(backEnd);
	}
	return 0;
}


/*	Generate a trampoline with no arguments */

	/* Cogit>>#genTrampolineFor:called: */
static sqInt
genTrampolineForcalled(void *aRoutine, char *aString)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 0, null, null, null, null, 0, 1, null, 0);
}


/*	Generate a trampoline with two arguments that answers a result.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

	/* Cogit>>#genTrampolineFor:called:arg:arg:arg:result: */
static sqInt
genTrampolineForcalledargargargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt resultReg)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 3, regOrConst0, regOrConst1, regOrConst2, null, 0, 1, resultReg, 0);
}


/*	Generate a trampoline with two arguments that answers a result.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

	/* Cogit>>#genTrampolineFor:called:arg:arg:result: */
static sqInt
genTrampolineForcalledargargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt resultReg)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 2, regOrConst0, regOrConst1, null, null, 0, 1, resultReg, 0);
}


/*	Generate a trampoline with one argument that answers a result.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

	/* Cogit>>#genTrampolineFor:called:arg:result: */
static sqInt
genTrampolineForcalledargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt resultReg)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 1, regOrConst0, null, null, null, 0, 1, resultReg, 0);
}


/*	Generate a trampoline with up to four arguments. Generate either a call or
	a jump to aRoutineOrNil
	as requested by callJumpBar. If generating a call and resultRegOrNil is
	non-zero pass the C result
	back in resultRegOrNil.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

	/* Cogit>>#genTrampolineFor:called:numArgs:arg:arg:arg:arg:saveRegs:pushLinkReg:resultReg:appendOpcodes: */
static sqInt
genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(void *aRoutine, char *trampolineName, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt saveRegs, sqInt pushLinkReg, sqInt resultRegOrNil, sqInt appendBoolean)
{
    sqInt startAddress;

	startAddress = methodZoneBase;
	if (!appendBoolean) {
		zeroOpcodeIndex();
	}
	compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(aRoutine, numArgs, regOrConst0, regOrConst1, regOrConst2, regOrConst3, saveRegs, pushLinkReg, resultRegOrNil);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress(trampolineName, startAddress);
	recordRunTimeObjectReferences();
	return startAddress;
}


/*	<Integer> */

	/* Cogit>>#gen: */
static AbstractInstruction *
gen(sqInt opcode)
{
    AbstractInstruction *abstractInstruction;

	assert(opcodeIndex < numAbstractOpcodes);
	abstractInstruction = abstractInstructionAt(opcodeIndex);
	opcodeIndex += 1;
	(abstractInstruction->opcode = opcode);
	
	return abstractInstruction;
}


/*	<Integer> */
/*	<Integer|CogAbstractInstruction> */

	/* Cogit>>#gen:operand: */
static AbstractInstruction *
genoperand(sqInt opcode, sqInt operand)
{
    AbstractInstruction *abstractInstruction;

	assert(opcodeIndex < numAbstractOpcodes);
	abstractInstruction = abstractInstructionAt(opcodeIndex);
	opcodeIndex += 1;
	(abstractInstruction->opcode = opcode);
	((abstractInstruction->operands))[0] = operand;
	
	return abstractInstruction;
}


/*	<Integer> */
/*	<Integer|CogAbstractInstruction> */
/*	<Integer|CogAbstractInstruction> */

	/* Cogit>>#gen:operand:operand: */
static AbstractInstruction *
genoperandoperand(sqInt opcode, sqInt operandOne, sqInt operandTwo)
{
    AbstractInstruction *abstractInstruction;

	assert(opcodeIndex < numAbstractOpcodes);
	abstractInstruction = abstractInstructionAt(opcodeIndex);
	opcodeIndex += 1;
	(abstractInstruction->opcode = opcode);
	((abstractInstruction->operands))[0] = operandOne;
	((abstractInstruction->operands))[1] = operandTwo;
	
	return abstractInstruction;
}


/*	<Integer> */
/*	<Integer|CogAbstractInstruction> */
/*	<Integer|CogAbstractInstruction> */
/*	<Integer|CogAbstractInstruction> */

	/* Cogit>>#gen:operand:operand:operand: */
static AbstractInstruction *
genoperandoperandoperand(sqInt opcode, sqInt operandOne, sqInt operandTwo, sqInt operandThree)
{
    AbstractInstruction *abstractInstruction;

	assert(opcodeIndex < numAbstractOpcodes);
	abstractInstruction = abstractInstructionAt(opcodeIndex);
	opcodeIndex += 1;
	(abstractInstruction->opcode = opcode);
	((abstractInstruction->operands))[0] = operandOne;
	((abstractInstruction->operands))[1] = operandTwo;
	((abstractInstruction->operands))[2] = operandThree;
	
	return abstractInstruction;
}

	/* Cogit>>#getLiteral: */
static sqInt
getLiteral(sqInt litIndex)
{
	if (maxLitIndex < litIndex) {
		maxLitIndex = litIndex;
	}
	return literalofMethod(litIndex, methodObj);
}


/*	Access for the literal manager. */

	/* Cogit>>#getOpcodeIndex */
static sqInt
getOpcodeIndex(void)
{
	return opcodeIndex;
}

	/* Cogit>>#incrementUsageOfTargetIfLinkedSend:mcpc:ignored: */
static sqInt
incrementUsageOfTargetIfLinkedSendmcpcignored(sqInt annotation, char *mcpc, sqInt superfluity)
{
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    CogMethod * targetMethod;
    CogMethod *targetMethod1;

	
	if (annotation >= IsSendCall) {
		assert(annotation != IsNSSendCall);
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */

			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if (((targetMethod1->cmUsageCount)) < (CMMaxUsageCount / 2)) {
				(targetMethod1->cmUsageCount = ((targetMethod1->cmUsageCount)) + 1);
			}

		}
	}
	return 0;
}


/*	Answer a usage count that reflects likely long-term usage. */

	/* Cogit>>#initialClosedPICUsageCount */
static sqInt
initialClosedPICUsageCount(void)
{
	return CMMaxUsageCount / 2;
}

	/* Cogit>>#initializeBackend */
static void
initializeBackend(void)
{
    AbstractInstruction *existingInst;
    sqInt i;
    sqInt iLimiT;
    AbstractInstruction *newInst;
    AbstractInstruction *newLiterals;

	(methodLabel->machineCodeSize = 0);
	(methodLabel->opcode = Label);
	((methodLabel->operands))[0] = 0;
	((methodLabel->operands))[1] = 0;
	callerSavedRegMask = callerSavedRegisterMask(backEnd);
	assert(((registerMaskFor(VarBaseReg)) & callerSavedRegMask) == 0);

	/* begin allocateLiterals: */
	if (4 > literalsSize) {

		/* Must copy across state (not using realloc, cuz...) and
		   must also update existing instructions to refer to the new ones...
		   It's either this or modify all generation routines to be able to retry
		   with more literals after running out of literals. */

		newLiterals = calloc(4, sizeof(CogAbstractInstruction));
		if (!(literals == null)) {
			for (i = 0; i < nextLiteralIndex; i += 1) {
				existingInst = literalInstructionAt(i);
				newInst = (&(newLiterals[i]));
				cloneLiteralFrom(newInst, existingInst);
				assert(((existingInst->dependent)) == null);
				(existingInst->dependent = newInst);
			}
			for (i = 0, iLimiT = (opcodeIndex - 1); i <= iLimiT; i += 1) {
				existingInst = abstractInstructionAt(i);
				if ((((existingInst->dependent)) != null)
				 && (((((existingInst->dependent))->opcode)) == Literal)) {
					(existingInst->dependent = (((existingInst->dependent))->dependent));
				}
			}
		}
		free(literals);
		literals = newLiterals;
		literalsSize = 4;
	}
	/* begin resetLiterals */

	/* an impossibly high value */

	firstOpcodeIndex = 1 << 16;
	nextLiteralIndex = (lastDumpedLiteralIndex = 0);
}

	/* Cogit>>#initializeCodeZoneFrom:upTo: */
void
initializeCodeZoneFromupTo(sqInt startAddress, sqInt endAddress)
{
	sqMakeMemoryExecutableFromTo(startAddress, endAddress);
	codeBase = (methodZoneBase = startAddress);
	minValidCallAddress = (((((codeBase < (interpretAddress())) ? codeBase : (interpretAddress()))) < (primitiveFailAddress())) ? (((codeBase < (interpretAddress())) ? codeBase : (interpretAddress()))) : (primitiveFailAddress()));
	initializeBackend();
	manageFromto(methodZoneBase, endAddress);
	maybeGenerateCheckFeatures();
	maybeGenerateICacheFlush();
	generateVMOwnerLockFunctions();
	ceGetSP = ((unsigned long (*)(void)) (genGetLeafCallStackPointer()));
	generateStackPointerCapture();
	generateTrampolines();
	manageFromto(methodZoneBase, endAddress);
	computeEntryOffsets();
	generateClosedPICPrototype();
	generateOpenPICPrototype();
}


/*	Answer a usage count that reflects likely long-term usage.
	Answer 1 for non-primitives or quick primitives (inst var accessors),
	2 for methods with interpreter primitives, and 3 for compiled primitives. */

	/* Cogit>>#initialMethodUsageCount */
static sqInt
initialMethodUsageCount(void)
{
	if ((primitiveIndex == 1)
	 || (isQuickPrimitiveIndex(primitiveIndex))) {
		return 1;
	}
	if ((primitiveGeneratorOrNil()) == null) {
		return 2;
	}
	return 3;
}


/*	Answer a usage count that reflects likely long-term usage. */

	/* Cogit>>#initialOpenPICUsageCount */
static sqInt
initialOpenPICUsageCount(void)
{
	return CMMaxUsageCount - 1;
}

	/* Cogit>>#inverseBranchFor: */
static sqInt
inverseBranchFor(sqInt opcode)
{
	
	switch (opcode) {
	case JumpLongZero:
		return JumpLongNonZero;

	case JumpLongNonZero:
		return JumpLongZero;

	case JumpZero:
		return JumpNonZero;

	case JumpNonZero:
		return JumpZero;

	case JumpNegative:
		return JumpNonNegative;

	case JumpNonNegative:
		return JumpNegative;

	case JumpOverflow:
		return JumpNoOverflow;

	case JumpNoOverflow:
		return JumpOverflow;

	case JumpCarry:
		return JumpNoCarry;

	case JumpNoCarry:
		return JumpCarry;

	case JumpLess:
		return JumpGreaterOrEqual;

	case JumpGreaterOrEqual:
		return JumpLess;

	case JumpGreater:
		return JumpLessOrEqual;

	case JumpLessOrEqual:
		return JumpGreater;

	case JumpBelow:
		return JumpAboveOrEqual;

	case JumpAboveOrEqual:
		return JumpBelow;

	case JumpAbove:
		return JumpBelowOrEqual;

	case JumpBelowOrEqual:
		return JumpAbove;

	default:
		error("Case not found and no otherwise clause");
	}
	error("invalid opcode for inverse");
	return 0;
}


/*	Answer if the branch bytecode with the given descriptor is a backward
	branch. 
 */

	/* Cogit>>#isBackwardBranch:at:exts:in: */
static sqInt
isBackwardBranchatextsin(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	assert(((descriptor->spanFunction)) != null);
	return (((descriptor->spanFunction))(descriptor, pc, nExts, aMethodObj)) < 0;
}

	/* Cogit>>#isPCMappedAnnotation: */
static sqInt
isPCMappedAnnotation(sqInt annotation)
{
	return (annotation >= IsSendCall)
	 || ((annotation == HasBytecodePC)
	 || (0));
}

	/* Cogit>>#isPCWithinMethodZone: */
sqInt
isPCWithinMethodZone(void *address)
{
	return (((((usqInt)address)) >= methodZoneBase) && ((((usqInt)address)) <= (freeStart())));
}


/*	Answer if the instruction preceeding retpc is a call instruction. */

	/* Cogit>>#isSendReturnPC: */
sqInt
isSendReturnPC(sqInt retpc)
{
    sqInt target;

	if (!(isCallPreceedingReturnPC(backEnd, retpc))) {
		return 0;
	}
	target = callTargetFromReturnAddress(backEnd, retpc);
	return (((target >= firstSend) && (target <= lastSend)))
	 || (((target >= methodZoneBase) && (target <= (freeStart()))));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

	/* Cogit>>#JumpFPEqual: */
static AbstractInstruction *
gJumpFPEqual(void *jumpTarget)
{
	/* begin genJumpFPEqual: */
	return genoperand(JumpFPEqual, ((sqInt)jumpTarget));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

	/* Cogit>>#JumpFPGreaterOrEqual: */
static AbstractInstruction *
gJumpFPGreaterOrEqual(void *jumpTarget)
{
	/* begin genJumpFPGreaterOrEqual: */
	return genoperand(JumpFPGreaterOrEqual, ((sqInt)jumpTarget));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

	/* Cogit>>#JumpFPGreater: */
static AbstractInstruction *
gJumpFPGreater(void *jumpTarget)
{
	/* begin genJumpFPGreater: */
	return genoperand(JumpFPGreater, ((sqInt)jumpTarget));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

	/* Cogit>>#JumpFPLessOrEqual: */
static AbstractInstruction *
gJumpFPLessOrEqual(void *jumpTarget)
{
	/* begin genJumpFPLessOrEqual: */
	return genoperand(JumpFPLessOrEqual, ((sqInt)jumpTarget));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

	/* Cogit>>#JumpFPLess: */
static AbstractInstruction *
gJumpFPLess(void *jumpTarget)
{
	/* begin genJumpFPLess: */
	return genoperand(JumpFPLess, ((sqInt)jumpTarget));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

	/* Cogit>>#JumpFPNotEqual: */
static AbstractInstruction *
gJumpFPNotEqual(void *jumpTarget)
{
	/* begin genJumpFPNotEqual: */
	return genoperand(JumpFPNotEqual, ((sqInt)jumpTarget));
}

	/* Cogit>>#Label */
static AbstractInstruction *
gLabel(void)
{
	return genoperandoperand(Label, (labelCounter += 1), bytecodePC);
}

	/* Cogit>>#LogicalShiftLeftCq:R: */
static AbstractInstruction *
gLogicalShiftLeftCqR(sqInt quickConstant, sqInt reg)
{
	return genoperandoperand(LogicalShiftLeftCqR, quickConstant, reg);
}

	/* Cogit>>#lastOpcode */
static AbstractInstruction *
lastOpcode(void)
{
	assert(opcodeIndex > 0);
	return abstractInstructionAt(opcodeIndex - 1);
}

	/* Cogit>>#linkSendAt:in:to:offset:receiver: */
void
linkSendAtintooffsetreceiver(sqInt callSiteReturnAddress, CogMethod *sendingMethod, CogMethod *targetMethod, sqInt theEntryOffset, sqInt receiver)
{
    sqInt address;
    sqInt extent;
    sqInt inlineCacheTag;

	assert((theEntryOffset == cmEntryOffset)
	 || (theEntryOffset == cmNoCheckEntryOffset));
	assert(((callSiteReturnAddress >= methodZoneBase) && (callSiteReturnAddress <= (freeStart()))));
	inlineCacheTag = (theEntryOffset == cmNoCheckEntryOffset
		? (targetMethod->selector)
		: inlineCacheTagForInstance(receiver));
	
	address = (((sqInt)targetMethod)) + theEntryOffset;
	extent = rewriteInlineCacheAttagtarget(backEnd, callSiteReturnAddress, inlineCacheTag, address);
	flushICacheFromto(processor, (((usqInt)callSiteReturnAddress)) - extent, ((usqInt)callSiteReturnAddress));
}

	/* Cogit>>#loadSubsequentBytesForDescriptor:at: */
static void
loadSubsequentBytesForDescriptorat(BytecodeDescriptor *descriptor, sqInt pc)
{
	if (((descriptor->numBytes)) > 1) {
		byte1 = fetchByteofObject(pc + 1, methodObj);
		if (((descriptor->numBytes)) > 2) {
			byte2 = fetchByteofObject(pc + 2, methodObj);
			if (((descriptor->numBytes)) > 3) {
				byte3 = fetchByteofObject(pc + 3, methodObj);
				if (((descriptor->numBytes)) > 4) {
					notYetImplemented();
				}
			}
		}
	}
}

	/* Cogit>>#MoveAw:R: */
static AbstractInstruction *
gMoveAwR(sqInt address, sqInt reg)
{
	/* begin gen:literal:operand: */
	return checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, reg));
}

	/* Cogit>>#MoveCw:R: */
static AbstractInstruction *
gMoveCwR(sqInt wordConstant, sqInt reg)
{
	/* begin gen:literal:operand: */
	return checkLiteralforInstruction(wordConstant, genoperandoperand(MoveCwR, wordConstant, reg));
}

	/* Cogit>>#MoveMw:r:R: */
static AbstractInstruction *
gMoveMwrR(sqInt offset, sqInt baseReg, sqInt destReg)
{
	/* begin gen:quickConstant:operand:operand: */
	return checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveMwrR, offset, baseReg, destReg));
}

	/* Cogit>>#MoveR:Mw:r: */
static AbstractInstruction *
gMoveRMwr(sqInt sourceReg, sqInt offset, sqInt baseReg)
{
	/* begin gen:operand:quickConstant:operand: */
	return checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveRMwr, sourceReg, offset, baseReg));
}

	/* Cogit>>#MoveR:R: */
static AbstractInstruction *
gMoveRR(sqInt reg1, sqInt reg2)
{
	return genoperandoperand(MoveRR, reg1, reg2);
}


/*	Multiplication is a little weird on some processors. Defer to the backEnd
	to allow it to generate any special code it may need to. */

	/* Cogit>>#MulR:R: */
static AbstractInstruction *
gMulRR(sqInt reg1, sqInt reg2)
{
	genMulRR(backEnd, reg1, reg2);
	return abstractInstructionAt(opcodeIndex - 1);
}


/*	Answer the address of the null byte at the end of the method map. */

	/* Cogit>>#mapEndFor: */
static sqInt
mapEndFor(CogMethod *cogMethod)
{
    sqInt end;

	end = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while ((byteAt(end)) != MapEnd) {
		end -= 1;
		assert(end > ((((sqInt)cogMethod)) + cmNoCheckEntryOffset));
	}
	return end;
}


/*	Unlinking/GC/Disassembly support */

	/* Cogit>>#mapFor:performUntil:arg: */
static sqInt
mapForperformUntilarg(CogMethod *cogMethod, int (*functionSymbol)(sqInt annotation, char *mcpc, sqInt arg), sqInt arg)
{
    sqInt annotation;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while (((mapByte = byteAt(map))) != MapEnd) {
		if (mapByte >= FirstAnnotation) {

			/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

			mcpc += (mapByte & DisplacementMask) * 4;
			if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
			 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
				annotation += mapByte & DisplacementMask;
				map -= 1;
			}
			result = functionSymbol(annotation, (((char *) mcpc)), arg);
			if (result != 0) {
				return result;
			}
		}
		else {
			if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
				mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
			}
		}
		map -= 1;
	}
	return 0;
}


/*	Remap all object references in the closed PIC. Answer if any references
	are young.
	Set codeModified if any modifications are made. */

	/* Cogit>>#mapObjectReferencesInClosedPIC: */
static sqInt
mapObjectReferencesInClosedPIC(CogMethod *cPIC)
{
    sqInt i;
    sqInt pc;
    sqInt refersToYoung;

	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	refersToYoung = updateMaybeObjRefInClosedPICAt(pc - (jumpLongByteSize(backEnd)));
	pc += cPICCaseSize;
	for (i = 2; i <= ((cPIC->cPICNumCases)); i += 1) {
		;
		if (updateMaybeObjRefInClosedPICAt(pc - (jumpLongConditionalByteSize(backEnd)))) {
			refersToYoung = 1;
		}
		pc += cPICCaseSize;
	}
	return refersToYoung;
}


/*	Update all references to objects in the generated runtime. */

	/* Cogit>>#mapObjectReferencesInGeneratedRuntime */
static void
mapObjectReferencesInGeneratedRuntime(void)
{
    sqInt i;
    sqInt literal;
    sqInt mappedLiteral;
    usqInt mcpc;

	for (i = 0; i < runtimeObjectRefIndex; i += 1) {
		mcpc = objectReferencesInRuntime[i];
		literal = longAt(mcpc);
		mappedLiteral = remapObject(literal);
		if (mappedLiteral != literal) {
			/* begin storeLiteral:atAnnotatedAddress:using: */
			longAtput(mcpc, mappedLiteral);
			codeModified = 1;
		}
	}
}


/*	Update all references to objects in machine code for a become.
	Unlike incrementalGC or fullGC a method that does not refer to young may
	refer to young as a result of the become operation. Unlike incrementalGC
	or fullGC the reference from a Cog method to its methodObject *must not*
	change since the two are two halves of the same object. */

	/* Cogit>>#mapObjectReferencesInMachineCodeForBecome */
static void
mapObjectReferencesInMachineCodeForBecome(void)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt freedPIC;
    sqInt hasYoungObj;
    sqInt hasYoungObjPtr;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt remappedMethod;
    sqInt result;
    sqInt val;

	val = 0;
	hasYoungObj = 0;
	hasYoungObjPtr = ((sqInt)((&hasYoungObj)));
	codeModified = (freedPIC = 0);
	mapObjectReferencesInGeneratedRuntime();
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		assert(!hasYoungObj);
		if (((cogMethod->cmType)) != CMFree) {
			assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
			(cogMethod->selector = remapOop((cogMethod->selector)));
			if (((cogMethod->cmType)) == CMClosedPIC) {
				if ((isYoung((cogMethod->selector)))
				 || (mapObjectReferencesInClosedPIC(cogMethod))) {
					freedPIC = 1;
					freeMethod(cogMethod);
				}
			}
			else {
				if (isYoung((cogMethod->selector))) {
					hasYoungObj = 1;
				}
				if (((cogMethod->cmType)) == CMMethod) {
					assert(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()));
					remappedMethod = remapOop((cogMethod->methodObject));
					if (remappedMethod != ((cogMethod->methodObject))) {
						if (methodHasCogMethod(remappedMethod)) {
							error("attempt to become two cogged methods");
						}
						if (!(withoutForwardingOnandwithsendToCogit((cogMethod->methodObject), remappedMethod, (cogMethod->cmUsesPenultimateLit), methodhasSameCodeAscheckPenultimate))) {
							error("attempt to become cogged method into different method");
						}
						if ((rawHeaderOf((cogMethod->methodObject))) == (((sqInt)cogMethod))) {
							rawHeaderOfput((cogMethod->methodObject), (cogMethod->methodHeader));
							(cogMethod->methodHeader = rawHeaderOf(remappedMethod));
							(cogMethod->methodObject = remappedMethod);
							rawHeaderOfput(remappedMethod, ((sqInt)cogMethod));
						}
						else {
							assert((noAssertMethodClassAssociationOf((cogMethod->methodObject))) == (nilObject()));
							(cogMethod->methodHeader = rawHeaderOf(remappedMethod));
							(cogMethod->methodObject = remappedMethod);
						}
					}
					if (isYoung((cogMethod->methodObject))) {
						hasYoungObj = 1;
					}
				}
				/* begin mapFor:performUntil:arg: */
				mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
				map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
				while (((mapByte = byteAt(map))) != MapEnd) {
					if (mapByte >= FirstAnnotation) {

						/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

						mcpc += (mapByte & DisplacementMask) * 4;
						if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
						 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
							annotation += mapByte & DisplacementMask;
							map -= 1;
						}
						result = remapIfObjectRefpchasYoung(annotation, (((char *) mcpc)), hasYoungObjPtr);
						if (result != 0) {
							result;
							goto l1;
						}
					}
					else {
						if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
							mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
						}
					}
					map -= 1;
				}
				0;
			l1:	/* end mapFor:performUntil:arg: */;
				if (hasYoungObj) {
					ensureInYoungReferrers(cogMethod);
					hasYoungObj = 0;
				}
				else {
					(cogMethod->cmRefersToYoung = 0);
				}
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	pruneYoungReferrers();
	if (freedPIC) {
		unlinkSendsToFree();
	}
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */

		flushICacheFromto(processor, ((usqInt)codeBase), ((usqInt)(limitZony())));
	}
}


/*	Update all references to objects in machine code for a full gc. Since
	the current (New)ObjectMemory GC makes everything old in a full GC
	a method not referring to young will not refer to young afterwards */

	/* Cogit>>#mapObjectReferencesInMachineCodeForFullGC */
static void
mapObjectReferencesInMachineCodeForFullGC(void)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	codeModified = 0;
	mapObjectReferencesInGeneratedRuntime();
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
			(cogMethod->selector = remapOop((cogMethod->selector)));
			if (((cogMethod->cmType)) == CMClosedPIC) {
				assert(!((cogMethod->cmRefersToYoung)));
				mapObjectReferencesInClosedPIC(cogMethod);
			}
			else {
				if (((cogMethod->cmType)) == CMMethod) {
					assert(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()));
					(cogMethod->methodObject = remapOop((cogMethod->methodObject)));
				}
				/* begin mapFor:performUntil:arg: */
				mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
				map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
				while (((mapByte = byteAt(map))) != MapEnd) {
					if (mapByte >= FirstAnnotation) {

						/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

						mcpc += (mapByte & DisplacementMask) * 4;
						if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
						 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
							annotation += mapByte & DisplacementMask;
							map -= 1;
						}
						result = remapIfObjectRefpchasYoung(annotation, (((char *) mcpc)), 0);
						if (result != 0) {
							result;
							goto l1;
						}
					}
					else {
						if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
							mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
						}
					}
					map -= 1;
				}
				0;
			l1:	/* end mapFor:performUntil:arg: */;
				
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	pruneYoungReferrers();
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */

		flushICacheFromto(processor, ((usqInt)codeBase), ((usqInt)(limitZony())));
	}
}


/*	Update all references to objects in machine code for either a Spur
	scavenging gc
	or a Squeak V3 incremental GC. Avoid scanning all code by using the
	youngReferrers list. In a young gc a method referring to young may no
	longer refer to young, but a
	method not referring to young cannot and will not refer to young
	afterwards.  */

	/* Cogit>>#mapObjectReferencesInMachineCodeForYoungGC */
static void
mapObjectReferencesInMachineCodeForYoungGC(void)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt hasYoungObj;
    sqInt hasYoungObjPtr;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    usqInt pointer;
    sqInt result;
    sqInt val;

	val = 0;
	hasYoungObj = 0;
	hasYoungObjPtr = ((sqInt)((&hasYoungObj)));
	codeModified = 0;
	pointer = youngReferrers();
	while (pointer < limitAddress) {
		assert(!hasYoungObj);
		cogMethod = ((CogMethod *) (longAt(pointer)));
		if (((cogMethod->cmType)) == CMFree) {
			assert(!((cogMethod->cmRefersToYoung)));
		}
		else {
			assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
			if ((cogMethod->cmRefersToYoung)) {
				assert((((cogMethod->cmType)) == CMMethod)
				 || (((cogMethod->cmType)) == CMOpenPIC));
				(cogMethod->selector = remapOop((cogMethod->selector)));
				if (isYoung((cogMethod->selector))) {
					hasYoungObj = 1;
				}
				if (((cogMethod->cmType)) == CMMethod) {
					assert(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()));
					(cogMethod->methodObject = remapOop((cogMethod->methodObject)));
					if (isYoung((cogMethod->methodObject))) {
						hasYoungObj = 1;
					}
				}
				/* begin mapFor:performUntil:arg: */
				mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
				map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
				while (((mapByte = byteAt(map))) != MapEnd) {
					if (mapByte >= FirstAnnotation) {

						/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

						mcpc += (mapByte & DisplacementMask) * 4;
						if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
						 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
							annotation += mapByte & DisplacementMask;
							map -= 1;
						}
						result = remapIfObjectRefpchasYoung(annotation, (((char *) mcpc)), hasYoungObjPtr);
						if (result != 0) {
							result;
							goto l1;
						}
					}
					else {
						if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
							mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
						}
					}
					map -= 1;
				}
				0;
			l1:	/* end mapFor:performUntil:arg: */;
				if (hasYoungObj) {
					hasYoungObj = 0;
				}
				else {
					(cogMethod->cmRefersToYoung = 0);
				}
			}
		}
		pointer += BytesPerWord;
	}
	pruneYoungReferrers();
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */

		flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
	}
}


/*	Update all references to objects in machine code. */

	/* Cogit>>#mapObjectReferencesInMachineCode: */
void
mapObjectReferencesInMachineCode(sqInt gcMode)
{
	
	switch (gcMode) {
	case GCModeNewSpace:
		mapObjectReferencesInMachineCodeForYoungGC();
		break;
	case GCModeFull:
		mapObjectReferencesInMachineCodeForFullGC();
		break;
	case GCModeBecome:
		mapObjectReferencesInMachineCodeForBecome();
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	if (!(asserta((freeStart()) <= (youngReferrers())))) {
		error("youngReferrers list overflowed");
	}
}


/*	Mark objects in machine-code of marked methods (or open PICs with marked
	selectors). 
 */

	/* Cogit>>#markAndTraceMachineCodeOfMarkedMethods */
void
markAndTraceMachineCodeOfMarkedMethods(void)
{
    sqInt annotation;
    sqInt annotation1;
    CogMethod *cogMethod;
    sqInt map;
    sqInt map1;
    sqInt mapByte;
    sqInt mapByte1;
    sqInt mcpc;
    sqInt mcpc1;
    sqInt result;
    sqInt result1;
    sqInt val;
    sqInt val1;

	val = 0;
	val1 = 0;
	if (leakCheckFullGC()) {
		assert(allMachineCodeObjectReferencesValid());
	}
	codeModified = 0;
	markAndTraceObjectReferencesInGeneratedRuntime();
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) == CMMethod)
		 && (isMarked((cogMethod->methodObject)))) {
			/* begin markAndTraceLiteralsIn: */
			assert(((((cogMethod->cmType)) == CMMethod)
			 && (isMarked((cogMethod->methodObject))))
			 || ((((cogMethod->cmType)) == CMOpenPIC)
			 && ((isImmediate((cogMethod->selector)))
			 || (isMarked((cogMethod->selector))))));
			markAndTraceLiteralinat((cogMethod->selector), cogMethod, (&((cogMethod->selector))));
			maybeMarkCountersIn(cogMethod);
			/* begin maybeMarkIRCsIn: */
			
#      if NewspeakVM
			markIfIRC(nextMethodOrIRCs(cogMethod));


#      endif /* NewspeakVM */

			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = markLiteralspcmethod(annotation, (((char *) mcpc)), (((sqInt)cogMethod)));
					if (result != 0) {
						result;
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
			0;
		l1:	/* end mapFor:performUntil:arg: */;
		}
		if ((((cogMethod->cmType)) == CMOpenPIC)
		 && ((isImmediate((cogMethod->selector)))
		 || (isMarked((cogMethod->selector))))) {
			/* begin markAndTraceLiteralsIn: */
			assert(((((cogMethod->cmType)) == CMMethod)
			 && (isMarked((cogMethod->methodObject))))
			 || ((((cogMethod->cmType)) == CMOpenPIC)
			 && ((isImmediate((cogMethod->selector)))
			 || (isMarked((cogMethod->selector))))));
			markAndTraceLiteralinat((cogMethod->selector), cogMethod, (&((cogMethod->selector))));
			maybeMarkCountersIn(cogMethod);
			/* begin maybeMarkIRCsIn: */
			
#      if NewspeakVM
			markIfIRC(nextMethodOrIRCs(cogMethod));


#      endif /* NewspeakVM */

			/* begin mapFor:performUntil:arg: */
			mcpc1 = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map1 = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte1 = byteAt(map1))) != MapEnd) {
				if (mapByte1 >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

					mcpc1 += (mapByte1 & DisplacementMask) * 4;
					if ((((annotation1 = ((usqInt) mapByte1) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte1 = byteAt(map1 - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation1 += mapByte1 & DisplacementMask;
						map1 -= 1;
					}
					result1 = markLiteralspcmethod(annotation1, (((char *) mcpc1)), (((sqInt)cogMethod)));
					if (result1 != 0) {
						result1;
						goto l2;
					}
				}
				else {
					if (mapByte1 < (IsAnnotationExtension << AnnotationShift)) {
						mcpc1 += ((mapByte1 - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map1 -= 1;
			}
			0;
		l2:	/* end mapFor:performUntil:arg: */;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (leakCheckFullGC()) {
		assert(allMachineCodeObjectReferencesValid());
	}
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */

		flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
	}
}


/*	Mark and trace any object references in the generated run-time. */

	/* Cogit>>#markAndTraceObjectReferencesInGeneratedRuntime */
static void
markAndTraceObjectReferencesInGeneratedRuntime(void)
{
    sqInt i;
    sqInt literal;
    usqInt mcpc;

	for (i = 0; i < runtimeObjectRefIndex; i += 1) {
		mcpc = objectReferencesInRuntime[i];
		literal = longAt(mcpc);
		markAndTraceLiteralinatpc(literal, ((CogMethod *) null), ((usqInt)mcpc));
	}
}


/*	Mark and trace objects in the argument and free if it is appropriate.
	Answer if the method has been freed. firstVisit is a hint used to avoid
	scanning methods we've already seen. False positives are fine.
	For a CMMethod this
	frees if the bytecode method isnt marked,
	marks and traces object literals and selectors,
	unlinks sends to targets that should be freed.
	For a CMClosedPIC this
	frees if it refers to anything that should be freed or isn't marked.
	For a CMOpenPIC this
	frees if the selector isn't marked. */
/*	this recurses at most one level down */

	/* Cogit>>#markAndTraceOrFreeCogMethod:firstVisit: */
static sqInt
markAndTraceOrFreeCogMethodfirstVisit(CogMethod *cogMethod, sqInt firstVisit)
{
    sqInt annotation;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;
    sqInt val;

	val = 0;
	if (((cogMethod->cmType)) == CMFree) {
		return 1;
	}
	assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
	if (((cogMethod->cmType)) == CMMethod) {
		if (!(isMarked((cogMethod->methodObject)))) {
			freeMethod(cogMethod);
			return 1;
		}
		if (firstVisit) {
			/* begin markLiteralsAndUnlinkUnmarkedSendsIn: */
			assert(((cogMethod->cmType)) == CMMethod);
			assert(isMarked((cogMethod->methodObject)));
			markAndTraceLiteralinat((cogMethod->selector), cogMethod, (&((cogMethod->selector))));
			maybeMarkCountersIn(cogMethod);
			/* begin maybeMarkIRCsIn: */
			
#      if NewspeakVM
			markIfIRC(nextMethodOrIRCs(cogMethod));


#      endif /* NewspeakVM */

			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = markLiteralsAndUnlinkIfUnmarkedSendpcmethod(annotation, (((char *) mcpc)), (((sqInt)cogMethod)));
					if (result != 0) {
						result;
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
			0;
		l1:	/* end mapFor:performUntil:arg: */;
		}
		return 0;
	}
	if (((cogMethod->cmType)) == CMClosedPIC) {
		if (!(closedPICRefersToUnmarkedObject(cogMethod))) {
			return 0;
		}
		freeMethod(cogMethod);
		return 1;
	}
	if (((cogMethod->cmType)) == CMOpenPIC) {
		if (isMarked((cogMethod->selector))) {
			return 0;
		}
		freeMethod(cogMethod);
		return 1;
	}
	assert((((cogMethod->cmType)) == CMMethod)
	 || ((((cogMethod->cmType)) == CMClosedPIC)
	 || (((cogMethod->cmType)) == CMOpenPIC)));
	return 0;
}


/*	Mark and trace literals. Unlink sends that have unmarked cache tags or
	targets. 
 */

	/* Cogit>>#markLiteralsAndUnlinkIfUnmarkedSend:pc:method: */
static sqInt
markLiteralsAndUnlinkIfUnmarkedSendpcmethod(sqInt annotation, char *mcpc, sqInt cogMethod)
{
    sqInt cacheTag;
    sqInt cacheTag1;
    sqInt cacheTagMarked;
    sqInt entryPoint;
    sqInt entryPoint1;
    sqInt literal;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt tagCouldBeObj;
    sqInt tagCouldBeObj1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;
    sqInt val;

	literal = 0;
	val = 0;
	if (annotation == IsObjectReference) {
		literal = longAt(((usqInt)mcpc));
		if (markAndTraceLiteralinatpc(literal, ((CogMethod *) cogMethod), ((usqInt)mcpc))) {
			codeModified = 1;
		}
	}
	
	if (annotation >= IsSendCall) {
		/* begin offsetCacheTagAndCouldBeObjectAt:annotation:into: */
		cacheTag1 = inlineCacheTagAt(backEnd, ((sqInt)mcpc));

		/* in-line cache tags are the selectors of sends if sends are unlinked,
		   the selectors of super sends (entry offset = cmNoCheckEntryOffset),
		   the selectors of open PIC sends (entry offset = cmEntryOffset, target is an Open PIC)
		   or in-line cache tags (classes, class indices, immediate bit patterns, etc).
		   Note that selectors can be immediate so there is no guarantee that they
		   are markable/remappable objects. */

		entryPoint1 = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		tagCouldBeObj1 = (entryPoint1 < methodZoneBase)
		 || (((entryPoint1 & entryPointMask) == uncheckedEntryAlignment)
		 || (((entryPoint1 & entryPointMask) == checkedEntryAlignment)
		 && ((((((CogMethod *) (entryPoint1 - cmEntryOffset)))->cmType)) == CMOpenPIC)));
		cacheTagMarked = tagCouldBeObj1
		 && (cacheTagIsMarked(cacheTag1));
		if (entryPoint1 > methodZoneBase) {

			/* It's a linked send. */

			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint1 - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint1 - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if ((!cacheTagMarked)
			 || (markAndTraceOrFreeCogMethodfirstVisit(targetMethod1, (((usqInt)targetMethod1)) > (((usqInt)mcpc))))) {

				/* Either the cacheTag is unmarked (e.g. new class) or the target
				   has been freed (because it is unmarked), so unlink the send. */

				/* begin unlinkSendAt:targetMethod:sendTable: */
				unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
				rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), (targetMethod1->selector), unlinkedRoutine);
				codeModified = 1;
				markAndTraceLiteralinat((targetMethod1->selector), targetMethod1, (&((targetMethod1->selector))));
			}

		}
		else {

			/* cacheTag is selector */

			if (markAndTraceCacheTagLiteralinatpc(cacheTag1, ((CogMethod *) cogMethod), ((usqInt)mcpc))) {
				codeModified = 1;
			}
		}

	}
	return 0;
}


/*	Mark and trace literals.
	Additionally in Newspeak, void push implicits that have unmarked classes. */

	/* Cogit>>#markLiterals:pc:method: */
static sqInt
markLiteralspcmethod(sqInt annotation, char *mcpc, sqInt cogMethod)
{
    sqInt cacheTag;
    sqInt cacheTag1;
    sqInt entryPoint;
    sqInt entryPoint1;
    sqInt literal;
    sqInt tagCouldBeObj;
    sqInt tagCouldBeObj1;

	literal = 0;
	if (annotation == IsObjectReference) {
		literal = longAt(((usqInt)mcpc));
		if (markAndTraceLiteralinatpc(literal, ((CogMethod *) cogMethod), ((usqInt)mcpc))) {
			codeModified = 1;
		}
	}
	
	if (annotation >= IsSendCall) {
		/* begin offsetCacheTagAndCouldBeObjectAt:annotation:into: */
		cacheTag1 = inlineCacheTagAt(backEnd, ((sqInt)mcpc));

		/* in-line cache tags are the selectors of sends if sends are unlinked,
		   the selectors of super sends (entry offset = cmNoCheckEntryOffset),
		   the selectors of open PIC sends (entry offset = cmEntryOffset, target is an Open PIC)
		   or in-line cache tags (classes, class indices, immediate bit patterns, etc).
		   Note that selectors can be immediate so there is no guarantee that they
		   are markable/remappable objects. */

		entryPoint1 = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		tagCouldBeObj1 = (entryPoint1 < methodZoneBase)
		 || (((entryPoint1 & entryPointMask) == uncheckedEntryAlignment)
		 || (((entryPoint1 & entryPointMask) == checkedEntryAlignment)
		 && ((((((CogMethod *) (entryPoint1 - cmEntryOffset)))->cmType)) == CMOpenPIC)));
		if (tagCouldBeObj1) {
			if (markAndTraceCacheTagLiteralinatpc(cacheTag1, ((CogMethod *) cogMethod), ((usqInt)mcpc))) {

				/* cacheTag is selector */

				codeModified = 1;
			}
		}

	}
	return 0;
}

	/* Cogit>>#markMethodAndReferents: */
void
markMethodAndReferents(CogBlockMethod *aCogMethod)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	assert((((aCogMethod->cmType)) == CMMethod)
	 || (((aCogMethod->cmType)) == CMBlock));
	cogMethod = (((aCogMethod->cmType)) == CMMethod
		? ((CogMethod *) aCogMethod)
		: cmHomeMethod(aCogMethod));
	(cogMethod->cmUsageCount = CMMaxUsageCount);
	/* begin mapFor:performUntil:arg: */
	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while (((mapByte = byteAt(map))) != MapEnd) {
		if (mapByte >= FirstAnnotation) {

			/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

			mcpc += (mapByte & DisplacementMask) * 4;
			if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
			 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
				annotation += mapByte & DisplacementMask;
				map -= 1;
			}
			result = incrementUsageOfTargetIfLinkedSendmcpcignored(annotation, (((char *) mcpc)), 0);
			if (result != 0) {
				result;
				goto l1;
			}
		}
		else {
			if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
				mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
			}
		}
		map -= 1;
	}
	0;
l1:	/* end mapFor:performUntil:arg: */;
}

	/* Cogit>>#maxCogMethodAddress */
usqInt
maxCogMethodAddress(void)
{
	return ((usqInt)(limitZony()));
}


/*	If this is the Newspeak VM and the objectRepresentation supports pinning
	then allocate space for the implicit receiver caches on the heap. */

	/* Cogit>>#maybeAllocAndInitIRCs */
static sqInt
maybeAllocAndInitIRCs(void)
{
	
#  if NewspeakVM
	indexOfIRC = (theIRCs = 0);
	if (numIRCs > 0) {
		assert((noAssertMethodClassAssociationOf(methodObj)) != (nilObject()));
		theIRCs = allocateNPinnedSlots(numIRCs * NumOopsPerNSC);
		return theIRCs != 0;
	}
	return 1;

#  else /* NewspeakVM */
	return 1;

#  endif /* NewspeakVM */

}


/*	Check that the header fields are consistent with the type.
	Answer 0 if it is ok, otherwise answer a code for the error. */

	/* Cogit>>#maybeFreeCogMethodDoesntLookKosher: */
static sqInt
maybeFreeCogMethodDoesntLookKosher(CogMethod *cogMethod)
{
    sqInt result;

	result = cogMethodDoesntLookKosher(cogMethod);
	return (result == 2
		? 0
		: result);
}

	/* Cogit>>#maybeGenerateCheckFeatures */
static sqInt
maybeGenerateCheckFeatures(void)
{
    sqInt fixupSize;
    sqInt numberOfAbstractOpcodes;
    sqInt opcodeSize;
    sqInt startAddress;

	return null;

	/* begin allocateOpcodes:bytecodes: */
	numberOfAbstractOpcodes = numCheckFeaturesOpcodes(backEnd);
	numAbstractOpcodes = numberOfAbstractOpcodes;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	startAddress = methodZoneBase;
	generateCheckFeatures(backEnd);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceCheckFeaturesFunction", startAddress);
	ceCheckFeaturesFunction = ((unsigned long (*)(void)) startAddress);
}

	/* Cogit>>#maybeGenerateICacheFlush */
static sqInt
maybeGenerateICacheFlush(void)
{
    static void (*ceFlushICache)(unsigned long from, unsigned long to);
    sqInt fixupSize;
    sqInt numberOfAbstractOpcodes;
    sqInt opcodeSize;
    sqInt startAddress;

	return null;

	/* begin allocateOpcodes:bytecodes: */
	numberOfAbstractOpcodes = numICacheFlushOpcodes(backEnd);
	numAbstractOpcodes = numberOfAbstractOpcodes;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	startAddress = methodZoneBase;
	generateICacheFlush(backEnd);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceFlushICache", startAddress);
	ceFlushICache = ((void (*)(unsigned long,unsigned long)) startAddress);
}


/*	In SIsta Spur counters are held on the heap in pinned objects which must
	be marked
	to avoid them being garbage collected. This is the hook through which that
	happens. 
 */

	/* Cogit>>#maybeMarkCountersIn: */
static void
maybeMarkCountersIn(CogMethod *cogMethod)
{
}

	/* Cogit>>#mclassIsSmallInteger: */
static sqInt
mclassIsSmallInteger(sqInt ignoredPrimIndex)
{
	return (methodClassOf(methodObj)) == (classSmallInteger());
}


/*	Answer the absolute machine code pc matching the zero-relative
	bytecode pc of a backward branch in cogMethod, given the start
	of the bytecodes for cogMethod's block or method object. */

	/* Cogit>>#mcPCForBackwardBranch:startBcpc:in: */
usqInt
mcPCForBackwardBranchstartBcpcin(sqInt bcpc, sqInt startbcpc, CogBlockMethod *cogMethod)
{
    sqInt aMethodObj;
    sqInt annotation;
    sqInt bcpc1;
    sqInt bsOffset;
    sqInt byte;
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt endbcpc;
    CogMethod *homeMethod;
    sqInt isBackwardBranch;
    sqInt isInBlock;
    sqInt latestContinuation;
    sqInt map;
    sqInt mapByte;
    usqInt mcpc;
    sqInt methodHeader;
    sqInt methodHeader1;
    sqInt nExts;
    sqInt nextBcpc;
    sqInt result;
    sqInt targetPC;

	latestContinuation = 0;
	/* begin mapFor:bcpc:performUntil:arg: */
	assert(((cogMethod->stackCheckOffset)) > 0);
	if (((cogMethod->cmType)) == CMMethod) {
		isInBlock = 0;
		homeMethod = ((CogMethod *) cogMethod);
		assert(startbcpc == (startPCOfMethodHeader((homeMethod->methodHeader))));
		map = ((((usqInt)homeMethod)) + ((homeMethod->blockSize))) - 1;
		assert(((((usqInt) (byteAt(map))) >> AnnotationShift) == IsAbsPCReference)
		 || (((((usqInt) (byteAt(map))) >> AnnotationShift) == IsObjectReference)
		 || (((((usqInt) (byteAt(map))) >> AnnotationShift) == IsRelativeCall)
		 || ((((usqInt) (byteAt(map))) >> AnnotationShift) == IsDisplacementX2N))));
		latestContinuation = startbcpc;
		aMethodObj = (homeMethod->methodObject);
		endbcpc = (numBytesOf(aMethodObj)) - 1;
		/* begin bytecodeSetOffsetForHeader: */
		methodHeader = (homeMethod->methodHeader);
		bsOffset = 0;
	}
	else {
		isInBlock = 1;
		homeMethod = cmHomeMethod(cogMethod);
		map = findMapLocationForMcpcinMethod((((usqInt)cogMethod)) + (sizeof(CogBlockMethod)), homeMethod);
		assert(map != 0);
		assert(((((usqInt) (byteAt(map))) >> AnnotationShift) == HasBytecodePC)
		 || ((((usqInt) (byteAt(map))) >> AnnotationShift) == IsDisplacementX2N));
		while ((((usqInt) (byteAt(map))) >> AnnotationShift) != HasBytecodePC) {
			map -= 1;
		}

		/* skip fiducial; i.e. the map entry for the pc immediately following the method header. */

		map -= 1;
		aMethodObj = (homeMethod->methodObject);
		bcpc1 = startbcpc - (blockCreationBytecodeSizeForHeader((homeMethod->methodHeader)));
		/* begin bytecodeSetOffsetForHeader: */
		methodHeader1 = (homeMethod->methodHeader);
		bsOffset = 0;
		byte = (fetchByteofObject(bcpc1, aMethodObj)) + bsOffset;
		descriptor = generatorAt(byte);
		endbcpc = (bcpc1 + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bcpc1, -1, aMethodObj)
	: 0));
	}
	bcpc1 = startbcpc;
	mcpc = (((usqInt)cogMethod)) + ((cogMethod->stackCheckOffset));

	/* The stack check maps to the start of the first bytecode,
	   the first bytecode being effectively after frame build. */

	nExts = 0;
	result = 0;
	if (result != 0) {
		return result;
	}
	while ((((usqInt) (byteAt(map))) >> AnnotationShift) != HasBytecodePC) {
		map -= 1;
	}
	map -= 1;
	while (((mapByte = byteAt(map))) != MapEnd) {

		/* defensive; we exit on bcpc */

		if (mapByte >= FirstAnnotation) {
			annotation = ((usqInt) mapByte) >> AnnotationShift;
			mcpc += (mapByte & DisplacementMask) * 4;
			if ((annotation >= IsSendCall)
			 || ((annotation == HasBytecodePC)
			 || (0))) {
				while (1) {
					byte = (fetchByteofObject(bcpc1, aMethodObj)) + bsOffset;
					descriptor = generatorAt(byte);
					if (isInBlock) {
						if (bcpc1 >= endbcpc) {
							return 0;
						}
					}
					else {
						if (((descriptor->isReturn))
						 && (bcpc1 >= latestContinuation)) {
							return 0;
						}
						if ((isBranch(descriptor))
						 || ((descriptor->isBlockCreation))) {
							/* begin latestContinuationPCFor:at:exts:in: */
							distance = ((descriptor->spanFunction))(descriptor, bcpc1, nExts, aMethodObj);
							targetPC = (bcpc1 + ((descriptor->numBytes))) + (((distance < 0) ? 0 : distance));
							latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
						}
					}
					nextBcpc = (bcpc1 + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bcpc1, nExts, aMethodObj)
	: 0));
					if (((descriptor->isMapped))
					 || (isInBlock
					 && ((descriptor->isMappedInBlock)))) break;
					bcpc1 = nextBcpc;
					nExts = ((descriptor->isExtension)
						? nExts + 1
						: 0);
				}
				isBackwardBranch = (isBranch(descriptor))
				 && (isBackwardBranchatextsin(descriptor, bcpc1, nExts, aMethodObj));
				result = (isBackwardBranch
				 && ((((sqInt)(((void *)bcpc)))) == bcpc1)
					? ((sqInt)(((char *) mcpc)))
					: 0);
				if (result != 0) {
					return result;
				}
				bcpc1 = nextBcpc;
				nExts = ((descriptor->isExtension)
					? nExts + 1
					: 0);
			}
		}
		else {
			assert(((((usqInt) mapByte) >> AnnotationShift) == IsDisplacementX2N)
			 || ((((usqInt) mapByte) >> AnnotationShift) == IsAnnotationExtension));
			if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
				mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
			}
		}
		map -= 1;
	}
	return 0;
}


/*	For the purposes of become: see if the two methods are similar, i.e. can
	be safely becommed.
	This is pretty strict. All literals and bytecodes must be identical. Only
	trailer bytes and header
	flags can differ. */

	/* Cogit>>#method:hasSameCodeAs:checkPenultimate: */
static sqInt
methodhasSameCodeAscheckPenultimate(sqInt methodA, sqInt methodB, sqInt comparePenultimateLiteral)
{
    sqInt bi;
    sqInt endPCA;
    sqInt headerA;
    sqInt headerB;
    sqInt li;
    sqInt numLitsA;

	headerA = methodHeaderOf(methodA);
	headerB = methodHeaderOf(methodB);
	numLitsA = literalCountOfMethodHeader(headerA);
	endPCA = endPCOf(methodA);
	if (((argumentCountOfMethodHeader(headerA)) != (argumentCountOfMethodHeader(headerB)))
	 || (((temporaryCountOfMethodHeader(headerA)) != (temporaryCountOfMethodHeader(headerB)))
	 || (((primitiveIndexOfMethodheader(methodA, headerA)) != (primitiveIndexOfMethodheader(methodB, headerB)))
	 || ((numLitsA != (literalCountOfMethodHeader(headerB)))
	 || (endPCA > (numBytesOf(methodB))))))) {
		return 0;
	}
	for (li = 1; li < numLitsA; li += 1) {
		if ((fetchPointerofObject(li, methodA)) != (fetchPointerofObject(li, methodB))) {
			if ((li < (numLitsA - 1))
			 || (comparePenultimateLiteral)) {
				return 0;
			}
		}
	}
	for (bi = (startPCOfMethod(methodA)); bi <= endPCA; bi += 1) {
		if ((fetchByteofObject(bi, methodA)) != (fetchByteofObject(bi, methodB))) {
			return 0;
		}
	}
	return 1;
}

	/* Cogit>>#minCogMethodAddress */
sqInt
minCogMethodAddress(void)
{
	return methodZoneBase;
}

	/* Cogit>>#mnuOffset */
sqInt
mnuOffset(void)
{
	return missOffset;
}

	/* Cogit>>#NegateR: */
static AbstractInstruction *
gNegateR(sqInt reg)
{
	return genoperand(NegateR, reg);
}

	/* Cogit>>#needsFrameIfInBlock: */
static sqInt
needsFrameIfInBlock(sqInt stackDelta)
{
	return inBlock;
}

	/* Cogit>>#needsFrameNever: */
static sqInt
needsFrameNever(sqInt stackDelta)
{
	return 0;
}

	/* Cogit>>#noAssertMethodClassAssociationOf: */
static sqInt
noAssertMethodClassAssociationOf(sqInt methodPointer)
{
	return literalofMethod((literalCountOfMethodHeader(noAssertHeaderOf(methodPointer))) - 1, methodPointer);
}


/*	Check that no method is maximally marked. A maximal mark is an indication
	the method has been scanned to increase the usage count of its referent
	methods.  */

	/* Cogit>>#noCogMethodsMaximallyMarked */
static sqInt
noCogMethodsMaximallyMarked(void)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) != CMFree)
		 && (((cogMethod->cmUsageCount)) == CMMaxUsageCount)) {
			return 0;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return 1;
}


/*	Answerr if all targets in the PIC are in-use methods. */

	/* Cogit>>#noTargetsFreeInClosedPIC: */
static sqInt
noTargetsFreeInClosedPIC(CogMethod *cPIC)
{
    sqInt entryPoint;
    sqInt i;
    sqInt pc;
    CogMethod *targetMethod;

	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	for (i = 1; i <= ((cPIC->cPICNumCases)); i += 1) {

		/* Find target from jump.  Ignore jumps to the interpret and MNU calls within this PIC */

		entryPoint = jumpLongTargetBeforeFollowingAddress(backEnd(), pc - ((i <= 1
	? BytesPerOop
	: BytesPerOop + 4)));
		if (!(((((usqInt)cPIC)) <= (((usqInt)entryPoint)))
			 && (((((usqInt)cPIC)) + ((cPIC->blockSize))) >= (((usqInt)entryPoint))))) {
			targetMethod = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
			if (((targetMethod->cmType)) != CMMethod) {
				return 0;
			}
		}
		if (i < ((cPIC->cPICNumCases))) {
			pc += cPICCaseSize;
		}
	}
	return 1;
}


/*	Store the generated machine code, answering the last address */

	/* Cogit>>#outputInstructionsAt: */
static sqInt
outputInstructionsAt(sqInt startAddress)
{
    sqInt absoluteAddress;
    AbstractInstruction *abstractInstruction;
    sqInt i;
    sqInt j;

	absoluteAddress = startAddress;
	for (i = 0; i < opcodeIndex; i += 1) {
		abstractInstruction = abstractInstructionAt(i);
		assert(((abstractInstruction->address)) == absoluteAddress);
		/* begin outputMachineCodeAt: */
		for (j = 0; j < ((abstractInstruction->machineCodeSize)); j += 4) {
			longAtput(absoluteAddress + j, ((abstractInstruction->machineCode))[j / 4]);
		}
		abstractInstruction;
		absoluteAddress += (abstractInstruction->machineCodeSize);
	}
	return absoluteAddress;
}


/*	Output instructions generated for one of the generated run-time routines,
	a trampoline, etc
 */

	/* Cogit>>#outputInstructionsForGeneratedRuntimeAt: */
static sqInt
outputInstructionsForGeneratedRuntimeAt(sqInt startAddress)
{
    sqInt endAddress;
    sqInt size;

	computeMaximumSizes();
	(methodLabel->address = startAddress);
	size = generateInstructionsAt(startAddress);
	endAddress = outputInstructionsAt(startAddress);
	assert((startAddress + size) == endAddress);
	methodZoneBase = alignUptoRoutineBoundary(endAddress);
	nopsFromto(backEnd, endAddress, methodZoneBase - 1);
	
	return startAddress;
}

	/* Cogit>>#PopR: */
static AbstractInstruction *
gPopR(sqInt reg)
{
	return genoperand(PopR, reg);
}

	/* Cogit>>#PushCw: */
static AbstractInstruction *
gPushCw(sqInt wordConstant)
{
	/* begin gen:literal: */
	return checkLiteralforInstruction(wordConstant, genoperand(PushCw, wordConstant));
}


/*	Code entry closed PIC full or miss to an instance of a young class or to a
	young target method.
	Attempt to patch the send site to an open PIC. Answer if the attempt
	succeeded; in fact it will
	only return if the attempt failed.
	The stack looks like:
	receiver
	args
	sp=>	sender return address */

	/* Cogit>>#patchToOpenPICFor:numArgs:receiver: */
sqInt
patchToOpenPICFornumArgsreceiver(sqInt selector, sqInt numArgs, sqInt receiver)
{
    sqInt extent;
    CogMethod *oPIC;
    sqInt outerReturn;


	/* See if an Open PIC is already available. */

	outerReturn = stackTop();
	oPIC = openPICWithSelector(selector);
	if (oPIC == null) {

		/* otherwise attempt to create an Open PIC. */

		oPIC = cogOpenPICSelectornumArgs(selector, numArgs);
		if ((((((sqInt)oPIC)) >= MaxNegativeErrorCode) && ((((sqInt)oPIC)) <= -1))) {

			/* For some reason the PIC couldn't be generated, most likely a lack of code memory. */

			if ((((sqInt)oPIC)) == InsufficientCodeSpace) {
				callForCogCompiledCodeCompaction();
			}
			return 0;
		}
	}
	extent = rewriteInlineCacheAttagtarget(backEnd, outerReturn, selector, (((sqInt)oPIC)) + cmEntryOffset);
	flushICacheFromto(processor, (((usqInt)outerReturn)) - extent, ((usqInt)outerReturn));
	flushICacheFromto(processor, ((usqInt)oPIC), (((usqInt)oPIC)) + openPICSize);
	executeCogMethodfromLinkedSendWithReceiver(oPIC, receiver);
	return 1;
}


/*	This value is used to decide between MNU processing
	or interpretation in the closed PIC aborts. */

	/* Cogit>>#picAbortDiscriminatorValue */
static sqInt
picAbortDiscriminatorValue(void)
{
	return 0;
}


/*	Answer the start of the abort sequence for invoking the interpreter in a
	closed PIC.
 */

	/* Cogit>>#picInterpretAbortOffset */
static sqInt
picInterpretAbortOffset(void)
{
	return (interpretOffset()) - ((pushLinkRegisterByteSize(backEnd)) + (callInstructionByteSize(backEnd)));
}


/*	If there is a generator for the current primitive then answer it;
	otherwise answer nil. */

	/* Cogit>>#primitiveGeneratorOrNil */
static PrimitiveDescriptor *
primitiveGeneratorOrNil(void)
{
    PrimitiveDescriptor *primitiveDescriptor;
    static PrimitiveDescriptor primitiveGeneratorTable[MaxCompiledPrimitiveIndex+1] = {
	{ 0, -1, 0 },
	{ genPrimitiveAdd, 1, mclassIsSmallInteger },
	{ genPrimitiveSubtract, 1, mclassIsSmallInteger },
	{ genPrimitiveLessThan, 1, mclassIsSmallInteger },
	{ genPrimitiveGreaterThan, 1, mclassIsSmallInteger },
	{ genPrimitiveLessOrEqual, 1, mclassIsSmallInteger },
	{ genPrimitiveGreaterOrEqual, 1, mclassIsSmallInteger },
	{ genPrimitiveEqual, 1, mclassIsSmallInteger },
	{ genPrimitiveNotEqual, 1, mclassIsSmallInteger },
	{ genPrimitiveMultiply, 1, processorHasMultiplyAndMClassIsSmallInteger },
	{ genPrimitiveDivide, 1, processorHasDivQuoRemAndMClassIsSmallInteger },
	{ genPrimitiveMod, 1, processorHasDivQuoRemAndMClassIsSmallInteger },
	{ genPrimitiveDiv, 1, processorHasDivQuoRemAndMClassIsSmallInteger },
	{ genPrimitiveQuo, 1, processorHasDivQuoRemAndMClassIsSmallInteger },
	{ genPrimitiveBitAnd, 1, mclassIsSmallInteger },
	{ genPrimitiveBitOr, 1, mclassIsSmallInteger },
	{ genPrimitiveBitXor, 1, mclassIsSmallInteger },
	{ genPrimitiveBitShift, 1, mclassIsSmallInteger },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveAsFloat, 0, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatAdd, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatSubtract, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatLessThan, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatGreaterThan, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatLessOrEqual, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatGreaterOrEqual, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatEqual, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatNotEqual, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatMultiply, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ genPrimitiveFloatDivide, 1, processorHasDoublePrecisionFloatingPointSupport },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveFloatSquareRoot, 0, processorHasDoublePrecisionFloatingPointSupport },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveAt, 1, 0 },
	{ genPrimitiveAtPut, 2, 0 },
	{ genPrimitiveSize, 0, 0 },
	{ genPrimitiveStringAt, 1, 0 },
	{ genPrimitiveStringAtPut, 2, 0 },
	{ genFastPrimFail, -1, 0 },
	{ genFastPrimFail, -1, 0 },
	{ genFastPrimFail, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveNew, 0, 0 },
	{ genPrimitiveNewWithArg, 1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveIdentityHash, 0, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveNewMethod, 2, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveIdentical, 1, 0 },
	{ genPrimitiveClass, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveNotIdentical, 1, 0 },
	{ genPrimitiveAsCharacter, -1, 0 },
	{ genPrimitiveCharacterValue, 0, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveIdentityHash, 0, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genFastPrimFail, -1, 0 },
	{ genFastPrimFail, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveClosureValue, 0, 0 },
	{ genPrimitiveClosureValue, 1, 0 },
	{ genPrimitiveClosureValue, 2, 0 },
	{ genPrimitiveClosureValue, 3, 0 },
	{ genPrimitiveClosureValue, 4, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ 0, -1, 0 },
	{ genPrimitiveClosureValue, 0, 0 },
	{ genPrimitiveClosureValue, 1, 0 }
};

	if (isQuickPrimitiveIndex(primitiveIndex)) {

		/* an unused one */

		primitiveDescriptor = (&(primitiveGeneratorTable[0]));
		(primitiveDescriptor->primitiveGenerator = quickPrimitiveGeneratorFor(primitiveIndex));
		return primitiveDescriptor;
	}
	if (((primitiveIndex >= 1) && (primitiveIndex <= MaxCompiledPrimitiveIndex))) {
		return (&(primitiveGeneratorTable[primitiveIndex]));
	}
	return null;
}

	/* Cogit>>#printCogMethodFor: */
void
printCogMethodFor(void *address)
{
    CogMethod *cogMethod;

	cogMethod = methodFor(address);
	if (cogMethod == 0) {
		print("not a method");
		cr();
	}
	else {
		printCogMethod(cogMethod);
	}
}

	/* Cogit>>#printTrampolineTable */
void
printTrampolineTable(void)
{
    sqInt i;

	for (i = 0; i < trampolineTableIndex; i += 2) {
		printHex(((sqInt)(trampolineAddresses[i + 1])));
		print(": ");
		print(((char *) (trampolineAddresses[i])));
		cr();
	}
}

	/* Cogit>>#processorHasDivQuoRemAndMClassIsSmallInteger: */
static sqInt
processorHasDivQuoRemAndMClassIsSmallInteger(sqInt ignoredPrimIndex)
{
	return 0;
}

	/* Cogit>>#processorHasDivQuoRem: */
static sqInt
processorHasDivQuoRem(sqInt ignoredPrimIndex)
{
	return 0;
}

	/* Cogit>>#processorHasDoublePrecisionFloatingPointSupport: */
static sqInt
processorHasDoublePrecisionFloatingPointSupport(sqInt ignoredPrimIndex)
{
	return 1;
}

	/* Cogit>>#processorHasMultiplyAndMClassIsSmallInteger: */
static sqInt
processorHasMultiplyAndMClassIsSmallInteger(sqInt ignoredPrimIndex)
{
	return mclassIsSmallInteger(ignoredPrimIndex);
}

	/* Cogit>>#processorHasMultiply: */
static sqInt
processorHasMultiply(sqInt ignoredPrimIndex)
{
	return 1;
}

	/* Cogit>>#RetN: */
static AbstractInstruction *
gRetN(sqInt offset)
{
	return genoperand(RetN, offset);
}

	/* Cogit>>#recordGeneratedRunTime:address: */
static void
recordGeneratedRunTimeaddress(char *aString, sqInt address)
{
	trampolineAddresses[trampolineTableIndex] = aString;
	trampolineAddresses[trampolineTableIndex + 1] = (((char *) address));
	trampolineTableIndex += 2;
}


/*	This one for C support code. */

	/* Cogit>>#recordPrimTraceFunc */
sqInt
recordPrimTraceFunc(void)
{
	return recordPrimTrace();
}

	/* Cogit>>#recordRunTimeObjectReferences */
static void
recordRunTimeObjectReferences(void)
{
    sqInt i;
    AbstractInstruction *instruction;

	for (i = 0; i < opcodeIndex; i += 1) {
		instruction = abstractInstructionAt(i);
		if (((instruction->annotation)) == IsObjectReference) {
			assert(runtimeObjectRefIndex < NumObjRefsInRuntime);
			assert(!hasYoungReferent);
			if (hasYoungReferent) {
				error("attempt to generate run-time routine containing young object reference.  Cannot initialize Cogit run-time.");
			}
			objectReferencesInRuntime[runtimeObjectRefIndex] = (((usqInt)((((instruction->opcode)) == Literal
	? (instruction->address)
	: ((instruction->address)) + ((instruction->machineCodeSize))))));
			runtimeObjectRefIndex += 1;
		}
	}
}


/*	Answer a bit mask identifying the symbolic register.
	Registers are negative numbers. */

	/* Cogit>>#registerMaskFor: */
static sqInt
registerMaskFor(sqInt reg)
{
	return 1 << (1 - reg);
}


/*	Answer a bit mask identifying the symbolic registers.
	Registers are negative numbers. */

	/* Cogit>>#registerMaskFor:and: */
static sqInt
registerMaskForand(sqInt reg1, sqInt reg2)
{
	return (1 << (1 - reg1)) | (1 << (1 - reg2));
}

	/* Cogit>>#relocateCallsAndSelfReferencesInMethod: */
static void
relocateCallsAndSelfReferencesInMethod(CogMethod *cogMethod)
{
    sqInt annotation;
    sqLong delta;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	delta = (cogMethod->objectHeader);
	assert((((cogMethod->cmType)) == CMMethod)
	 || (((cogMethod->cmType)) == CMOpenPIC));
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)cogMethod)) + missOffset)) == ((((cogMethod->cmType)) == CMMethod
	? methodAbortTrampolineFor((cogMethod->cmNumArgs))
	: picAbortTrampolineFor((cogMethod->cmNumArgs)))));
	relocateCallBeforeReturnPCby(backEnd, (((sqInt)cogMethod)) + missOffset, -delta);
	/* begin mapFor:performUntil:arg: */
	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while (((mapByte = byteAt(map))) != MapEnd) {
		if (mapByte >= FirstAnnotation) {

			/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

			mcpc += (mapByte & DisplacementMask) * 4;
			if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
			 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
				annotation += mapByte & DisplacementMask;
				map -= 1;
			}
			result = relocateIfCallOrMethodReferencemcpcdelta(annotation, (((char *) mcpc)), (((sqInt) delta)));
			if (result != 0) {
				result;
				goto l1;
			}
		}
		else {
			if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
				mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
			}
		}
		map -= 1;
	}
	0;
l1:	/* end mapFor:performUntil:arg: */;
}

	/* Cogit>>#relocateCallsInClosedPIC: */
static void
relocateCallsInClosedPIC(CogMethod *cPIC)
{
    sqLong delta;
    sqInt delta1;
    sqInt entryPoint;
    sqInt i;
    sqInt pc;
    CogMethod *targetMethod;

	delta = (cPIC->objectHeader);
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)cPIC)) + missOffset)) == (picAbortTrampolineFor((cPIC->cmNumArgs))));
	relocateCallBeforeReturnPCby(backEnd, (((sqInt)cPIC)) + missOffset, -delta);
	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	for (i = 1; i <= ((cPIC->cPICNumCases)); i += 1) {

		/* Find target from jump.  Ignore jumps to the interpret and MNU calls within this PIC */

		entryPoint = jumpLongTargetBeforeFollowingAddress(backEnd(), pc - ((i <= 1
	? BytesPerOop
	: BytesPerOop + 4)));
		if (!(((((usqInt)cPIC)) <= (((usqInt)entryPoint)))
			 && (((((usqInt)cPIC)) + ((cPIC->blockSize))) >= (((usqInt)entryPoint))))) {
			targetMethod = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
			assert(((targetMethod->cmType)) == CMMethod);
			/* begin cPICCase:relocateJumpLongBefore:by: */
			delta1 = -(delta - ((targetMethod->objectHeader)));
			relocateJumpLongBeforeFollowingAddressby(backEnd(), pc - ((i <= 1
	? BytesPerOop
	: BytesPerOop + 4)), delta1);
		}
		pc += cPICCaseSize;
	}
	assert(((cPIC->cPICNumCases)) > 0);

	/* Finally relocate the load of the PIC and the jump to the overflow routine ceCPICMiss:receiver: */

	pc -= cPICCaseSize;
	relocateMethodReferenceBeforeAddressby(backEnd, pc + (loadPICLiteralByteSize(backEnd)), delta);
	relocateJumpLongBeforeFollowingAddressby(backEnd, pc + cPICEndSize, -delta);
}

	/* Cogit>>#relocateIfCallOrMethodReference:mcpc:delta: */
static sqInt
relocateIfCallOrMethodReferencemcpcdelta(sqInt annotation, char *mcpc, sqInt delta)
{
    sqInt entryPoint;
    sqInt offset;
    sqInt offset1;
    sqInt sendTable;
    sqInt *sendTable1;
    CogMethod *targetMethod;
    sqInt unlinkedRoutine;

	
	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint <= methodZoneBase) {

			/* send is not linked; just relocate */

			relocateCallBeforeReturnPCby(backEnd, ((sqInt)mcpc), -delta);
			return 0;
		}
		/* begin offsetAndSendTableFor:annotation:into: */
		if (annotation == IsSendCall) {
			offset1 = cmEntryOffset;
			sendTable1 = ordinarySendTrampolines;
		}
		else {
			assert(annotation == IsSuperSend);
			offset1 = cmNoCheckEntryOffset;
			sendTable1 = superSendTrampolines;



		}
		targetMethod = ((CogMethod *) (entryPoint - offset1));
		if (((targetMethod->cmType)) != CMFree) {

			/* send target not freed; just relocate. */

			relocateCallBeforeReturnPCby(backEnd, ((sqInt)mcpc), -(delta - ((targetMethod->objectHeader))));
			
			return 0;
		}
		unlinkedRoutine = sendTable1[((((targetMethod->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod->cmNumArgs)) : (NumSendTrampolines - 1))];
		unlinkedRoutine -= delta;
		rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), (targetMethod->selector), unlinkedRoutine);
		return 0;

	}
	if (annotation == IsRelativeCall) {
		relocateCallBeforeReturnPCby(backEnd, ((sqInt)mcpc), -delta);
		return 0;
	}
	if (annotation == IsAbsPCReference) {
		relocateMethodReferenceBeforeAddressby(backEnd, ((sqInt)mcpc), delta);
	}
	return 0;
}

	/* Cogit>>#remapIfObjectRef:pc:hasYoung: */
static sqInt
remapIfObjectRefpchasYoung(sqInt annotation, char *mcpc, sqInt hasYoungPtr)
{
    sqInt cacheTag;
    sqInt cacheTag1;
    sqInt callSiteReturnAddress;
    sqInt entryPoint;
    sqInt entryPoint1;
    sqInt ignored;
    sqInt literal;
    sqInt mappedCacheTag;
    sqInt mappedLiteral;
    sqInt *sendTable;
    sqInt tagCouldBeObj;
    sqInt tagCouldBeObj1;
    CogMethod *targetMethod;
    CogMethod *targetMethod1;

	if (annotation == IsObjectReference) {
		literal = longAt(((usqInt)mcpc));
		if (couldBeObject(literal)) {
			mappedLiteral = remapObject(literal);
			if (literal != mappedLiteral) {
				/* begin storeLiteral:atAnnotatedAddress:using: */
				longAtput(((usqInt)mcpc), mappedLiteral);
				codeModified = 1;
			}
			if ((hasYoungPtr != 0)
			 && (isYoung(mappedLiteral))) {
				(((sqInt *) hasYoungPtr))[0] = 1;
			}
		}
	}
	
	if (annotation >= IsSendCall) {
		/* begin offsetCacheTagAndCouldBeObjectAt:annotation:into: */
		cacheTag1 = inlineCacheTagAt(backEnd, ((sqInt)mcpc));

		/* in-line cache tags are the selectors of sends if sends are unlinked,
		   the selectors of super sends (entry offset = cmNoCheckEntryOffset),
		   the selectors of open PIC sends (entry offset = cmEntryOffset, target is an Open PIC)
		   or in-line cache tags (classes, class indices, immediate bit patterns, etc).
		   Note that selectors can be immediate so there is no guarantee that they
		   are markable/remappable objects. */

		entryPoint1 = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		tagCouldBeObj1 = (entryPoint1 < methodZoneBase)
		 || (((entryPoint1 & entryPointMask) == uncheckedEntryAlignment)
		 || (((entryPoint1 & entryPointMask) == checkedEntryAlignment)
		 && ((((((CogMethod *) (entryPoint1 - cmEntryOffset)))->cmType)) == CMOpenPIC)));
		if (tagCouldBeObj1
		 && (couldBeObject(cacheTag1))) {
			mappedCacheTag = remapObject(cacheTag1);
			if (cacheTag1 != mappedCacheTag) {
				/* begin rewriteInlineCacheTag:at: */
				callSiteReturnAddress = ((usqInt)mcpc);
				longAtput(pcRelativeAddressAt(((AbstractInstruction *) backEnd), callSiteReturnAddress - 8), mappedCacheTag);
				((AbstractInstruction *) backEnd);
				codeModified = 1;
			}
			if ((hasYoungPtr != 0)
			 && (isYoung(mappedCacheTag))) {
				(((sqInt *) hasYoungPtr))[0] = 1;
			}
		}
		if (hasYoungPtr != 0) {

			/* Since the unlinking routines may rewrite the cacheTag to the send's selector, and
			   since they don't have the cogMethod to hand and can't add it to youngReferrers,
			   the method must remain in youngReferrers if the targetMethod's selector is young. */

			if (entryPoint1 > methodZoneBase) {

				/* It's a linked send. */

				/* begin targetMethodAndSendTableFor:annotation:into: */
				if (annotation == IsSendCall) {
					targetMethod1 = ((CogMethod *) (entryPoint1 - cmEntryOffset));
					sendTable = ordinarySendTrampolines;
				}
				else {
					assert(annotation == IsSuperSend);
					targetMethod1 = ((CogMethod *) (entryPoint1 - cmNoCheckEntryOffset));
					sendTable = superSendTrampolines;



				}
				if (isYoung((targetMethod1->selector))) {
					(((sqInt *) hasYoungPtr))[0] = 1;
				}

			}
		}

	}
	return 0;
}

	/* Cogit>>#SubCw:R: */
static AbstractInstruction *
gSubCwR(sqInt wordConstant, sqInt reg)
{
	/* begin gen:literal:operand: */
	return checkLiteralforInstruction(wordConstant, genoperandoperand(SubCwR, wordConstant, reg));
}


/*	Answer the number of clean blocks found in the literal frame */

	/* Cogit>>#scanForCleanBlocks */
static sqInt
scanForCleanBlocks(void)
{
    sqInt i;
    sqInt iLimiT;
    sqInt lit;
    sqInt numCleanBlocks;
    sqInt startPCOrNil;

	numCleanBlocks = 0;
	for (i = 1, iLimiT = (literalCountOf(methodObj)); i <= iLimiT; i += 1) {
		lit = fetchPointerofObject(i, methodObj);
		startPCOrNil = startPCOrNilOfLiteralin(lit, methodObj);
		if (!(startPCOrNil == null)) {
			numCleanBlocks += 1;
		}
	}
	return numCleanBlocks;
}

	/* Cogit>>#setBreakMethod: */
void
setBreakMethod(sqInt anObj)
{
	breakMethod = anObj;
}

	/* Cogit>>#setPostCompileHook: */
void
setPostCompileHook(void (*aFunction)(CogMethod *))
{
	postCompileHook = aFunction;
}


/*	If a method is compiled to machine code via a block entry it won't have a
	selector. A subsequent send can find the method and hence fill in the
	selector. 
 */
/*	self disassembleMethod: cogMethod */

	/* Cogit>>#setSelectorOf:to: */
void
setSelectorOfto(CogMethod *cogMethod, sqInt aSelectorOop)
{
	compilationBreakpointisMNUCase(aSelectorOop, numBytesOf(aSelectorOop), 0);
	assert(((cogMethod->cmType)) == CMMethod);
	(cogMethod->selector = aSelectorOop);
	if (isYoung(aSelectorOop)) {
		ensureInYoungReferrers(cogMethod);
	}
}

	/* Cogit>>#spanForCleanBlockStartingAt: */
static sqInt
spanForCleanBlockStartingAt(sqInt startPC)
{
    BytecodeDescriptor *descriptor;
    sqInt end;
    sqInt pc;

	pc = startPC;
	end = numBytesOf(methodObj);
	while (pc <= end) {
		descriptor = generatorAt((fetchByteofObject(pc, methodObj)) + bytecodeSetOffset);
		pc += (descriptor->numBytes);
		if ((descriptor->isReturn)) {
			return pc - startPC;
		}
	}
	error("couldn't locate end of clean block");
	return 0;
}

	/* Cogit>>#traceLinkedSendOffset */
sqInt
traceLinkedSendOffset(void)
{
	return (cmNoCheckEntryOffset + (callInstructionByteSize(backEnd))) + (pushLinkRegisterByteSize(backEnd));
}

	/* Cogit>>#trampolineName:numArgs: */
static char *
trampolineNamenumArgs(char *routinePrefix, sqInt numArgs)
{
    char *theString;

	/* begin trampolineName:numArgs:limit: */
	;
	theString = malloc((strlen(routinePrefix)) + 6);
	sprintf(theString, "%s%cArgs", routinePrefix, (numArgs <= (NumSendTrampolines - 2)
		? '0' + numArgs
		: 'N'));
	return theString;
}

	/* Cogit>>#trampolineName:numRegArgs: */
static char *
trampolineNamenumRegArgs(char *routinePrefix, sqInt numArgs)
{
    char *theString;

	/* begin trampolineName:numArgs:limit: */
	;
	theString = malloc((strlen(routinePrefix)) + 6);
	sprintf(theString, "%s%cArgs", routinePrefix, (numArgs <= 2
		? '0' + numArgs
		: 'N'));
	return theString;
}

	/* Cogit>>#unimplementedPrimitive */
static sqInt
unimplementedPrimitive(void)
{
	return UnimplementedPrimitive;
}

	/* Cogit>>#unknownBytecode */
static sqInt
unknownBytecode(void)
{
	return EncounteredUnknownBytecode;
}


/*	Unlink all sends in cog methods. */

	/* Cogit>>#unlinkAllSends */
void
unlinkAllSends(void)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	if (methodZoneBase == null) {
		return;
	}
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = unlinkIfLinkedSendpcignored(annotation, (((char *) mcpc)), 0);
					if (result != 0) {
						result;
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
			0;
		l1:	/* end mapFor:performUntil:arg: */;
		}
		else {
			if (((cogMethod->cmType)) != CMFree) {
				freeMethod(cogMethod);
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
}

	/* Cogit>>#unlinkIfFreeOrLinkedSend:pc:of: */
static sqInt
unlinkIfFreeOrLinkedSendpcof(sqInt annotation, char *mcpc, sqInt theSelector)
{
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    CogMethod * targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	
	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */

			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if ((((targetMethod1->cmType)) == CMFree)
			 || (((targetMethod1->selector)) == theSelector)) {
				/* begin unlinkSendAt:targetMethod:sendTable: */
				unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
				rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), (targetMethod1->selector), unlinkedRoutine);
				codeModified = 1;
			}

		}
	}
	return 0;
}

	/* Cogit>>#unlinkIfInvalidClassSend:pc:ignored: */
static sqInt
unlinkIfInvalidClassSendpcignored(sqInt annotation, char *mcpc, sqInt superfluity)
{
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	
	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send, but maybe a super send or linked to an OpenPIC, in which case the cache tag will be a selector.... */

			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if (!(((annotation == IsSuperSend)
				 || (0))
				 || (((targetMethod1->cmType)) == CMOpenPIC))) {
				if (!(isValidClassTag(inlineCacheTagAt(backEnd, ((sqInt)mcpc))))) {
					/* begin unlinkSendAt:targetMethod:sendTable: */
					unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
					rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), (targetMethod1->selector), unlinkedRoutine);
					codeModified = 1;
				}
			}

		}
	}
	return 0;
}

	/* Cogit>>#unlinkIfLinkedSendToFree:pc:ignored: */
static sqInt
unlinkIfLinkedSendToFreepcignored(sqInt annotation, char *mcpc, sqInt superfluity)
{
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	
	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */

			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if (((targetMethod1->cmType)) == CMFree) {
				/* begin unlinkSendAt:targetMethod:sendTable: */
				unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
				rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), (targetMethod1->selector), unlinkedRoutine);
				codeModified = 1;
			}

		}
	}
	return 0;
}

	/* Cogit>>#unlinkIfLinkedSend:pc:ignored: */
static sqInt
unlinkIfLinkedSendpcignored(sqInt annotation, char *mcpc, sqInt superfluity)
{
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	
	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */

			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			/* begin unlinkSendAt:targetMethod:sendTable: */
			unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
			rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), (targetMethod1->selector), unlinkedRoutine);
			codeModified = 1;

		}
	}
	return 0;
}

	/* Cogit>>#unlinkIfLinkedSend:pc:to: */
static sqInt
unlinkIfLinkedSendpcto(sqInt annotation, char *mcpc, sqInt theCogMethod)
{
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	
	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */

			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if ((((sqInt)targetMethod1)) == theCogMethod) {
				/* begin unlinkSendAt:targetMethod:sendTable: */
				unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
				rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), (targetMethod1->selector), unlinkedRoutine);
				codeModified = 1;
			}

		}
	}
	return 0;
}


/*	Unlink all sends in cog methods whose class tag is that of a forwarded
	class. 
 */

	/* Cogit>>#unlinkSendsLinkedForInvalidClasses */
void
unlinkSendsLinkedForInvalidClasses(void)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt freedPIC;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	if (!(methodZoneBase)) {
		return;
	}
	cogMethod = ((CogMethod *) methodZoneBase);
	codeModified = (freedPIC = 0);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = unlinkIfInvalidClassSendpcignored(annotation, (((char *) mcpc)), 0);
					if (result != 0) {
						result;
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
			0;
		l1:	/* end mapFor:performUntil:arg: */;
		}
		else {
			if ((((cogMethod->cmType)) == CMClosedPIC)
			 && (cPICHasForwardedClass(cogMethod))) {
				freeMethod(cogMethod);
				freedPIC = 1;
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (freedPIC) {
		unlinkSendsToFree();
	}
	else {
		if (codeModified) {

			/* After possibly updating inline caches we need to flush the icache. */

			flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
		}
	}
}


/*	Unlink all sends in cog methods. Free all Closed PICs with the selector,
	or with an MNU case if isMNUSelector. First check if any method actually
	has the selector; if not there can't be any linked send to it. This
	routine (including descendents) is performance critical. It contributes
	perhaps 30% of entire execution time in Compiler recompileAll. */

	/* Cogit>>#unlinkSendsOf:isMNUSelector: */
void
unlinkSendsOfisMNUSelector(sqInt selector, sqInt isMNUSelector)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt mustScanAndUnlink;
    sqInt result;

	if (methodZoneBase == null) {
		return;
	}
	cogMethod = ((CogMethod *) methodZoneBase);
	mustScanAndUnlink = 0;
	if (isMNUSelector) {
		while (cogMethod < (limitZony())) {
			if (((cogMethod->cmType)) != CMFree) {
				if ((cogMethod->cpicHasMNUCase)) {
					assert(((cogMethod->cmType)) == CMClosedPIC);
					freeMethod(cogMethod);
					mustScanAndUnlink = 1;
				}
				else {
					if (((cogMethod->selector)) == selector) {
						mustScanAndUnlink = 1;
						if (((cogMethod->cmType)) == CMClosedPIC) {
							freeMethod(cogMethod);
						}
					}
				}
			}
			cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		}
	}
	else {
		while (cogMethod < (limitZony())) {
			if ((((cogMethod->cmType)) != CMFree)
			 && (((cogMethod->selector)) == selector)) {
				mustScanAndUnlink = 1;
				if (((cogMethod->cmType)) == CMClosedPIC) {
					freeMethod(cogMethod);
				}
			}
			cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		}
	}
	if (!mustScanAndUnlink) {
		return;
	}
	codeModified = 0;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = unlinkIfFreeOrLinkedSendpcof(annotation, (((char *) mcpc)), selector);
					if (result != 0) {
						result;
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
			0;
		l1:	/* end mapFor:performUntil:arg: */;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (codeModified) {

		/* After possibly updating inline caches we need to flush the icache. */

		flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
	}
}


/*	Unlink all sends in cog methods to free methods and/or pics. */

	/* Cogit>>#unlinkSendsToFree */
void
unlinkSendsToFree(void)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	if (methodZoneBase == null) {
		return;
	}
	codeModified = 0;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = unlinkIfLinkedSendToFreepcignored(annotation, (((char *) mcpc)), 0);
					if (result != 0) {
						result;
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
			0;
		l1:	/* end mapFor:performUntil:arg: */;
		}
		else {
			if (((cogMethod->cmType)) == CMClosedPIC) {
				assert(noTargetsFreeInClosedPIC(cogMethod));
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (codeModified) {

		/* After possibly updating inline caches we need to flush the icache. */

		flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
	}
}


/*	Unlink all sends in cog methods to a particular target method.
	If targetMethodObject isn't actually a method (perhaps being
	used via invokeAsMethod) then there's nothing to do. */

	/* Cogit>>#unlinkSendsTo:andFreeIf: */
void
unlinkSendsToandFreeIf(sqInt targetMethodObject, sqInt freeIfTrue)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt freedPIC;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;
    CogMethod *targetMethod;

	if (!((isOopCompiledMethod(targetMethodObject))
		 && (methodHasCogMethod(targetMethodObject)))) {
		return;
	}
	targetMethod = cogMethodOf(targetMethodObject);
	if (methodZoneBase == null) {
		return;
	}
	codeModified = (freedPIC = 0);
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */

					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = unlinkIfLinkedSendpcto(annotation, (((char *) mcpc)), (((sqInt)targetMethod)));
					if (result != 0) {
						result;
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
			0;
		l1:	/* end mapFor:performUntil:arg: */;
		}
		else {
			if ((((cogMethod->cmType)) == CMClosedPIC)
			 && (cPICHasTarget(cogMethod, targetMethod))) {
				freeMethod(cogMethod);
				freedPIC = 1;
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (freeIfTrue) {
		freeMethod(targetMethod);
	}
	if (freedPIC) {
		unlinkSendsToFree();
	}
	else {
		if (codeModified) {

			/* After possibly updating inline caches we need to flush the icache. */

			flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
		}
	}
}


/*	Update a potential object reference from a closed PIC.
	This may be an object reference, an inline cache tag or null.
	Answer if the updated literal is young. */

	/* Cogit>>#updateMaybeClassRefInClosedPICAt: */
static sqInt
updateMaybeClassRefInClosedPICAt(sqInt mcpc)
{
    sqInt object;
    sqInt subject;

	object = longAt(mcpc - BytesPerOop);
	if (!(couldBeObject(object))) {
		return 0;
	}
	subject = remapOop(object);
	if (object != subject) {
		/* begin storeClassRef:inClosedPICAt: */
		longAt(mcpc - BytesPerOop);

		codeModified = 1;
	}
	return isYoungObject(subject);
}


/*	Update a potential object reference from a closed PIC.
	This may be an object reference, an inline cache tag or null.
	Answer if the updated literal is young. */

	/* Cogit>>#updateMaybeObjRefInClosedPICAt: */
static sqInt
updateMaybeObjRefInClosedPICAt(sqInt mcpc)
{
    sqInt object;
    sqInt subject;

	object = longAt(mcpc);
	if (!(couldBeObject(object))) {
		return 0;
	}
	subject = remapOop(object);
	if (object != subject) {
		/* begin storeObjRef:inClosedPICAt: */
		longAtput(mcpc, subject);
		codeModified = 1;
	}
	return isYoungObject(subject);
}

	/* Cogit>>#XorCw:R: */
static AbstractInstruction *
gXorCwR(sqInt wordConstant, sqInt reg)
{
	/* begin gen:literal:operand: */
	return checkLiteralforInstruction(wordConstant, genoperandoperand(XorCwR, wordConstant, reg));
}


/*	Access for the object representations when they need to prepend code to
	trampolines. 
 */

	/* Cogit>>#zeroOpcodeIndex */
static void
zeroOpcodeIndex(void)
{
	opcodeIndex = 0;
	/* begin resetLiterals */

	/* an impossibly high value */

	firstOpcodeIndex = 1 << 16;
	nextLiteralIndex = (lastDumpedLiteralIndex = 0);
}

	/* CogMethodZone>>#addAllToYoungReferrers */
void
addAllToYoungReferrers(void)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) == CMMethod)
		 || (((cogMethod->cmType)) == CMOpenPIC)) {
			ensureInYoungReferrers(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#addToOpenPICList: */
static void
addToOpenPICList(CogMethod *anOpenPIC)
{
	assert(((anOpenPIC->cmType)) == CMOpenPIC);
	assert((openPICList == null)
	 || (((openPICList->cmType)) == CMOpenPIC));
	(anOpenPIC->nextOpenPIC = ((usqInt)openPICList));
	openPICList = anOpenPIC;
}

	/* CogMethodZone>>#addToYoungReferrers: */
static void
addToYoungReferrers(CogMethod *cogMethod)
{
	assert(youngReferrers <= limitAddress);
	assert((occurrencesInYoungReferrers(cogMethod)) == 0);
	assert((cogMethod->cmRefersToYoung));
	assert((youngReferrers <= limitAddress)
	 && (youngReferrers >= (limitAddress - (methodCount * BytesPerWord))));
	if (!(asserta((limitAddress - (methodCount * BytesPerWord)) >= mzFreeStart))) {
		error("no room on youngReferrers list");
	}
	youngReferrers -= BytesPerWord;
	longAtput(youngReferrers, ((usqInt)cogMethod));
}

	/* CogMethodZone>>#allocate: */
static sqInt
allocate(sqInt numBytes)
{
    usqInt allocation;
    sqInt roundedBytes;

	roundedBytes = (numBytes + 7) & -8;
	if ((mzFreeStart + roundedBytes) >= (limitAddress - (methodCount * BytesPerWord))) {
		return 0;
	}
	allocation = mzFreeStart;
	mzFreeStart += roundedBytes;
	methodCount += 1;
	
	return allocation;
}


/*	Free all methods */

	/* CogMethodZone>>#clearCogCompiledCode */
static void
clearCogCompiledCode(void)
{
    CogMethod *cogMethod;

	
	cogMethod = ((CogMethod *) baseAddress);
	while ((((usqInt)cogMethod)) < mzFreeStart) {
		if (((cogMethod->cmType)) == CMMethod) {
			freeMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	manageFromto(baseAddress, limitAddress);
}

	/* CogMethodZone>>#compactCompiledCode */
static void
compactCompiledCode(void)
{
    unsigned short bytes;
    CogMethod *dest;
    sqLong objectHeaderValue;
    CogMethod *source;

	objectHeaderValue = nullHeaderForMachineCodeMethod();
	source = ((CogMethod *) baseAddress);
	openPICList = null;
	methodCount = 0;
	
	while ((source < (limitZony()))
	 && (((source->cmType)) != CMFree)) {
		assert((cogMethodDoesntLookKosher(source)) == 0);
		(source->objectHeader = objectHeaderValue);
		if (((source->cmUsageCount)) > 0) {
			(source->cmUsageCount = ((source->cmUsageCount)) / 2);
		}
		
		
		if (((source->cmType)) == CMOpenPIC) {
			(source->nextOpenPIC = ((usqInt)openPICList));
			openPICList = source;
		}
		methodCount += 1;
		source = ((CogMethod *) (roundUpLength((((sqInt)source)) + ((source->blockSize)))));
	}
	if (source >= (limitZony())) {
		haltmsg("no free methods; cannot compact.");
		return;
	}
	dest = source;
	while (source < (limitZony())) {
		assert((maybeFreeCogMethodDoesntLookKosher(source)) == 0);
		bytes = (source->blockSize);
		if (((source->cmType)) != CMFree) {
			methodCount += 1;
			memmove(dest, source, bytes);
			(dest->objectHeader = objectHeaderValue);
			if (((dest->cmType)) == CMMethod) {

				/* For non-Newspeak there should be a one-to-one mapping between bytecoded and
				   cog methods.  For Newspeak not necessarily, but only for anonymous accessors. */
				/* Only update the original method's header if it is referring to this CogMethod. */

				if ((((sqInt)(rawHeaderOf((dest->methodObject))))) == (((sqInt)source))) {
					rawHeaderOfput((dest->methodObject), ((sqInt)dest));
				}
				else {
					assert((noAssertMethodClassAssociationOf((dest->methodObject))) == (nilObject()));
					
				}
			}
			else {
				;
				if (((dest->cmType)) == CMOpenPIC) {
					(dest->nextOpenPIC = ((usqInt)openPICList));
					openPICList = dest;
				}
			}
			if (((dest->cmUsageCount)) > 0) {
				(dest->cmUsageCount = ((dest->cmUsageCount)) / 2);
			}
			dest = ((CogMethod *) ((((usqInt)dest)) + bytes));
		}
		source = ((CogMethod *) ((((usqInt)source)) + bytes));
	}
	mzFreeStart = ((usqInt)dest);
	methodBytesFreedSinceLastCompaction = 0;
}

	/* CogMethodZone>>#ensureInYoungReferrers: */
static void
ensureInYoungReferrers(CogMethod *cogMethod)
{
	if (!((cogMethod->cmRefersToYoung))) {
		assert((occurrencesInYoungReferrers(cogMethod)) == 0);
		(cogMethod->cmRefersToYoung = 1);
		addToYoungReferrers(cogMethod);
	}
}

	/* CogMethodZone>>#freeMethod: */
void
freeMethod(CogMethod *cogMethod)
{
	assert(((cogMethod->cmType)) != CMFree);
	assert(((cogMethodDoesntLookKosher(cogMethod)) == 0)
	 || (((cogMethodDoesntLookKosher(cogMethod)) == 23)
	 && ((((((CogMethod *) ((cogMethod->methodObject))))->cmType)) == CMFree)));
	if (((cogMethod->cmType)) == CMMethod) {

		/* For non-Newspeak there should ne a one-to-one mapping between bytecoded and
		   cog methods.  For Newspeak not necessarily, but only for anonymous accessors. */
		/* Only reset the original method's header if it is referring to this CogMethod. */

		if ((((sqInt)(rawHeaderOf((cogMethod->methodObject))))) == (((sqInt)cogMethod))) {
			rawHeaderOfput((cogMethod->methodObject), (cogMethod->methodHeader));
			
		}
		else {
			assert((noAssertMethodClassAssociationOf((cogMethod->methodObject))) == (nilObject()));
			
		}
		/* begin maybeFreeCountersOf: */
	}
	if (((cogMethod->cmType)) == CMOpenPIC) {
		removeFromOpenPICList(cogMethod);
	}
	(cogMethod->cmRefersToYoung = 0);
	(cogMethod->cmType = CMFree);
	methodBytesFreedSinceLastCompaction += (cogMethod->blockSize);
}


/*	Free methods, preferring older methods for compaction, up to some
	fraction, currently a quarter.
 */

	/* CogMethodZone>>#freeOlderMethodsForCompaction */
static void
freeOlderMethodsForCompaction(void)
{
    sqInt amountToFree;
    sqInt cascade0;
    sqInt cascade1;
    CogMethod *cogMethod;
    sqInt freeableUsage;
    usqInt freedSoFar;
    usqInt initialFreeSpace;
    usqInt zoneSize;

	zoneSize = limitAddress - baseAddress;
	initialFreeSpace = (limitAddress - mzFreeStart) + methodBytesFreedSinceLastCompaction;
	freedSoFar = initialFreeSpace;

	/* 4 needs to be e.g. a start-up parameter */

	amountToFree = zoneSize / 4;
	freeableUsage = 0;
	do {
		;
		cogMethod = ((CogMethod *) baseAddress);
		while (((((usqInt)cogMethod)) < mzFreeStart)
		 && (freedSoFar < amountToFree)) {
			if ((((cogMethod->cmType)) != CMFree)
			 && (((cogMethod->cmUsageCount)) <= freeableUsage)) {
				freeMethod(cogMethod);
				freedSoFar += (cogMethod->blockSize);
			}
			cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		}
	} while((freedSoFar < amountToFree)
		 && (((freeableUsage += 1)) < CMMaxUsageCount));
	
}


/*	Answer that all entries in youngReferrers are in-use and have the
	cmRefersToYoung flag set.
	Used to check that the youngreferrers pruning routines work correctly. */

	/* CogMethodZone>>#kosherYoungReferrers */
static sqInt
kosherYoungReferrers(void)
{
    CogMethod *cogMethod;
    usqInt pointer;

	if ((youngReferrers > limitAddress)
	 || (youngReferrers < mzFreeStart)) {
		return 0;
	}
	pointer = youngReferrers;
	while (pointer < limitAddress) {
		cogMethod = ((CogMethod *) (longAt(pointer)));
		if (!((((cogMethod->cmType)) != CMFree)
			 && ((cogMethod->cmRefersToYoung)))) {
			return 0;
		}
		pointer += BytesPerWord;
	}
	return 1;
}

	/* CogMethodZone>>#manageFrom:to: */
static void
manageFromto(sqInt theStartAddress, sqInt theLimitAddress)
{
	mzFreeStart = (baseAddress = theStartAddress);
	youngReferrers = (limitAddress = theLimitAddress);
	openPICList = null;
	
	methodBytesFreedSinceLastCompaction = 0;
	methodCount = 0;
}

	/* CogMethodZone>>#methodFor: */
CogMethod *
methodFor(void *address)
{
    CogMethod *cogMethod;
    CogMethod *nextMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while ((cogMethod < (limitZony()))
	 && ((((usqInt)cogMethod)) <= (((usqInt)address)))) {
		nextMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		if (nextMethod == cogMethod) {
			return 0;
		}
		if (((((usqInt)address)) >= (((usqInt)cogMethod)))
		 && ((((usqInt)address)) < (((usqInt)nextMethod)))) {
			return cogMethod;
		}
		cogMethod = nextMethod;
	}
	return 0;
}

	/* CogMethodZone>>#numMethods */
static sqInt
numMethods(void)
{
	return methodCount;
}

	/* CogMethodZone>>#numMethodsOfType: */
sqInt
numMethodsOfType(sqInt cogMethodType)
{
    CogMethod *cogMethod;
    sqInt n;

	n = 0;
	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == cogMethodType) {
			n += 1;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return n;
}

	/* CogMethodZone>>#occurrencesInYoungReferrers: */
static sqInt
occurrencesInYoungReferrers(CogMethod *cogMethod)
{
    sqInt count;
    usqInt pointer;

	assert(youngReferrers <= limitAddress);
	count = 0;
	pointer = youngReferrers;
	while (pointer < limitAddress) {
		if ((((sqInt)cogMethod)) == (longAt(pointer))) {
			count += 1;
		}
		pointer += BytesPerWord;
	}
	return count;
}

	/* CogMethodZone>>#openPICWithSelector: */
static CogMethod *
openPICWithSelector(sqInt aSelector)
{
    CogMethod *openPIC;

	openPIC = openPICList;
	do {
		if ((openPIC == null)
		 || (((openPIC->selector)) == aSelector)) {
			return openPIC;
		}
		openPIC = ((CogMethod *) ((openPIC->nextOpenPIC)));
	} while(1);
}


/*	Some methods have been freed. Compute how much each survivor needs to
	move during the ensuing compaction and record it in the objectHeader
	field. 
	For Sista, where we want PICs to last so they can be observed, we need to
	keep PICs unless
	they are definitely unused. So we need to identify unused PICs. So in
	planCompact, zero the
	usage counts of all PICs, saving the actual usage count in
	blockEntryOffset. Then in
	relocateMethodsPreCompaction (actually in
	relocateIfCallOrMethodReference:mcpc:delta:) restore the usage counts of
	used PICs. Finally in compactCompiledCode, clear the blockEntryOffset
	of the unused PICs; they will then have a zero count and be reclaimed in
	the next code compaction. */

	/* CogMethodZone>>#planCompaction */
static void
planCompaction(void)
{
    CogMethod *cogMethod;
    sqInt delta;

	delta = 0;
	cogMethod = ((CogMethod *) baseAddress);
	while ((((usqInt)cogMethod)) < mzFreeStart) {
		if (((cogMethod->cmType)) == CMFree) {
			delta -= (cogMethod->blockSize);
		}
		else {
			assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
			(cogMethod->objectHeader = delta);
			
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#printCogMethods */
void
printCogMethods(void)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		printCogMethod(cogMethod);
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#printCogMethodsOfType: */
void
printCogMethodsOfType(sqInt cmType)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == cmType) {
			printCogMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#printCogMethodsWithMethod: */
void
printCogMethodsWithMethod(sqInt methodOop)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) != CMFree)
		 && (((cogMethod->methodObject)) == methodOop)) {
			printCogMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#printCogMethodsWithPrimitive: */
void
printCogMethodsWithPrimitive(sqInt primIdx)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) != CMFree)
		 && (primIdx == (primitiveIndexOfMethodheader((cogMethod->methodObject), (cogMethod->methodHeader))))) {
			printCogMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#printCogMethodsWithSelector: */
void
printCogMethodsWithSelector(sqInt selectorOop)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) != CMFree)
		 && (((cogMethod->selector)) == selectorOop)) {
			printCogMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#printCogYoungReferrers */
void
printCogYoungReferrers(void)
{
    CogMethod *cogMethod;
    usqInt pointer;

	pointer = youngReferrers;
	while (pointer < limitAddress) {
		cogMethod = ((CogMethod *) (longAt(pointer)));
		if (!((cogMethod->cmRefersToYoung))) {
			print("*");
		}
		if (((cogMethod->cmType)) == CMFree) {
			print("!");
		}
		if (!(((cogMethod->cmRefersToYoung))
			 && (((cogMethod->cmType)) != CMFree))) {
			print(" ");
		}
		printCogMethod(cogMethod);
		pointer += BytesPerWord;
	}
}

	/* CogMethodZone>>#printOpenPICList */
void
printOpenPICList(void)
{
    CogMethod *openPIC;

	openPIC = openPICList;
	while (!(openPIC == null)) {
		printCogMethod(openPIC);
		openPIC = ((CogMethod *) ((openPIC->nextOpenPIC)));
	}
}

	/* CogMethodZone>>#pruneYoungReferrers */
static sqInt
pruneYoungReferrers(void)
{
    usqInt dest;
    usqInt next;
    usqInt source;

	assert(youngReferrers <= limitAddress);
	if (youngReferrers == limitAddress) {
		return null;
	}
	dest = limitAddress;
	while (1) {
		next = dest - BytesPerWord;
		if (!((next >= youngReferrers)
		 && (((((CogMethod *) (longAt(next))))->cmRefersToYoung)))) break;
		dest = next;
	}
	assert(dest >= youngReferrers);
	source = dest - BytesPerWord;
	while (source >= youngReferrers) {
		if (((((CogMethod *) (longAt(source))))->cmRefersToYoung)) {
			assert(source < (dest - BytesPerWord));
			longAtput((dest -= BytesPerWord), longAt(source));
		}
		source -= BytesPerWord;
	}
	youngReferrers = dest;
	assert(kosherYoungReferrers());
}

	/* CogMethodZone>>#relocateAndPruneYoungReferrers */
static sqInt
relocateAndPruneYoungReferrers(void)
{
    CogMethod *cogMethod;
    usqInt dest;
    usqInt next;
    usqInt source;

	assert(youngReferrers <= limitAddress);
	if (youngReferrers == limitAddress) {
		return null;
	}
	dest = limitAddress;
	while (1) {
		next = dest - BytesPerWord;
		if (!((next >= youngReferrers)
		 && (((((cogMethod = ((CogMethod *) (longAt(next))))->cmType)) != CMFree)
		 && ((cogMethod->cmRefersToYoung))))) break;
		if (((cogMethod->objectHeader)) != 0) {
			longAtput(next, (((sqInt)cogMethod)) + ((cogMethod->objectHeader)));
		}
		dest = next;
	}
	assert(dest >= youngReferrers);
	source = dest - BytesPerWord;
	while (source >= youngReferrers) {
		cogMethod = ((CogMethod *) (longAt(source)));
		if ((((cogMethod->cmType)) != CMFree)
		 && ((cogMethod->cmRefersToYoung))) {
			assert(source < (dest - BytesPerWord));
			if (((cogMethod->objectHeader)) != 0) {
				cogMethod = ((CogMethod *) ((((sqInt)cogMethod)) + (((sqInt)((cogMethod->objectHeader))))));
			}
			longAtput((dest -= BytesPerWord), ((sqInt)cogMethod));
		}
		source -= BytesPerWord;
	}
	youngReferrers = dest;
}


/*	All surviving methods have had the amount they are going to relocate by
	stored in their objectHeader fields. Relocate all relative calls so that
	after the compaction of both the method containing each call and the call
	target the calls invoke the same target. */

	/* CogMethodZone>>#relocateMethodsPreCompaction */
static sqInt
relocateMethodsPreCompaction(void)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while ((((usqInt)cogMethod)) < mzFreeStart) {
		if (((cogMethod->cmType)) != CMFree) {
			if (((cogMethod->cmType)) == CMClosedPIC) {
				relocateCallsInClosedPIC(cogMethod);
			}
			else {
				relocateCallsAndSelfReferencesInMethod(cogMethod);
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	relocateAndPruneYoungReferrers();
	return 1;
}

	/* CogMethodZone>>#removeFromOpenPICList: */
static sqInt
removeFromOpenPICList(CogMethod *anOpenPIC)
{
    CogMethod *prevPIC;

	assert(((anOpenPIC->cmType)) == CMOpenPIC);
	if (anOpenPIC == openPICList) {

		/* N.B. Use self rather than coInterpreter to avoid attempting to cast nil.
		   Conversion to CogMethod done in the nextOpenPIC accessor. */

		openPICList = ((CogMethod *) ((anOpenPIC->nextOpenPIC)));
		return null;
	}
	prevPIC = openPICList;
	do {
		assert((prevPIC != null)
		 && (((prevPIC->cmType)) == CMOpenPIC));
		if (((prevPIC->nextOpenPIC)) == (((sqInt)anOpenPIC))) {
			(prevPIC->nextOpenPIC = (anOpenPIC->nextOpenPIC));
			return null;
		}
		prevPIC = ((CogMethod *) ((prevPIC->nextOpenPIC)));
	} while(1);
}

	/* CogMethodZone>>#voidYoungReferrersPostTenureAll */
static void
voidYoungReferrersPostTenureAll(void)
{
    CogMethod *cogMethod;
    usqInt pointer;

	assert(youngReferrers <= limitAddress);
	pointer = youngReferrers;
	while (pointer < limitAddress) {
		cogMethod = ((CogMethod *) (longAt(pointer)));
		if (((cogMethod->cmType)) != CMFree) {
			(cogMethod->cmRefersToYoung = 0);
		}
		pointer += BytesPerWord;
	}
	youngReferrers = limitAddress;
}

	/* CogMethodZone>>#whereIsMaybeCodeThing: */
char *
whereIsMaybeCodeThing(sqInt anOop)
{
	if (oopisGreaterThanOrEqualToandLessThan(anOop, cogCodeBase(), limitAddress)) {
		if (oopisLessThan(anOop, minCogMethodAddress())) {
			return " is in generated runtime";
		}
		if (oopisLessThan(anOop, mzFreeStart)) {
			return " is in generated methods";
		}
		if (oopisLessThan(anOop, youngReferrers)) {
			return " is in code zone";
		}
		return " is in young referrers";
	}
	return null;
}

	/* CogObjectRepresentation>>#checkValidObjectReference: */
static sqInt
checkValidObjectReference(sqInt anOop)
{
	return (!(isImmediate(anOop)))
	 && ((heapMapAtWord(pointerForOop(anOop))) != 0);
}

	/* CogObjectRepresentation>>#genCmpClassFloatCompactIndexR: */
static AbstractInstruction *
genCmpClassFloatCompactIndexR(sqInt reg)
{
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	return checkQuickConstantforInstruction(ClassFloatCompactIndex, genoperandoperand(CmpCqR, ClassFloatCompactIndex, reg));
}

	/* CogObjectRepresentation>>#genCmpClassMethodContextCompactIndexR: */
static AbstractInstruction *
genCmpClassMethodContextCompactIndexR(sqInt reg)
{
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	return checkQuickConstantforInstruction(ClassMethodContextCompactIndex, genoperandoperand(CmpCqR, ClassMethodContextCompactIndex, reg));
}


/*	subclasses override if they can */

	/* CogObjectRepresentation>>#genInnerPrimitiveNewMethod: */
static sqInt
genInnerPrimitiveNewMethod(sqInt retNoffset)
{
	return unimplementedPrimitive();
}


/*	Generate a compare and branch to test if aRegister contains other than a
	SmallInteger. Answer the jump. Use scratch if required. Subclasses will
	override if scratch is needed. */

	/* CogObjectRepresentation>>#genJumpNotSmallInteger:scratchReg: */
static AbstractInstruction *
genJumpNotSmallIntegerscratchReg(sqInt aRegister, sqInt scratch)
{
	return genJumpNotSmallInteger(aRegister);
}

	/* CogObjectRepresentation>>#genLoadSlot:sourceReg:destReg: */
static sqInt
genLoadSlotsourceRegdestReg(sqInt index, sqInt sourceReg, sqInt destReg)
{
    sqInt offset;

	/* begin MoveMw:r:R: */
	offset = (index * BytesPerWord) + BaseHeaderSize;
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveMwrR, offset, sourceReg, destReg));
	return 0;
}

	/* CogObjectRepresentation>>#isUnannotatableConstant: */
static sqInt
isUnannotatableConstant(CogSimStackEntry *simStackEntry)
{
	return (((simStackEntry->type)) == SSConstant)
	 && (!(shouldAnnotateObjectReference((simStackEntry->constant))));
}

	/* CogObjectRepresentationFor32BitSpur>>#genAddSmallIntegerTagsTo: */
static sqInt
genAddSmallIntegerTagsTo(sqInt aRegister)
{
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(AddCqR, 1, aRegister));
	return 0;
}


/*	Convert the SmallInteger in reg to a Character, assuming
	the SmallInteger's value is a valid character. */
/*	self assume: objectMemory smallIntegerTag = 1 */

	/* CogObjectRepresentationFor32BitSpur>>#genConvertCharacterToSmallIntegerInReg: */
static void
genConvertCharacterToSmallIntegerInReg(sqInt reg)
{
	assert(((numCharacterBits()) + 1) == (numSmallIntegerBits()));
	/* begin LogicalShiftRightCq:R: */
	genoperandoperand(LogicalShiftRightCqR, 1, reg);
}

	/* CogObjectRepresentationFor32BitSpur>>#genConvertIntegerToSmallIntegerInReg: */
static sqInt
genConvertIntegerToSmallIntegerInReg(sqInt reg)
{
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, 1, reg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(AddCqR, 1, reg));
	return 0;
}


/*	Convert the SmallInteger in reg to a Character, assuming
	the SmallInteger's value is a valid character. */
/*	self assume: objectMemory smallIntegerTag = 1 */

	/* CogObjectRepresentationFor32BitSpur>>#genConvertSmallIntegerToCharacterInReg: */
static void
genConvertSmallIntegerToCharacterInReg(sqInt reg)
{
	assert(((numCharacterBits()) + 1) == (numSmallIntegerBits()));
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, 1, reg);
}

	/* CogObjectRepresentationFor32BitSpur>>#genConvertSmallIntegerToIntegerInReg: */
static sqInt
genConvertSmallIntegerToIntegerInReg(sqInt reg)
{
	/* begin ArithmeticShiftRightCq:R: */
	genoperandoperand(ArithmeticShiftRightCqR, 1, reg);
	return 0;
}


/*	Create a closure with the given startpc, numArgs and numCopied
	within a context with ctxtNumArgs, large if isLargeCtxt that is in a
	block if isInBlock. If numCopied > 0 pop those values off the stack. */

	/* CogObjectRepresentationFor32BitSpur>>#genCreateClosureAt:numArgs:numCopied:contextNumArgs:large:inBlock: */
static sqInt
genCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(sqInt bcpc, sqInt numArgs, sqInt numCopied, sqInt ctxtNumArgs, sqInt isLargeCtxt, sqInt isInBlock)
{
    sqInt i;
    sqInt offset;

	genNoPopCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(bcpc, numArgs, numCopied, ctxtNumArgs, isLargeCtxt, isInBlock);
	for (i = 1; i <= numCopied; i += 1) {
		/* begin PopR: */
		genoperand(PopR, TempReg);
		/* begin MoveR:Mw:r: */
		offset = (((numCopied - i) + ClosureFirstCopiedValueIndex) * BytesPerOop) + BaseHeaderSize;
		/* begin gen:operand:quickConstant:operand: */
		checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveRMwr, TempReg, offset, ReceiverResultReg));
	}
	return 0;
}


/*	indexReg contains the 1-relative index of an element in tableObj.
	Since BaseHeaderSize > BytesPerOop we must adjust it to use
	it as a zero-relative index from the beginning of the object. */

	/* CogObjectRepresentationFor32BitSpur>>#genFetchIndexRegister:from:into: */
static sqInt
genFetchIndexRegisterfrominto(sqInt indexReg, sqInt tableObj, sqInt destReg)
{
    sqInt operandOne;

	assert(indexReg != destReg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	operandOne = (BaseHeaderSize / BytesPerWord) - 1;
	checkQuickConstantforInstruction(operandOne, genoperandoperand(AddCqR, operandOne, indexReg));
	/* begin genMoveConstant:R: */
	if (shouldAnnotateObjectReference(tableObj)) {
		annotateobjRef(gMoveCwR(tableObj, destReg), tableObj);
	}
	else {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(tableObj, genoperandoperand(MoveCqR, tableObj, destReg));
	}
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, indexReg, destReg, destReg);
	return 0;
}


/*	Create a trampoline to answer the active context that will
	answer it if a frame is already married, and create it otherwise.
	Assume numArgs is in SendNumArgsReg and ClassReg is free. */

	/* CogObjectRepresentationFor32BitSpur>>#genGetActiveContextLarge:inBlock: */
static sqInt
genGetActiveContextLargeinBlock(sqInt isLarge, sqInt isInBlock)
{
    AbstractInstruction *abstractInstruction;
    sqInt address;
    sqInt address1;
    sqInt constant;
    AbstractInstruction *continuation;
    AbstractInstruction *exit;
    AbstractInstruction *first;
    usqLong header;
    AbstractInstruction * inst;
    AbstractInstruction *jumpNeedScavenge;
    AbstractInstruction *jumpSingle;
    AbstractInstruction *loopHead;
    sqInt offset;
    sqInt offset1;
    sqInt offset2;
    sqInt offset3;
    sqInt offset4;
    sqInt offset5;
    sqInt offset6;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    sqInt quickConstant5;
    sqInt quickConstant6;
    sqInt quickConstant7;
    sqInt quickConstant8;
    AbstractInstruction * self_in_saveAndRestoreLinkRegAround;
    sqInt slotSize;


	/* load the flag; stash it in both TempReg & ClassReg; do the compare (a prime candidated for use of AndCq:R:R:) */

	/* begin MoveMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(FoxMethod, genoperandoperandoperand(MoveMwrR, FoxMethod, FPReg, ClassReg));
	/* begin AndCq:R:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(MFMethodFlagHasContextFlag, genoperandoperandoperand(AndCqRR, MFMethodFlagHasContextFlag, ClassReg, TempReg));
	goto l1;

	first = genoperandoperand(MoveRR, ClassReg, TempReg);
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(MFMethodFlagHasContextFlag, genoperandoperand(AndCqR, MFMethodFlagHasContextFlag, TempReg));
	first;
l1:	/* end AndCq:R:R: */;
	/* begin JumpZero: */
	jumpSingle = genoperand(JumpZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(FoxThisContext, genoperandoperandoperand(MoveMwrR, FoxThisContext, FPReg, ReceiverResultReg));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpSingle, gLabel());
	/* begin OrCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(MFMethodFlagHasContextFlag, genoperandoperand(OrCqR, MFMethodFlagHasContextFlag, ClassReg));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(FoxMethod, genoperandoperandoperand(MoveRMwr, ClassReg, FoxMethod, FPReg));
	if (isInBlock) {
		/* begin SubCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(3, genoperandoperand(SubCqR, 3, ClassReg));
		/* begin MoveM16:r:R: */
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveM16rR, 0, ClassReg, TempReg));
		/* begin SubR:R: */
		genoperandoperand(SubRR, TempReg, ClassReg);
	}
	else {
		/* begin SubCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(1, genoperandoperand(SubCqR, 1, ClassReg));
	}
	slotSize = (isLarge
		? LargeContextSlots
		: SmallContextSlots);
	header = headerForSlotsformatclassIndex(slotSize, indexablePointersFormat(), ClassMethodContextCompactIndex);
	flag("endianness");
	/* begin MoveAw:R: */
	address = freeStartAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, ReceiverResultReg));
	/* begin MoveCq:R: */
	quickConstant1 = ((usqInt) header);
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(MoveCqR, quickConstant1, TempReg));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveRMwr, TempReg, 0, ReceiverResultReg));
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(header >> 32, genoperandoperand(MoveCqR, header >> 32, TempReg));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(4, genoperandoperandoperand(MoveRMwr, TempReg, 4, ReceiverResultReg));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	/* begin AddCq:R: */
	quickConstant2 = smallObjectBytesForSlots(slotSize);
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant2, genoperandoperand(AddCqR, quickConstant2, TempReg));
	/* begin MoveR:Aw: */
	address1 = freeStartAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address1, genoperandoperand(MoveRAw, TempReg, address1));
	/* begin CmpCq:R: */
	quickConstant3 = getScavengeThreshold();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant3, genoperandoperand(CmpCqR, quickConstant3, TempReg));
	/* begin JumpAboveOrEqual: */
	jumpNeedScavenge = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	continuation = genoperandoperand(MoveRR, FPReg, TempReg);
	genSetSmallIntegerTagsIn(TempReg);
	/* begin MoveR:Mw:r: */
	offset = BaseHeaderSize + (SenderIndex * BytesPerOop);
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveRMwr, TempReg, offset, ReceiverResultReg));
	/* begin MoveMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(FoxSavedFP, genoperandoperandoperand(MoveMwrR, FoxSavedFP, FPReg, TempReg));
	genSetSmallIntegerTagsIn(TempReg);
	/* begin MoveR:Mw:r: */
	offset1 = BaseHeaderSize + (InstructionPointerIndex * BytesPerOop);
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset1, genoperandoperandoperand(MoveRMwr, TempReg, offset1, ReceiverResultReg));
	/* begin MoveMw:r:R: */
	offset2 = offsetof(CogMethod, methodObject);
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset2, genoperandoperandoperand(MoveMwrR, offset2, ClassReg, TempReg));
	/* begin MoveR:Mw:r: */
	offset3 = BaseHeaderSize + (MethodIndex * BytesPerWord);
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset3, genoperandoperandoperand(MoveRMwr, TempReg, offset3, ReceiverResultReg));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(FoxThisContext, genoperandoperandoperand(MoveRMwr, ReceiverResultReg, FoxThisContext, FPReg));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, FPReg, TempReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, SPReg, TempReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant4 = log2BytesPerWord();
	genoperandoperand(LogicalShiftRightCqR, quickConstant4, TempReg);
	/* begin SubCq:R: */
	quickConstant5 = 3;
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant5, genoperandoperand(SubCqR, quickConstant5, TempReg));
	/* begin AddR:R: */
	genoperandoperand(AddRR, SendNumArgsReg, TempReg);
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:Mw:r: */
	offset4 = BaseHeaderSize + (StackPointerIndex * BytesPerOop);
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset4, genoperandoperandoperand(MoveRMwr, TempReg, offset4, ReceiverResultReg));
	if (isInBlock) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, SendNumArgsReg, TempReg);
		/* begin AddCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(2, genoperandoperand(AddCqR, 2, TempReg));
		/* begin MoveXwr:R:R: */
		genoperandoperandoperand(MoveXwrRR, TempReg, FPReg, TempReg);
	}
	else {
		/* begin genMoveConstant:R: */
		constant = nilObject();
		if (shouldAnnotateObjectReference(constant)) {
			annotateobjRef(gMoveCwR(constant, TempReg), constant);
		}
		else {
			/* begin MoveCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, TempReg));
		}
	}
	/* begin MoveR:Mw:r: */
	offset5 = BaseHeaderSize + (ClosureIndex * BytesPerOop);
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset5, genoperandoperandoperand(MoveRMwr, TempReg, offset5, ReceiverResultReg));
	/* begin MoveMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(FoxMFReceiver, genoperandoperandoperand(MoveMwrR, FoxMFReceiver, FPReg, TempReg));
	/* begin MoveR:Mw:r: */
	offset6 = BaseHeaderSize + (ReceiverIndex * BytesPerOop);
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset6, genoperandoperandoperand(MoveRMwr, TempReg, offset6, ReceiverResultReg));
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(MoveCqR, 1, ClassReg));
	/* begin CmpR:R: */
	loopHead = genoperandoperand(CmpRR, SendNumArgsReg, ClassReg);
	/* begin JumpGreater: */
	exit = genoperand(JumpGreater, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, TempReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, ClassReg, TempReg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(2, genoperandoperand(AddCqR, 2, TempReg));
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, TempReg, FPReg, TempReg);
	/* begin AddCq:R: */
	quickConstant6 = ReceiverIndex + (BaseHeaderSize / BytesPerWord);
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant6, genoperandoperand(AddCqR, quickConstant6, ClassReg));
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, TempReg, ClassReg, ReceiverResultReg);
	/* begin SubCq:R: */
	quickConstant7 = (ReceiverIndex + (BaseHeaderSize / BytesPerWord)) - 1;
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant7, genoperandoperand(SubCqR, quickConstant7, ClassReg));
	/* begin Jump: */
	genoperand(Jump, ((sqInt)loopHead));
	jmpTarget(exit, gLabel());
	/* begin MoveCq:R: */
	quickConstant = nilObject();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(MoveCqR, quickConstant, TempReg));

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, FPReg, ClassReg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(FoxMFReceiver, genoperandoperand(AddCqR, FoxMFReceiver, ClassReg));
	/* begin AddCq:R: */
	quickConstant8 = (ReceiverIndex + 1) + (BaseHeaderSize / BytesPerWord);
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant8, genoperandoperand(AddCqR, quickConstant8, SendNumArgsReg));
	/* begin SubCq:R: */
	/* begin gen:quickConstant:operand: */
	loopHead = checkQuickConstantforInstruction(BytesPerWord, genoperandoperand(SubCqR, BytesPerWord, ClassReg));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, SPReg, ClassReg);
	/* begin JumpBelow: */
	exit = genoperand(JumpBelow, ((sqInt)0));

	
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, TempReg, SendNumArgsReg, ReceiverResultReg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(AddCqR, 1, SendNumArgsReg));
	/* begin Jump: */
	genoperand(Jump, ((sqInt)loopHead));
	jmpTarget(exit, gLabel());
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNeedScavenge, gLabel());
	/* begin saveAndRestoreLinkRegAround: */
	self_in_saveAndRestoreLinkRegAround = ((AbstractInstruction *) (backEnd()));
	/* begin PushR: */
	inst = genoperand(PushR, LinkReg);
	/* begin CallRT: */
	/* begin annotateCall: */
	/* begin Call: */
	abstractInstruction = genoperand(Call, ceScheduleScavengeTrampoline);
	(abstractInstruction->annotation = IsRelativeCall);
	abstractInstruction;

	/* begin PopR: */
	genoperand(PopR, LinkReg);
	inst;
	/* begin Jump: */
	genoperand(Jump, ((sqInt)continuation));
	return 0;
}

	/* CogObjectRepresentationFor32BitSpur>>#genGetClassTagOf:into:scratchReg: */
static AbstractInstruction *
genGetClassTagOfintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg)
{
	return genGetInlineCacheClassTagFromintoforEntry(instReg, destReg, 1);
}


/*	Fetch the instance's identity hash into destReg, encoded as a
	SmallInteger. 
 */
/*	Get header word in scratchReg */

	/* CogObjectRepresentationFor32BitSpur>>#genGetHashFieldNonImmOf:asSmallIntegerInto: */
static sqInt
genGetHashFieldNonImmOfasSmallIntegerInto(sqInt instReg, sqInt destReg)
{
    sqInt quickConstant;

	/* begin MoveMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(4, genoperandoperandoperand(MoveMwrR, 4, instReg, destReg));
	/* begin AndCq:R: */
	quickConstant = identityHashHalfWordMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(AndCqR, quickConstant, destReg));
	genConvertIntegerToSmallIntegerInReg(destReg);
	return 0;
}


/*	Fetch the instance's identity hash into destReg, unencoded. */

	/* CogObjectRepresentationFor32BitSpur>>#genGetHashFieldNonImmOf:into: */
static sqInt
genGetHashFieldNonImmOfinto(sqInt instReg, sqInt destReg)
{
    sqInt quickConstant;

	/* begin MoveMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(4, genoperandoperandoperand(MoveMwrR, 4, instReg, destReg));
	/* begin AndCq:R: */
	quickConstant = identityHashHalfWordMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(AndCqR, quickConstant, destReg));
	return 0;
}


/*	Extract the inline cache tag for the object in sourceReg into destReg. The
	inline cache tag for a given object is the value loaded in inline caches
	to distinguish
	objects of different classes. In Spur this is either the tags for
	immediates, (with
	1 & 3 collapsed to 1 for SmallIntegers, and 2 collapsed to 0 for
	Characters), or
	the receiver's classIndex.
	If forEntry is true answer the entry label at which control is to enter
	(cmEntryOffset). If forEntry is false, control enters at the start.
	If forEntry is true, generate something like this:
	Limm:
	andl $0x1, rDest
	j Lcmp
	Lentry:
	movl rSource, rDest
	andl $0x3, rDest
	jnz Limm
	movl 0(%edx), rDest
	andl $0x3fffff, rDest
	Lcmp:
	If forEntry is false, generate something like the following.
	At least on a 2.2GHz Intel Core i7 the following is slightly faster than
	the above,
	136m sends/sec vs 130m sends/sec for nfib in tinyBenchmarks
	Lentry:
	movl rSource, rDest
	andl $0x3, rDest
	jz LnotImm
	andl $1, rDest
	j Lcmp
	LnotImm:
	movl 0(%edx), rDest
	andl $0x3fffff, rDest
	Lcmp:
	But we expect most SmallInteger arithmetic to be performed in-line and so
	prefer the
	version that is faster for non-immediates (because it branches for
	immediates only). */

	/* CogObjectRepresentationFor32BitSpur>>#genGetInlineCacheClassTagFrom:into:forEntry: */
static AbstractInstruction *
genGetInlineCacheClassTagFromintoforEntry(sqInt sourceReg, sqInt destReg, sqInt forEntry)
{
    AbstractInstruction *entryLabel;
    AbstractInstruction *first;
    AbstractInstruction *first1;
    AbstractInstruction *immLabel;
    AbstractInstruction *jumpCompare;
    AbstractInstruction *jumpNotImm;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;

	if (forEntry) {
		/* begin AlignmentNops: */
		genoperand(AlignmentNops, BytesPerWord);
		/* begin Label */
		immLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		/* begin AndCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(1, genoperandoperand(AndCqR, 1, destReg));
		/* begin Jump: */
		jumpCompare = genoperand(Jump, ((sqInt)0));
		/* begin AlignmentNops: */
		genoperand(AlignmentNops, BytesPerWord);
		/* begin Label */
		entryLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		/* begin AndCq:R:R: */
		quickConstant1 = tagMask();
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(quickConstant1, genoperandoperandoperand(AndCqRR, quickConstant1, sourceReg, destReg));
		goto l1;

		first = genoperandoperand(MoveRR, sourceReg, destReg);
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(quickConstant1, genoperandoperand(AndCqR, quickConstant1, destReg));
		first;
	l1:	/* end AndCq:R:R: */;
		/* begin JumpNonZero: */
		genoperand(JumpNonZero, ((sqInt)immLabel));
		flag("endianness");
		/* begin MoveMw:r:R: */
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveMwrR, 0, sourceReg, destReg));
		/* begin AndCq:R: */
		quickConstant = classIndexMask();
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(quickConstant, genoperandoperand(AndCqR, quickConstant, destReg));
		jmpTarget(jumpCompare, gLabel());
	}
	else {
		/* begin Label */
		entryLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		/* begin AndCq:R:R: */
		quickConstant2 = tagMask();
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(quickConstant2, genoperandoperandoperand(AndCqRR, quickConstant2, sourceReg, destReg));
		goto l2;

		first1 = genoperandoperand(MoveRR, sourceReg, destReg);
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(quickConstant2, genoperandoperand(AndCqR, quickConstant2, destReg));
		first1;
	l2:	/* end AndCq:R:R: */;
		/* begin JumpZero: */
		jumpNotImm = genoperand(JumpZero, ((sqInt)0));
		/* begin AndCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(1, genoperandoperand(AndCqR, 1, destReg));
		/* begin Jump: */
		jumpCompare = genoperand(Jump, ((sqInt)0));
		flag("endianness");
		jmpTarget(jumpNotImm, gMoveMwrR(0, sourceReg, destReg));
		jmpTarget(jumpCompare, gAndCqR(classIndexMask(), destReg));
	}
	return entryLabel;
}


/*	Get the size in byte-sized slots of the object in srcReg into destReg.
	srcReg may equal destReg.
	destReg <- numSlots << self shiftForWord - (fmt bitAnd: 3).
	Assumes the object in srcReg has a byte format, i.e. 16 to 23 or 24 to 31 */

	/* CogObjectRepresentationFor32BitSpur>>#genGetNumBytesOf:into: */
static sqInt
genGetNumBytesOfinto(sqInt srcReg, sqInt destReg)
{
    AbstractInstruction *jmp;
    sqInt quickConstant;

	genGetRawSlotSizeOfNonImminto(srcReg, destReg);
	/* begin CmpCq:R: */
	quickConstant = numSlotsMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, destReg));
	/* begin JumpLess: */
	jmp = genoperand(JumpLess, ((sqInt)0));
	genGetOverflowSlotsOfinto(srcReg, destReg);
	jmpTarget(jmp, gLogicalShiftLeftCqR(shiftForWord(), destReg));
	genGetBitsofFormatByteOfintobaseHeaderIntoScratch(3, srcReg, TempReg, null);
	/* begin SubR:R: */
	genoperandoperand(SubRR, TempReg, destReg);
	return 0;
}


/*	Get the size in word-sized slots of the object in srcReg into destReg.
	srcReg may equal destReg. */

	/* CogObjectRepresentationFor32BitSpur>>#genGetNumSlotsOf:into: */
static sqInt
genGetNumSlotsOfinto(sqInt srcReg, sqInt destReg)
{
    AbstractInstruction *jmp;
    sqInt quickConstant;

	assert(srcReg != destReg);
	genGetRawSlotSizeOfNonImminto(srcReg, destReg);
	/* begin CmpCq:R: */
	quickConstant = numSlotsMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, destReg));
	/* begin JumpLess: */
	jmp = genoperand(JumpLess, ((sqInt)0));
	genGetOverflowSlotsOfinto(srcReg, destReg);
	jmpTarget(jmp, gLabel());
	return 0;
}

	/* CogObjectRepresentationFor32BitSpur>>#genGetOverflowSlotsOf:into: */
static sqInt
genGetOverflowSlotsOfinto(sqInt srcReg, sqInt destReg)
{
	/* begin MoveMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(-BaseHeaderSize, genoperandoperandoperand(MoveMwrR, -BaseHeaderSize, srcReg, destReg));
	return 0;
}


/*	Implement the guts of primitiveAtPut */

	/* CogObjectRepresentationFor32BitSpur>>#genInnerPrimitiveAtPut: */
static sqInt
genInnerPrimitiveAtPut(sqInt retNoffset)
{
    sqInt formatReg;
    AbstractInstruction *jumpArrayOutOfBounds;
    AbstractInstruction *jumpBadIndex;
    AbstractInstruction *jumpBytesOutOfBounds;
    AbstractInstruction * jumpBytesOutOfRange;
    AbstractInstruction * jumpFixedFieldsOutOfBounds;
    AbstractInstruction *jumpHasFixedFields;
    AbstractInstruction *jumpImmediate;
    AbstractInstruction *jumpIsBytes;
    AbstractInstruction * jumpIsCompiledMethod;
    AbstractInstruction *jumpIsContext;
    AbstractInstruction * jumpNonSmallIntegerValue;
    AbstractInstruction *jumpNotIndexableBits;
    AbstractInstruction *jumpNotIndexablePointers;
    AbstractInstruction * jumpNotPointers;
    AbstractInstruction *jumpShortsUnsupported;
    AbstractInstruction *jumpWordsOutOfBounds;
    sqInt operandOne;
    sqInt operandOne1;
    sqInt operandOne2;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    sqInt quickConstant5;


	/* c.f. StackInterpreter>>stSizeOf: SpurMemoryManager>>lengthOf:format: fixedFieldsOf:format:length: */

	jumpImmediate = genJumpImmediate(ReceiverResultReg);
	jumpBadIndex = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	genConvertSmallIntegerToIntegerInReg(Arg0Reg);
	/* begin SubCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(SubCqR, 1, Arg0Reg));
	genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(ReceiverResultReg, (formatReg = SendNumArgsReg), null);
	genGetNumSlotsOfinto(ReceiverResultReg, ClassReg);
	/* begin CmpCq:R: */
	quickConstant = weakArrayFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, formatReg));
	/* begin JumpAbove: */
	jumpNotPointers = genoperand(JumpAbove, ((sqInt)0));
	genStoreCheckReceiverRegvalueRegscratchReginFrame(ReceiverResultReg, Arg1Reg, TempReg, 0);
	/* begin CmpCq:R: */
	quickConstant1 = arrayFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(CmpCqR, quickConstant1, formatReg));
	/* begin JumpBelow: */
	jumpNotIndexablePointers = genoperand(JumpBelow, ((sqInt)0));
	/* begin JumpNonZero: */
	jumpHasFixedFields = genoperand(JumpNonZero, ((sqInt)0));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpArrayOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	operandOne = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	checkQuickConstantforInstruction(operandOne, genoperandoperand(AddCqR, operandOne, Arg0Reg));
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, Arg1Reg, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpHasFixedFields, gLabel());
	genGetClassIndexOfNonImminto(ReceiverResultReg, formatReg);
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(ClassMethodContextCompactIndex, genoperandoperand(CmpCqR, ClassMethodContextCompactIndex, formatReg));
	/* begin JumpZero: */
	jumpIsContext = genoperand(JumpZero, ((sqInt)0));
	/* begin PushR: */
	genoperand(PushR, ClassReg);
	genGetClassObjectOfClassIndexintoscratchReg(formatReg, ClassReg, TempReg);
	genLoadSlotsourceRegdestReg(InstanceSpecificationIndex, ClassReg, formatReg);
	/* begin PopR: */
	genoperand(PopR, ClassReg);
	genConvertSmallIntegerToIntegerInReg(formatReg);
	/* begin AndCq:R: */
	quickConstant2 = fixedFieldsOfClassFormatMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant2, genoperandoperand(AndCqR, quickConstant2, formatReg));
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	operandOne1 = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	checkQuickConstantforInstruction(operandOne1, genoperandoperand(AddCqR, operandOne1, formatReg));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpFixedFieldsOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddR:R: */
	genoperandoperand(AddRR, formatReg, Arg0Reg);
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, Arg1Reg, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpNotPointers, gCmpCqR(firstCompiledMethodFormat(), formatReg));
	/* begin JumpAboveOrEqual: */
	jumpIsCompiledMethod = genoperand(JumpAboveOrEqual, ((sqInt)0));
	jumpNonSmallIntegerValue = genJumpNotSmallIntegerscratchReg(Arg1Reg, TempReg);
	/* begin CmpCq:R: */
	quickConstant3 = firstByteFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant3, genoperandoperand(CmpCqR, quickConstant3, formatReg));
	/* begin JumpAboveOrEqual: */
	jumpIsBytes = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant4 = firstShortFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant4, genoperandoperand(CmpCqR, quickConstant4, formatReg));
	/* begin JumpAboveOrEqual: */
	jumpShortsUnsupported = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant5 = firstLongFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant5, genoperandoperand(CmpCqR, quickConstant5, formatReg));
	/* begin JumpBelow: */
	jumpNotIndexableBits = genoperand(JumpBelow, ((sqInt)0));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpWordsOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	operandOne2 = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	checkQuickConstantforInstruction(operandOne2, genoperandoperand(AddCqR, operandOne2, Arg0Reg));
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, TempReg, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpIsBytes, gCmpCqR(((0xFF << 1) | 1), Arg1Reg));
	/* begin JumpAbove: */
	jumpBytesOutOfRange = genoperand(JumpAbove, ((sqInt)0));
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, shiftForWord(), ClassReg);
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BytesPerWord - 1, genoperandoperand(AndCqR, BytesPerWord - 1, formatReg));
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpBytesOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BaseHeaderSize, genoperandoperand(AddCqR, BaseHeaderSize, Arg0Reg));
	/* begin MoveR:Xbr:R: */
	genoperandoperandoperand(MoveRXbrR, TempReg, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpIsContext, jmpTarget(jumpNotIndexableBits, jmpTarget(jumpBytesOutOfRange, jmpTarget(jumpIsCompiledMethod, jmpTarget(jumpArrayOutOfBounds, jmpTarget(jumpBytesOutOfBounds, jmpTarget(jumpShortsUnsupported, jmpTarget(jumpWordsOutOfBounds, jmpTarget(jumpNotIndexablePointers, jmpTarget(jumpNonSmallIntegerValue, jmpTarget(jumpFixedFieldsOutOfBounds, gLabel())))))))))));
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(AddCqR, 1, Arg0Reg));
	genConvertIntegerToSmallIntegerInReg(Arg0Reg);
	jmpTarget(jumpBadIndex, jmpTarget(jumpImmediate, gLabel()));
	return 0;
}


/*	Implement the guts of primitiveAt */

	/* CogObjectRepresentationFor32BitSpur>>#genInnerPrimitiveAt: */
static sqInt
genInnerPrimitiveAt(sqInt retNoffset)
{
    sqInt formatReg;
    AbstractInstruction *jumpArrayOutOfBounds;
    AbstractInstruction *jumpBadIndex;
    AbstractInstruction *jumpBytesDone;
    AbstractInstruction *jumpBytesOutOfBounds;
    AbstractInstruction *jumpFixedFieldsDone;
    AbstractInstruction *jumpFixedFieldsOutOfBounds;
    AbstractInstruction *jumpHasFixedFields;
    AbstractInstruction *jumpImmediate;
    AbstractInstruction * jumpIsArray;
    AbstractInstruction *jumpIsBytes;
    AbstractInstruction *jumpIsContext;
    AbstractInstruction *jumpIsShorts;
    AbstractInstruction * jumpIsWords;
    AbstractInstruction *jumpNotIndexable;
    AbstractInstruction *jumpShortsDone;
    AbstractInstruction *jumpShortsOutOfBounds;
    AbstractInstruction *jumpWordsDone;
    AbstractInstruction *jumpWordsOutOfBounds;
    AbstractInstruction *jumpWordTooBig;
    sqInt operandOne;
    sqInt operandOne1;
    sqInt operandOne2;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    sqInt quickConstant5;
    sqInt quickConstant6;


	/* c.f. StackInterpreter>>stSizeOf: SpurMemoryManager>>lengthOf:format: fixedFieldsOf:format:length: */

	jumpImmediate = genJumpImmediate(ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, Arg1Reg);
	jumpBadIndex = genJumpNotSmallInteger(Arg0Reg);
	genConvertSmallIntegerToIntegerInReg(Arg1Reg);
	/* begin SubCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(SubCqR, 1, Arg1Reg));
	genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(ReceiverResultReg, (formatReg = SendNumArgsReg), TempReg);
	genGetNumSlotsOfinto(ReceiverResultReg, ClassReg);
	/* begin CmpCq:R: */
	quickConstant = firstByteFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, formatReg));
	/* begin JumpAboveOrEqual: */
	jumpIsBytes = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant1 = arrayFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(CmpCqR, quickConstant1, formatReg));
	/* begin JumpZero: */
	jumpIsArray = genoperand(JumpZero, ((sqInt)0));
	/* begin JumpBelow: */
	jumpNotIndexable = genoperand(JumpBelow, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant2 = weakArrayFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant2, genoperandoperand(CmpCqR, quickConstant2, formatReg));
	/* begin JumpBelowOrEqual: */
	jumpHasFixedFields = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant3 = firstShortFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant3, genoperandoperand(CmpCqR, quickConstant3, formatReg));
	/* begin JumpAboveOrEqual: */
	jumpIsShorts = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant4 = firstLongFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant4, genoperandoperand(CmpCqR, quickConstant4, formatReg));
	/* begin JumpAboveOrEqual: */
	jumpIsWords = genoperand(JumpAboveOrEqual, ((sqInt)0));
	jmpTarget(jumpNotIndexable, gLabel());
	/* begin Jump: */
	jumpNotIndexable = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpIsBytes, gLogicalShiftLeftCqR(shiftForWord(), ClassReg));
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BytesPerWord - 1, genoperandoperand(AndCqR, BytesPerWord - 1, formatReg));
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpBytesOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BaseHeaderSize, genoperandoperand(AddCqR, BaseHeaderSize, Arg1Reg));
	/* begin MoveXbr:R:R: */
	genoperandoperandoperand(MoveXbrRR, Arg1Reg, ReceiverResultReg, ReceiverResultReg);
	genConvertIntegerToSmallIntegerInReg(ReceiverResultReg);
	/* begin Jump: */
	jumpBytesDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpIsShorts, gLogicalShiftLeftCqR((shiftForWord()) - 1, ClassReg));
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(AndCqR, 1, formatReg));
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpShortsOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddR:R: */
	genoperandoperand(AddRR, Arg1Reg, ReceiverResultReg);
	/* begin MoveM16:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(BaseHeaderSize, genoperandoperandoperand(MoveM16rR, BaseHeaderSize, ReceiverResultReg, ReceiverResultReg));
	genConvertIntegerToSmallIntegerInReg(ReceiverResultReg);
	/* begin Jump: */
	jumpShortsDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpIsWords, gCmpRR(Arg1Reg, ClassReg));
	/* begin JumpBelowOrEqual: */
	jumpWordsOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	operandOne = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	checkQuickConstantforInstruction(operandOne, genoperandoperand(AddCqR, operandOne, Arg1Reg));
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, Arg1Reg, ReceiverResultReg, TempReg);
	/* begin SubCq:R: */
	quickConstant6 = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant6, genoperandoperand(SubCqR, quickConstant6, Arg1Reg));
	jumpWordTooBig = jumpNotSmallIntegerUnsignedValueInRegister(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	genConvertIntegerToSmallIntegerInReg(ReceiverResultReg);
	/* begin Jump: */
	jumpWordsDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpHasFixedFields, gAndCqR(classIndexMask(), TempReg));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, formatReg);
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(ClassMethodContextCompactIndex, genoperandoperand(CmpCqR, ClassMethodContextCompactIndex, TempReg));
	/* begin JumpZero: */
	jumpIsContext = genoperand(JumpZero, ((sqInt)0));
	/* begin PushR: */
	genoperand(PushR, ClassReg);
	genGetClassObjectOfClassIndexintoscratchReg(formatReg, ClassReg, TempReg);
	genLoadSlotsourceRegdestReg(InstanceSpecificationIndex, ClassReg, formatReg);
	/* begin PopR: */
	genoperand(PopR, ClassReg);
	genConvertSmallIntegerToIntegerInReg(formatReg);
	/* begin AndCq:R: */
	quickConstant5 = fixedFieldsOfClassFormatMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant5, genoperandoperand(AndCqR, quickConstant5, formatReg));
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpFixedFieldsOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddR:R: */
	genoperandoperand(AddRR, formatReg, Arg1Reg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	operandOne1 = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	checkQuickConstantforInstruction(operandOne1, genoperandoperand(AddCqR, operandOne1, Arg1Reg));
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, Arg1Reg, ReceiverResultReg, ReceiverResultReg);
	/* begin Jump: */
	jumpFixedFieldsDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpIsArray, gCmpRR(Arg1Reg, ClassReg));
	/* begin JumpBelowOrEqual: */
	jumpArrayOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	operandOne2 = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	checkQuickConstantforInstruction(operandOne2, genoperandoperand(AddCqR, operandOne2, Arg1Reg));
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, Arg1Reg, ReceiverResultReg, ReceiverResultReg);
	jmpTarget(jumpFixedFieldsDone, jmpTarget(jumpWordsDone, jmpTarget(jumpShortsDone, jmpTarget(jumpBytesDone, gRetN(retNoffset)))));
	jmpTarget(jumpFixedFieldsOutOfBounds, jmpTarget(jumpArrayOutOfBounds, jmpTarget(jumpBytesOutOfBounds, jmpTarget(jumpShortsOutOfBounds, jmpTarget(jumpWordsOutOfBounds, jmpTarget(jumpWordTooBig, jmpTarget(jumpNotIndexable, jmpTarget(jumpIsContext, jmpTarget(jumpBadIndex, jmpTarget(jumpImmediate, gLabel()))))))))));
	return 0;
}

	/* CogObjectRepresentationFor32BitSpur>>#genInnerPrimitiveIdentityHash: */
static sqInt
genInnerPrimitiveIdentityHash(sqInt retNoffset)
{
    AbstractInstruction *jumpImm;
    AbstractInstruction *jumpNotSet;
    AbstractInstruction *jumpSI;
    AbstractInstruction * ret;

	jumpImm = genJumpImmediate(ReceiverResultReg);
	genGetHashFieldNonImmOfasSmallIntegerInto(ReceiverResultReg, TempReg);
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(ConstZero, genoperandoperand(CmpCqR, ConstZero, TempReg));
	/* begin JumpZero: */
	jumpNotSet = genoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin RetN: */
	ret = genoperand(RetN, retNoffset);
	jmpTarget(jumpImm, gLabel());
	jumpSI = genJumpSmallInteger(ReceiverResultReg);
	jmpTarget(jumpSI, ret);
	genConvertCharacterToSmallIntegerInReg(ReceiverResultReg);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)ret));
	jmpTarget(jumpNotSet, gLabel());
	return 0;
}


/*	Implement primitiveNewWithArg for convenient cases:
	- the receiver has a hash
	- the receiver is variable and not compiled method
	- single word header/num slots < numSlotsMask
	- the result fits in eden
	See superclass method for dynamic frequencies of formats.
	For the moment we implement only arrayFormat, firstByteFormat &
	firstLongFormat 
 */

	/* CogObjectRepresentationFor32BitSpur>>#genInnerPrimitiveNewWithArg: */
static sqInt
genInnerPrimitiveNewWithArg(sqInt retNoffset)
{
    sqInt address;
    sqInt address1;
    sqInt byteSizeReg;
    AbstractInstruction *fillLoop;
    sqInt fillReg;
    sqInt halfHeaderReg;
    sqInt instSpecReg;
    AbstractInstruction *jumpArrayFormat;
    AbstractInstruction *jumpArrayTooBig;
    AbstractInstruction *jumpByteFormat;
    AbstractInstruction *jumpBytePrepDone;
    AbstractInstruction *jumpByteTooBig;
    AbstractInstruction *jumpFailCuzFixed;
    AbstractInstruction *jumpHasSlots;
    AbstractInstruction *jumpLongPrepDone;
    AbstractInstruction *jumpLongTooBig;
    AbstractInstruction *jumpNElementsNonInt;
    AbstractInstruction *jumpNoSpace;
    AbstractInstruction *jumpUnhashed;
    sqInt maxSlots;
    sqInt operandOne;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    sqInt quickConstant5;
    sqInt quickConstant6;
    sqInt quickConstant7;
    AbstractInstruction *skip;
    sqInt wordConstant;


	/* half header will contain 1st half of header (classIndex/class's hash & format),
	   then 2nd half of header (numSlots) and finally fill value (nilObject). */


	/* inst spec will hold class's instance specification and then byte size and finally numSlots half of header */

	halfHeaderReg = (fillReg = SendNumArgsReg);

	/* The max slots we'll allocate here are those for a single header */

	instSpecReg = (byteSizeReg = ClassReg);

	/* get freeStart as early as possible so as not to wait later... */

	maxSlots = (numSlotsMask()) - 1;
	/* begin MoveAw:R: */
	address = freeStartAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, Arg1Reg));
	genGetHashFieldNonImmOfinto(ReceiverResultReg, halfHeaderReg);
	/* begin JumpZero: */
	jumpUnhashed = genoperand(JumpZero, ((sqInt)0));

	/* get class's format inst var for inst spec (format field) */

	jumpNElementsNonInt = genJumpNotSmallInteger(Arg0Reg);
	genLoadSlotsourceRegdestReg(InstanceSpecificationIndex, ReceiverResultReg, instSpecReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant = (fixedFieldsFieldWidth()) + (numSmallIntegerTagBits());
	genoperandoperand(LogicalShiftRightCqR, quickConstant, instSpecReg);
	/* begin AndCq:R: */
	quickConstant1 = formatMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(AndCqR, quickConstant1, instSpecReg));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, instSpecReg, TempReg);
	/* begin LogicalShiftLeftCq:R: */
	quickConstant2 = formatShift();
	genoperandoperand(LogicalShiftLeftCqR, quickConstant2, TempReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, TempReg, halfHeaderReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	/* begin CmpCq:R: */
	quickConstant3 = arrayFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant3, genoperandoperand(CmpCqR, quickConstant3, instSpecReg));
	/* begin JumpZero: */
	jumpArrayFormat = genoperand(JumpZero, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant4 = firstByteFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant4, genoperandoperand(CmpCqR, quickConstant4, instSpecReg));
	/* begin JumpZero: */
	jumpByteFormat = genoperand(JumpZero, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant5 = firstLongFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant5, genoperandoperand(CmpCqR, quickConstant5, instSpecReg));
	/* begin JumpNonZero: */
	jumpFailCuzFixed = genoperand(JumpNonZero, ((sqInt)0));
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(((maxSlots << 1) | 1), genoperandoperand(CmpCqR, ((maxSlots << 1) | 1), Arg0Reg));
	/* begin JumpAbove: */
	jumpLongTooBig = genoperand(JumpAbove, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, instSpecReg);
	/* begin PushCq: */
	/* begin gen:quickConstant: */
	checkQuickConstantforInstruction(0, genoperand(PushCq, 0));
	/* begin Jump: */
	jumpLongPrepDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpByteFormat, gCmpCqR((((maxSlots * BytesPerWord) << 1) | 1), Arg0Reg));
	/* begin JumpAbove: */
	jumpByteTooBig = genoperand(JumpAbove, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, instSpecReg);
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BytesPerWord, genoperandoperand(MoveCqR, BytesPerWord, TempReg));
	/* begin SubR:R: */
	genoperandoperand(SubRR, instSpecReg, TempReg);
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BytesPerWord - 1, genoperandoperand(AndCqR, BytesPerWord - 1, TempReg));
	/* begin LogicalShiftLeftCq:R: */
	quickConstant6 = formatShift();
	genoperandoperand(LogicalShiftLeftCqR, quickConstant6, TempReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, TempReg, halfHeaderReg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BytesPerWord - 1, genoperandoperand(AddCqR, BytesPerWord - 1, instSpecReg));
	/* begin LogicalShiftRightCq:R: */
	genoperandoperand(LogicalShiftRightCqR, shiftForWord(), instSpecReg);
	/* begin PushCq: */
	/* begin gen:quickConstant: */
	checkQuickConstantforInstruction(0, genoperand(PushCq, 0));
	/* begin Jump: */
	jumpBytePrepDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpArrayFormat, gCmpCqR(((maxSlots << 1) | 1), Arg0Reg));
	/* begin JumpAbove: */
	jumpArrayTooBig = genoperand(JumpAbove, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, instSpecReg);
	/* begin PushCw: */
	wordConstant = nilObject();
	/* begin gen:literal: */
	checkLiteralforInstruction(wordConstant, genoperand(PushCw, wordConstant));
	jmpTarget(jumpBytePrepDone, jmpTarget(jumpLongPrepDone, gLabel()));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveRMwr, halfHeaderReg, 0, Arg1Reg));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, instSpecReg, halfHeaderReg);
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, byteSizeReg));
	/* begin JumpNonZero: */
	jumpHasSlots = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BaseHeaderSize * 2, genoperandoperand(MoveCqR, BaseHeaderSize * 2, byteSizeReg));
	/* begin Jump: */
	skip = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpHasSlots, gMoveRR(byteSizeReg, TempReg));
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(AndCqR, 1, TempReg));
	/* begin AddR:R: */
	genoperandoperand(AddRR, TempReg, byteSizeReg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	operandOne = BaseHeaderSize / BytesPerWord;
	checkQuickConstantforInstruction(operandOne, genoperandoperand(AddCqR, operandOne, byteSizeReg));
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, shiftForWord(), byteSizeReg);
	jmpTarget(skip, gLogicalShiftLeftCqR(numSlotsHalfShift(), halfHeaderReg));
	/* begin AddR:R: */
	genoperandoperand(AddRR, Arg1Reg, byteSizeReg);
	/* begin CmpCq:R: */
	quickConstant7 = getScavengeThreshold();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant7, genoperandoperand(CmpCqR, quickConstant7, byteSizeReg));
	/* begin JumpAboveOrEqual: */
	jumpNoSpace = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin MoveR:Aw: */
	address1 = freeStartAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address1, genoperandoperand(MoveRAw, byteSizeReg, address1));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(4, genoperandoperandoperand(MoveRMwr, halfHeaderReg, 4, ReceiverResultReg));
	/* begin PopR: */
	genoperand(PopR, fillReg);
	/* begin LoadEffectiveAddressMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(BaseHeaderSize, genoperandoperandoperand(LoadEffectiveAddressMwrR, BaseHeaderSize, ReceiverResultReg, Arg1Reg));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	fillLoop = checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveRMwr, fillReg, 0, Arg1Reg));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(4, genoperandoperandoperand(MoveRMwr, fillReg, 4, Arg1Reg));
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(8, genoperandoperand(AddCqR, 8, Arg1Reg));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, byteSizeReg);
	/* begin JumpAbove: */
	genoperand(JumpAbove, ((sqInt)fillLoop));
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpNoSpace, gPopR(TempReg));
	jmpTarget(jumpUnhashed, jmpTarget(jumpFailCuzFixed, jmpTarget(jumpArrayTooBig, jmpTarget(jumpByteTooBig, jmpTarget(jumpLongTooBig, jmpTarget(jumpNElementsNonInt, gLabel()))))));
	return 0;
}


/*	Implement primitiveNew for convenient cases:
	- the receiver has a hash
	- the receiver is fixed size (excluding ephemerons to save instructions &
	miniscule time)
	- single word header/num slots < numSlotsMask
	- the result fits in eden (actually below scavengeThreshold)
 */

	/* CogObjectRepresentationFor32BitSpur>>#genInnerPrimitiveNew: */
static sqInt
genInnerPrimitiveNew(sqInt retNoffset)
{
    sqInt address;
    sqInt address1;
    sqInt byteSizeReg;
    AbstractInstruction *fillLoop;
    sqInt fillReg;
    sqInt halfHeaderReg;
    sqInt instSpecReg;
    AbstractInstruction *jumpHasSlots;
    AbstractInstruction *jumpNoSpace;
    AbstractInstruction *jumpTooBig;
    AbstractInstruction *jumpUnhashed;
    AbstractInstruction *jumpVariableOrEphemeron;
    sqInt operandOne;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    sqInt quickConstant5;
    sqInt quickConstant6;
    sqInt quickConstant7;
    AbstractInstruction *skip;


	/* half header will contain 1st half of header (classIndex/class's hash & format),
	   then 2nd half of header (numSlots/fixed size) and finally fill value (nilObject). */


	/* inst spec will hold class's instance specification, then byte size and finally end of new object. */

	halfHeaderReg = (fillReg = SendNumArgsReg);

	/* get freeStart as early as possible so as not to wait later... */

	instSpecReg = (byteSizeReg = ClassReg);
	/* begin MoveAw:R: */
	address = freeStartAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, Arg1Reg));
	genGetHashFieldNonImmOfinto(ReceiverResultReg, halfHeaderReg);
	/* begin JumpZero: */
	jumpUnhashed = genoperand(JumpZero, ((sqInt)0));
	genLoadSlotsourceRegdestReg(InstanceSpecificationIndex, ReceiverResultReg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, instSpecReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant = fixedFieldsFieldWidth();
	genoperandoperand(LogicalShiftRightCqR, quickConstant, TempReg);
	/* begin AndCq:R: */
	quickConstant1 = formatMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(AndCqR, quickConstant1, TempReg));
	/* begin AndCq:R: */
	quickConstant2 = fixedFieldsOfClassFormatMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant2, genoperandoperand(AndCqR, quickConstant2, instSpecReg));
	/* begin CmpCq:R: */
	quickConstant3 = nonIndexablePointerFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant3, genoperandoperand(CmpCqR, quickConstant3, TempReg));
	/* begin JumpAbove: */
	jumpVariableOrEphemeron = genoperand(JumpAbove, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant4 = numSlotsMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant4, genoperandoperand(CmpCqR, quickConstant4, instSpecReg));
	/* begin JumpAboveOrEqual: */
	jumpTooBig = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin LogicalShiftLeftCq:R: */
	quickConstant5 = formatShift();
	genoperandoperand(LogicalShiftLeftCqR, quickConstant5, TempReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, TempReg, halfHeaderReg);
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveRMwr, halfHeaderReg, 0, Arg1Reg));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, instSpecReg, halfHeaderReg);
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, byteSizeReg));
	/* begin JumpNonZero: */
	jumpHasSlots = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BaseHeaderSize * 2, genoperandoperand(MoveCqR, BaseHeaderSize * 2, byteSizeReg));
	/* begin Jump: */
	skip = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpHasSlots, gMoveRR(byteSizeReg, TempReg));
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(AndCqR, 1, TempReg));
	/* begin AddR:R: */
	genoperandoperand(AddRR, TempReg, byteSizeReg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	operandOne = BaseHeaderSize / BytesPerWord;
	checkQuickConstantforInstruction(operandOne, genoperandoperand(AddCqR, operandOne, byteSizeReg));
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, shiftForWord(), byteSizeReg);
	jmpTarget(skip, gLogicalShiftLeftCqR(numSlotsHalfShift(), halfHeaderReg));
	/* begin AddR:R: */
	genoperandoperand(AddRR, Arg1Reg, byteSizeReg);
	/* begin CmpCq:R: */
	quickConstant6 = getScavengeThreshold();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant6, genoperandoperand(CmpCqR, quickConstant6, byteSizeReg));
	/* begin JumpAboveOrEqual: */
	jumpNoSpace = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin MoveR:Aw: */
	address1 = freeStartAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address1, genoperandoperand(MoveRAw, byteSizeReg, address1));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(4, genoperandoperandoperand(MoveRMwr, halfHeaderReg, 4, Arg1Reg));
	/* begin LoadEffectiveAddressMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(BaseHeaderSize, genoperandoperandoperand(LoadEffectiveAddressMwrR, BaseHeaderSize, ReceiverResultReg, Arg1Reg));
	/* begin MoveCq:R: */
	quickConstant7 = nilObject();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant7, genoperandoperand(MoveCqR, quickConstant7, fillReg));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	fillLoop = checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveRMwr, fillReg, 0, Arg1Reg));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(4, genoperandoperandoperand(MoveRMwr, fillReg, 4, Arg1Reg));
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(8, genoperandoperand(AddCqR, 8, Arg1Reg));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, byteSizeReg);
	/* begin JumpAbove: */
	genoperand(JumpAbove, ((sqInt)fillLoop));
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpUnhashed, jmpTarget(jumpVariableOrEphemeron, jmpTarget(jumpTooBig, jmpTarget(jumpNoSpace, gLabel()))));
	return 0;
}


/*	Implement the guts of primitiveStringAtPut */

	/* CogObjectRepresentationFor32BitSpur>>#genInnerPrimitiveStringAtPut: */
static sqInt
genInnerPrimitiveStringAtPut(sqInt retNoffset)
{
    sqInt formatReg;
    AbstractInstruction *jumpBadArg;
    AbstractInstruction *jumpBadIndex;
    AbstractInstruction *jumpBytesOutOfBounds;
    AbstractInstruction * jumpBytesOutOfRange;
    AbstractInstruction *jumpIsBytes;
    AbstractInstruction * jumpIsCompiledMethod;
    AbstractInstruction * jumpNotString;
    AbstractInstruction *jumpShortsUnsupported;
    AbstractInstruction *jumpWordsDone;
    AbstractInstruction *jumpWordsOutOfBounds;
    sqInt operandOne;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;


	/* c.f. StackInterpreter>>stSizeOf: SpurMemoryManager>>lengthOf:format: fixedFieldsOf:format:length: */

	jumpBadIndex = genJumpNotSmallInteger(Arg0Reg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, TempReg);
	jumpBadArg = genJumpNotCharacterInScratchReg(TempReg);
	genConvertSmallIntegerToIntegerInReg(Arg0Reg);
	/* begin SubCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(SubCqR, 1, Arg0Reg));
	genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(ReceiverResultReg, (formatReg = SendNumArgsReg), null);
	genGetNumSlotsOfinto(ReceiverResultReg, ClassReg);
	/* begin CmpCq:R: */
	quickConstant = firstLongFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, formatReg));
	/* begin JumpBelowOrEqual: */
	jumpNotString = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant1 = firstCompiledMethodFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(CmpCqR, quickConstant1, formatReg));
	/* begin JumpAboveOrEqual: */
	jumpIsCompiledMethod = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant2 = firstByteFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant2, genoperandoperand(CmpCqR, quickConstant2, formatReg));
	/* begin JumpGreaterOrEqual: */
	jumpIsBytes = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant3 = firstShortFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant3, genoperandoperand(CmpCqR, quickConstant3, formatReg));
	/* begin JumpGreaterOrEqual: */
	jumpShortsUnsupported = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpWordsOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	operandOne = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	checkQuickConstantforInstruction(operandOne, genoperandoperand(AddCqR, operandOne, Arg0Reg));
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, TempReg, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin Jump: */
	jumpWordsDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpIsBytes, gCmpCqR(characterObjectOf(0xFF), Arg1Reg));
	/* begin JumpAbove: */
	jumpBytesOutOfRange = genoperand(JumpAbove, ((sqInt)0));
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, shiftForWord(), ClassReg);
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BytesPerWord - 1, genoperandoperand(AndCqR, BytesPerWord - 1, formatReg));
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpBytesOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, TempReg);
	genConvertCharacterToCodeInReg(TempReg);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BaseHeaderSize, genoperandoperand(AddCqR, BaseHeaderSize, Arg0Reg));
	/* begin MoveR:Xbr:R: */
	genoperandoperandoperand(MoveRXbrR, TempReg, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	jmpTarget(jumpWordsDone, gRetN(retNoffset));
	jmpTarget(jumpBadArg, jmpTarget(jumpNotString, jmpTarget(jumpBytesOutOfRange, jmpTarget(jumpIsCompiledMethod, jmpTarget(jumpBytesOutOfBounds, jmpTarget(jumpShortsUnsupported, jmpTarget(jumpWordsOutOfBounds, gLabel())))))));
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(AddCqR, 1, Arg0Reg));
	genConvertIntegerToSmallIntegerInReg(Arg0Reg);
	jmpTarget(jumpBadIndex, gLabel());
	return 0;
}


/*	Implement the guts of primitiveStringAt; dispatch on size */

	/* CogObjectRepresentationFor32BitSpur>>#genInnerPrimitiveStringAt: */
static sqInt
genInnerPrimitiveStringAt(sqInt retNoffset)
{
    AbstractInstruction *done;
    sqInt formatReg;
    AbstractInstruction *jumpBadIndex;
    AbstractInstruction *jumpBytesOutOfBounds;
    AbstractInstruction *jumpIsBytes;
    AbstractInstruction *jumpIsShorts;
    AbstractInstruction *jumpIsWords;
    AbstractInstruction *jumpNotIndexable;
    AbstractInstruction *jumpShortsOutOfBounds;
    AbstractInstruction *jumpWordsOutOfBounds;
    AbstractInstruction *jumpWordTooBig;
    sqInt operandOne;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;


	/* c.f. StackInterpreter>>stSizeOf: SpurMemoryManager>>lengthOf:format: fixedFieldsOf:format:length: */

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, Arg1Reg);
	jumpBadIndex = genJumpNotSmallInteger(Arg0Reg);
	genConvertSmallIntegerToIntegerInReg(Arg1Reg);
	/* begin SubCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(SubCqR, 1, Arg1Reg));
	genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(ReceiverResultReg, (formatReg = SendNumArgsReg), null);
	genGetNumSlotsOfinto(ReceiverResultReg, ClassReg);
	/* begin CmpCq:R: */
	quickConstant = firstByteFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, formatReg));
	/* begin JumpGreaterOrEqual: */
	jumpIsBytes = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant1 = firstShortFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(CmpCqR, quickConstant1, formatReg));
	/* begin JumpGreaterOrEqual: */
	jumpIsShorts = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant2 = firstLongFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant2, genoperandoperand(CmpCqR, quickConstant2, formatReg));
	/* begin JumpGreaterOrEqual: */
	jumpIsWords = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin Jump: */
	jumpNotIndexable = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpIsBytes, gLogicalShiftLeftCqR(shiftForWord(), ClassReg));
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BytesPerWord - 1, genoperandoperand(AndCqR, BytesPerWord - 1, formatReg));
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpBytesOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BaseHeaderSize, genoperandoperand(AddCqR, BaseHeaderSize, Arg1Reg));
	/* begin MoveXbr:R:R: */
	genoperandoperandoperand(MoveXbrRR, Arg1Reg, ReceiverResultReg, ReceiverResultReg);
	/* begin Label */
	done = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	genConvertIntegerToCharacterInReg(ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpIsShorts, gLogicalShiftLeftCqR((shiftForWord()) - 1, ClassReg));
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(AndCqR, 1, formatReg));
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpShortsOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddR:R: */
	genoperandoperand(AddRR, Arg1Reg, ReceiverResultReg);
	/* begin MoveM16:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(BaseHeaderSize, genoperandoperandoperand(MoveM16rR, BaseHeaderSize, ReceiverResultReg, ReceiverResultReg));
	/* begin Jump: */
	genoperand(Jump, ((sqInt)done));
	jmpTarget(jumpIsWords, gCmpRR(Arg1Reg, ClassReg));
	/* begin JumpBelowOrEqual: */
	jumpWordsOutOfBounds = genoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	operandOne = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	checkQuickConstantforInstruction(operandOne, genoperandoperand(AddCqR, operandOne, Arg1Reg));
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, Arg1Reg, ReceiverResultReg, TempReg);
	/* begin SubCq:R: */
	quickConstant3 = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant3, genoperandoperand(SubCqR, quickConstant3, Arg1Reg));
	jumpWordTooBig = jumpNotCharacterUnsignedValueInRegister(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)done));
	jmpTarget(jumpBytesOutOfBounds, jmpTarget(jumpShortsOutOfBounds, jmpTarget(jumpWordsOutOfBounds, jmpTarget(jumpWordTooBig, jmpTarget(jumpNotIndexable, jmpTarget(jumpBadIndex, gLabel()))))));
	return 0;
}

	/* CogObjectRepresentationFor32BitSpur>>#genJumpNotSmallIntegerInScratchReg: */
static AbstractInstruction *
genJumpNotSmallIntegerInScratchReg(sqInt aRegister)
{
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(AndCqR, 1, aRegister));
	/* begin JumpZero: */
	return genoperand(JumpZero, ((sqInt)0));
}

	/* CogObjectRepresentationFor32BitSpur>>#genJumpNotSmallInteger: */
static AbstractInstruction *
genJumpNotSmallInteger(sqInt aRegister)
{
	/* begin TstCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(TstCqR, 1, aRegister));
	/* begin JumpZero: */
	return genoperand(JumpZero, ((sqInt)0));
}

	/* CogObjectRepresentationFor32BitSpur>>#genJumpSmallInteger: */
static AbstractInstruction *
genJumpSmallInteger(sqInt aRegister)
{
	/* begin TstCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(TstCqR, 1, aRegister));
	/* begin JumpNonZero: */
	return genoperand(JumpNonZero, ((sqInt)0));
}


/*	Generate a call to code that allocates a new Array of size.
	The Array should be initialized with nils iff initialized is true.
	The size arg is passed in SendNumArgsReg, the result
	must come back in ReceiverResultReg. */

	/* CogObjectRepresentationFor32BitSpur>>#genNewArrayOfSize:initialized: */
static sqInt
genNewArrayOfSizeinitialized(sqInt size, sqInt initialized)
{
    AbstractInstruction *abstractInstruction;
    sqInt address;
    sqInt address1;
    sqInt constant;
    usqLong header;
    sqInt i;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    AbstractInstruction *skip;

	assert(size < (numSlotsMask()));
	header = headerForSlotsformatclassIndex(size, arrayFormat(), ClassArrayCompactIndex);
	flag("endianness");
	/* begin MoveAw:R: */
	address = freeStartAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, ReceiverResultReg));
	/* begin MoveCq:R: */
	quickConstant = ((usqInt) header);
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(MoveCqR, quickConstant, TempReg));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveRMwr, TempReg, 0, ReceiverResultReg));
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(header >> 32, genoperandoperand(MoveCqR, header >> 32, TempReg));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(4, genoperandoperandoperand(MoveRMwr, TempReg, 4, ReceiverResultReg));
	if (initialized
	 && (size > 0)) {
		/* begin genMoveConstant:R: */
		constant = nilObject();
		if (shouldAnnotateObjectReference(constant)) {
			annotateobjRef(gMoveCwR(constant, TempReg), constant);
		}
		else {
			/* begin MoveCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, TempReg));
		}
		for (i = 1; i <= size; i += 1) {
			/* begin MoveR:Mw:r: */
			/* begin gen:operand:quickConstant:operand: */
			checkQuickConstantforInstruction((i * 4) + 4, genoperandoperandoperand(MoveRMwr, TempReg, (i * 4) + 4, ReceiverResultReg));
		}
	}
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	/* begin AddCq:R: */
	quickConstant1 = smallObjectBytesForSlots(size);
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(AddCqR, quickConstant1, TempReg));
	/* begin MoveR:Aw: */
	address1 = freeStartAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address1, genoperandoperand(MoveRAw, TempReg, address1));
	/* begin CmpCq:R: */
	quickConstant2 = getScavengeThreshold();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant2, genoperandoperand(CmpCqR, quickConstant2, TempReg));
	/* begin JumpBelow: */
	skip = genoperand(JumpBelow, ((sqInt)0));
	/* begin CallRT: */
	/* begin annotateCall: */
	/* begin Call: */
	abstractInstruction = genoperand(Call, ceScheduleScavengeTrampoline);
	(abstractInstruction->annotation = IsRelativeCall);
	abstractInstruction;
	jmpTarget(skip, gLabel());
	return 0;
}


/*	Create a closure with the given startpc, numArgs and numCopied
	within a context with ctxtNumArgs, large if isLargeCtxt that is in a
	block if isInBlock. Do /not/ initialize the copied values. */

	/* CogObjectRepresentationFor32BitSpur>>#genNoPopCreateClosureAt:numArgs:numCopied:contextNumArgs:large:inBlock: */
static sqInt
genNoPopCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(sqInt bcpc, sqInt numArgs, sqInt numCopied, sqInt ctxtNumArgs, sqInt isLargeCtxt, sqInt isInBlock)
{
    AbstractInstruction *abstractInstruction;
    sqInt address;
    sqInt address1;
    usqLong header;
    sqInt offset;
    sqInt offset1;
    sqInt offset2;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    AbstractInstruction *skip;
    sqInt slotSize;


	/* First get thisContext into ReceiverResultRega and thence in ClassReg. */

	genGetActiveContextNumArgslargeinBlock(ctxtNumArgs, isLargeCtxt, isInBlock);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, ClassReg);
	slotSize = ClosureFirstCopiedValueIndex + numCopied;
	header = headerForSlotsformatclassIndex(slotSize, indexablePointersFormat(), ClassBlockClosureCompactIndex);
	/* begin MoveAw:R: */
	address = freeStartAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, ReceiverResultReg));
	/* begin MoveCq:R: */
	quickConstant = ((usqInt) header);
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(MoveCqR, quickConstant, TempReg));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveRMwr, TempReg, 0, ReceiverResultReg));
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(header >> 32, genoperandoperand(MoveCqR, header >> 32, TempReg));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(4, genoperandoperandoperand(MoveRMwr, TempReg, 4, ReceiverResultReg));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	/* begin AddCq:R: */
	quickConstant1 = smallObjectBytesForSlots(slotSize);
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(AddCqR, quickConstant1, TempReg));
	/* begin MoveR:Aw: */
	address1 = freeStartAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address1, genoperandoperand(MoveRAw, TempReg, address1));
	/* begin CmpCq:R: */
	quickConstant2 = getScavengeThreshold();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant2, genoperandoperand(CmpCqR, quickConstant2, TempReg));
	/* begin JumpBelow: */
	skip = genoperand(JumpBelow, ((sqInt)0));
	/* begin CallRT: */
	/* begin annotateCall: */
	/* begin Call: */
	abstractInstruction = genoperand(Call, ceScheduleScavengeTrampoline);
	(abstractInstruction->annotation = IsRelativeCall);
	abstractInstruction;
	jmpTarget(skip, gLabel());
	/* begin MoveR:Mw:r: */
	offset = (ClosureOuterContextIndex * BytesPerOop) + BaseHeaderSize;
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveRMwr, ClassReg, offset, ReceiverResultReg));
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(((bcpc << 1) | 1), genoperandoperand(MoveCqR, ((bcpc << 1) | 1), TempReg));
	/* begin MoveR:Mw:r: */
	offset1 = (ClosureStartPCIndex * BytesPerOop) + BaseHeaderSize;
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset1, genoperandoperandoperand(MoveRMwr, TempReg, offset1, ReceiverResultReg));
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(((numArgs << 1) | 1), genoperandoperand(MoveCqR, ((numArgs << 1) | 1), TempReg));
	/* begin MoveR:Mw:r: */
	offset2 = (ClosureNumArgsIndex * BytesPerOop) + BaseHeaderSize;
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset2, genoperandoperandoperand(MoveRMwr, TempReg, offset2, ReceiverResultReg));
	return 0;
}

	/* CogObjectRepresentationFor32BitSpur>>#genRemoveSmallIntegerTagsInScratchReg: */
static sqInt
genRemoveSmallIntegerTagsInScratchReg(sqInt scratchReg)
{
	/* begin SubCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(SubCqR, 1, scratchReg));
	return 0;
}

	/* CogObjectRepresentationFor32BitSpur>>#genSetSmallIntegerTagsIn: */
static sqInt
genSetSmallIntegerTagsIn(sqInt scratchReg)
{
	/* begin OrCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(OrCqR, 1, scratchReg));
	return 0;
}

	/* CogObjectRepresentationFor32BitSpur>>#genShiftAwaySmallIntegerTagsInScratchReg: */
static sqInt
genShiftAwaySmallIntegerTagsInScratchReg(sqInt scratchReg)
{
	/* begin ArithmeticShiftRightCq:R: */
	genoperandoperand(ArithmeticShiftRightCqR, 1, scratchReg);
	return 0;
}


/*	Answer the relevant inline cache tag for an instance.
	c.f. getInlineCacheClassTagFrom:into: & inlineCacheTagForClass: */

	/* CogObjectRepresentationFor32BitSpur>>#inlineCacheTagForInstance: */
static sqInt
inlineCacheTagForInstance(sqInt oop)
{
	return (isImmediate(oop)
		? oop & 1
		: classIndexOf(oop));
}

	/* CogObjectRepresentationFor32BitSpur>>#jumpNotSmallIntegerUnsignedValueInRegister: */
static AbstractInstruction *
jumpNotSmallIntegerUnsignedValueInRegister(sqInt reg)
{
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0x3FFFFFFF, genoperandoperand(CmpCqR, 0x3FFFFFFF, reg));
	/* begin JumpAbove: */
	return genoperand(JumpAbove, ((sqInt)0));
}

	/* CogObjectRepresentationFor32BitSpur>>#log2BytesPerWord */
static sqInt
log2BytesPerWord(void)
{
	return 2;
}

	/* CogObjectRepresentationFor32BitSpur>>#numCharacterBits */
static sqInt
numCharacterBits(void)
{
	return 30;
}

	/* CogObjectRepresentationFor32BitSpur>>#numSmallIntegerBits */
static sqInt
numSmallIntegerBits(void)
{
	return 0x1F;
}

	/* CogObjectRepresentationFor32BitSpur>>#numSmallIntegerTagBits */
static sqInt
numSmallIntegerTagBits(void)
{
	return 1;
}


/*	The two valid tag patterns are 0 (Character) and 1 (SmallInteger) */

	/* CogObjectRepresentationFor32BitSpur>>#validInlineCacheTag: */
static sqInt
validInlineCacheTag(usqInt classIndexOrTagPattern)
{
	return (classIndexOrTagPattern <= 1)
	 || ((classAtIndex(classIndexOrTagPattern)) != null);
}

	/* CogObjectRepresentationForSpur>>#allYoungObjectsAgeInFullGC */
static sqInt
allYoungObjectsAgeInFullGC(void)
{
	return 0;
}


/*	Answer if the cacheTag is not unmarked, i.e. answer true for compact class
	indices and immediates; only answer false for unmarked objects. In Spur
	linked send cache tags are class indices so effectively they're always
	marked.  */

	/* CogObjectRepresentationForSpur>>#cacheTagIsMarked: */
static sqInt
cacheTagIsMarked(sqInt cacheTag)
{
	return 1;
}

	/* CogObjectRepresentationForSpur>>#checkValidOopReference: */
static sqInt
checkValidOopReference(sqInt anOop)
{
	return (isImmediate(anOop))
	 || ((heapMapAtWord(pointerForOop(anOop))) != 0);
}

	/* CogObjectRepresentationForSpur>>#couldBeObject: */
static sqInt
couldBeObject(sqInt literal)
{
	return (isNonImmediate(literal))
	 && (oopisGreaterThanOrEqualTo(literal, startOfMemory()));
}


/*	Answer if the object representation allocates closures inline. By
	default answer false. Better code can be generated when creating
	closures inline if copied values are /not/ flushed to the stack. */

	/* CogObjectRepresentationForSpur>>#createsClosuresInline */
static sqInt
createsClosuresInline(void)
{
	return 1;
}


/*	Create a trampoline to answer the active context that will
	answer it if a frame is already married, and create it otherwise.
	Assume numArgs is in SendNumArgsReg and ClassReg is free. */

	/* CogObjectRepresentationForSpur>>#genActiveContextTrampolineLarge:inBlock:called: */
static sqInt
genActiveContextTrampolineLargeinBlockcalled(sqInt isLarge, sqInt isInBlock, char *aString)
{
    sqInt startAddress;

	startAddress = methodZoneBase();
	zeroOpcodeIndex();
	genGetActiveContextLargeinBlock(isLarge, isInBlock);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress(aString, startAddress);
	recordRunTimeObjectReferences();
	return startAddress;
}

	/* CogObjectRepresentationForSpur>>#genAllocFloatValue:into:scratchReg:scratchReg: */
static AbstractInstruction *
genAllocFloatValueintoscratchRegscratchReg(sqInt dpreg, sqInt resultReg, sqInt scratch1, sqInt scratch2)
{
    sqInt address;
    sqInt address1;
    sqInt allocSize;
    AbstractInstruction *jumpFail;
    usqLong newFloatHeader;
    sqInt quickConstant;

	allocSize = BaseHeaderSize + (sizeof(double));
	newFloatHeader = headerForSlotsformatclassIndex((sizeof(double)) / BytesPerWord, firstLongFormat(), ClassFloatCompactIndex);
	/* begin MoveAw:R: */
	address = freeStartAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, resultReg));
	/* begin LoadEffectiveAddressMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(allocSize, genoperandoperandoperand(LoadEffectiveAddressMwrR, allocSize, resultReg, scratch1));
	/* begin CmpCq:R: */
	quickConstant = getScavengeThreshold();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, scratch1));
	/* begin JumpAboveOrEqual: */
	jumpFail = genoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin MoveR:Aw: */
	address1 = freeStartAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address1, genoperandoperand(MoveRAw, scratch1, address1));
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(((sqInt) newFloatHeader), genoperandoperand(MoveCqR, ((sqInt) newFloatHeader), scratch2));
	flag("endianness");
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(newFloatHeader >> 32, genoperandoperand(MoveCqR, newFloatHeader >> 32, scratch1));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveRMwr, scratch2, 0, resultReg));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(BytesPerWord, genoperandoperandoperand(MoveRMwr, scratch1, BytesPerWord, resultReg));

	/* begin MoveRd:M64:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(BaseHeaderSize, genoperandoperandoperand(MoveRdM64r, dpreg, BaseHeaderSize, resultReg));
	return jumpFail;
}

	/* CogObjectRepresentationForSpur>>#genConvertCharacterToCodeInReg: */
static sqInt
genConvertCharacterToCodeInReg(sqInt reg)
{
    sqInt quickConstant;

	/* begin LogicalShiftRightCq:R: */
	quickConstant = numTagBits();
	genoperandoperand(LogicalShiftRightCqR, quickConstant, reg);
	return 0;
}

	/* CogObjectRepresentationForSpur>>#genConvertIntegerToCharacterInReg: */
static sqInt
genConvertIntegerToCharacterInReg(sqInt reg)
{
    sqInt quickConstant;
    sqInt quickConstant1;

	/* begin LogicalShiftLeftCq:R: */
	quickConstant = numTagBits();
	genoperandoperand(LogicalShiftLeftCqR, quickConstant, reg);
	/* begin AddCq:R: */
	quickConstant1 = characterTag();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(AddCqR, quickConstant1, reg));
	return 0;
}


/*	Make sure that the object in reg is not forwarded. This routine assumes
	the object will
	never be forwarded to an immediate, as it is used to unforward literal
	variables (associations). 
	Use the fact that isForwardedObjectClassIndexPun is a power of two to save
	an instruction. */

	/* CogObjectRepresentationForSpur>>#genEnsureObjInRegNotForwarded:scratchReg: */
static sqInt
genEnsureObjInRegNotForwardedscratchReg(sqInt reg, sqInt scratch)
{
    AbstractInstruction *loop;
    AbstractInstruction *ok;
    sqInt quickConstant;

	assert(reg != scratch);
	/* begin Label */
	loop = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	/* begin MoveMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveMwrR, 0, reg, scratch));
	/* begin AndCq:R: */
	quickConstant = (classIndexMask()) - (isForwardedObjectClassIndexPun());
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(AndCqR, quickConstant, scratch));
	/* begin JumpNonZero: */
	ok = genoperand(JumpNonZero, ((sqInt)0));
	genLoadSlotsourceRegdestReg(0, reg, reg);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)loop));
	jmpTarget(ok, gLabel());
	return 0;
}

	/* CogObjectRepresentationForSpur>>#genEnsureOopInRegNotForwarded:scratchReg: */
static sqInt
genEnsureOopInRegNotForwardedscratchReg(sqInt reg, sqInt scratch)
{
	return genEnsureOopInRegNotForwardedscratchRegjumpBackTo(reg, scratch, gLabel());
}

	/* CogObjectRepresentationForSpur>>#genEnsureOopInRegNotForwarded:scratchReg:jumpBackTo: */
static sqInt
genEnsureOopInRegNotForwardedscratchRegjumpBackTo(sqInt reg, sqInt scratch, AbstractInstruction *instruction)
{
    AbstractInstruction *finished;
    AbstractInstruction *imm;
    AbstractInstruction *ok;
    sqInt quickConstant;

	/* begin genEnsureOopInRegNotForwarded:scratchReg:ifForwarder:ifNotForwarder: */
	assert(reg != scratch);

	/* notionally
	   self genGetClassIndexOfNonImm: reg into: scratch.
	   cogit CmpCq: objectMemory isForwardedObjectClassIndexPun R: TempReg.
	   but the following is an instruction shorter: */

	imm = genJumpImmediate(reg);
	/* begin MoveMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveMwrR, 0, reg, scratch));
	/* begin AndCq:R: */
	quickConstant = (classIndexMask()) - (isForwardedObjectClassIndexPun());
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(AndCqR, quickConstant, scratch));
	/* begin JumpNonZero: */
	ok = genoperand(JumpNonZero, ((sqInt)0));
	genLoadSlotsourceRegdestReg(0, reg, reg);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)(((void *) instruction))));
	/* begin Label */
	finished = genoperandoperand(Label, (labelCounter += 1), bytecodePC);

	jmpTarget(imm, jmpTarget(ok, finished));
	return 0;
}


/*	Make sure that the oop in reg is not forwarded, updating the slot in
	objReg with the value.
 */

	/* CogObjectRepresentationForSpur>>#genEnsureOopInRegNotForwarded:scratchReg:updatingSlot:in: */
static sqInt
genEnsureOopInRegNotForwardedscratchRegupdatingSlotin(sqInt reg, sqInt scratch, sqInt index, sqInt objReg)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *imm;
    AbstractInstruction *loop;
    sqInt offset;
    AbstractInstruction *ok;
    sqInt quickConstant;


	/* Open-code
	   self genEnsureOopInRegNotForwarded: reg
	   scratchReg: scratch
	   updatingMw: index * objectMemory wordSize + objectMemory baseHeaderSize
	   r: objReg.
	   to avoid calling the store check unless the receiver is forwarded. */

	assert((reg != scratch)
	 && (objReg != scratch));
	/* begin Label */
	loop = genoperandoperand(Label, (labelCounter += 1), bytecodePC);

	/* notionally
	   self genGetClassIndexOfNonImm: reg into: scratch.
	   cogit CmpCq: objectMemory isForwardedObjectClassIndexPun R: TempReg.
	   but the following is an instruction shorter: */

	imm = genJumpImmediate(reg);
	/* begin MoveMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveMwrR, 0, reg, scratch));
	/* begin AndCq:R: */
	quickConstant = (classIndexMask()) - (isForwardedObjectClassIndexPun());
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(AndCqR, quickConstant, scratch));
	/* begin JumpNonZero: */
	ok = genoperand(JumpNonZero, ((sqInt)0));
	genLoadSlotsourceRegdestReg(0, reg, reg);
	/* begin MoveR:Mw:r: */
	offset = (index * BytesPerWord) + BaseHeaderSize;
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveRMwr, reg, offset, objReg));
	assert((reg == Arg0Reg)
	 && ((scratch == TempReg)
	 && (objReg == ReceiverResultReg)));
	/* begin CallRT: */
	/* begin annotateCall: */
	/* begin Call: */
	abstractInstruction = genoperand(Call, ceStoreCheckContextReceiverTrampoline);
	(abstractInstruction->annotation = IsRelativeCall);
	abstractInstruction;
	/* begin Jump: */
	genoperand(Jump, ((sqInt)loop));
	jmpTarget(ok, jmpTarget(imm, gLabel()));
	return 0;
}


/*	Do the store check. Answer the argument for the benefit of the code
	generator; ReceiverResultReg may be caller-saved and hence smashed by this
	call. Answering
	it allows the code generator to reload ReceiverResultReg cheaply.
	In Spur the only thing we leave to the run-time is adding the receiver to
	the remembered set and setting its isRemembered bit. */

	/* CogObjectRepresentationForSpur>>#generateObjectRepresentationTrampolines */
static void
generateObjectRepresentationTrampolines(void)
{
	ceStoreCheckTrampoline = genTrampolineForcalledargresult(remember, "ceStoreCheckTrampoline", ReceiverResultReg, returnRegForStoreCheck());
	ceStoreCheckContextReceiverTrampoline = genStoreCheckContextReceiverTrampoline();
	ceScheduleScavengeTrampoline = genSafeTrampolineForcalled(ceScheduleScavenge, "ceScheduleScavengeTrampoline");
	ceSmallActiveContextInMethodTrampoline = genActiveContextTrampolineLargeinBlockcalled(0, 0, "ceSmallMethodContext");
	ceSmallActiveContextInBlockTrampoline = genActiveContextTrampolineLargeinBlockcalled(0, 1, "ceSmallBlockContext");
	ceLargeActiveContextInMethodTrampoline = genActiveContextTrampolineLargeinBlockcalled(1, 0, "ceLargeMethodContext");
	ceLargeActiveContextInBlockTrampoline = genActiveContextTrampolineLargeinBlockcalled(1, 1, "ceLargeBlockContext");
}


/*	Get the active context into ReceiverResultReg, creating it if necessary. */

	/* CogObjectRepresentationForSpur>>#genGetActiveContextNumArgs:large:inBlock: */
static sqInt
genGetActiveContextNumArgslargeinBlock(sqInt numArgs, sqInt isLargeContext, sqInt isInBlock)
{
    AbstractInstruction *abstractInstruction;
    sqInt routine;

	routine = (isLargeContext
		? (isInBlock
				? ceLargeActiveContextInBlockTrampoline
				: ceLargeActiveContextInMethodTrampoline)
		: (isInBlock
				? ceSmallActiveContextInBlockTrampoline
				: ceSmallActiveContextInMethodTrampoline));
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(numArgs, genoperandoperand(MoveCqR, numArgs, SendNumArgsReg));
	/* begin CallRT: */
	/* begin annotateCall: */
	/* begin Call: */
	abstractInstruction = genoperand(Call, routine);
	(abstractInstruction->annotation = IsRelativeCall);
	abstractInstruction;
	return 0;
}

	/* CogObjectRepresentationForSpur>>#genGetBits:ofFormatByteOf:into:baseHeaderIntoScratch: */
static sqInt
genGetBitsofFormatByteOfintobaseHeaderIntoScratch(sqInt mask, sqInt sourceReg, sqInt destReg, sqInt scratchReg)
{
    sqInt quickConstant;

	if (scratchReg == null) {
		flag("endianness");
		/* begin MoveMb:r:R: */
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(3, genoperandoperandoperand(MoveMbrR, 3, sourceReg, destReg));
	}
	else {
		/* begin MoveMw:r:R: */
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveMwrR, 0, sourceReg, destReg));
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, destReg, scratchReg);
		/* begin LogicalShiftRightCq:R: */
		quickConstant = formatShift();
		genoperandoperand(LogicalShiftRightCqR, quickConstant, destReg);
	}
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(mask, genoperandoperand(AndCqR, mask, destReg));
	return 0;
}


/*	Fetch the instance's class index into destReg. */

	/* CogObjectRepresentationForSpur>>#genGetClassIndexOfNonImm:into: */
static sqInt
genGetClassIndexOfNonImminto(sqInt sourceReg, sqInt destReg)
{
    sqInt quickConstant;

	/* begin MoveMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveMwrR, 0, sourceReg, destReg));
	/* begin AndCq:R: */
	quickConstant = classIndexMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(AndCqR, quickConstant, destReg));
	return 0;
}


/*	Fetch the class object whose index is in instReg into destReg.
	It is non-obvious, but the Cogit assumes loading a class does not involve
	a runtime call, so do not call classAtIndex: */

	/* CogObjectRepresentationForSpur>>#genGetClassObjectOfClassIndex:into:scratchReg: */
static sqInt
genGetClassObjectOfClassIndexintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg)
{
    sqInt offset;
    sqInt operandOne;
    sqInt quickConstant;
    sqInt quickConstant1;

	assert(instReg != destReg);
	assert(instReg != scratchReg);
	assert(destReg != scratchReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, instReg, scratchReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant = classTableMajorIndexShift();
	genoperandoperand(LogicalShiftRightCqR, quickConstant, scratchReg);
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, shiftForWord(), scratchReg);
	assert(!(shouldAnnotateObjectReference(classTableRootObj())));
	/* begin MoveMw:r:R: */
	offset = (classTableRootObj()) + BaseHeaderSize;
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveMwrR, offset, scratchReg, destReg));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, instReg, scratchReg);
	/* begin AndCq:R: */
	quickConstant1 = classTableMinorIndexMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(AndCqR, quickConstant1, scratchReg));
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	operandOne = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	checkQuickConstantforInstruction(operandOne, genoperandoperand(AddCqR, operandOne, scratchReg));
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, scratchReg, destReg, destReg);
	return 0;
}


/*	Fetch the instance's class into destReg. If the instance is not the
	receiver and is forwarded, follow forwarding. */

	/* CogObjectRepresentationForSpur>>#genGetClassObjectOf:into:scratchReg:instRegIsReceiver: */
static sqInt
genGetClassObjectOfintoscratchReginstRegIsReceiver(sqInt instReg, sqInt destReg, sqInt scratchReg, sqInt instRegIsReceiver)
{
    AbstractInstruction *jumpIsImm;
    AbstractInstruction *jumpNotForwarded;
    AbstractInstruction *loop;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;

	if (instReg == destReg) {
		return BadRegisterSet;
	}
	/* begin MoveR:R: */
	loop = genoperandoperand(MoveRR, instReg, scratchReg);
	/* begin AndCq:R: */
	quickConstant1 = tagMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(AndCqR, quickConstant1, scratchReg));
	/* begin JumpNonZero: */
	jumpIsImm = genoperand(JumpNonZero, ((sqInt)0));
	flag("endianness");
	/* begin MoveMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveMwrR, 0, instReg, scratchReg));
	/* begin AndCq:R: */
	quickConstant2 = classIndexMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant2, genoperandoperand(AndCqR, quickConstant2, scratchReg));
	if (!instRegIsReceiver) {

		/* if it is forwarded... */

		/* begin CmpCq:R: */
		quickConstant = isForwardedObjectClassIndexPun();
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, scratchReg));
		/* begin JumpNonZero: */
		jumpNotForwarded = genoperand(JumpNonZero, ((sqInt)0));
		/* begin MoveMw:r:R: */
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(BaseHeaderSize, genoperandoperandoperand(MoveMwrR, BaseHeaderSize, instReg, instReg));
		/* begin Jump: */
		genoperand(Jump, ((sqInt)loop));
		jmpTarget(jumpNotForwarded, gLabel());
	}
	jmpTarget(jumpIsImm, gMoveRR(scratchReg, destReg));
	/* begin PushR: */
	genoperand(PushR, instReg);
	genGetClassObjectOfClassIndexintoscratchReg(destReg, instReg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, instReg, destReg);
	/* begin PopR: */
	genoperand(PopR, instReg);
	return 0;
}


/*	Fetch the instance's class index into destReg. */

	/* CogObjectRepresentationForSpur>>#genGetCompactClassIndexNonImmOf:into: */
static sqInt
genGetCompactClassIndexNonImmOfinto(sqInt instReg, sqInt destReg)
{
	return genGetClassIndexOfNonImminto(instReg, destReg);
}

	/* CogObjectRepresentationForSpur>>#genGetDoubleValueOf:into: */
static sqInt
genGetDoubleValueOfinto(sqInt srcReg, sqInt destFPReg)
{
	/* begin MoveM64:r:Rd: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(BaseHeaderSize, genoperandoperandoperand(MoveM64rRd, BaseHeaderSize, srcReg, destFPReg));
	return 0;
}


/*	Get the format field of the object in srcReg into destReg.
	srcReg may equal destReg. */

	/* CogObjectRepresentationForSpur>>#genGetFormatOf:into: */
static sqInt
genGetFormatOfinto(sqInt srcReg, sqInt destReg)
{
	return genGetBitsofFormatByteOfintobaseHeaderIntoScratch(formatMask(), srcReg, destReg, null);
}


/*	Get the format of the object in sourceReg into destReg. If scratchRegOrNil
	is not nil, load at least the least significant 32-bits (64-bits in
	64-bits) of the
	header word, which contains the format, into scratchRegOrNil. */

	/* CogObjectRepresentationForSpur>>#genGetFormatOf:into:leastSignificantHalfOfBaseHeaderIntoScratch: */
static sqInt
genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(sqInt sourceReg, sqInt destReg, sqInt scratchRegOrNil)
{
    sqInt quickConstant;
    sqInt quickConstant1;

	if (scratchRegOrNil == null) {
		flag("endianness");
		/* begin MoveMb:r:R: */
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(3, genoperandoperandoperand(MoveMbrR, 3, sourceReg, destReg));
	}
	else {
		/* begin MoveMw:r:R: */
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveMwrR, 0, sourceReg, destReg));
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, destReg, scratchRegOrNil);
		/* begin LogicalShiftRightCq:R: */
		quickConstant = formatShift();
		genoperandoperand(LogicalShiftRightCqR, quickConstant, destReg);
	}
	/* begin AndCq:R: */
	quickConstant1 = formatMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(AndCqR, quickConstant1, destReg));
	return 0;
}


/*	The raw numSlots field is the most significant byte of the 64-bit header
	word. MoveMbrR zero-extends. */

	/* CogObjectRepresentationForSpur>>#genGetRawSlotSizeOfNonImm:into: */
static sqInt
genGetRawSlotSizeOfNonImminto(sqInt sourceReg, sqInt destReg)
{
	/* begin MoveMb:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(7, genoperandoperandoperand(MoveMbrR, 7, sourceReg, destReg));
	return 0;
}

	/* CogObjectRepresentationForSpur>>#genInnerPrimitiveAsCharacter:inReg: */
static sqInt
genInnerPrimitiveAsCharacterinReg(sqInt retNOffset, sqInt reg)
{
    AbstractInstruction *jumpNotInt;
    AbstractInstruction *jumpOutOfRange;

	if (reg != ReceiverResultReg) {
		jumpNotInt = genJumpNotSmallInteger(reg);
	}
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, reg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction((1 << 30) - 1, genoperandoperand(CmpCqR, (1 << 30) - 1, TempReg));
	/* begin JumpAbove: */
	jumpOutOfRange = genoperand(JumpAbove, ((sqInt)0));
	genConvertSmallIntegerToCharacterInReg(reg);
	if (reg != ReceiverResultReg) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, reg, ReceiverResultReg);
	}
	/* begin RetN: */
	genoperand(RetN, retNOffset);
	jmpTarget(jumpOutOfRange, gLabel());
	if (reg != ReceiverResultReg) {
		jmpTarget(jumpNotInt, getJmpTarget(jumpOutOfRange));
	}
	return 0;
}

	/* CogObjectRepresentationForSpur>>#genInnerPrimitiveCharacterValue: */
static sqInt
genInnerPrimitiveCharacterValue(sqInt retNOffset)
{
	genConvertCharacterToSmallIntegerInReg(ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNOffset);
	return UnfailingPrimitive;
}

	/* CogObjectRepresentationForSpur>>#genInnerPrimitiveIdentical:orNotIf: */
static sqInt
genInnerPrimitiveIdenticalorNotIf(sqInt retNoffset, sqInt orNot)
{
    sqInt constant;
    AbstractInstruction *jumpCmp;
    AbstractInstruction *jumpImmediate;

	jumpImmediate = genJumpImmediate(Arg0Reg);
	genEnsureObjInRegNotForwardedscratchReg(Arg0Reg, TempReg);
	jmpTarget(jumpImmediate, gCmpRR(Arg0Reg, ReceiverResultReg));
	if (orNot) {
		/* begin JumpZero: */
		jumpCmp = genoperand(JumpZero, ((sqInt)0));
	}
	else {
		/* begin JumpNonZero: */
		jumpCmp = genoperand(JumpNonZero, ((sqInt)0));
	}
	/* begin genMoveTrueR: */
	/* begin genMoveConstant:R: */
	constant = trueObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, ReceiverResultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, ReceiverResultReg));
	}
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpCmp, genMoveFalseR(ReceiverResultReg));
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	return 0;
}


/*	c.f. StackInterpreter>>stSizeOf: lengthOf:baseHeader:format:
	fixedFieldsOf:format:length: 
 */

	/* CogObjectRepresentationForSpur>>#genInnerPrimitiveSize: */
static sqInt
genInnerPrimitiveSize(sqInt retNoffset)
{
    sqInt jic;
    sqInt jnx;
    AbstractInstruction *jump32BitLongsDone;
    AbstractInstruction *jumpArrayDone;
    AbstractInstruction * jumpBytesDone;
    AbstractInstruction *jumpHasFixedFields;
    AbstractInstruction *jumpImm;
    AbstractInstruction *jumpIsBytes;
    AbstractInstruction *jumpIsContext;
    AbstractInstruction *jumpIsContext1;
    AbstractInstruction *jumpIsShorts;
    AbstractInstruction *jumpNotIndexable;
    AbstractInstruction *jumpNotIndexable1;
    AbstractInstruction * jumpShortsDone;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    sqInt quickConstant5;

	jumpImm = genJumpImmediate(ReceiverResultReg);
	/* begin genGetSizeOf:into:formatReg:scratchReg:abortJumpsInto: */
	genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(ReceiverResultReg, SendNumArgsReg, TempReg);
	genGetNumSlotsOfinto(ReceiverResultReg, ClassReg);
	/* begin CmpCq:R: */
	quickConstant = firstByteFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, SendNumArgsReg));
	/* begin JumpGreaterOrEqual: */
	jumpIsBytes = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant1 = arrayFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(CmpCqR, quickConstant1, SendNumArgsReg));
	/* begin JumpZero: */
	jumpArrayDone = genoperand(JumpZero, ((sqInt)0));
	/* begin JumpLess: */
	jumpNotIndexable1 = genoperand(JumpLess, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant2 = weakArrayFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant2, genoperandoperand(CmpCqR, quickConstant2, SendNumArgsReg));
	/* begin JumpLessOrEqual: */
	jumpHasFixedFields = genoperand(JumpLessOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant3 = firstShortFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant3, genoperandoperand(CmpCqR, quickConstant3, SendNumArgsReg));
	/* begin JumpGreaterOrEqual: */
	jumpIsShorts = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant4 = firstLongFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant4, genoperandoperand(CmpCqR, quickConstant4, SendNumArgsReg));
	/* begin JumpGreaterOrEqual: */
	jump32BitLongsDone = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	jmpTarget(jumpNotIndexable1, gLabel());
	/* begin Jump: */
	jumpNotIndexable1 = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpIsBytes, gLogicalShiftLeftCqR(shiftForWord(), ClassReg));
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(BytesPerWord - 1, genoperandoperand(AndCqR, BytesPerWord - 1, SendNumArgsReg));
	/* begin SubR:R: */
	genoperandoperand(SubRR, SendNumArgsReg, ClassReg);
	/* begin Jump: */
	jumpBytesDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpIsShorts, gLogicalShiftLeftCqR((shiftForWord()) - 1, ClassReg));
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(AndCqR, 1, SendNumArgsReg));
	/* begin SubR:R: */
	genoperandoperand(SubRR, SendNumArgsReg, ClassReg);
	/* begin Jump: */
	jumpShortsDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpHasFixedFields, gAndCqR(classIndexMask(), TempReg));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, SendNumArgsReg);
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(ClassMethodContextCompactIndex, genoperandoperand(CmpCqR, ClassMethodContextCompactIndex, TempReg));
	/* begin JumpZero: */
	jumpIsContext1 = genoperand(JumpZero, ((sqInt)0));
	/* begin PushR: */
	genoperand(PushR, ClassReg);
	genGetClassObjectOfClassIndexintoscratchReg(SendNumArgsReg, ClassReg, TempReg);
	genLoadSlotsourceRegdestReg(InstanceSpecificationIndex, ClassReg, SendNumArgsReg);
	genConvertSmallIntegerToIntegerInReg(SendNumArgsReg);
	/* begin PopR: */
	genoperand(PopR, ClassReg);
	/* begin AndCq:R: */
	quickConstant5 = fixedFieldsOfClassFormatMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant5, genoperandoperand(AndCqR, quickConstant5, SendNumArgsReg));
	/* begin SubR:R: */
	genoperandoperand(SubRR, SendNumArgsReg, ClassReg);
	jmpTarget(jumpArrayDone, jmpTarget(jump32BitLongsDone, jmpTarget(jumpShortsDone, jmpTarget(jumpBytesDone, gLabel()))));
	jumpNotIndexable = jumpNotIndexable1;
	jumpIsContext = jumpIsContext1;

	genConvertIntegerToSmallIntegerInReg(ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, retNoffset);
	jmpTarget(jumpImm, jmpTarget(jumpNotIndexable, jmpTarget(jumpIsContext, gLabel())));
	return 0;
}

	/* CogObjectRepresentationForSpur>>#genJumpImmediate: */
static AbstractInstruction *
genJumpImmediate(sqInt aRegister)
{
    sqInt quickConstant;

	/* begin TstCq:R: */
	quickConstant = tagMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(TstCqR, quickConstant, aRegister));
	/* begin JumpNonZero: */
	return genoperand(JumpNonZero, ((sqInt)0));
}

	/* CogObjectRepresentationForSpur>>#genJumpNotCharacterInScratchReg: */
static AbstractInstruction *
genJumpNotCharacterInScratchReg(sqInt reg)
{
    sqInt quickConstant;
    sqInt quickConstant1;

	/* begin AndCq:R: */
	quickConstant = tagMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(AndCqR, quickConstant, reg));
	/* begin CmpCq:R: */
	quickConstant1 = characterTag();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(CmpCqR, quickConstant1, reg));
	/* begin JumpNonZero: */
	return genoperand(JumpNonZero, ((sqInt)0));
}


/*	Create a trampoline to store-check the update of the receiver in a
	closure's outerContext in compileBlockFrameBuild:. */

	/* CogObjectRepresentationForSpur>>#genStoreCheckContextReceiverTrampoline */
static sqInt
genStoreCheckContextReceiverTrampoline(void)
{
    sqInt startAddress;

	startAddress = methodZoneBase();
	zeroOpcodeIndex();
	genStoreCheckReceiverRegvalueRegscratchReginFrame(ReceiverResultReg, Arg0Reg, TempReg, 0);
	/* begin RetN: */
	genoperand(RetN, 0);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceStoreCheckContextReceiver", startAddress);
	recordRunTimeObjectReferences();
	return startAddress;
}


/*	Generate the code for a store check of valueReg into destReg. */

	/* CogObjectRepresentationForSpur>>#genStoreCheckReceiverReg:valueReg:scratchReg:inFrame: */
static sqInt
genStoreCheckReceiverRegvalueRegscratchReginFrame(sqInt destReg, sqInt valueReg, sqInt scratchReg, sqInt inFrame)
{
    AbstractInstruction * inst;
    AbstractInstruction *jmpAlreadyRemembered;
    AbstractInstruction *jmpDestYoung;
    AbstractInstruction *jmpImmediate;
    AbstractInstruction *jmpSourceOld;
    sqInt mask;
    sqInt quickConstant;
    sqInt rememberedBitByteOffset;
    AbstractInstruction * self_in_saveAndRestoreLinkRegAround;
    sqInt wordConstant;


	/* Is value stored an integer?  If so we're done */

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, valueReg, scratchReg);
	/* begin AndCq:R: */
	quickConstant = tagMask();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(AndCqR, quickConstant, scratchReg));
	/* begin JumpNonZero: */
	jmpImmediate = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveCw:R: */
	wordConstant = storeCheckBoundary();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(wordConstant, genoperandoperand(MoveCwR, wordConstant, scratchReg));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, scratchReg, destReg);
	/* begin JumpBelow: */
	jmpDestYoung = genoperand(JumpBelow, ((sqInt)0));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, scratchReg, valueReg);
	/* begin JumpAboveOrEqual: */
	jmpSourceOld = genoperand(JumpAboveOrEqual, ((sqInt)0));
	rememberedBitByteOffset = (rememberedBitShift()) / 8;
	mask = 1 << ((rememberedBitShift()) % 8);
	/* begin MoveMb:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(rememberedBitByteOffset, genoperandoperandoperand(MoveMbrR, rememberedBitByteOffset, destReg, scratchReg));
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(mask, genoperandoperand(AndCqR, mask, scratchReg));
	/* begin JumpNonZero: */
	jmpAlreadyRemembered = genoperand(JumpNonZero, ((sqInt)0));
	assert(destReg == ReceiverResultReg);
	if (inFrame) {
		CallRTregistersToBeSavedMask(ceStoreCheckTrampoline, ((((registerMaskFor(valueReg)) | (callerSavedRegMask())) | (registerMaskFor(ReceiverResultReg))) - (registerMaskFor(ReceiverResultReg))));
	}
	else {
		/* begin saveAndRestoreLinkRegAround: */
		self_in_saveAndRestoreLinkRegAround = ((AbstractInstruction *) (backEnd()));
		/* begin PushR: */
		inst = genoperand(PushR, LinkReg);
		CallRTregistersToBeSavedMask(ceStoreCheckTrampoline, ((((registerMaskFor(valueReg)) | (callerSavedRegMask())) | (registerMaskFor(ReceiverResultReg))) - (registerMaskFor(ReceiverResultReg))));

		/* begin PopR: */
		genoperand(PopR, LinkReg);
		inst;
	}
	jmpTarget(jmpImmediate, jmpTarget(jmpDestYoung, jmpTarget(jmpSourceOld, jmpTarget(jmpAlreadyRemembered, gLabel()))));
	return 0;
}

	/* CogObjectRepresentationForSpur>>#genStoreImmediateInSourceReg:slotIndex:destReg: */
static sqInt
genStoreImmediateInSourceRegslotIndexdestReg(sqInt sourceReg, sqInt index, sqInt destReg)
{
    sqInt offset;

	/* begin MoveR:Mw:r: */
	offset = (index * BytesPerWord) + BaseHeaderSize;
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveRMwr, sourceReg, offset, destReg));
	return 0;
}


/*	do the store */

	/* CogObjectRepresentationForSpur>>#genStoreSourceReg:slotIndex:destReg:scratchReg:inFrame: */
static sqInt
genStoreSourceRegslotIndexdestRegscratchReginFrame(sqInt sourceReg, sqInt index, sqInt destReg, sqInt scratchReg, sqInt inFrame)
{
    sqInt offset;

	/* begin MoveR:Mw:r: */
	offset = (index * BytesPerWord) + BaseHeaderSize;
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveRMwr, sourceReg, offset, destReg));
	return genStoreCheckReceiverRegvalueRegscratchReginFrame(destReg, sourceReg, scratchReg, inFrame);
}

	/* CogObjectRepresentationForSpur>>#genStoreSourceReg:slotIndex:intoNewObjectInDestReg: */
static sqInt
genStoreSourceRegslotIndexintoNewObjectInDestReg(sqInt sourceReg, sqInt index, sqInt destReg)
{
    sqInt offset;

	/* begin MoveR:Mw:r: */
	offset = (index * BytesPerWord) + BaseHeaderSize;
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveRMwr, sourceReg, offset, destReg));
	return 0;
}


/*	Make sure SendNumArgsReg and ClassReg are available in addition to
	ReceiverResultReg and TempReg in
	genGetActiveContextNumArgs:large:inBlock:. 
 */

	/* CogObjectRepresentationForSpur>>#getActiveContextAllocatesInMachineCode */
static sqInt
getActiveContextAllocatesInMachineCode(void)
{
	return 1;
}

	/* CogObjectRepresentationForSpur>>#hasSpurMemoryManagerAPI */
static sqInt
hasSpurMemoryManagerAPI(void)
{
	return 1;
}


/*	Since all cache tags in Spur are class indices none of
	them are young or have to be updated in a scavenge. */

	/* CogObjectRepresentationForSpur>>#inlineCacheTagIsYoung: */
static sqInt
inlineCacheTagIsYoung(sqInt cacheTag)
{
	return 0;
}

	/* CogObjectRepresentationForSpur>>#isSmallIntegerTagNonZero */
static sqInt
isSmallIntegerTagNonZero(void)
{
	return 1;
}

	/* CogObjectRepresentationForSpur>>#jumpNotCharacterUnsignedValueInRegister: */
static AbstractInstruction *
jumpNotCharacterUnsignedValueInRegister(sqInt reg)
{
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0x3FFFFFFF, genoperandoperand(CmpCqR, 0x3FFFFFFF, reg));
	/* begin JumpAbove: */
	return genoperand(JumpAbove, ((sqInt)0));
}


/*	Mark and trace a literal in an inline cache preceeding address in
	cogMethodOrNil. Answer if code was modified. */

	/* CogObjectRepresentationForSpur>>#markAndTraceCacheTagLiteral:in:atpc: */
static sqInt
markAndTraceCacheTagLiteralinatpc(sqInt literal, CogMethod *cogMethodOrNil, usqInt address)
{
    sqInt objOop;
    AbstractInstruction * self_in_rewriteInlineCacheTagat;

	if (!(couldBeObject(literal))) {
		return 0;
	}
	assert(addressCouldBeObj(literal));
	if (!(isForwarded(literal))) {
		markAndTrace(literal);
		return 0;
	}
	objOop = followForwarded(literal);
	/* begin rewriteInlineCacheTag:at: */
	self_in_rewriteInlineCacheTagat = ((AbstractInstruction *) (backEnd()));
	longAtput(pcRelativeAddressAt(self_in_rewriteInlineCacheTagat, address - 8), objOop);
	self_in_rewriteInlineCacheTagat;
	markAndTraceUpdatedLiteralin(objOop, cogMethodOrNil);
	return 1;
}


/*	Mark and trace a literal in a machine code instruction preceeding address
	in cogMethodOrNil.
	Answer if code was modified. */

	/* CogObjectRepresentationForSpur>>#markAndTraceLiteral:in:atpc: */
static sqInt
markAndTraceLiteralinatpc(sqInt literal, CogMethod *cogMethodOrNil, usqInt address)
{
    sqInt objOop;

	if (!(couldBeObject(literal))) {
		return 0;
	}
	assert(addressCouldBeObj(literal));
	if (!(isForwarded(literal))) {
		markAndTrace(literal);
		return 0;
	}
	objOop = followForwarded(literal);
	storeLiteralbeforeFollowingAddress(backEnd(), objOop, address);
	markAndTraceUpdatedLiteralin(objOop, cogMethodOrNil);
	return 1;
}


/*	Mark and trace a literal in a sqInt variable of cogMethod. */

	/* CogObjectRepresentationForSpur>>#markAndTraceLiteral:in:at: */
static void
markAndTraceLiteralinat(sqInt literal, CogMethod *cogMethod, sqInt *address)
{
    sqInt objOop;

	if (!(couldBeObject(literal))) {
		return;
	}
	assert(addressCouldBeObj(literal));
	if (!(isForwarded(literal))) {
		markAndTrace(literal);
		return;
	}
	objOop = followForwarded(literal);
	address[0] = objOop;
	markAndTraceUpdatedLiteralin(objOop, cogMethod);
}


/*	Common code to mark a literal in cogMethod and add
	the cogMethod to youngReferrers if the literal is young. */

	/* CogObjectRepresentationForSpur>>#markAndTraceUpdatedLiteral:in: */
static void
markAndTraceUpdatedLiteralin(sqInt objOop, CogMethod *cogMethodOrNil)
{
	if (isNonImmediate(objOop)) {
		if ((cogMethodOrNil != null)
		 && (isYoungObject(objOop))) {
			ensureInYoungReferrers(cogMethodOrNil);
		}
		markAndTrace(objOop);
	}
}


/*	If primIndex has an accessorDepth, check for primitive failure and call
	ceCheckForAndFollowForwardedPrimitiveState if so If ceCheck.... answers
	true, retry the primitive. */

	/* CogObjectRepresentationForSpur>>#maybeCompileRetry:onPrimitiveFail: */
static sqInt
maybeCompileRetryonPrimitiveFail(AbstractInstruction *retryInst, sqInt primIndex)
{
    sqInt address;
    AbstractInstruction *jmp;

	if ((accessorDepthForPrimitiveIndex(primIndex)) < 0) {
		return 0;
	}
	/* begin MoveAw:R: */
	address = primFailCodeAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, TempReg));
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, TempReg));
	/* begin JumpZero: */
	jmp = genoperand(JumpZero, ((sqInt)0));
	compileCallFornumArgsargargargargresultRegsaveRegs(ceCheckForAndFollowForwardedPrimitiveState, 0, null, null, null, null, TempReg, 0);
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, TempReg));
	/* begin JumpNonZero: */
	genoperand(JumpNonZero, ((sqInt)retryInst));
	jmpTarget(jmp, gLabel());
	return 0;
}


/*	Define how many register arguments a StackToRegisterMappingCogit can
	and should use with the receiver. The value must be 0, 1 or 2. Note that a
	SimpleStackBasedCogit always has 0 register args (although the receiver is
	passed in a register). The Spur object representation is simple enough
	that implementing at:put: is straight-forward and hence 2 register args
	are worth
	while. The method must be inlined in CoInterpreter, and dead code
	eliminated so that the register-popping enilopmarts such as
	enterRegisterArgCogMethod:- at:receiver: do not have to be implemented in
	SimpleStackBasedCogit.  */

	/* CogObjectRepresentationForSpur>>#numRegArgs */
sqInt
numRegArgs(void)
{
	return 2;
}

	/* CogObjectRepresentationForSpur>>#remapObject: */
static sqInt
remapObject(sqInt objOop)
{
	return (shouldRemapObj(objOop)
		? remapObj(objOop)
		: objOop);
}

	/* CogObjectRepresentationForSpur>>#remapOop: */
static sqInt
remapOop(sqInt objOop)
{
	return (shouldRemapOop(objOop)
		? remapObj(objOop)
		: objOop);
}


/*	Objects in newSpace or oldSpace except nil, true, false &
	classTableRootObj need to be annotated.
 */

	/* CogObjectRepresentationForSpur>>#shouldAnnotateObjectReference: */
static sqInt
shouldAnnotateObjectReference(sqInt anOop)
{
	return (isNonImmediate(anOop))
	 && ((oopisGreaterThan(anOop, classTableRootObj()))
	 || (oopisLessThan(anOop, nilObject())));
}

	/* CogObjectRepresentationForSpur>>#slotOffsetOfInstVarIndex: */
static sqInt
slotOffsetOfInstVarIndex(sqInt index)
{
	return (index * BytesPerWord) + BaseHeaderSize;
}

	/* CogObjectRepresentationForSpur>>#smallIntegerIsOnlyImmediateType */
static sqInt
smallIntegerIsOnlyImmediateType(void)
{
	return 0;
}


/*	Generate an out-of-line literal. Copy the value and any annotation from
	the stand-in in the literals manager. */

	/* CogOutOfLineLiteralsARMCompiler>>#concretizeLiteral */
static AbstractInstruction *
concretizeLiteral(AbstractInstruction * self_in_concretizeLiteral)
{
    unsigned long literal;
    AbstractInstruction * literalAsInstruction;

	literalAsInstruction = ((AbstractInstruction *) (((self_in_concretizeLiteral->operands))[0]));
	literal = ((addressIsInInstructions(literalAsInstruction))
	 || (literalAsInstruction == (methodLabel()))
		? (literalAsInstruction->address)
		: ((usqInt)literalAsInstruction));
	assert((((self_in_concretizeLiteral->dependent)) != null)
	 && (((((self_in_concretizeLiteral->dependent))->opcode)) == Literal));
	if (!(((((self_in_concretizeLiteral->dependent))->annotation)) == null)) {
		assert(((self_in_concretizeLiteral->annotation)) == null);
		(self_in_concretizeLiteral->annotation) = (((self_in_concretizeLiteral->dependent))->annotation);
	}
	if (!(((((self_in_concretizeLiteral->dependent))->address)) == null)) {
		assert(((((self_in_concretizeLiteral->dependent))->address)) == ((self_in_concretizeLiteral->address)));
	}
	(((self_in_concretizeLiteral->dependent))->address = (self_in_concretizeLiteral->address));
	/* begin machineCodeAt:put: */
	((self_in_concretizeLiteral->machineCode))[0 / 4] = literal;
	self_in_concretizeLiteral;
	(self_in_concretizeLiteral->machineCodeSize) = 4;
	return self_in_concretizeLiteral;
}

	/* CogOutOfLineLiteralsARMCompiler>>#inlineCacheTagAt: */
static sqInt
inlineCacheTagAt(AbstractInstruction * self_in_inlineCacheTagAt, sqInt followingAddress)
{
	return longAt(pcRelativeAddressAt(self_in_inlineCacheTagAt, followingAddress - 8));
}


/*	Answer if the receiver is a pc-dependent instruction. With out-of-line
	literals any instruction
	that refers to a literal depends on the address of the literal, so add
	them in addition to the jumps. */

	/* CogOutOfLineLiteralsARMCompiler>>#isPCDependent */
static sqInt
isPCDependent(AbstractInstruction * self_in_isPCDependent)
{
	return (isJump(self_in_isPCDependent))
	 || ((((self_in_isPCDependent->opcode)) == AlignmentNops)
	 || ((((self_in_isPCDependent->opcode)) != Literal)
	 && ((((self_in_isPCDependent->dependent)) != null)
	 && (((((self_in_isPCDependent->dependent))->opcode)) == Literal))));
}


/*	Hack: To know if a literal should be unique (not shared) mark the second
	operand. 
 */

	/* CogOutOfLineLiteralsARMCompiler>>#isSharable */
static usqInt
isSharable(AbstractInstruction * self_in_isSharable)
{
	assert(((self_in_isSharable->opcode)) == Literal);
	return ((self_in_isSharable->operands))[1];
}


/*	Answer the size of a literal load instruction (which does not include the
	size of the literal).
	With out-of-line literals this is always a single LDR instruction that
	refers to the literal.
 */

	/* CogOutOfLineLiteralsARMCompiler>>#literalLoadInstructionBytes */
static sqInt
literalLoadInstructionBytes(AbstractInstruction * self_in_literalLoadInstructionBytes)
{
	return 4;
}


/*	The maximum offset in a LDR is (1<<12)-1, or (1<<10)-1 instructions.
	Be conservative. The issue is that one abstract instruction can emit
	multiple hardware instructions so we assume a 2 to 1 worst case of
	hardware instructions to abstract opcodes.. */

	/* CogOutOfLineLiteralsARMCompiler>>#outOfLineLiteralOpcodeLimit */
static sqInt
outOfLineLiteralOpcodeLimit(AbstractInstruction * self_in_outOfLineLiteralOpcodeLimit)
{
	return (1 << ((12 - 2) - 1)) - 1;
}


/*	Extract the address of the ldr rX, [pc, #NNN] instruction at address */

	/* CogOutOfLineLiteralsARMCompiler>>#pcRelativeAddressAt: */
static sqInt
pcRelativeAddressAt(AbstractInstruction * self_in_pcRelativeAddressAt, sqInt instrAddress)
{
    sqInt inst;
    sqInt offset;

	inst = longAt(instrAddress);
	assert((inst & 4284416000UL) == (ldrrnplusimm(self_in_pcRelativeAddressAt, 0, PC, 0, 0)));
	offset = inst & 0xFFF;
	return (instrAddress + 8) + ((inst & (1 << 23)
	? offset
	: -offset));
}


/*	If possible we generate the method address using pc-relative addressing.
	If so we don't need to relocate it in code. So check if pc-relative code
	was generated, and if not, adjust a load literal. There are two cases, a
	push or a register load. If a push, then there is a register load, but in
	the instruction
	before. */

	/* CogOutOfLineLiteralsARMCompiler>>#relocateMethodReferenceBeforeAddress:by: */
static AbstractInstruction *
relocateMethodReferenceBeforeAddressby(AbstractInstruction * self_in_relocateMethodReferenceBeforeAddressby, sqInt pc, sqInt delta)
{
    sqInt litAddr;
    sqInt pcPreceedingLoad;
    sqInt reference;


	/* If the load is not done via pc-relative addressing we have to relocate. */

	pcPreceedingLoad = (instructionIsPush(self_in_relocateMethodReferenceBeforeAddressby, longAt(pc - 4))
		? pc - 4
		: pc);
	if (!(isPCRelativeValueLoad(self_in_relocateMethodReferenceBeforeAddressby, longAt(pcPreceedingLoad - 4)))) {
		litAddr = pcRelativeAddressAt(self_in_relocateMethodReferenceBeforeAddressby, pcPreceedingLoad);
		reference = longAt(litAddr);
		longAtput(litAddr, reference + delta);
	}
	return self_in_relocateMethodReferenceBeforeAddressby;
}


/*	Rewrite a CallFull or JumpFull instruction to transfer to a different
	target. This variant is used to rewrite cached primitive calls. Answer the
	extent of the code change which is used to compute the range of the icache
	to flush. */

	/* CogOutOfLineLiteralsARMCompiler>>#rewriteFullTransferAt:target:expectedInstruction: */
static sqInt
rewriteFullTransferAttargetexpectedInstruction(AbstractInstruction * self_in_rewriteFullTransferAttargetexpectedInstruction, usqInt callSiteReturnAddress, usqInt callTargetAddress, sqInt expectedInstruction)
{
	assert((instructionBeforeAddress(self_in_rewriteFullTransferAttargetexpectedInstruction, callSiteReturnAddress)) == expectedInstruction);
	longAtput(pcRelativeAddressAt(self_in_rewriteFullTransferAttargetexpectedInstruction, callSiteReturnAddress - 8), callTargetAddress);
	return 0;
}


/*	Rewrite an inline cache to call a different target for a new tag. This
	variant is used
	to link unlinked sends in ceSend:to:numArgs: et al. Answer the extent of
	the code
	change which is used to compute the range of the icache to flush. */

	/* CogOutOfLineLiteralsARMCompiler>>#rewriteInlineCacheAt:tag:target: */
static sqInt
rewriteInlineCacheAttagtarget(AbstractInstruction * self_in_rewriteInlineCacheAttagtarget, usqInt callSiteReturnAddress, sqInt cacheTag, usqInt callTargetAddress)
{
    sqInt call;
    usqInt callDistance;

	if (!(callTargetAddress >= (minCallAddress()))) {
		error("linking callsite to invalid address");
	}

	/* pc offset */
	/* return offset */

	callDistance = ((usqInt) (callTargetAddress - ((callSiteReturnAddress + 8) - 4)));
	assert(isInImmediateJumpRange(self_in_rewriteInlineCacheAttagtarget, callDistance));
	call = bl(self_in_rewriteInlineCacheAttagtarget, callDistance);
	longAtput(callSiteReturnAddress - 4, call);
	longAtput(pcRelativeAddressAt(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 8), cacheTag);
	assert((inlineCacheTagAt(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress)) == cacheTag);
	return 4;
}


/*	Rewrite an inline cache with a new tag. This variant is used
	by the garbage collector. */

	/* CogOutOfLineLiteralsARMCompiler>>#rewriteInlineCacheTag:at: */
static AbstractInstruction *
rewriteInlineCacheTagat(AbstractInstruction * self_in_rewriteInlineCacheTagat, sqInt cacheTag, sqInt callSiteReturnAddress)
{
	longAtput(pcRelativeAddressAt(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 8), cacheTag);
	return self_in_rewriteInlineCacheTagat;
}


/*	Size a jump and set its address. The target may be another instruction
	or an absolute address. On entry the address inst var holds our virtual
	address. On exit address is set to eventualAbsoluteAddress, which is
	where this instruction will be output. The span of a jump to a following
	instruction is therefore between that instruction's address and this
	instruction's address ((which are both still their virtual addresses), but
	the span of a jump to a preceeding instruction or to an absolute address
	is between that instruction's address (which by now is its eventual
	absolute address) or absolute address and eventualAbsoluteAddress.
	
	ARM is simple; the 26-bit call/jump range means no short jumps. This
	routine only has to determine the targets of jumps, not determine sizes.
	
	This version also deals with out-of-line literals. If this is the real
	literal, update the stand-in in literalsManager with the address (because
	instructions referring to the literal are referring to the stand-in). If
	this is annotated with
	IsObjectReference transfer the annotation to the stand-in, whence it will
	be transferred to the real literal, simplifying update of literals. */

	/* CogOutOfLineLiteralsARMCompiler>>#sizePCDependentInstructionAt: */
static usqInt
sizePCDependentInstructionAt(AbstractInstruction * self_in_sizePCDependentInstructionAt, sqInt eventualAbsoluteAddress)
{
    unsigned long alignment;

	if (((self_in_sizePCDependentInstructionAt->opcode)) == AlignmentNops) {
		(self_in_sizePCDependentInstructionAt->address) = eventualAbsoluteAddress;
		alignment = ((self_in_sizePCDependentInstructionAt->operands))[0];
		return ((self_in_sizePCDependentInstructionAt->machineCodeSize) = ((eventualAbsoluteAddress + (alignment - 1)) & (-alignment)) - eventualAbsoluteAddress);
	}
	assert((isJump(self_in_sizePCDependentInstructionAt))
	 || ((((self_in_sizePCDependentInstructionAt->opcode)) == Call)
	 || ((((self_in_sizePCDependentInstructionAt->opcode)) == CallFull)
	 || ((((self_in_sizePCDependentInstructionAt->dependent)) != null)
	 && (((((self_in_sizePCDependentInstructionAt->dependent))->opcode)) == Literal)))));
	if (isJump(self_in_sizePCDependentInstructionAt)) {
		resolveJumpTarget(self_in_sizePCDependentInstructionAt);
	}
	(self_in_sizePCDependentInstructionAt->address) = eventualAbsoluteAddress;
	if ((((self_in_sizePCDependentInstructionAt->dependent)) != null)
	 && (((((self_in_sizePCDependentInstructionAt->dependent))->opcode)) == Literal)) {
		if (((self_in_sizePCDependentInstructionAt->opcode)) == Literal) {
			(((self_in_sizePCDependentInstructionAt->dependent))->address = (self_in_sizePCDependentInstructionAt->address));
		}
		if (((self_in_sizePCDependentInstructionAt->annotation)) == (getIsObjectReference())) {
			(((self_in_sizePCDependentInstructionAt->dependent))->annotation = (self_in_sizePCDependentInstructionAt->annotation));
			(self_in_sizePCDependentInstructionAt->annotation) = null;
		}
	}
	return ((self_in_sizePCDependentInstructionAt->machineCodeSize) = (self_in_sizePCDependentInstructionAt->maxSize));
}


/*	Rewrite the literal in the instruction immediately preceeding
	followingAddress. 
 */

	/* CogOutOfLineLiteralsARMCompiler>>#storeLiteral:beforeFollowingAddress: */
static AbstractInstruction *
storeLiteralbeforeFollowingAddress(AbstractInstruction * self_in_storeLiteralbeforeFollowingAddress, sqInt literal, sqInt followingAddress)
{
	longAtput(pcRelativeAddressAt(self_in_storeLiteralbeforeFollowingAddress, followingAddress - 4), literal);
	return self_in_storeLiteralbeforeFollowingAddress;
}


/*	Update an instruction that depends on a label outside of
	generated code (e.g. a method or block header). */

	/* CogOutOfLineLiteralsARMCompiler>>#updateLabel: */
static AbstractInstruction *
updateLabel(AbstractInstruction * self_in_updateLabel, AbstractInstruction *labelInstruction)
{
    unsigned long offsetAddress;

	if (((self_in_updateLabel->opcode)) != Literal) {
		offsetAddress = ((labelInstruction->address)) + (labelOffset(labelInstruction));
		
		switch ((self_in_updateLabel->opcode)) {
		case MoveCwR:
		case PushCw:
		case FillFromWord:
			((self_in_updateLabel->operands))[0] = offsetAddress;
			break;
		default:
			error("Case not found and no otherwise clause");
		}
	}
	return self_in_updateLabel;
}


/*	Answer if the receiver uses an out-of-line literal. Needs only
	to work for the opcodes created with gen:literal:operand: et al. */

	/* CogOutOfLineLiteralsARMCompiler>>#usesOutOfLineLiteral */
static sqInt
usesOutOfLineLiteral(AbstractInstruction * self_in_usesOutOfLineLiteral)
{
    sqInt constant;
    sqInt constant1;
    sqInt constant2;
    sqInt constant3;
    sqInt constant4;
    sqInt constant5;
    sqInt i;
    sqInt i1;
    sqInt i2;
    sqInt i3;
    sqInt i4;
    sqInt n;
    sqInt r;
    sqInt u;
    sqInt value;
    sqInt value1;
    sqInt value2;

	
	switch ((self_in_usesOutOfLineLiteral->opcode)) {
	case CallFull:
	case JumpFull:
	case AddCwR:
	case AndCwR:
	case CmpCwR:
	case OrCwR:
	case SubCwR:
	case XorCwR:
		return 1;

	case AddCqR:
	case CmpCqR:
	case SubCqR:
		/* begin rotateable8bitSignedImmediate:ifTrue:ifFalse: */
		constant = ((self_in_usesOutOfLineLiteral->operands))[0];
		value = constant;
		while (1) {
			if ((value & 0xFF) == value) {
				return 0;

			}
			for (i1 = 2; i1 <= 30; i1 += 2) {
				if ((value & (((0xFF << i1) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i1)))) == value) {
					return 0;

				}
			}
			if (!((value == constant)
			 && (constant != 0))) break;
			value = -constant;
		}
		return 1;


	case AndCqR:
	case AndCqRR:
		/* begin rotateable8bitBitwiseImmediate:ifTrue:ifFalse: */
		constant1 = ((self_in_usesOutOfLineLiteral->operands))[0];
		value1 = constant1;
		while (1) {
			if ((value1 & 0xFF) == value1) {
				return 0;

			}
			for (i2 = 2; i2 <= 30; i2 += 2) {
				if ((value1 & (((0xFF << i2) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i2)))) == value1) {
					return 0;

				}
			}
			if (!(value1 == constant1)) break;
			value1 = (constant1 < 0
				? -1 - constant1
				: (unsigned int)~constant1);
		}
		return (1 << (highBit(((self_in_usesOutOfLineLiteral->operands))[0]))) != ((((self_in_usesOutOfLineLiteral->operands))[0]) + 1);


	case OrCqR:
	case TstCqR:
	case LoadEffectiveAddressMwrR:
	case MoveCqR:
	case MoveM16rR:
	case PushCq:
		/* begin rotateable8bitImmediate:ifTrue:ifFalse: */
		constant2 = ((self_in_usesOutOfLineLiteral->operands))[0];
		if ((constant2 & 0xFF) == constant2) {
			return 0;

		}
		for (i3 = 2; i3 <= 30; i3 += 2) {
			if ((constant2 & (((0xFF << i3) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i3)))) == constant2) {
				return 0;

			}
		}
		return 1;


	case XorCqR:
		/* begin rotateable8bitBitwiseImmediate:ifTrue:ifFalse: */
		constant3 = ((self_in_usesOutOfLineLiteral->operands))[0];
		value2 = constant3;
		while (1) {
			if ((value2 & 0xFF) == value2) {
				return 0;

			}
			for (i4 = 2; i4 <= 30; i4 += 2) {
				if ((value2 & (((0xFF << i4) & 0xFFFFFFFFUL) | (((usqInt) 0xFF) >> (32 - i4)))) == value2) {
					return 0;

				}
			}
			if (!(value2 == constant3)) break;
			value2 = (constant3 < 0
				? -1 - constant3
				: (unsigned int)~constant3);
		}
		return 1;


	case MoveCwR:
	case PushCw:
		return !((isAnInstruction(self_in_usesOutOfLineLiteral, ((AbstractInstruction *) (((self_in_usesOutOfLineLiteral->operands))[0]))))
 || (addressIsInCurrentCompilation(((self_in_usesOutOfLineLiteral->operands))[0])));

	case MoveAwR:
	case PrefetchAw:
		return (isAddressRelativeToVarBase(self_in_usesOutOfLineLiteral, ((self_in_usesOutOfLineLiteral->operands))[0])
			? 0
			: 1);

	case MoveRAw:
		return (isAddressRelativeToVarBase(self_in_usesOutOfLineLiteral, ((self_in_usesOutOfLineLiteral->operands))[1])
			? 0
			: 1);

	case MoveRMwr:
	case MoveRdM64r:
	case MoveRMbr:
		/* begin is12BitValue:ifTrue:ifFalse: */
		constant4 = ((self_in_usesOutOfLineLiteral->operands))[1];
		if ((abs(constant4)) <= 0xFFF) {

			/* (2 raisedTo: 12)-1 */

			if (constant4 >= 0) {
				return 0;

			}
			else {
				return 0;

			}
		}
		else {
			return 1;

		}

	case MoveMbrR:
	case MoveM64rRd:
	case MoveMwrR:
		/* begin is12BitValue:ifTrue:ifFalse: */
		constant5 = ((self_in_usesOutOfLineLiteral->operands))[0];
		if ((abs(constant5)) <= 0xFFF) {

			/* (2 raisedTo: 12)-1 */

			if (constant5 >= 0) {
				return 0;

			}
			else {
				return 0;

			}
		}
		else {
			return 1;

		}

	default:
		assert(0);

	}
	return 0;
}

	/* CogSimStackEntry>>#ensureSpilledAt:from: */
static CogSimStackEntry *
ensureSpilledAtfrom(CogSimStackEntry * self_in_ensureSpilledAtfrom, sqInt baseOffset, sqInt baseRegister)
{
    sqInt baseReg;
    AbstractInstruction *inst;
    sqInt offset;
    sqInt reg;

	if ((self_in_ensureSpilledAtfrom->spilled)) {
		if (((self_in_ensureSpilledAtfrom->type)) == SSSpill) {
			assert((((self_in_ensureSpilledAtfrom->offset)) == baseOffset)
			 && (((self_in_ensureSpilledAtfrom->registerr)) == baseRegister));
			return self_in_ensureSpilledAtfrom;
		}
	}
	assert(((self_in_ensureSpilledAtfrom->type)) != SSSpill);
	traceSpill(self_in_ensureSpilledAtfrom);
	if (((self_in_ensureSpilledAtfrom->type)) == SSConstant) {
		inst = annotateobjRef(gPushCw((self_in_ensureSpilledAtfrom->constant)), (self_in_ensureSpilledAtfrom->constant));
	}
	else {
		if (((self_in_ensureSpilledAtfrom->type)) == SSBaseOffset) {
			/* begin MoveMw:r:R: */
			offset = (self_in_ensureSpilledAtfrom->offset);
			baseReg = (self_in_ensureSpilledAtfrom->registerr);
			/* begin gen:quickConstant:operand:operand: */
			checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveMwrR, offset, baseReg, TempReg));
			/* begin PushR: */
			inst = genoperand(PushR, TempReg);
		}
		else {
			assert(((self_in_ensureSpilledAtfrom->type)) == SSRegister);
			/* begin PushR: */
			reg = (self_in_ensureSpilledAtfrom->registerr);
			inst = genoperand(PushR, reg);
		}
		(self_in_ensureSpilledAtfrom->type) = SSSpill;
		(self_in_ensureSpilledAtfrom->offset) = baseOffset;
		(self_in_ensureSpilledAtfrom->registerr) = baseRegister;
	}
	(self_in_ensureSpilledAtfrom->spilled) = 1;
	if ((self_in_ensureSpilledAtfrom->annotateUse)) {
		/* begin annotateBytecode: */
		(inst->annotation = HasBytecodePC);
		inst;
		(self_in_ensureSpilledAtfrom->annotateUse) = 0;
	}
	return self_in_ensureSpilledAtfrom;
}


/*	Discard type information because of a control-flow merge. */

	/* CogSimStackEntry>>#mergeAt:from: */
static CogSimStackEntry *
mergeAtfrom(CogSimStackEntry * self_in_mergeAtfrom, sqInt baseOffset, sqInt baseRegister)
{
	assert((self_in_mergeAtfrom->spilled));
	if (((self_in_mergeAtfrom->type)) == SSSpill) {
		assert((((self_in_mergeAtfrom->offset)) == baseOffset)
		 && (((self_in_mergeAtfrom->registerr)) == baseRegister));
	}
	else {
		(self_in_mergeAtfrom->type) = SSSpill;
		(self_in_mergeAtfrom->offset) = baseOffset;
		(self_in_mergeAtfrom->registerr) = baseRegister;
	}
	return self_in_mergeAtfrom;
}

	/* CogSimStackEntry>>#popToReg: */
static CogSimStackEntry *
popToReg(CogSimStackEntry * self_in_popToReg, sqInt reg)
{
    sqInt baseReg;
    sqInt constant;
    AbstractInstruction *inst;
    sqInt offset;
    sqInt reg1;

	if ((self_in_popToReg->spilled)) {
		/* begin PopR: */
		inst = genoperand(PopR, reg);
	}
	else {
		
		switch ((self_in_popToReg->type)) {
		case SSBaseOffset:
			/* begin MoveMw:r:R: */
			offset = (self_in_popToReg->offset);
			baseReg = (self_in_popToReg->registerr);
			/* begin gen:quickConstant:operand:operand: */
			inst = checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveMwrR, offset, baseReg, reg));
			break;
		case SSConstant:
			/* begin genMoveConstant:R: */
			constant = (self_in_popToReg->constant);
			if (shouldAnnotateObjectReference(constant)) {
				inst = annotateobjRef(gMoveCwR(constant, reg), constant);
			}
			else {
				/* begin MoveCq:R: */
				/* begin gen:quickConstant:operand: */
				inst = checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, reg));
			}
			break;
		case SSRegister:
			if (reg != ((self_in_popToReg->registerr))) {
				/* begin MoveR:R: */
				reg1 = (self_in_popToReg->registerr);
				inst = genoperandoperand(MoveRR, reg1, reg);
			}
			else {
				/* begin Label */
				inst = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
			}
			break;
		default:
			error("Case not found and no otherwise clause");
		}
	}
	if ((self_in_popToReg->annotateUse)) {
		/* begin annotateBytecode: */
		(inst->annotation = HasBytecodePC);
		inst;
		(self_in_popToReg->annotateUse) = 0;
	}
	return self_in_popToReg;
}


/*	Answer a bit mask for the receiver's register, if any. */

	/* CogSimStackEntry>>#registerMask */
static sqInt
registerMask(CogSimStackEntry * self_in_registerMask)
{
	return ((((self_in_registerMask->type)) == SSBaseOffset)
	 || (((self_in_registerMask->type)) == SSRegister)
		? registerMaskFor((self_in_registerMask->registerr))
		: 0);
}

	/* CogSimStackEntry>>#registerOrNil */
static sqInt
registerOrNil(CogSimStackEntry * self_in_registerOrNil)
{
	return (((self_in_registerOrNil->type)) == SSRegister
		? (self_in_registerOrNil->registerr)
		: 0);
}

	/* CogSimStackEntry>>#storeToReg: */
static CogSimStackEntry *
storeToReg(CogSimStackEntry * self_in_storeToReg, sqInt reg)
{
    sqInt baseReg;
    sqInt constant;
    AbstractInstruction *inst;
    sqInt offset;
    sqInt reg1;

	
	switch ((self_in_storeToReg->type)) {
	case SSBaseOffset:
	case SSSpill:
		/* begin MoveMw:r:R: */
		offset = (self_in_storeToReg->offset);
		baseReg = (self_in_storeToReg->registerr);
		/* begin gen:quickConstant:operand:operand: */
		inst = checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveMwrR, offset, baseReg, reg));
		break;
	case SSConstant:
		/* begin genMoveConstant:R: */
		constant = (self_in_storeToReg->constant);
		if (shouldAnnotateObjectReference(constant)) {
			inst = annotateobjRef(gMoveCwR(constant, reg), constant);
		}
		else {
			/* begin MoveCq:R: */
			/* begin gen:quickConstant:operand: */
			inst = checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, reg));
		}
		break;
	case SSRegister:
		if (reg != ((self_in_storeToReg->registerr))) {
			/* begin MoveR:R: */
			reg1 = (self_in_storeToReg->registerr);
			inst = genoperandoperand(MoveRR, reg1, reg);
		}
		else {
			/* begin Label */
			inst = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		}
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	if ((self_in_storeToReg->annotateUse)) {
		/* begin annotateBytecode: */
		(inst->annotation = HasBytecodePC);
		inst;
		(self_in_storeToReg->annotateUse) = 0;
	}
	return self_in_storeToReg;
}


/*	Allocate an unsharable Literal instruction for the literal and answer it. */

	/* OutOfLineLiteralsManager>>#allocateLiteral: */
static AbstractInstruction *
allocateLiteral(sqInt aLiteral)
{
    AbstractInstruction *existingInst;
    sqInt i;
    sqInt iLimiT;
    sqInt initialNumLiterals;
    AbstractInstruction *litInst;
    AbstractInstruction *newInst;
    AbstractInstruction *newLiterals;

	if (nextLiteralIndex >= literalsSize) {
		/* begin allocateLiterals: */
		initialNumLiterals = literalsSize + 8;
		if (initialNumLiterals > literalsSize) {

			/* Must copy across state (not using realloc, cuz...) and
			   must also update existing instructions to refer to the new ones...
			   It's either this or modify all generation routines to be able to retry
			   with more literals after running out of literals. */

			newLiterals = calloc(initialNumLiterals, sizeof(CogAbstractInstruction));
			if (!(literals == null)) {
				for (i = 0; i < nextLiteralIndex; i += 1) {
					existingInst = literalInstructionAt(i);
					newInst = (&(newLiterals[i]));
					cloneLiteralFrom(newInst, existingInst);
					assert(((existingInst->dependent)) == null);
					(existingInst->dependent = newInst);
				}
				for (i = 0, iLimiT = (opcodeIndex - 1); i <= iLimiT; i += 1) {
					existingInst = abstractInstructionAt(i);
					if ((((existingInst->dependent)) != null)
					 && (((((existingInst->dependent))->opcode)) == Literal)) {
						(existingInst->dependent = (((existingInst->dependent))->dependent));
					}
				}
			}
			free(literals);
			literals = newLiterals;
			literalsSize = initialNumLiterals;
		}
	}
	litInst = literalInstructionAt(nextLiteralIndex);
	initializeUniqueLiteral(litInst, aLiteral);

	/* Record the opcodeIndex of the first dependent instruction (the first instruction that references an out-of-line literal) */

	nextLiteralIndex += 1;
	if (firstOpcodeIndex > opcodeIndex) {
		firstOpcodeIndex = opcodeIndex - 1;
	}
	return litInst;
}

	/* OutOfLineLiteralsManager>>#checkLiteral:forInstruction: */
static AbstractInstruction *
checkLiteralforInstruction(sqInt literal, AbstractInstruction *anInstruction)
{
	if (usesOutOfLineLiteral(anInstruction)) {
		(anInstruction->dependent = locateLiteral(literal));
	}
	return anInstruction;
}

	/* OutOfLineLiteralsManager>>#checkQuickConstant:forInstruction: */
static AbstractInstruction *
checkQuickConstantforInstruction(sqInt literal, AbstractInstruction *anInstruction)
{
	if (usesOutOfLineLiteral(anInstruction)) {
		(anInstruction->dependent = locateLiteral(literal));
	}
	return anInstruction;
}


/*	If inline cache tags are not objects they will be 32-bit values. */

	/* OutOfLineLiteralsManager>>#classRefInClosedPICAt: */
static sqInt
classRefInClosedPICAt(sqInt address)
{
	return longAt(address - BytesPerOop);
}


/*	Output all pending literal instructions, making the originals dependents
	of the generated ones
	so that a later pass will copy the address of each generated literl inst
	to its original in literals,
	and hence allow the instruction using the literal to compute the correct
	address.. 
 */

	/* OutOfLineLiteralsManager>>#dumpLiterals: */
static sqInt
dumpLiterals(sqInt generateBranchAround)
{
    sqInt i;
    sqInt index;
    AbstractInstruction *jump;
    AbstractInstruction *litInst;

	if (generateBranchAround) {
		/* begin Jump: */
		jump = genoperand(Jump, ((sqInt)0));
	}
	for (i = lastDumpedLiteralIndex; i < nextLiteralIndex; i += 1) {
		litInst = literalInstructionAt(i);
		((genoperand(Literal, ((litInst->operands))[0]))->dependent = litInst);
		/* begin setLiteralOpcodeIndex: */
		index = opcodeIndex;
		assert(((litInst->opcode)) == Literal);
		((litInst->operands))[2] = index;
		litInst;
	}
	if (generateBranchAround) {
		jmpTarget(jump, gLabel());
	}
	firstOpcodeIndex = opcodeIndex;
	lastDumpedLiteralIndex = nextLiteralIndex;
}


/*	A literal is in range if its opcode index is within
	outOfLineLiteralOpcodeLimit, or if its index has yet to be assigned. */

	/* OutOfLineLiteralsManager>>#literalInstructionInRange: */
static sqInt
literalInstructionInRange(AbstractInstruction *litInst)
{
    sqInt opcodeIdx;

	/* begin literalOpcodeIndex */
	assert(((litInst->opcode)) == Literal);
	opcodeIdx = ((sqInt)(((litInst->operands))[2]));
	return ((((sqInt)opcodeIdx)) < 0)
	 || ((assert((getOpcodeIndex()) >= opcodeIdx),
	(opcodeIndex - opcodeIdx) < (outOfLineLiteralOpcodeLimit(backEnd()))));
}


/*	Search for a Literal instruction that is in-range and answer it. Otherwise
	allocate a new sharable Literal instruction for the literal and answer it. */

	/* OutOfLineLiteralsManager>>#locateLiteral: */
static AbstractInstruction *
locateLiteral(sqInt aLiteral)
{
    AbstractInstruction *existingInst;
    sqInt i;
    sqInt i1;
    sqInt iLimiT;
    sqInt initialNumLiterals;
    AbstractInstruction *litInst;
    AbstractInstruction *newInst;
    AbstractInstruction *newLiterals;

	for (i = 0; i < nextLiteralIndex; i += 1) {
		litInst = literalInstructionAt(i);
		if (((((litInst->operands))[0]) == aLiteral)
		 && ((isSharable(litInst))
		 && (literalInstructionInRange(litInst)))) {
			return litInst;
		}
	}
	if (nextLiteralIndex >= literalsSize) {
		/* begin allocateLiterals: */
		initialNumLiterals = literalsSize + 8;
		if (initialNumLiterals > literalsSize) {

			/* Must copy across state (not using realloc, cuz...) and
			   must also update existing instructions to refer to the new ones...
			   It's either this or modify all generation routines to be able to retry
			   with more literals after running out of literals. */

			newLiterals = calloc(initialNumLiterals, sizeof(CogAbstractInstruction));
			if (!(literals == null)) {
				for (i1 = 0; i1 < nextLiteralIndex; i1 += 1) {
					existingInst = literalInstructionAt(i1);
					newInst = (&(newLiterals[i1]));
					cloneLiteralFrom(newInst, existingInst);
					assert(((existingInst->dependent)) == null);
					(existingInst->dependent = newInst);
				}
				for (i1 = 0, iLimiT = (opcodeIndex - 1); i1 <= iLimiT; i1 += 1) {
					existingInst = abstractInstructionAt(i1);
					if ((((existingInst->dependent)) != null)
					 && (((((existingInst->dependent))->opcode)) == Literal)) {
						(existingInst->dependent = (((existingInst->dependent))->dependent));
					}
				}
			}
			free(literals);
			literals = newLiterals;
			literalsSize = initialNumLiterals;
		}
	}
	litInst = literalInstructionAt(nextLiteralIndex);
	initializeSharableLiteral(litInst, aLiteral);

	/* Record the opcodeIndex of the first dependent instruction (the first instruction that references an out-of-line literal) */

	nextLiteralIndex += 1;
	if (firstOpcodeIndex > opcodeIndex) {
		firstOpcodeIndex = opcodeIndex - 1;
	}
	return litInst;
}

	/* OutOfLineLiteralsManager>>#mustDumpLiterals: */
static sqInt
mustDumpLiterals(sqInt currentOpcodeIndex)
{
	return (currentOpcodeIndex >= firstOpcodeIndex)
	 && ((currentOpcodeIndex - firstOpcodeIndex) >= (outOfLineLiteralOpcodeLimit(backEnd())));
}

	/* OutOfLineLiteralsManager>>#objRefInClosedPICAt: */
static sqInt
objRefInClosedPICAt(sqInt address)
{
	return longAt(address);
}

	/* OutOfLineLiteralsManager>>#resetForBlockCompile */
static sqInt
resetForBlockCompile(void)
{
	firstOpcodeIndex = savedFirstOpcodeIndex;
	nextLiteralIndex = savedNextLiteralIndex;
	lastDumpedLiteralIndex = savedLastDumpedLiteralIndex;
}

	/* OutOfLineLiteralsManager>>#saveForBlockCompile */
static sqInt
saveForBlockCompile(void)
{
	savedFirstOpcodeIndex = firstOpcodeIndex;
	savedNextLiteralIndex = nextLiteralIndex;
	savedLastDumpedLiteralIndex = lastDumpedLiteralIndex;
}


/*	Compile the jump instruction(s) at the end of the method that dispatch to
	each block body.
 */

	/* SimpleStackBasedCogit>>#compileBlockDispatch */
static sqInt
compileBlockDispatch(void)
{
    AbstractInstruction *jumpSkip;

	assert(blockCount > 0);
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	blockEntryNoContextSwitch = checkQuickConstantforInstruction(0, genoperandoperand(MoveCqR, 0, SendNumArgsReg));
	/* begin Jump: */
	jumpSkip = genoperand(Jump, ((sqInt)0));
	/* begin MoveR:R: */
	blockEntryLabel = genoperandoperand(MoveRR, ReceiverResultReg, SendNumArgsReg);
	jmpTarget(jumpSkip, gLabel());
	if (blockCount > 1) {
		genLoadSlotsourceRegdestReg(ClosureStartPCIndex, ReceiverResultReg, TempReg);
	}
	compileBlockDispatchFromto(0, blockCount - 1);
	return 0;
}

	/* SimpleStackBasedCogit>>#compileFallbackToInterpreterPrimitive */
static sqInt
compileFallbackToInterpreterPrimitive(void)
{
	return compileInterpreterPrimitive(functionPointerForCompiledMethodprimitiveIndex(methodObj, primitiveIndex));
}


/*	After pushing the temporaries but before the stack limit check a primitive
	method needs to fetch the error code, if any, and replace the last temp
	with it. */

	/* SimpleStackBasedCogit>>#compileGetErrorCode */
static void
compileGetErrorCode(void)
{
    sqInt address;
    sqInt address1;
    AbstractInstruction *jmpGotError;
    AbstractInstruction *jmpIntError;
    AbstractInstruction *jmpNoError;
    sqInt primErrorTable;
    sqInt primErrorTableSize;

	/* begin MoveAw:R: */
	address = primFailCodeAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, TempReg));
	flag("ask concrete code gen if move sets condition codes?");
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, TempReg));
	/* begin JumpZero: */
	jmpNoError = genoperand(JumpZero, ((sqInt)0));
	primErrorTable = primErrTable();
	primErrorTableSize = lengthOf(primErrorTable);
	flag("use CmpCqR if pc mapping means stable contexts never contain native pcs");
	/* begin CmpCw:R: */
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(primErrorTableSize, genoperandoperand(CmpCwR, primErrorTableSize, TempReg));
	/* begin JumpAboveOrEqual: */
	jmpIntError = genoperand(JumpAboveOrEqual, ((sqInt)0));
	genFetchIndexRegisterfrominto(TempReg, primErrorTable, ClassReg);
	/* begin Jump: */
	jmpGotError = genoperand(Jump, ((sqInt)0));
	jmpTarget(jmpIntError, gLabel());
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ClassReg);
	jmpTarget(jmpGotError, gMoveRMwr(ClassReg, 0, SPReg));
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(MoveCqR, 0, TempReg));
	/* begin MoveR:Aw: */
	address1 = primFailCodeAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address1, genoperandoperand(MoveRAw, TempReg, address1));
	jmpTarget(jmpNoError, gLabel());
}


/*	Compile a call to an interpreter primitive. Call the C routine with the
	usual stack-switching dance, test the primFailCode and then either
	return on success or continue to the method body. */

	/* SimpleStackBasedCogit>>#compileInterpreterPrimitive: */
static sqInt
compileInterpreterPrimitive(void (*primitiveRoutine)(void))
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    AbstractInstruction *abstractInstruction2;
    AbstractInstruction *abstractInstruction3;
    sqInt address;
    sqInt address1;
    sqInt address10;
    sqInt address11;
    sqInt address12;
    sqInt address13;
    sqInt address2;
    sqInt address3;
    sqInt address4;
    sqInt address5;
    sqInt address6;
    sqInt address7;
    sqInt address8;
    sqInt address9;
    sqInt callTarget;
    sqInt callTarget1;
    AbstractInstruction *continuePostSampleNonPrim;
    AbstractInstruction *continuePostSamplePrim;
    sqInt flags;
    AbstractInstruction *jmp;
    AbstractInstruction *jmpSampleNonPrim;
    AbstractInstruction *jmpSamplePrim;
    void *jumpTarget;
    sqInt offset;
    sqInt offset1;
    sqInt offset2;
    sqInt reg;
    sqInt retpc;
    AbstractInstruction *retry;


	/* Save processor fp, sp and return pc in the interpreter's frame stack and instruction pointers */

	genExternalizePointersForPrimitiveCall();
	genLoadCStackPointersForPrimCall();
	flags = primitivePropertyFlags(primitiveIndex);
	if (flags & PrimCallDoNotJIT) {
		return ShouldNotJIT;
	}
	if (flags & PrimCallCollectsProfileSamples) {

		/* Test nextProfileTick for being non-zero and call checkProfileTick if so */

		/* begin MoveAw:R: */
		address = nextProfileTickAddress();
		/* begin gen:literal:operand: */
		checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, TempReg));
		/* begin MoveAw:R: */
		address1 = (nextProfileTickAddress()) + BytesPerWord;
		/* begin gen:literal:operand: */
		checkLiteralforInstruction(address1, genoperandoperand(MoveAwR, address1, ClassReg));
		/* begin OrR:R: */
		genoperandoperand(OrRR, TempReg, ClassReg);

		/* begin JumpNonZero: */
		jmpSampleNonPrim = genoperand(JumpNonZero, ((sqInt)0));
		/* begin Label */
		continuePostSampleNonPrim = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	}
	if (recordPrimTrace()) {
		genFastPrimTraceUsingand(ClassReg, SendNumArgsReg);
	}
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	retry = checkQuickConstantforInstruction(0, genoperandoperand(MoveCqR, 0, TempReg));
	/* begin MoveR:Aw: */
	address11 = primFailCodeAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address11, genoperandoperand(MoveRAw, TempReg, address11));
	if (methodOrBlockNumArgs != 0) {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(methodOrBlockNumArgs, genoperandoperand(MoveCqR, methodOrBlockNumArgs, TempReg));
	}
	/* begin MoveR:Aw: */
	address12 = argumentCountAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address12, genoperandoperand(MoveRAw, TempReg, address12));
	if (flags & PrimCallNeedsPrimitiveFunction) {
		/* begin MoveCw:R: */
		/* begin gen:literal:operand: */
		checkLiteralforInstruction(((sqInt)primitiveRoutine), genoperandoperand(MoveCwR, ((sqInt)primitiveRoutine), TempReg));
		/* begin MoveR:Aw: */
		address3 = primitiveFunctionPointerAddress();
		/* begin gen:operand:literal: */
		primSetFunctionLabel = checkLiteralforInstruction(address3, genoperandoperand(MoveRAw, TempReg, address3));
	}
	if (flags & (PrimCallNeedsNewMethod + PrimCallMayCallBack)) {

		/* The ceActivateFailingPrimitiveMethod: machinery can't handle framelessness. */

		if (flags & PrimCallMayCallBack) {
			needsFrame = 1;
		}
		addDependent(methodLabel, annotateAbsolutePCRef(gMoveCwR(((sqInt)methodLabel), ClassReg)));
		/* begin MoveMw:r:R: */
		offset = offsetof(CogMethod, methodObject);
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveMwrR, offset, ClassReg, TempReg));
		/* begin MoveR:Aw: */
		address4 = newMethodAddress();
		/* begin gen:operand:literal: */
		checkLiteralforInstruction(address4, genoperandoperand(MoveRAw, TempReg, address4));
	}
	/* begin PrefetchAw: */
	address13 = primFailCodeAddress();
	/* begin gen:literal: */
	checkLiteralforInstruction(address13, genoperand(PrefetchAw, address13));
	if (flags & PrimCallMayCallBack) {

		/* Sideways call the C primitive routine so that we return through cePrimReturnEnterCogCode. */
		/* On Spur ceActivateFailingPrimitiveMethod: would like to retry if forwarders
		   are found. So insist on PrimCallNeedsPrimitiveFunction being set too. */

		assert(flags & PrimCallNeedsPrimitiveFunction);
		/* begin genSubstituteReturnAddress: */
		retpc = (flags & PrimCallCollectsProfileSamples
			? cePrimReturnEnterCogCodeProfiling
			: cePrimReturnEnterCogCode);
		/* begin MoveCw:R: */
		/* begin gen:literal:operand: */
		checkLiteralforInstruction(retpc, genoperandoperand(MoveCwR, retpc, LR));
		/* begin JumpFullRT: */
		/* begin JumpFull: */
		/* begin gen:literal: */
		checkLiteralforInstruction(((sqInt)primitiveRoutine), genoperand(JumpFull, ((sqInt)primitiveRoutine)));

		/* begin Label */
		primInvokeLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		jmp = (jmpSamplePrim = (continuePostSamplePrim = null));
	}
	else {

		/* Call the C primitive routine. */

		/* begin CallFullRT: */
		/* begin CallFull: */
		/* begin gen:literal: */
		checkLiteralforInstruction(((sqInt)primitiveRoutine), genoperand(CallFull, ((sqInt)primitiveRoutine)));

		/* begin Label */
		primInvokeLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		if (flags & PrimCallCollectsProfileSamples) {
			assert(flags & PrimCallNeedsNewMethod);
			/* begin MoveAw:R: */
			address5 = nextProfileTickAddress();
			/* begin gen:literal:operand: */
			checkLiteralforInstruction(address5, genoperandoperand(MoveAwR, address5, TempReg));
			/* begin MoveAw:R: */
			address6 = (nextProfileTickAddress()) + BytesPerWord;
			/* begin gen:literal:operand: */
			checkLiteralforInstruction(address6, genoperandoperand(MoveAwR, address6, ClassReg));
			/* begin OrR:R: */
			genoperandoperand(OrRR, TempReg, ClassReg);

			/* begin JumpNonZero: */
			jmpSamplePrim = genoperand(JumpNonZero, ((sqInt)0));
			/* begin Label */
			continuePostSamplePrim = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		}
		maybeCompileRetryonPrimitiveFail(retry, primitiveIndex);
		maybeCompileAllocFillerCheck();
		/* begin MoveAw:R: */
		address8 = instructionPointerAddress();
		reg = LinkReg;
		/* begin gen:literal:operand: */
		checkLiteralforInstruction(address8, genoperandoperand(MoveAwR, address8, reg));
		genLoadStackPointers(backEnd);
		/* begin MoveAw:R: */
		address9 = primFailCodeAddress();
		/* begin gen:literal:operand: */
		checkLiteralforInstruction(address9, genoperandoperand(MoveAwR, address9, TempReg));
		
		flag("ask concrete code gen if move sets condition codes?");
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, TempReg));
		/* begin JumpNonZero: */
		jmp = genoperand(JumpNonZero, ((sqInt)0));
		/* begin MoveMw:r:R: */
		offset1 = 0;
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(offset1, genoperandoperandoperand(MoveMwrR, offset1, SPReg, ReceiverResultReg));
		/* begin RetN: */
		genoperand(RetN, BytesPerWord);
	}
	if (flags & PrimCallCollectsProfileSamples) {

		/* The sample is collected by cePrimReturnEnterCogCode for external calls */

		if (jmpSamplePrim != null) {

			/* Call ceCheckProfileTick: to record sample and then continue. */

			jmpTarget(jmpSamplePrim, gLabel());
			assert(flags & PrimCallNeedsNewMethod);
			/* begin CallFullRT: */
			callTarget = ((unsigned long)ceCheckProfileTick);
			/* begin CallFull: */
			/* begin gen:literal: */
			checkLiteralforInstruction(callTarget, genoperand(CallFull, callTarget));

			/* begin Jump: */
			genoperand(Jump, ((sqInt)continuePostSamplePrim));
		}
		jmpTarget(jmpSampleNonPrim, gLabel());
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(0, genoperandoperand(MoveCqR, 0, TempReg));
		/* begin MoveR:Aw: */
		address10 = newMethodAddress();
		/* begin gen:operand:literal: */
		checkLiteralforInstruction(address10, genoperandoperand(MoveRAw, TempReg, address10));
		/* begin CallFullRT: */
		callTarget1 = ((unsigned long)ceCheckProfileTick);
		/* begin CallFull: */
		/* begin gen:literal: */
		checkLiteralforInstruction(callTarget1, genoperand(CallFull, callTarget1));

		/* begin Jump: */
		genoperand(Jump, ((sqInt)continuePostSampleNonPrim));
	}
	if (jmp != null) {

		/* Jump to restore of receiver reg and proceed to frame build for failure. */

		jmpTarget(jmp, gLabel());
		/* begin MoveMw:r:R: */
		offset2 = BytesPerWord * (methodOrBlockNumArgs + (0));
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(offset2, genoperandoperandoperand(MoveMwrR, offset2, SPReg, ReceiverResultReg));
	}
	return 0;
}

	/* SimpleStackBasedCogit>>#extendedPushBytecode */
static sqInt
extendedPushBytecode(void)
{
    sqInt variableIndex;
    sqInt variableType;

	variableType = (((usqInt) byte1) >> 6) & 3;
	variableIndex = byte1 & 0x3F;
	if (variableType == 0) {
		return genPushReceiverVariable(variableIndex);
	}
	if (variableType == 1) {
		return genPushTemporaryVariable(variableIndex);
	}
	if (variableType == 2) {
		return genPushLiteralIndex(variableIndex);
	}
	return genPushLiteralVariable(variableIndex);
}

	/* SimpleStackBasedCogit>>#extendedStoreAndPopBytecode */
static sqInt
extendedStoreAndPopBytecode(void)
{
    sqInt variableIndex;
    sqInt variableType;

	variableType = (((usqInt) byte1) >> 6) & 3;
	variableIndex = byte1 & 0x3F;
	if (variableType == 0) {
		return genStorePopReceiverVariable(1, variableIndex);
	}
	if (variableType == 1) {
		return genStorePopTemporaryVariable(1, variableIndex);
	}
	if (variableType == 3) {
		return genStorePopLiteralVariable(1, variableIndex);
	}
	return EncounteredUnknownBytecode;
}

	/* SimpleStackBasedCogit>>#extendedStoreBytecode */
static sqInt
extendedStoreBytecode(void)
{
    sqInt variableIndex;
    sqInt variableType;

	variableType = (((usqInt) byte1) >> 6) & 3;
	variableIndex = byte1 & 0x3F;
	if (variableType == 0) {
		return genStorePopReceiverVariable(0, variableIndex);
	}
	if (variableType == 1) {
		return genStorePopTemporaryVariable(0, variableIndex);
	}
	if (variableType == 3) {
		return genStorePopLiteralVariable(0, variableIndex);
	}
	return EncounteredUnknownBytecode;
}

	/* SimpleStackBasedCogit>>#frameOffsetOfTemporary: */
static sqInt
frameOffsetOfTemporary(sqInt index)
{
	return (index < methodOrBlockNumArgs
		? FoxCallerSavedIP + ((methodOrBlockNumArgs - index) * BytesPerWord)
		: (FoxMFReceiver - BytesPerWord) + ((methodOrBlockNumArgs - index) * BytesPerWord));
}


/*	Return from block, assuming result already loaded into ReceiverResultReg. */

	/* SimpleStackBasedCogit>>#genBlockReturn */
static sqInt
genBlockReturn(void)
{
	if (needsFrame) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, FPReg, SPReg);
		/* begin PopR: */
		genoperand(PopR, FPReg);
		/* begin PopR: */
		genoperand(PopR, LinkReg);

	}
	/* begin RetN: */
	genoperand(RetN, (methodOrBlockNumArgs + 1) * BytesPerWord);
	return 0;
}

	/* SimpleStackBasedCogit>>#genDoubleFailIfZeroArgRcvr:arg: */
static AbstractInstruction *
genDoubleFailIfZeroArgRcvrarg(sqInt rcvrReg, sqInt argReg)
{
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(MoveCqR, 0, TempReg));
	/* begin ConvertR:Rd: */
	genoperandoperand(ConvertRRd, TempReg, DPFPReg2);
	/* begin CmpRd:Rd: */
	genoperandoperand(CmpRdRd, DPFPReg2, argReg);
	return gJumpFPEqual(0);
}


/*	Can use any of the first 32 literals for the selector and pass up to 7
	arguments. 
 */

	/* SimpleStackBasedCogit>>#genExtendedSendBytecode */
static sqInt
genExtendedSendBytecode(void)
{
	return genSendnumArgs(getLiteral(byte1 & 0x1F), ((usqInt) byte1) >> 5);
}

	/* SimpleStackBasedCogit>>#genExtendedSuperBytecode */
static sqInt
genExtendedSuperBytecode(void)
{
	return genSendSupernumArgs(getLiteral(byte1 & 0x1F), ((usqInt) byte1) >> 5);
}

	/* SimpleStackBasedCogit>>#genFastPrimFail */
static sqInt
genFastPrimFail(void)
{
	primitiveIndex = 0;
	return 0;
}


/*	Suport for compileInterpreterPrimitive. Generate inline code so as to
	record the primitive
	trace as fast as possible. */

	/* SimpleStackBasedCogit>>#genFastPrimTraceUsing:and: */
static void
genFastPrimTraceUsingand(sqInt r1, sqInt r2)
{
    sqInt offset;
    sqInt offset1;
    sqInt offset2;
    sqInt wordConstant;

	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(MoveCqR, 0, TempReg));
	/* begin MoveMb:r:R: */
	offset = primTraceLogIndexAddress();
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveMbrR, offset, TempReg, r2));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, r2, r1);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(AddCqR, 1, r1));
	/* begin MoveR:Mb:r: */
	offset1 = primTraceLogIndexAddress();
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset1, genoperandoperandoperand(MoveRMbr, r1, offset1, TempReg));
	addDependent(methodLabel, annotateAbsolutePCRef(gMoveCwR(((sqInt)methodLabel), r1)));
	/* begin MoveMw:r:R: */
	offset2 = offsetof(CogMethod, selector);
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset2, genoperandoperandoperand(MoveMwrR, offset2, r1, TempReg));
	/* begin MoveCw:R: */
	wordConstant = ((sqInt)(primTraceLogAddress()));
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(wordConstant, genoperandoperand(MoveCwR, wordConstant, r1));
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, TempReg, r2, r1);
}

	/* SimpleStackBasedCogit>>#genLongJumpIfFalse */
static sqInt
genLongJumpIfFalse(void)
{
    sqInt distance;
    sqInt target;

	distance = v3LongForwardBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	target = (distance + 2) + bytecodePC;
	return genJumpIfto(falseObject(), target);
}

	/* SimpleStackBasedCogit>>#genLongJumpIfTrue */
static sqInt
genLongJumpIfTrue(void)
{
    sqInt distance;
    sqInt target;

	distance = v3LongForwardBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	target = (distance + 2) + bytecodePC;
	return genJumpIfto(trueObject(), target);
}


/*	237		11101101	i i i i i i i i	Pop and Store Temporary Variable #iiiiiiii */

	/* SimpleStackBasedCogit>>#genLongStoreAndPopTemporaryVariableBytecode */
static sqInt
genLongStoreAndPopTemporaryVariableBytecode(void)
{
	return genStorePopTemporaryVariable(1, byte1);
}

	/* SimpleStackBasedCogit>>#genLongUnconditionalBackwardJump */
static sqInt
genLongUnconditionalBackwardJump(void)
{
    sqInt distance;
    sqInt targetpc;

	distance = v3LongBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	assert(distance < 0);
	targetpc = (distance + 2) + bytecodePC;
	return genJumpBackTo(targetpc);
}

	/* SimpleStackBasedCogit>>#genLongUnconditionalForwardJump */
static sqInt
genLongUnconditionalForwardJump(void)
{
    sqInt distance;
    sqInt targetpc;

	distance = v3LongBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	assert(distance >= 0);
	targetpc = (distance + 2) + bytecodePC;
	return genJumpTo(targetpc);
}

	/* SimpleStackBasedCogit>>#genMoveFalseR: */
static AbstractInstruction *
genMoveFalseR(sqInt reg)
{
    sqInt constant;

	/* begin genMoveConstant:R: */
	constant = falseObject();
	return (shouldAnnotateObjectReference(constant)
		? annotateobjRef(gMoveCwR(constant, reg), constant)
		: (/* begin MoveCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, reg))));
}

	/* SimpleStackBasedCogit>>#genMoveTrueR: */
static AbstractInstruction *
genMoveTrueR(sqInt reg)
{
    sqInt constant;

	/* begin genMoveConstant:R: */
	constant = trueObject();
	return (shouldAnnotateObjectReference(constant)
		? annotateobjRef(gMoveCwR(constant, reg), constant)
		: (/* begin MoveCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, reg))));
}

	/* SimpleStackBasedCogit>>#genMustBeBooleanTrampolineFor:called: */
static sqInt
genMustBeBooleanTrampolineForcalled(sqInt boolean, char *trampolineName)
{
	zeroOpcodeIndex();
	assert(!(shouldAnnotateObjectReference(boolean)));
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(boolean, genoperandoperand(AddCqR, boolean, TempReg));
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceSendMustBeBoolean, trampolineName, 1, TempReg, null, null, null, 0, 1, null, 1);
}

	/* SimpleStackBasedCogit>>#genPrimitiveEqual */
static sqInt
genPrimitiveEqual(void)
{
	return genSmallIntegerComparisonorDoubleComparison(JumpZero, gJumpFPEqual);
}

	/* SimpleStackBasedCogit>>#genPrimitiveFloatAdd */
static sqInt
genPrimitiveFloatAdd(void)
{
	return genDoubleArithmeticpreOpCheck(AddRdRd, null);
}

	/* SimpleStackBasedCogit>>#genPrimitiveFloatDivide */
static sqInt
genPrimitiveFloatDivide(void)
{
	return genDoubleArithmeticpreOpCheck(DivRdRd, genDoubleFailIfZeroArgRcvrarg);
}

	/* SimpleStackBasedCogit>>#genPrimitiveFloatEqual */
static sqInt
genPrimitiveFloatEqual(void)
{
	return genDoubleComparisoninvert(gJumpFPEqual, 0);
}

	/* SimpleStackBasedCogit>>#genPrimitiveFloatGreaterOrEqual */
static sqInt
genPrimitiveFloatGreaterOrEqual(void)
{
	return genDoubleComparisoninvert(gJumpFPGreaterOrEqual, 0);
}

	/* SimpleStackBasedCogit>>#genPrimitiveFloatGreaterThan */
static sqInt
genPrimitiveFloatGreaterThan(void)
{
	return genDoubleComparisoninvert(gJumpFPGreater, 0);
}

	/* SimpleStackBasedCogit>>#genPrimitiveFloatLessOrEqual */
static sqInt
genPrimitiveFloatLessOrEqual(void)
{
	return genDoubleComparisoninvert(gJumpFPGreaterOrEqual, 1);
}

	/* SimpleStackBasedCogit>>#genPrimitiveFloatLessThan */
static sqInt
genPrimitiveFloatLessThan(void)
{
	return genDoubleComparisoninvert(gJumpFPGreater, 1);
}

	/* SimpleStackBasedCogit>>#genPrimitiveFloatMultiply */
static sqInt
genPrimitiveFloatMultiply(void)
{
	return genDoubleArithmeticpreOpCheck(MulRdRd, null);
}

	/* SimpleStackBasedCogit>>#genPrimitiveFloatNotEqual */
static sqInt
genPrimitiveFloatNotEqual(void)
{
	return genDoubleComparisoninvert(gJumpFPNotEqual, 0);
}

	/* SimpleStackBasedCogit>>#genPrimitiveFloatSubtract */
static sqInt
genPrimitiveFloatSubtract(void)
{
	return genDoubleArithmeticpreOpCheck(SubRdRd, null);
}

	/* SimpleStackBasedCogit>>#genPrimitiveGreaterOrEqual */
static sqInt
genPrimitiveGreaterOrEqual(void)
{
	return genSmallIntegerComparisonorDoubleComparison(JumpGreaterOrEqual, gJumpFPGreaterOrEqual);
}

	/* SimpleStackBasedCogit>>#genPrimitiveGreaterThan */
static sqInt
genPrimitiveGreaterThan(void)
{
	return genSmallIntegerComparisonorDoubleComparison(JumpGreater, gJumpFPGreater);
}

	/* SimpleStackBasedCogit>>#genPrimitiveLessOrEqual */
static sqInt
genPrimitiveLessOrEqual(void)
{
	return genSmallIntegerComparisonorDoubleComparison(JumpLessOrEqual, gJumpFPLessOrEqual);
}

	/* SimpleStackBasedCogit>>#genPrimitiveLessThan */
static sqInt
genPrimitiveLessThan(void)
{
	return genSmallIntegerComparisonorDoubleComparison(JumpLess, gJumpFPLess);
}

	/* SimpleStackBasedCogit>>#genPrimitiveNotEqual */
static sqInt
genPrimitiveNotEqual(void)
{
	return genSmallIntegerComparisonorDoubleComparison(JumpNonZero, gJumpFPNotEqual);
}


/*	Generate the substitute return code for an external or FFI primitive call.
	On success simply return, extracting numArgs from newMethod.
	On primitive failure call ceActivateFailingPrimitiveMethod: newMethod. */

	/* SimpleStackBasedCogit>>#genPrimReturnEnterCogCodeEnilopmart: */
static void
genPrimReturnEnterCogCodeEnilopmart(sqInt profiling)
{
    AbstractInstruction *abstractInstruction;
    sqInt address;
    sqInt address1;
    sqInt address2;
    sqInt address3;
    sqInt address4;
    sqInt address5;
    sqInt address6;
    sqInt address7;
    sqInt address8;
    sqInt callTarget;
    AbstractInstruction *continuePostSample;
    AbstractInstruction * inst;
    AbstractInstruction *jmpFail;
    AbstractInstruction *jmpSample;
    sqInt reg;

	zeroOpcodeIndex();
	if (profiling) {

		/* Test nextProfileTick for being non-zero and call checkProfileTick: if so.
		   N.B. nextProfileTick is 64-bits so 32-bit systems need to test both halves. */

		/* begin MoveAw:R: */
		address = nextProfileTickAddress();
		/* begin gen:literal:operand: */
		checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, TempReg));
		/* begin MoveAw:R: */
		address1 = (nextProfileTickAddress()) + BytesPerWord;
		/* begin gen:literal:operand: */
		checkLiteralforInstruction(address1, genoperandoperand(MoveAwR, address1, ClassReg));
		/* begin OrR:R: */
		genoperandoperand(OrRR, TempReg, ClassReg);

		/* begin JumpNonZero: */
		jmpSample = genoperand(JumpNonZero, ((sqInt)0));
		/* begin Label */
		continuePostSample = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	}
	maybeCompileAllocFillerCheck();
	/* begin MoveAw:R: */
	address6 = primFailCodeAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address6, genoperandoperand(MoveAwR, address6, TempReg));
	flag("ask concrete code gen if move sets condition codes?");
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, TempReg));
	/* begin JumpNonZero: */
	jmpFail = genoperand(JumpNonZero, ((sqInt)0));
	genLoadStackPointers(backEnd);
	/* begin PopR: */
	genoperand(PopR, ReceiverResultReg);
	/* begin MoveAw:R: */
	address3 = instructionPointerAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address3, genoperandoperand(MoveAwR, address3, PCReg));


	jmpTarget(jmpFail, gMoveAwR(newMethodAddress(), SendNumArgsReg));
	/* begin MoveAw:R: */
	address7 = cStackPointerAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address7, genoperandoperand(MoveAwR, address7, SPReg));
	compileCallFornumArgsargargargargresultRegsaveRegs(ceActivateFailingPrimitiveMethod, 1, SendNumArgsReg, null, null, null, null, 0);
	/* begin MoveAw:R: */
	address8 = instructionPointerAddress();
	reg = LinkReg;
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address8, genoperandoperand(MoveAwR, address8, reg));
	genLoadStackPointers(backEnd);
	/* begin MoveMw:r:R: */
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveMwrR, 0, SPReg, ReceiverResultReg));

	/* begin RetN: */
	genoperand(RetN, BytesPerWord);
	if (profiling) {

		/* Call ceCheckProfileTick: to record sample and then continue.  newMethod
		   should be up-to-date.  Need to save and restore the link reg around this call. */

		jmpTarget(jmpSample, gLabel());
		/* begin saveAndRestoreLinkRegAround: */
		/* begin PushR: */
		inst = genoperand(PushR, LinkReg);
		/* begin CallFullRT: */
		callTarget = (unsigned long)ceCheckProfileTick;
		/* begin CallFull: */
		/* begin gen:literal: */
		checkLiteralforInstruction(callTarget, genoperand(CallFull, callTarget));


		/* begin PopR: */
		genoperand(PopR, LinkReg);
		inst;
		/* begin Jump: */
		genoperand(Jump, ((sqInt)continuePostSample));
	}
}


/*	SistaV1: 230		11100110	iiiiiiii		PushNClosureTemps iiiiiiii */

	/* SimpleStackBasedCogit>>#genPushClosureTempsBytecode */
static sqInt
genPushClosureTempsBytecode(void)
{
    sqInt i;

	for (i = 1; i <= byte1; i += 1) {
		genPushLiteral(nilObject());
	}
	return 0;
}

	/* SimpleStackBasedCogit>>#genPushConstantFalseBytecode */
static sqInt
genPushConstantFalseBytecode(void)
{
	return genPushLiteral(falseObject());
}

	/* SimpleStackBasedCogit>>#genPushConstantNilBytecode */
static sqInt
genPushConstantNilBytecode(void)
{
	return genPushLiteral(nilObject());
}

	/* SimpleStackBasedCogit>>#genPushConstantTrueBytecode */
static sqInt
genPushConstantTrueBytecode(void)
{
	return genPushLiteral(trueObject());
}

	/* SimpleStackBasedCogit>>#genPushLiteralConstantBytecode */
static sqInt
genPushLiteralConstantBytecode(void)
{
	return genPushLiteralIndex(byte0 & 0x1F);
}


/*	<SmallInteger> */

	/* SimpleStackBasedCogit>>#genPushLiteralIndex: */
static sqInt
genPushLiteralIndex(sqInt literalIndex)
{
    sqInt literal;

	literal = getLiteral(literalIndex);
	return genPushLiteral(literal);
}

	/* SimpleStackBasedCogit>>#genPushLiteralVariableBytecode */
static sqInt
genPushLiteralVariableBytecode(void)
{
	return genPushLiteralVariable(byte0 & 0x1F);
}

	/* SimpleStackBasedCogit>>#genPushQuickIntegerConstantBytecode */
static sqInt
genPushQuickIntegerConstantBytecode(void)
{
	return genPushLiteral((((byte0 - 117) << 1) | 1));
}

	/* SimpleStackBasedCogit>>#genPushReceiverVariableBytecode */
static sqInt
genPushReceiverVariableBytecode(void)
{
	return genPushReceiverVariable(byte0 & 15);
}

	/* SimpleStackBasedCogit>>#genPushTemporaryVariableBytecode */
static sqInt
genPushTemporaryVariableBytecode(void)
{
	return genPushTemporaryVariable(byte0 & 15);
}


/*	because selected by CoInterpreter>>quickPrimitiveGeneratorFor: */

	/* SimpleStackBasedCogit>>#genQuickReturnConst */
sqInt
genQuickReturnConst(void)
{
    sqInt constant;

	constant = quickPrimitiveConstantFor(primitiveIndex);
	annotateobjRef((isImmediate(constant)
		? (/* begin MoveCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, ReceiverResultReg)))
		: (/* begin MoveCw:R: */
			/* begin gen:literal:operand: */
			checkLiteralforInstruction(constant, genoperandoperand(MoveCwR, constant, ReceiverResultReg)))), constant);
	return genUpArrowReturn();
}


/*	because selected by CoInterpreter>>quickPrimitiveGeneratorFor: */

	/* SimpleStackBasedCogit>>#genQuickReturnInstVar */
sqInt
genQuickReturnInstVar(void)
{
    sqInt index;

	index = quickPrimitiveInstVarIndexFor(primitiveIndex);
	genLoadSlotsourceRegdestReg(index, ReceiverResultReg, ReceiverResultReg);
	return genUpArrowReturn();
}


/*	because selected by CoInterpreter>>quickPrimitiveGeneratorFor: */

	/* SimpleStackBasedCogit>>#genQuickReturnSelf */
sqInt
genQuickReturnSelf(void)
{
	return genUpArrowReturn();
}

	/* SimpleStackBasedCogit>>#genReturnFalse */
static sqInt
genReturnFalse(void)
{
    sqInt constant;

	/* begin genMoveFalseR: */
	/* begin genMoveConstant:R: */
	constant = falseObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, ReceiverResultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, ReceiverResultReg));
	}
	return genUpArrowReturn();
}

	/* SimpleStackBasedCogit>>#genReturnNil */
static sqInt
genReturnNil(void)
{
    sqInt constant;

	/* begin genMoveConstant:R: */
	constant = nilObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, ReceiverResultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, ReceiverResultReg));
	}
	return genUpArrowReturn();
}

	/* SimpleStackBasedCogit>>#genReturnTrue */
static sqInt
genReturnTrue(void)
{
    sqInt constant;

	/* begin genMoveTrueR: */
	/* begin genMoveConstant:R: */
	constant = trueObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, ReceiverResultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, ReceiverResultReg));
	}
	return genUpArrowReturn();
}


/*	Can use any of the first 64 literals for the selector and pass up to 3
	arguments. 
 */

	/* SimpleStackBasedCogit>>#genSecondExtendedSendBytecode */
static sqInt
genSecondExtendedSendBytecode(void)
{
	return genSendnumArgs(getLiteral(byte1 & 0x3F), ((usqInt) byte1) >> 6);
}

	/* SimpleStackBasedCogit>>#genSendLiteralSelector0ArgsBytecode */
static sqInt
genSendLiteralSelector0ArgsBytecode(void)
{
	return genSendnumArgs(getLiteral(byte0 & 15), 0);
}

	/* SimpleStackBasedCogit>>#genSendLiteralSelector1ArgBytecode */
static sqInt
genSendLiteralSelector1ArgBytecode(void)
{
	return genSendnumArgs(getLiteral(byte0 & 15), 1);
}

	/* SimpleStackBasedCogit>>#genSendLiteralSelector2ArgsBytecode */
static sqInt
genSendLiteralSelector2ArgsBytecode(void)
{
	return genSendnumArgs(getLiteral(byte0 & 15), 2);
}

	/* SimpleStackBasedCogit>>#genShortJumpIfFalse */
static sqInt
genShortJumpIfFalse(void)
{
    sqInt distance;
    sqInt target;

	distance = v3ShortForwardBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	target = (distance + 1) + bytecodePC;
	return genJumpIfto(falseObject(), target);
}

	/* SimpleStackBasedCogit>>#genShortUnconditionalJump */
static sqInt
genShortUnconditionalJump(void)
{
    sqInt distance;
    sqInt target;

	distance = v3ShortForwardBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	target = (distance + 1) + bytecodePC;
	return genJumpTo(target);
}

	/* SimpleStackBasedCogit>>#genSpecialSelectorSend */
static sqInt
genSpecialSelectorSend(void)
{
    sqInt index;
    sqInt numArgs;
    sqInt selector;

	index = byte0 - (FirstSpecialSelector);
	selector = specialSelector(index);
	numArgs = specialSelectorNumArgs(index);
	return genSendnumArgs(selector, numArgs);
}

	/* SimpleStackBasedCogit>>#genStoreAndPopReceiverVariableBytecode */
static sqInt
genStoreAndPopReceiverVariableBytecode(void)
{
	return genStorePopReceiverVariable(1, byte0 & 7);
}

	/* SimpleStackBasedCogit>>#genStoreAndPopRemoteTempLongBytecode */
static sqInt
genStoreAndPopRemoteTempLongBytecode(void)
{
	return genStorePopRemoteTempAt(1, byte1, byte2);
}

	/* SimpleStackBasedCogit>>#genStoreAndPopTemporaryVariableBytecode */
static sqInt
genStoreAndPopTemporaryVariableBytecode(void)
{
	return genStorePopTemporaryVariable(1, byte0 & 7);
}

	/* SimpleStackBasedCogit>>#genStoreRemoteTempLongBytecode */
static sqInt
genStoreRemoteTempLongBytecode(void)
{
	return genStorePopRemoteTempAt(0, byte1, byte2);
}


/*	If allocCheckFiller is true, words in newSpace from freeStart to
	scavengeThreshold are filled with their address, and after each call of a
	plugin primitive, the VM checks
	that freeStart points to a word containing the value of freeStart. This is
	a simple
	check for primitives overwriting the ends of an object. */

	/* SimpleStackBasedCogit>>#maybeCompileAllocFillerCheck */
static void
maybeCompileAllocFillerCheck(void)
{
    sqInt address;
    sqInt address1;
    AbstractInstruction *jmpOk;

	if (getCheckAllocFiller()) {
		/* begin MoveAw:R: */
		address = freeStartAddress();
		/* begin gen:literal:operand: */
		checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, ClassReg));
		/* begin MoveMw:r:R: */
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveMwrR, 0, ClassReg, TempReg));
		/* begin CmpR:R: */
		genoperandoperand(CmpRR, ClassReg, TempReg);
		/* begin JumpZero: */
		jmpOk = genoperand(JumpZero, ((sqInt)0));
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(PrimErrWritePastObject, genoperandoperand(MoveCqR, PrimErrWritePastObject, TempReg));
		/* begin MoveR:Aw: */
		address1 = primFailCodeAddress();
		/* begin gen:operand:literal: */
		checkLiteralforInstruction(address1, genoperandoperand(MoveRAw, TempReg, address1));
		jmpTarget(jmpOk, gLabel());
	}
}

	/* SimpleStackBasedCogit>>#recordCallOffsetIn: */
void
recordCallOffsetIn(CogMethod *cogMethod)
{
    unsigned long offset;
    sqInt *offsetTable;

	offset = ((primSetFunctionLabel->address)) - (((sqInt)cogMethod));
	if ((externalSetPrimOffsets[(cogMethod->cmNumArgs)]) == null) {
		externalSetPrimOffsets[(cogMethod->cmNumArgs)] = offset;
	}
	else {
		assert((externalSetPrimOffsets[(cogMethod->cmNumArgs)]) == offset);
	}
	offsetTable = (isCallPreceedingReturnPC(backEnd, ((usqInt)((primInvokeLabel->address))))
		? externalPrimCallOffsets
		: externalPrimJumpOffsets);
	offset = ((primInvokeLabel->address)) - (((sqInt)cogMethod));
	if ((offsetTable[(cogMethod->cmNumArgs)]) == null) {
		offsetTable[(cogMethod->cmNumArgs)] = offset;
	}
	else {
		assert((offsetTable[(cogMethod->cmNumArgs)]) == offset);
	}
}

	/* SimpleStackBasedCogit>>#register:isInMask: */
static sqInt
registerisInMask(sqInt reg, sqInt mask)
{
	return mask & (registerMaskFor(reg));
}


/*	We must ensure the ReceiverResultReg is live across the store check so
	that we can store into receiver inst vars in a frameless method since self
	exists only in ReceiverResultReg in a frameless method. So if
	ReceiverResultReg is
	caller-saved we use the fact that ceStoreCheck: answers its argument to
	reload ReceiverResultReg cheaply. Otherwise we don't care about the result
	and use the cResultRegister, effectively a no-op (see
	compileTrampoline...)  */

	/* SimpleStackBasedCogit>>#returnRegForStoreCheck */
static sqInt
returnRegForStoreCheck(void)
{
	return (callerSavedRegMask & (registerMaskFor(ReceiverResultReg))
		? ReceiverResultReg
		: cResultRegister(backEnd));
}

	/* SimpleStackBasedCogit>>#rewritePrimInvocationIn:to: */
void
rewritePrimInvocationInto(CogMethod *cogMethod, void (*primFunctionPointer)(void))
{
    usqInt address;
    sqInt extent;
    sqInt flags;
    sqInt primIndex;

	assert(((cogMethod->cmType)) == CMMethod);
	primIndex = primitiveIndexOfMethodheader((cogMethod->methodObject), (cogMethod->methodHeader));
	flags = primitivePropertyFlags(primIndex);
	if (flags & PrimCallNeedsPrimitiveFunction) {
		storeLiteralbeforeFollowingAddress(backEnd, ((usqInt)primFunctionPointer), (((usqInt)cogMethod)) + (externalSetPrimOffsets[(cogMethod->cmNumArgs)]));
	}
	if (flags & PrimCallMayCallBack) {
		address = (((usqInt)cogMethod)) + (externalPrimJumpOffsets[(cogMethod->cmNumArgs)]);
		extent = rewriteFullTransferAttargetexpectedInstruction(backEnd, address, ((usqInt)primFunctionPointer), 3778019100UL);
	}
	else {
		address = (((usqInt)cogMethod)) + (externalPrimCallOffsets[(cogMethod->cmNumArgs)]);
		extent = rewriteFullTransferAttargetexpectedInstruction(backEnd, address, ((usqInt)primFunctionPointer), 3778019132UL);
	}
	flushICacheFromto(processor, (((usqInt)cogMethod)) + cmNoCheckEntryOffset, (((usqInt)address)) + extent);
}

	/* SimpleStackBasedCogit>>#v3:Block:Code:Size: */
static sqInt
v3BlockCodeSize(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	assert(nExts <= 0);
	return ((fetchByteofObject(pc + 2, aMethodObj)) << 8) + (fetchByteofObject(pc + 3, aMethodObj));
}


/*	Answer the distance of a two byte forward long jump. */

	/* SimpleStackBasedCogit>>#v3:LongForward:Branch:Distance: */
static sqInt
v3LongForwardBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	assert(nExts == 0);
	return (((fetchByteofObject(pc, aMethodObj)) & 3) << 8) + (fetchByteofObject(pc + 1, aMethodObj));
}


/*	Answer the distance of a two byte forward long jump. */

	/* SimpleStackBasedCogit>>#v3:Long:Branch:Distance: */
static sqInt
v3LongBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	assert(nExts == 0);
	return ((((fetchByteofObject(pc, aMethodObj)) & 7) - 4) << 8) + (fetchByteofObject(pc + 1, aMethodObj));
}


/*	N.B. This serves for both BlueBook/V3 and V4 short jumps. */

	/* SimpleStackBasedCogit>>#v3:ShortForward:Branch:Distance: */
static sqInt
v3ShortForwardBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	assert(nExts == 0);
	return ((fetchByteofObject(pc, aMethodObj)) & 7) + 1;
}

	/* SimpleStackBasedCogit>>#voidCogCompiledCode */
void
voidCogCompiledCode(void)
{
    sqInt i;

	clearCogCompiledCode();
	for (i = 0; i <= MaxNumArgs; i += 1) {
		externalPrimJumpOffsets[i] = null;
		externalPrimCallOffsets[i] = null;
	}
}


/*	Add a blockStart for an embedded block. For a binary tree walk block
	dispatch blocks must be compiled in pc/depth-first order but are scanned
	in breadth-first
	order, so do an insertion sort (which of course is really a bubble sort
	because we
	have to move everything higher to make room). */

	/* StackToRegisterMappingCogit>>#addBlockStartAt:numArgs:numCopied:span: */
static BlockStart *
addBlockStartAtnumArgsnumCopiedspan(sqInt bytecodepc, sqInt numArgs, sqInt numCopied, sqInt span)
{
    BlockStart *blockStart;
    sqInt i;
    sqInt j;


	/* Transcript ensureCr; nextPutAll: 'addBlockStartAt: '; print: bytecodepc; cr; flush. */

	if (blockCount > 0) {
		i = blockCount - 1;
		while (1) {

			/* check for repeat addition during recompilation due to initialNil miscount. */

			blockStart = (&(blockStarts[i]));
			if (((blockStart->startpc)) == bytecodepc) {
				return blockStart;
			}
			if (!((((blockStart->startpc)) > bytecodepc)
			 && (i > 0))) break;
			i -= 1;
		}
		for (j = blockCount; j >= (i + 1); j += -1) {
			blockStarts[j] = (blockStarts[j - 1]);
		}
		blockStart = (&(blockStarts[i + 1]));
	}
	else {
		blockStart = (&(blockStarts[blockCount]));
	}
	blockCount += 1;
	(blockStart->startpc = bytecodepc);
	(blockStart->numArgs = numArgs);
	(blockStart->numCopied = numCopied);
	(blockStart->numInitialNils = 0);
	(blockStart->stackCheckLabel = null);
	(blockStart->hasInstVarRef = 0);
	(blockStart->span = span);
	return blockStart;
}


/*	If the stack entry is already in a register not conflicting with regMask,
	answers it,
	else allocate a new register not conflicting with reg mask
 */

	/* StackToRegisterMappingCogit>>#allocateRegForStackEntryAt:notConflictingWith: */
static sqInt
allocateRegForStackEntryAtnotConflictingWith(sqInt index, sqInt regMask)
{
    CogSimStackEntry *stackEntry;

	stackEntry = ssValue(index);
	if ((((stackEntry->type)) == SSRegister)
	 && (!(registerisInMask((stackEntry->registerr), regMask)))) {
		return (stackEntry->registerr);
	}
	return allocateRegNotConflictingWith(regMask);
}


/*	if there's a free register, use it */

	/* StackToRegisterMappingCogit>>#allocateRegNotConflictingWith: */
static sqInt
allocateRegNotConflictingWith(sqInt regMask)
{
    sqInt reg;

	reg = availableRegisterOrNilFor(backEnd, (liveRegisters()) | regMask);
	if (!(reg)) {

		/* No free register, choose one that does not conflict with regMask */

		reg = freeAnyRegNotConflictingWith(regMask);
	}
	if (reg == ReceiverResultReg) {

		/* If we've allocated RcvrResultReg, it's not live anymore */

		(optStatus.isReceiverResultRegLive = 0);
	}
	return reg;
}

	/* StackToRegisterMappingCogit>>#annotateBytecodeIfAnnotated: */
static void
annotateBytecodeIfAnnotated(CogSimStackEntry *aSimStackEntry)
{
    AbstractInstruction *abstractInstruction;

	if ((aSimStackEntry->annotateUse)) {
		/* begin annotateBytecode: */
		if (prevInstIsPCAnnotated()) {
			/* begin Nop */
			abstractInstruction = gen(Nop);
		}
		else {
			/* begin Label */
			abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		}
		(abstractInstruction->annotation = HasBytecodePC);
		abstractInstruction;
		(aSimStackEntry->annotateUse = 0);
	}
}

	/* StackToRegisterMappingCogit>>#anyReferencesToRegister:inTopNItems: */
static sqInt
anyReferencesToRegisterinTopNItems(sqInt reg, sqInt n)
{
    sqInt i;
    sqInt regMask;

	regMask = registerMaskFor(reg);
	for (i = simStackPtr; i >= ((simStackPtr - n) + 1); i += -1) {
		if ((registerMask(simStackAt(i))) & regMask) {
			return 1;
		}
	}
	return 0;
}


/*	This is a static version of ceCallCogCodePopReceiverArg0Regs
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

	/* StackToRegisterMappingCogit>>#callCogCodePopReceiverArg0Regs */
void
callCogCodePopReceiverArg0Regs(void)
{
	realCECallCogCodePopReceiverArg0Regs();
}


/*	This is a static version of ceCallCogCodePopReceiverArg1Arg0Regs
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

	/* StackToRegisterMappingCogit>>#callCogCodePopReceiverArg1Arg0Regs */
void
callCogCodePopReceiverArg1Arg0Regs(void)
{
	realCECallCogCodePopReceiverArg1Arg0Regs();
}


/*	Loop over bytecodes, dispatching to the generator for each bytecode,
	handling fixups in due course.
 */

	/* StackToRegisterMappingCogit>>#compileAbstractInstructionsFrom:through: */
static sqInt
compileAbstractInstructionsFromthrough(sqInt start, sqInt end)
{
    AbstractInstruction *abstractInstruction;
    sqInt debugBytecodePointers;
    BytecodeDescriptor *descriptor;
    BytecodeFixup *fixup;
    sqInt nExts;
    sqInt nextOpcodeIndex;
    sqInt result;

	traceSimStack();
	bytecodePC = start;
	nExts = 0;
	descriptor = null;
	deadCode = 0;
	while (1) {
		;

		/* If there's no fixup following a return there's no jump to that code and it is dead. */

		fixup = fixupAt(bytecodePC - initialPC);
		if ((descriptor != null)
		 && ((descriptor->isReturn))) {
			deadCode = 1;
		}
		if ((((usqInt)((fixup->targetInstruction)))) > 0) {
			if ((((usqInt)((fixup->targetInstruction)))) >= 2) {
				mergeafterContinuation(fixup, !deadCode);
			}
			deadCode = 0;
		}
		
		byte0 = (fetchByteofObject(bytecodePC, methodObj)) + bytecodeSetOffset;
		descriptor = generatorAt(byte0);
		loadSubsequentBytesForDescriptorat(descriptor, bytecodePC);
		nextOpcodeIndex = opcodeIndex;
		if (deadCode) {

			/* insert nops for dead code that is mapped so that bc to mc mapping is not many to one */

			if (((descriptor->isMapped))
			 || (inBlock
			 && ((descriptor->isMappedInBlock)))) {
				/* begin annotateBytecode: */
				/* begin Nop */
				abstractInstruction = gen(Nop);
				(abstractInstruction->annotation = HasBytecodePC);
				abstractInstruction;
			}
			result = 0;
		}
		else {
			result = ((descriptor->generator))();
		}
		if (!((descriptor->isExtension))) {

			/* extended bytecodes must consume their extensions */

			assert((extA == 0)
			 && (extB == 0));
		}
		traceDescriptor(descriptor);
		traceSimStack();
		if ((((((usqInt)((fixup->targetInstruction)))) >= 1) && ((((usqInt)((fixup->targetInstruction)))) <= 2))) {

			/* There is a fixup for this bytecode.  It must point to the first generated
			   instruction for this bytecode.  If there isn't one we need to add a label. */

			if (opcodeIndex == nextOpcodeIndex) {
				/* begin Label */
				genoperandoperand(Label, (labelCounter += 1), bytecodePC);
			}
			(fixup->targetInstruction = abstractInstructionAt(nextOpcodeIndex));
		}
		/* begin maybeDumpLiterals: */
		if ((mustDumpLiterals(opcodeIndex))
		 || ((isUnconditionalBranch(descriptor))
		 || ((descriptor->isReturn)))) {
			dumpLiterals(!((isUnconditionalBranch(descriptor))
 || ((descriptor->isReturn))));
		}
		bytecodePC = (bytecodePC + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bytecodePC, nExts, methodObj)
	: 0));
		if (!((result == 0)
		 && (bytecodePC <= end))) break;
		nExts = ((descriptor->isExtension)
			? nExts + 1
			: 0);
	}
	/* begin checkEnoughOpcodes */
	if (opcodeIndex > numAbstractOpcodes) {
		error("Cog JIT internal error. Too many abstract opcodes.  Num opcodes heuristic is too optimistic.");
	}
	return result;
}

	/* StackToRegisterMappingCogit>>#compileBlockBodies */
static sqInt
compileBlockBodies(void)
{
    BlockStart *blockStart;
    sqInt compiledBlocksCount;
    sqInt i;
    sqInt initialIndexOfIRC;
    sqInt initialOpcodeIndex;
    sqInt initialStackPtr;
    sqInt result;
    sqInt savedNeedsFrame;
    sqInt savedNumArgs;
    sqInt savedNumTemps;

	initialIndexOfIRC = 0;
	assert(blockCount > 0);
	savedNeedsFrame = needsFrame;
	savedNumArgs = methodOrBlockNumArgs;
	savedNumTemps = methodOrBlockNumTemps;
	inBlock = 1;
	compiledBlocksCount = 0;
	while (compiledBlocksCount < blockCount) {
		blockStart = blockStartAt(compiledBlocksCount);
		scanBlock(blockStart);
		initialOpcodeIndex = opcodeIndex;
		saveForBlockCompile();
		
#    if NewspeakVM
		initialIndexOfIRC = indexOfIRC;

#    endif /* NewspeakVM */

		while (1) {
			compileBlockEntry(blockStart);
			initialStackPtr = simStackPtr;
			if (((result = compileAbstractInstructionsFromthrough(((blockStart->startpc)) + (pushNilSizenumInitialNils(methodObj, (blockStart->numInitialNils))), (((blockStart->startpc)) + ((blockStart->span))) - 1))) < 0) {
				return result;
			}
			if (initialStackPtr == simStackPtr) break;
			assert(initialStackPtr > simStackPtr);
			(blockStart->numInitialNils = (((blockStart->numInitialNils)) + simStackPtr) - initialStackPtr);
			(((blockStart->fakeHeader))->dependent = null);
			reinitializeFixupsFromthrough(((blockStart->startpc)) + ((blockStart->numInitialNils)), (((blockStart->startpc)) + ((blockStart->span))) - 1);
			bzero(abstractOpcodes + initialOpcodeIndex,
									(opcodeIndex - initialOpcodeIndex) * sizeof(AbstractInstruction));
			opcodeIndex = initialOpcodeIndex;
			resetForBlockCompile();
			
#      if NewspeakVM
			indexOfIRC = initialIndexOfIRC;

#      endif /* NewspeakVM */

		}
		compiledBlocksCount += 1;
	}
	needsFrame = savedNeedsFrame;
	methodOrBlockNumArgs = savedNumArgs;
	methodOrBlockNumTemps = savedNumTemps;
	return 0;
}


/*	Build a frame for a block activation. See CoInterpreter
	class>>initializeFrameIndices. closure (in ReceiverResultReg)
	arg0
	...
	argN
	caller's saved ip/this stackPage (for a base frame)
	fp->	saved fp
	method
	context (uninitialized?)
	receiver
	first temp
	...
	sp->	Nth temp
	Avoid use of SendNumArgsReg which is the flag determining whether
	context switch is allowed on stack-overflow. */
/*	Build a frame for a block activation. See CoInterpreter
	class>>initializeFrameIndices. Override to push the register receiver and
	register arguments, if any, and to correctly
	initialize the explicitly nilled/pushed temp entries (they are /not/ of
	type constant nil). */

	/* StackToRegisterMappingCogit>>#compileBlockFrameBuild: */
static void
compileBlockFrameBuild(BlockStart *blockStart)
{
    AbstractInstruction *abstractInstruction;
    sqInt address;
    AbstractInstruction * cascade0;
    sqInt constant;
    sqInt i;
    sqInt ign;

	/* begin annotateBytecode: */
	/* begin Label */
	abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	(abstractInstruction->annotation = HasBytecodePC);
	abstractInstruction;
	/* begin PushR: */
	genoperand(PushR, LinkReg);

	/* begin PushR: */
	genoperand(PushR, FPReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SPReg, FPReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, ClassReg);
	cascade0 = (blockStart->fakeHeader);
	addDependent(cascade0, annotateAbsolutePCRef(gPushCw(((sqInt)((blockStart->fakeHeader))))));
	setLabelOffset(cascade0, MFMethodFlagIsBlockFlag);
	annotateobjRef(gPushCw(nilObject()), nilObject());
	if ((blockStart->hasInstVarRef)) {

		/* Use ReceiverResultReg for Context to agree with store check trampoline */

		genLoadSlotsourceRegdestReg(ClosureOuterContextIndex, ClassReg, ReceiverResultReg);
		genLoadSlotsourceRegdestReg(ReceiverIndex, ReceiverResultReg, Arg0Reg);
		genEnsureOopInRegNotForwardedscratchRegupdatingSlotin(Arg0Reg, TempReg, ReceiverIndex, ReceiverResultReg);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, Arg0Reg, ReceiverResultReg);
	}
	else {
		genLoadSlotsourceRegdestReg(ClosureOuterContextIndex, ClassReg, Arg0Reg);
		genLoadSlotsourceRegdestReg(ReceiverIndex, Arg0Reg, ReceiverResultReg);
	}
	/* begin PushR: */
	genoperand(PushR, ReceiverResultReg);
	for (i = 0; i < ((blockStart->numCopied)); i += 1) {
		genLoadSlotsourceRegdestReg(i + ClosureFirstCopiedValueIndex, ClassReg, TempReg);
		/* begin PushR: */
		genoperand(PushR, TempReg);
	}
	/* begin MoveAw:R: */
	address = stackLimitAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, TempReg));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, TempReg, SPReg);
	/* begin JumpBelow: */
	genoperand(JumpBelow, ((sqInt)stackOverflowCall));
	(blockStart->stackCheckLabel = annotateBytecode(gLabel()));
	methodOrBlockNumTemps = (((blockStart->numArgs)) + ((blockStart->numCopied))) + ((blockStart->numInitialNils));
	initSimStackForFramefulMethod((blockStart->startpc));
	if (((blockStart->numInitialNils)) > 0) {
		if (((blockStart->numInitialNils)) > 1) {
			/* begin genMoveConstant:R: */
			constant = nilObject();
			if (shouldAnnotateObjectReference(constant)) {
				annotateobjRef(gMoveCwR(constant, TempReg), constant);
			}
			else {
				/* begin MoveCq:R: */
				/* begin gen:quickConstant:operand: */
				checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, TempReg));
			}
			for (ign = 1; ign <= ((blockStart->numInitialNils)); ign += 1) {
				/* begin PushR: */
				genoperand(PushR, TempReg);
			}
		}
		else {
			annotateobjRef(gPushCw(nilObject()), nilObject());
		}
		methodOrBlockNumTemps = ((blockStart->numArgs)) + ((blockStart->numCopied));
	}
}


/*	Make sure ReceiverResultReg holds the receiver, loaded from the closure,
	which is what is initially in ReceiverResultReg. We must annotate the
	first instruction so that findMethodForStartBcpc:inHomeMethod: can
	function. We need two annotations because the first is a fiducial. */
/*	Make sure ReceiverResultReg holds the receiver, loaded from
	the closure, which is what is initially in ReceiverResultReg */

	/* StackToRegisterMappingCogit>>#compileBlockFramelessEntry: */
static void
compileBlockFramelessEntry(BlockStart *blockStart)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;

	methodOrBlockNumTemps = (((blockStart->numArgs)) + ((blockStart->numCopied))) + ((blockStart->numInitialNils));
	initSimStackForFramelessBlock((blockStart->startpc));
	/* begin annotateBytecode: */
	abstractInstruction = (blockStart->entryLabel);
	(abstractInstruction->annotation = HasBytecodePC);
	abstractInstruction;
	/* begin annotateBytecode: */
	abstractInstruction1 = (blockStart->entryLabel);
	(abstractInstruction1->annotation = HasBytecodePC);
	abstractInstruction1;
	genLoadSlotsourceRegdestReg(ClosureOuterContextIndex, ReceiverResultReg, TempReg);
	genLoadSlotsourceRegdestReg(ReceiverIndex, TempReg, ReceiverResultReg);
}

	/* StackToRegisterMappingCogit>>#compileCogMethod: */
static CogMethod *
compileCogMethod(sqInt selector)
{
    sqInt allocSize;
    sqInt debugStackPointers;
    sqInt extra;
    sqInt fixupSize;
    sqInt numBlocks;
    sqInt numBytecodes;
    sqInt numCleanBlocks;
    sqInt opcodeSize;
    sqInt result;

	methodOrBlockNumTemps = tempCountOf(methodObj);
	
	hasYoungReferent = (isYoungObject(methodObj))
	 || (isYoung(selector));
	methodOrBlockNumArgs = argumentCountOf(methodObj);
	inBlock = 0;
	postCompileHook = null;
	maxLitIndex = -1;
	extra = ((((primitiveIndex = primitiveIndexOf(methodObj))) > 0)
	 && (!(isQuickPrimitiveIndex(primitiveIndex)))
		? 30
		: 10);

	/* initial estimate.  Actual endPC is determined in scanMethod. */

	initialPC = startPCOfMethod(methodObj);
	endPC = (isQuickPrimitiveIndex(primitiveIndex)
		? initialPC - 1
		: numBytesOf(methodObj));
	numBytecodes = (endPC - initialPC) + 1;
	/* begin allocateOpcodes:bytecodes:ifFail: */
	numAbstractOpcodes = (numBytecodes + extra) * 10;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	allocSize = opcodeSize + fixupSize;
	if (allocSize > MaxStackAllocSize) {
		return ((CogMethod *) MethodTooBig);

		goto l1;
	}
	abstractOpcodes = alloca(allocSize);
	bzero(abstractOpcodes, allocSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
l1:	/* end allocateOpcodes:bytecodes:ifFail: */;
	if (((numBlocks = scanMethod())) < 0) {
		return ((CogMethod *) numBlocks);
	}
	numCleanBlocks = scanForCleanBlocks();
	allocateBlockStarts(numBlocks + numCleanBlocks);
	blockCount = 0;
	if (numCleanBlocks > 0) {
		addCleanBlockStarts();
	}
	if (!(maybeAllocAndInitIRCs())) {

		/* Inaccurate error code, but it'll do.  This will likely never fail. */

		return ((CogMethod *) InsufficientCodeSpace);
	}
	blockEntryLabel = null;
	(methodLabel->dependent = null);
	if (((result = compileEntireMethod())) < 0) {
		return ((CogMethod *) result);
	}
	return generateCogMethod(selector);
}


/*	Compile the abstract instructions for the entire method, including blocks. */
/*	Compile the abstract instructions for the entire method, including blocks. */

	/* StackToRegisterMappingCogit>>#compileEntireMethod */
static sqInt
compileEntireMethod(void)
{
    sqInt result;

	regArgsHaveBeenPushed = 0;
	compileAbort();
	compileEntry();
	if (((result = compilePrimitive())) < 0) {
		return result;
	}
	compileFrameBuild();
	if (((result = compileMethodBody())) < 0) {
		return result;
	}
	if (blockCount == 0) {
		return 0;
	}
	if (((result = compileBlockBodies())) < 0) {
		return result;
	}
	return compileBlockDispatch();
}


/*	Build a frame for a CogMethod activation. See CoInterpreter
	class>>initializeFrameIndices. receiver (in ReceiverResultReg)
	arg0
	...
	argN
	caller's saved ip/this stackPage (for a base frame)
	fp->	saved fp
	method
	context (uninitialized?)
	receiver
	first temp
	...
	sp->	Nth temp
	If there is a primitive and an error code the Nth temp is the error code.
	Ensure SendNumArgsReg is set early on (incidentally to nilObj) because
	it is the flag determining whether context switch is allowed on
	stack-overflow.  */
/*	Build a frame for a CogMethod activation. See CoInterpreter
	class>>initializeFrameIndices. Override to push the register receiver and
	register arguments, if any. */

	/* StackToRegisterMappingCogit>>#compileFrameBuild */
static sqInt
compileFrameBuild(void)
{
    sqInt address;
    sqInt constant;
    sqInt i;
    sqInt iLimiT;
    AbstractInstruction *jumpSkip;
    sqInt methodHeader;

	if (!needsFrame) {
		initSimStackForFramelessMethod(initialPC);
		return 0;
	}
	genPushRegisterArgs();
	if (!needsFrame) {
		return 0;
	}
	methodHeader = methodHeaderOf(methodObj);
	/* begin PushR: */
	genoperand(PushR, LinkReg);

	/* begin PushR: */
	genoperand(PushR, FPReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SPReg, FPReg);
	addDependent(methodLabel, annotateAbsolutePCRef(gPushCw(((sqInt)methodLabel))));
	/* begin genMoveConstant:R: */
	constant = nilObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, SendNumArgsReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, SendNumArgsReg));
	}
	/* begin PushR: */
	genoperand(PushR, SendNumArgsReg);
	/* begin PushR: */
	genoperand(PushR, ReceiverResultReg);
	for (i = (methodOrBlockNumArgs + 1), iLimiT = (temporaryCountOfMethodHeader(methodHeader)); i <= iLimiT; i += 1) {
		/* begin PushR: */
		genoperand(PushR, SendNumArgsReg);
	}
	if ((primitiveIndex > 0)
	 && ((longStoreBytecodeForHeader(methodHeader)) == (fetchByteofObject(initialPC + (sizeOfCallPrimitiveBytecode(methodHeader)), methodObj)))) {
		compileGetErrorCode();
		initialPC = (initialPC + (sizeOfCallPrimitiveBytecode(methodHeader))) + (sizeOfLongStoreTempBytecode(methodHeader));
	}
	/* begin MoveAw:R: */
	address = stackLimitAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, TempReg));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, TempReg, SPReg);
	if (canContextSwitchIfActivatingheader(methodObj, methodHeader)) {
		/* begin JumpBelow: */
		genoperand(JumpBelow, ((sqInt)stackOverflowCall));
		/* begin Label */
		stackCheckLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	}
	else {
		/* begin JumpAboveOrEqual: */
		jumpSkip = genoperand(JumpAboveOrEqual, ((sqInt)0));
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(0, genoperandoperand(MoveCqR, 0, SendNumArgsReg));
		/* begin Jump: */
		genoperand(Jump, ((sqInt)stackOverflowCall));
		jmpTarget(jumpSkip, (stackCheckLabel = gLabel()));
	}
	/* begin annotateBytecode: */
	(stackCheckLabel->annotation = HasBytecodePC);
	stackCheckLabel;
	
#  if NewspeakVM
	if (numIRCs > 0) {
		/* begin PrefetchAw: */
		/* begin gen:literal: */
		checkLiteralforInstruction(theIRCs, genoperand(PrefetchAw, theIRCs));
	}

#  endif /* NewspeakVM */

	initSimStackForFramefulMethod(initialPC);
}


/*	Compile the code for an open PIC. Perform a probe of the first-level
	method lookup cache followed by a call of ceSendFromInLineCacheMiss: if
	the probe fails.
	Override to push the register args when calling ceSendFromInLineCacheMiss: */

	/* StackToRegisterMappingCogit>>#compileOpenPIC:numArgs: */
static void
compileOpenPICnumArgs(sqInt selector, sqInt numArgs)
{
    AbstractInstruction *itsAHit;
    AbstractInstruction *jumpBCMethod;
    AbstractInstruction *jumpClassMiss;
    AbstractInstruction *jumpSelectorMiss;
    sqInt offset;
    sqInt offset1;
    sqInt offset2;
    sqInt offset3;
    sqInt offset4;
    sqInt offset5;
    sqInt offset6;

	compilePICAbort(numArgs);

	/* Do first of three probes.  See CoInterpreter>>lookupInMethodCacheSel:classTag: */

	entry = genGetClassTagOfintoscratchReg(ReceiverResultReg, ClassReg, TempReg);
	flag("lookupInMethodCacheSel:classTag:");
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, SendNumArgsReg);
	annotateobjRef(gXorCwR(selector, ClassReg), selector);
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, shiftForWord(), ClassReg);
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(MethodCacheMask << (shiftForWord()), genoperandoperand(AndCqR, MethodCacheMask << (shiftForWord()), ClassReg));
	/* begin MoveMw:r:R: */
	offset = (((usqInt)(methodCacheAddress()))) + (MethodCacheSelector << (shiftForWord()));
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveMwrR, offset, ClassReg, TempReg));
	annotateobjRef(gCmpCwR(selector, TempReg), selector);
	/* begin JumpNonZero: */
	jumpSelectorMiss = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	offset1 = (((usqInt)(methodCacheAddress()))) + (MethodCacheClass << (shiftForWord()));
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset1, genoperandoperandoperand(MoveMwrR, offset1, ClassReg, TempReg));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, SendNumArgsReg, TempReg);
	/* begin JumpNonZero: */
	jumpClassMiss = genoperand(JumpNonZero, ((sqInt)0));
	/* begin Label */
	itsAHit = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	/* begin MoveMw:r:R: */
	offset2 = (((usqInt)(methodCacheAddress()))) + (MethodCacheMethod << (shiftForWord()));
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset2, genoperandoperandoperand(MoveMwrR, offset2, ClassReg, SendNumArgsReg));
	genLoadSlotsourceRegdestReg(HeaderIndex, SendNumArgsReg, ClassReg);
	jumpBCMethod = genJumpImmediate(ClassReg);
	jmpTarget(jumpBCMethod, picInterpretAbort);
	/* begin AddCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(cmNoCheckEntryOffset, genoperandoperand(AddCqR, cmNoCheckEntryOffset, ClassReg));
	/* begin JumpR: */
	genoperand(JumpR, ClassReg);
	jmpTarget(jumpSelectorMiss, jmpTarget(jumpClassMiss, gLabel()));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ClassReg);
	annotateobjRef(gXorCwR(selector, ClassReg), selector);
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, (shiftForWord()) - 1, ClassReg);
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(MethodCacheMask << (shiftForWord()), genoperandoperand(AndCqR, MethodCacheMask << (shiftForWord()), ClassReg));
	/* begin MoveMw:r:R: */
	offset3 = (((usqInt)(methodCacheAddress()))) + (MethodCacheSelector << (shiftForWord()));
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset3, genoperandoperandoperand(MoveMwrR, offset3, ClassReg, TempReg));
	annotateobjRef(gCmpCwR(selector, TempReg), selector);
	/* begin JumpNonZero: */
	jumpSelectorMiss = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	offset4 = (((usqInt)(methodCacheAddress()))) + (MethodCacheClass << (shiftForWord()));
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset4, genoperandoperandoperand(MoveMwrR, offset4, ClassReg, TempReg));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, SendNumArgsReg, TempReg);
	/* begin JumpZero: */
	genoperand(JumpZero, ((sqInt)itsAHit));
	jmpTarget(jumpSelectorMiss, gLabel());
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ClassReg);
	annotateobjRef(gXorCwR(selector, ClassReg), selector);
	
	/* begin AndCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(MethodCacheMask << (shiftForWord()), genoperandoperand(AndCqR, MethodCacheMask << (shiftForWord()), ClassReg));
	/* begin MoveMw:r:R: */
	offset5 = (((usqInt)(methodCacheAddress()))) + (MethodCacheSelector << (shiftForWord()));
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset5, genoperandoperandoperand(MoveMwrR, offset5, ClassReg, TempReg));
	annotateobjRef(gCmpCwR(selector, TempReg), selector);
	/* begin JumpNonZero: */
	jumpSelectorMiss = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	offset6 = (((usqInt)(methodCacheAddress()))) + (MethodCacheClass << (shiftForWord()));
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset6, genoperandoperandoperand(MoveMwrR, offset6, ClassReg, TempReg));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, SendNumArgsReg, TempReg);
	/* begin JumpZero: */
	genoperand(JumpZero, ((sqInt)itsAHit));
	jmpTarget(jumpSelectorMiss, gLabel());
	genPushRegisterArgsForNumArgsscratchReg(backEnd, numArgs, SendNumArgsReg);
	genSmalltalkToCStackSwitch(1);
	addDependent(methodLabel, annotateAbsolutePCRef(gMoveCwR(((sqInt)methodLabel), SendNumArgsReg)));
	compileCallFornumArgsargargargargresultRegsaveRegs(ceSendFromInLineCacheMiss, 1, SendNumArgsReg, null, null, null, null, 0);
}

	/* StackToRegisterMappingCogit>>#cPICMissTrampolineFor: */
static sqInt
cPICMissTrampolineFor(sqInt numArgs)
{
	return picMissTrampolines[((numArgs < (2 + 1)) ? numArgs : (2 + 1))];
}


/*	Replaces the Blue Book double-extended send [132], in which the first byte
	was wasted on 8 bits of argument count. 
	Here we use 3 bits for the operation sub-type (opType), and the remaining
	5 bits for argument count where needed. 
	The last byte give access to 256 instVars or literals. 
	See also secondExtendedSendBytecode
 */

	/* StackToRegisterMappingCogit>>#doubleExtendedDoAnythingBytecode */
static sqInt
doubleExtendedDoAnythingBytecode(void)
{
    AbstractInstruction *abstractInstruction;
    sqInt opType;

	opType = ((usqInt) byte1) >> 5;
	if (opType == 0) {
		return genSendnumArgs(getLiteral(byte2), byte1 & 0x1F);
	}
	if (opType == 1) {
		return genSendSupernumArgs(getLiteral(byte2), byte1 & 0x1F);
	}
	
	switch (opType) {
	case 2:
		if (isReadMediatedContextInstVarIndex(byte2)) {
			genPushMaybeContextReceiverVariable(byte2);
		}
		else {
			genPushReceiverVariable(byte2);
			((ssTop())->annotateUse = 1);
			return 0;
		}
		break;
	case 3:
		genPushLiteralIndex(byte2);
		((ssTop())->annotateUse = 1);
		return 0;

	case 4:
		genPushLiteralVariable(byte2);
		break;
	case 7:
		genStorePopLiteralVariable(0, byte2);
		break;
	default:
		
		/* 5 & 6 */

		if (isWriteMediatedContextInstVarIndex(byte2)) {
			genStorePopMaybeContextReceiverVariable(opType == 6, byte2);
		}
		else {
			genStorePopReceiverVariable(opType == 6, byte2);
		}

	}
	assert(needsFrame);
	assert(!(prevInstIsPCAnnotated()));
	/* begin annotateBytecode: */
	/* begin Label */
	abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	(abstractInstruction->annotation = HasBytecodePC);
	abstractInstruction;
	return 0;
}

	/* StackToRegisterMappingCogit>>#duplicateTopBytecode */
static sqInt
duplicateTopBytecode(void)
{
    CogSimStackEntry desc;

	desc = ssTopDescriptor();
	return ssPushDesc(desc);
}


/*	Make sure there's a flagged fixup at the targetIndex (pc relative to first
	pc) in fixups.
	Initially a fixup's target is just a flag. Later on it is replaced with a
	proper instruction. */

	/* StackToRegisterMappingCogit>>#ensureFixupAt: */
static BytecodeFixup *
ensureFixupAt(sqInt targetIndex)
{
    BytecodeFixup *fixup;

	fixup = fixupAt(targetIndex);
	traceFixup(fixup);
	
	if ((((usqInt)((fixup->targetInstruction)))) <= 1) {

		/* convert a non-merge into a merge */

		(fixup->targetInstruction = ((AbstractInstruction *) 2));
		(fixup->simStackPtr = simStackPtr);
	}
	else {
		if (((fixup->simStackPtr)) <= -2) {

			/* this is the target of a backward branch and
			   so doesn't have a simStackPtr assigned yet. */

			(fixup->simStackPtr = simStackPtr);
		}
		else {
			assert(((fixup->simStackPtr)) == simStackPtr);
		}
	}
	return fixup;
}


/*	Make sure there's a flagged fixup at the targetIndex (pc relative to first
	pc) in fixups.
	Initially a fixup's target is just a flag. Later on it is replaced with a
	proper instruction. */

	/* StackToRegisterMappingCogit>>#ensureNonMergeFixupAt: */
static BytecodeFixup *
ensureNonMergeFixupAt(sqInt targetIndex)
{
    BytecodeFixup *fixup;

	fixup = fixupAt(targetIndex);
	if (((fixup->targetInstruction)) == 0) {
		(fixup->targetInstruction = ((AbstractInstruction *) 1));
	}
	
	return fixup;
}

	/* StackToRegisterMappingCogit>>#ensureReceiverResultRegContainsSelf */
static void
ensureReceiverResultRegContainsSelf(void)
{
	if (needsFrame) {
		if (!((optStatus.isReceiverResultRegLive))) {
			ssAllocateRequiredReg(ReceiverResultReg);
			storeToReg((&simSelf), ReceiverResultReg);
		}
		(optStatus.isReceiverResultRegLive = 1);
	}
	else {
		assert((((simSelf.type)) == SSRegister)
		 && (((simSelf.registerr)) == ReceiverResultReg));
		assert(((optStatus.isReceiverResultRegLive))
		 && (((optStatus.ssEntry)) == ((&simSelf))));
	}
}

	/* StackToRegisterMappingCogit>>#evaluate:at: */
static void
evaluateat(BytecodeDescriptor *descriptor, sqInt pc)
{
	byte0 = fetchByteofObject(pc, methodObj);
	assert(descriptor == (generatorAt(bytecodeSetOffset + byte0)));
	loadSubsequentBytesForDescriptorat(descriptor, pc);
	((descriptor->generator))();
}


/*	Spill the closest register on stack not conflicting with regMask. 
	Assertion Failure if regMask has already all the registers */

	/* StackToRegisterMappingCogit>>#freeAnyRegNotConflictingWith: */
static sqInt
freeAnyRegNotConflictingWith(sqInt regMask)
{
    CogSimStackEntry *desc;
    sqInt index;
    sqInt reg;

	reg = 0;
	assert(needsFrame);
	index = ((simSpillBase < 0) ? 0 : simSpillBase);
	while ((reg == null)
	 && (index < simStackPtr)) {
		desc = simStackAt(index);
		if (((desc->type)) == SSRegister) {
			if (!(regMask & (registerMaskFor((desc->registerr))))) {
				reg = (desc->registerr);
			}
		}
		index += 1;
	}
	assert(reg != null);
	ssAllocateRequiredReg(reg);
	return reg;
}


/*	Const op var version of binary inline primitives. */
/*	SistaV1: 248		11111000 iiiiiiii		mjjjjjjj		Call Primitive #iiiiiiii +
	(jjjjjjj * 256) m=1 means inlined primitive, no hard return after
	execution. See EncoderForSistaV1's class comment and
	StackInterpreter>>#binaryInlinePrimitive: 
 */

	/* StackToRegisterMappingCogit>>#genBinaryConstOpVarInlinePrimitive: */
static sqInt
genBinaryConstOpVarInlinePrimitive(sqInt prim)
{
    sqInt adjust;
    sqInt ra;
    sqInt untaggedVal;
    sqInt val;

	ra = allocateRegForStackEntryAtnotConflictingWith(0, 0);
	popToReg(ssTop(), ra);
	ssPop(1);
	val = ((ssTop())->constant);
	ssPop(1);
	untaggedVal = val - (smallIntegerTag());
	
	switch (prim) {
	case 0:
		/* begin AddCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(untaggedVal, genoperandoperand(AddCqR, untaggedVal, ra));
		break;
	case 1:
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(val, genoperandoperand(MoveCqR, val, TempReg));
		/* begin SubR:R: */
		genoperandoperand(SubRR, ra, TempReg);
		genAddSmallIntegerTagsTo(TempReg);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, TempReg, ra);
		break;
	case 2:
		genRemoveSmallIntegerTagsInScratchReg(ra);
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction((val >> 1), genoperandoperand(MoveCqR, (val >> 1), TempReg));
		gMulRR(TempReg, ra);
		genAddSmallIntegerTagsTo(ra);
		break;
	case 32:
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(val, genoperandoperand(CmpCqR, val, ra));
		genBinaryInlineComparisonopFalsedestReg(JumpLess, JumpGreaterOrEqual, ra);
		break;
	case 33:
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(val, genoperandoperand(CmpCqR, val, ra));
		genBinaryInlineComparisonopFalsedestReg(JumpGreater, JumpLessOrEqual, ra);
		break;
	case 34:
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(val, genoperandoperand(CmpCqR, val, ra));
		genBinaryInlineComparisonopFalsedestReg(JumpLessOrEqual, JumpGreater, ra);
		break;
	case 35:
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(val, genoperandoperand(CmpCqR, val, ra));
		genBinaryInlineComparisonopFalsedestReg(JumpGreaterOrEqual, JumpLess, ra);
		break;
	case 36:
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(val, genoperandoperand(CmpCqR, val, ra));
		genBinaryInlineComparisonopFalsedestReg(JumpZero, JumpNonZero, ra);
		break;
	case 37:
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(val, genoperandoperand(CmpCqR, val, ra));
		genBinaryInlineComparisonopFalsedestReg(JumpNonZero, JumpZero, ra);
		break;
	case 64:
		genConvertSmallIntegerToIntegerInReg(ra);

		/* shift by baseHeaderSize and then move from 1 relative to zero relative */

		adjust = (((usqInt) BaseHeaderSize) >> (shiftForWord())) - 1;
		if (adjust != 0) {
			/* begin AddCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(adjust, genoperandoperand(AddCqR, adjust, ra));
		}
		/* begin genMoveConstant:R: */
		if (shouldAnnotateObjectReference(val)) {
			annotateobjRef(gMoveCwR(val, TempReg), val);
		}
		else {
			/* begin MoveCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(val, genoperandoperand(MoveCqR, val, TempReg));
		}
		/* begin MoveXwr:R:R: */
		genoperandoperandoperand(MoveXwrRR, ra, TempReg, ra);
		break;
	case 65:
		genConvertSmallIntegerToIntegerInReg(ra);

		/* shift by baseHeaderSize and then move from 1 relative to zero relative */

		adjust = BaseHeaderSize - 1;
		/* begin AddCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(adjust, genoperandoperand(AddCqR, adjust, ra));
		/* begin genMoveConstant:R: */
		if (shouldAnnotateObjectReference(val)) {
			annotateobjRef(gMoveCwR(val, TempReg), val);
		}
		else {
			/* begin MoveCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(val, genoperandoperand(MoveCqR, val, TempReg));
		}
		/* begin MoveXbr:R:R: */
		genoperandoperandoperand(MoveXbrRR, ra, TempReg, ra);
		genConvertIntegerToSmallIntegerInReg(ra);
		break;
	default:
		return EncounteredUnknownBytecode;

	}
	ssPushRegister(ra);
	return 0;
}


/*	Inlined comparison. opTrue = jump for true and opFalse = jump for false */

	/* StackToRegisterMappingCogit>>#genBinaryInlineComparison:opFalse:destReg: */
static sqInt
genBinaryInlineComparisonopFalsedestReg(sqInt opTrue, sqInt opFalse, sqInt destReg)
{
    BytecodeDescriptor *branchDescriptor;
    BytecodeDescriptor *branchDescriptor1;
    AbstractInstruction * condJump;
    sqInt constant;
    sqInt descr;
    AbstractInstruction * jump;
    void *jumpTarget;
    sqInt nExts;
    sqInt next;
    sqInt nextPC;
    sqInt nextPC1;
    sqInt postBranch;
    sqInt postBranchPC;
    sqInt postBranchPC1;
    BytecodeDescriptor *primDescriptor;
    sqInt target;
    sqInt targetBytecodePC;
    sqInt targetBytecodePC1;

	/* begin extractMaybeBranchDescriptorInto: */
	primDescriptor = generatorAt(byte0);
	nextPC1 = bytecodePC + ((primDescriptor->numBytes));
	nExts = 0;
	while (1) {
		branchDescriptor1 = generatorAt((fetchByteofObject(nextPC1, methodObj)) + bytecodeSetOffset);
		if (!((branchDescriptor1->isExtension))) break;
		nExts += 1;
		nextPC1 += (branchDescriptor1->numBytes);
	}
	targetBytecodePC1 = (postBranchPC1 = 0);
	if (((branchDescriptor1->isBranchTrue))
	 || ((branchDescriptor1->isBranchFalse))) {
		targetBytecodePC1 = (nextPC1 + ((branchDescriptor1->numBytes))) + (((branchDescriptor1->spanFunction))(branchDescriptor1, nextPC1, nExts, methodObj));
		postBranchPC1 = nextPC1 + ((branchDescriptor1->numBytes));
	}
	branchDescriptor = branchDescriptor1;
	nextPC = nextPC1;
	postBranchPC = postBranchPC1;
	targetBytecodePC = targetBytecodePC1;

	if (((branchDescriptor->isBranchTrue))
	 || ((branchDescriptor->isBranchFalse))) {

		/* This is the path where the inlined comparison is followed immediately by a branch */

		if ((((fixupAt(nextPC - initialPC))->targetInstruction)) == 0) {

			/* The next instruction is dead.  we can skip it. */

			deadCode = 1;
			ensureFixupAt(targetBytecodePC - initialPC);
			ensureFixupAt(postBranchPC - initialPC);
		}
		else {
			ssPushConstant(trueObject());
		}
		genoperand(((branchDescriptor->isBranchTrue)
			? opTrue
			: opFalse), ((usqInt)(ensureNonMergeFixupAt(targetBytecodePC - initialPC))));
		if (!deadCode) {
			/* begin Jump: */
			jumpTarget = ensureNonMergeFixupAt(postBranchPC - initialPC);
			genoperand(Jump, ((sqInt)jumpTarget));
		}
	}
	else {

		/* This is the path where the inlined comparison is *not* followed immediately by a branch */

		condJump = genoperand(opTrue, 0);
		/* begin genMoveFalseR: */
		/* begin genMoveConstant:R: */
		constant = falseObject();
		if (shouldAnnotateObjectReference(constant)) {
			annotateobjRef(gMoveCwR(constant, destReg), constant);
		}
		else {
			/* begin MoveCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, destReg));
		}
		/* begin Jump: */
		jump = genoperand(Jump, ((sqInt)0));
		jmpTarget(condJump, genMoveTrueR(destReg));
		jmpTarget(jump, gLabel());
	}
	return 0;
}


/*	Var op const version of inline binary inline primitives. */
/*	SistaV1: 248		11111000 iiiiiiii		mjjjjjjj		Call Primitive #iiiiiiii +
	(jjjjjjj * 256) m=1 means inlined primitive, no hard return after
	execution. See EncoderForSistaV1's class comment and
	StackInterpreter>>#binaryInlinePrimitive: 
 */

	/* StackToRegisterMappingCogit>>#genBinaryVarOpConstInlinePrimitive: */
static sqInt
genBinaryVarOpConstInlinePrimitive(sqInt prim)
{
    sqInt quickConstant;
    sqInt rr;
    sqInt untaggedVal;
    sqInt val;

	val = ((ssTop())->constant);
	ssPop(1);
	rr = allocateRegForStackEntryAtnotConflictingWith(0, 0);
	popToReg(ssTop(), rr);
	ssPop(1);
	untaggedVal = val - (smallIntegerTag());
	
	switch (prim) {
	case 0:
		/* begin AddCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(untaggedVal, genoperandoperand(AddCqR, untaggedVal, rr));
		break;
	case 1:
		/* begin SubCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(untaggedVal, genoperandoperand(SubCqR, untaggedVal, rr));
		break;
	case 2:
		flag("could use MulCq:R");
		genShiftAwaySmallIntegerTagsInScratchReg(rr);
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction((val >> 1), genoperandoperand(MoveCqR, (val >> 1), TempReg));
		gMulRR(TempReg, rr);
		genAddSmallIntegerTagsTo(rr);
		break;
	case 32:
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(val, genoperandoperand(CmpCqR, val, rr));
		genBinaryInlineComparisonopFalsedestReg(JumpGreater, JumpLessOrEqual, rr);
		break;
	case 33:
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(val, genoperandoperand(CmpCqR, val, rr));
		genBinaryInlineComparisonopFalsedestReg(JumpLess, JumpGreaterOrEqual, rr);
		break;
	case 34:
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(val, genoperandoperand(CmpCqR, val, rr));
		genBinaryInlineComparisonopFalsedestReg(JumpGreaterOrEqual, JumpLess, rr);
		break;
	case 35:
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(val, genoperandoperand(CmpCqR, val, rr));
		genBinaryInlineComparisonopFalsedestReg(JumpLessOrEqual, JumpGreater, rr);
		break;
	case 36:
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(val, genoperandoperand(CmpCqR, val, rr));
		genBinaryInlineComparisonopFalsedestReg(JumpZero, JumpNonZero, rr);
		break;
	case 37:
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(val, genoperandoperand(CmpCqR, val, rr));
		genBinaryInlineComparisonopFalsedestReg(JumpNonZero, JumpZero, rr);
		break;
	case 64:
		genLoadSlotsourceRegdestReg(((val >> 1)) - 1, rr, rr);
		break;
	case 65:
		/* begin MoveCq:R: */
		quickConstant = (((val >> 1)) + BaseHeaderSize) - 1;
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(quickConstant, genoperandoperand(MoveCqR, quickConstant, TempReg));
		/* begin MoveXbr:R:R: */
		genoperandoperandoperand(MoveXbrRR, TempReg, rr, rr);
		genConvertIntegerToSmallIntegerInReg(rr);
		break;
	default:
		return EncounteredUnknownBytecode;

	}
	ssPushRegister(rr);
	return 0;
}


/*	Var op var version of binary inline primitives. */
/*	SistaV1: 248		11111000 iiiiiiii		mjjjjjjj		Call Primitive #iiiiiiii +
	(jjjjjjj * 256) m=1 means inlined primitive, no hard return after
	execution. See EncoderForSistaV1's class comment and
	StackInterpreter>>#binaryInlinePrimitive: 
 */

	/* StackToRegisterMappingCogit>>#genBinaryVarOpVarInlinePrimitive: */
static sqInt
genBinaryVarOpVarInlinePrimitive(sqInt prim)
{
    sqInt adjust;
    sqInt ra;
    sqInt rNext;
    sqInt rNext1;
    sqInt rr;
    sqInt rTop;
    sqInt rTop1;
    sqInt topRegistersMask;

	rNext1 = 0;
	rTop1 = 0;
	/* begin allocateRegForStackTopTwoEntriesInto: */
	topRegistersMask = 0;
	if ((((ssTop())->type)) == SSRegister) {
		rTop1 = ((ssTop())->registerr);
	}
	if ((((ssValue(1))->type)) == SSRegister) {
		topRegistersMask = registerMaskFor((rNext1 = ((ssValue(1))->registerr)));
	}
	if (!(rTop1)) {
		rTop1 = allocateRegNotConflictingWith(topRegistersMask);
	}
	if (!(rNext1)) {
		rNext1 = allocateRegNotConflictingWith(registerMaskFor(rTop1));
	}
	ra = rTop1;
	rr = rNext1;

	popToReg(ssTop(), ra);
	ssPop(1);
	popToReg(ssTop(), rr);
	ssPop(1);
	
	switch (prim) {
	case 0:
		genRemoveSmallIntegerTagsInScratchReg(ra);
		/* begin AddR:R: */
		genoperandoperand(AddRR, ra, rr);
		break;
	case 1:
		/* begin SubR:R: */
		genoperandoperand(SubRR, ra, rr);
		genAddSmallIntegerTagsTo(rr);
		break;
	case 2:
		genRemoveSmallIntegerTagsInScratchReg(rr);
		genShiftAwaySmallIntegerTagsInScratchReg(ra);
		gMulRR(ra, rr);
		genAddSmallIntegerTagsTo(rr);
		break;
	case 32:
		/* begin CmpR:R: */
		genoperandoperand(CmpRR, ra, rr);
		genBinaryInlineComparisonopFalsedestReg(JumpGreater, JumpLessOrEqual, rr);
		break;
	case 33:
		/* begin CmpR:R: */
		genoperandoperand(CmpRR, ra, rr);
		genBinaryInlineComparisonopFalsedestReg(JumpLess, JumpGreaterOrEqual, rr);
		break;
	case 34:
		/* begin CmpR:R: */
		genoperandoperand(CmpRR, ra, rr);
		genBinaryInlineComparisonopFalsedestReg(JumpGreaterOrEqual, JumpLess, rr);
		break;
	case 35:
		/* begin CmpR:R: */
		genoperandoperand(CmpRR, ra, rr);
		genBinaryInlineComparisonopFalsedestReg(JumpLessOrEqual, JumpGreater, rr);
		break;
	case 36:
		/* begin CmpR:R: */
		genoperandoperand(CmpRR, ra, rr);
		genBinaryInlineComparisonopFalsedestReg(JumpZero, JumpNonZero, rr);
		break;
	case 37:
		/* begin CmpR:R: */
		genoperandoperand(CmpRR, ra, rr);
		genBinaryInlineComparisonopFalsedestReg(JumpNonZero, JumpZero, rr);
		break;
	case 64:
		genConvertSmallIntegerToIntegerInReg(ra);

		/* shift by baseHeaderSize and then move from 1 relative to zero relative */

		adjust = (((usqInt) BaseHeaderSize) >> (shiftForWord())) - 1;
		if (adjust != 0) {
			/* begin AddCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(adjust, genoperandoperand(AddCqR, adjust, ra));
		}
		/* begin MoveXwr:R:R: */
		genoperandoperandoperand(MoveXwrRR, ra, rr, rr);
		break;
	case 65:
		genConvertSmallIntegerToIntegerInReg(ra);

		/* shift by baseHeaderSize and then move from 1 relative to zero relative */

		adjust = BaseHeaderSize - 1;
		/* begin AddCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(adjust, genoperandoperand(AddCqR, adjust, ra));
		/* begin MoveXbr:R:R: */
		genoperandoperandoperand(MoveXbrRR, ra, rr, rr);
		genConvertIntegerToSmallIntegerInReg(rr);
		break;
	default:
		return EncounteredUnknownBytecode;

	}
	ssPushRegister(rr);
	return 0;
}


/*	Generate special versions of the ceCallCogCodePopReceiverAndClassRegs
	enilopmart that also pop register args from the stack to undo the pushing
	of register args in the abort/miss trampolines. */

	/* StackToRegisterMappingCogit>>#genCallPICEnilopmartNumArgs: */
static void (*genCallPICEnilopmartNumArgs(sqInt numArgs))(void)

{
    sqInt endAddress;
    sqInt enilopmart;
    sqInt reg;
    sqInt size;

	zeroOpcodeIndex();
	maybeEstablishVarBase(backEnd);
	genLoadStackPointers(backEnd);
	/* begin PopR: */
	genoperand(PopR, ClassReg);
	/* begin PopR: */
	genoperand(PopR, TempReg);
	/* begin PopR: */
	reg = LinkReg;
	genoperand(PopR, reg);
	if (numArgs > 0) {
		if (numArgs > 1) {
			/* begin PopR: */
			genoperand(PopR, Arg1Reg);
			assert((numRegArgs()) == 2);
		}
		/* begin PopR: */
		genoperand(PopR, Arg0Reg);
	}
	/* begin PopR: */
	genoperand(PopR, ReceiverResultReg);
	
	/* begin JumpR: */
	genoperand(JumpR, TempReg);
	computeMaximumSizes();
	size = generateInstructionsAt(methodZoneBase);
	endAddress = outputInstructionsAt(methodZoneBase);
	assert((methodZoneBase + size) == endAddress);
	enilopmart = methodZoneBase;
	methodZoneBase = alignUptoRoutineBoundary(endAddress);
	nopsFromto(backEnd, endAddress, methodZoneBase - 1);
	recordGeneratedRunTimeaddress(trampolineNamenumRegArgs("ceCallPIC", numArgs), enilopmart);
	return ((void (*)(void)) enilopmart);
}


/*	SistaV1: 248		11111000 iiiiiiii		mjjjjjjj		Call Primitive #iiiiiiii +
	(jjjjjjj * 256) m=1 means inlined primitive, no hard return after
	execution. See EncoderForSistaV1's class comment and
	StackInterpreter>>#inlinePrimitiveBytecode: 
 */

	/* StackToRegisterMappingCogit>>#genCallPrimitiveBytecode */
static sqInt
genCallPrimitiveBytecode(void)
{
    sqInt prim;

	if (byte2 < 128) {
		return (bytecodePC == initialPC
			? 0
			: EncounteredUnknownBytecode);
	}
	prim = ((byte2 - 128) << 8) + byte1;
	if (prim < 1000) {
		return genNullaryInlinePrimitive(prim);
	}
	if (prim < 2000) {
		return genUnaryInlinePrimitive(prim - 1000);
	}
	if (prim < 3000) {
		if ((((ssTop())->type)) == SSConstant) {
			return genBinaryVarOpConstInlinePrimitive(prim - 2000);
		}
		if ((((ssValue(1))->type)) == SSConstant) {
			return genBinaryConstOpVarInlinePrimitive(prim - 2000);
		}
		return genBinaryVarOpVarInlinePrimitive(prim - 2000);
	}
	if (prim < 4000) {
		return genTrinaryInlinePrimitive(prim - 3000);
	}
	return EncounteredUnknownBytecode;
}


/*	Receiver and arg in registers.
	Stack looks like
	return address */

	/* StackToRegisterMappingCogit>>#genDoubleArithmetic:preOpCheck: */
static sqInt
genDoubleArithmeticpreOpCheck(sqInt arithmeticOperator, AbstractInstruction *(*preOpCheckOrNil)(int rcvrReg, int argReg))
{
    AbstractInstruction *doOp;
    AbstractInstruction *jumpFailAlloc;
    AbstractInstruction *jumpFailCheck;
    AbstractInstruction *jumpFailClass;
    AbstractInstruction *jumpImmediate;
    AbstractInstruction *jumpNonInt;

	genGetDoubleValueOfinto(ReceiverResultReg, DPFPReg0);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	jumpImmediate = genJumpImmediate(Arg0Reg);
	genGetCompactClassIndexNonImmOfinto(Arg0Reg, SendNumArgsReg);
	genCmpClassFloatCompactIndexR(SendNumArgsReg);
	/* begin JumpNonZero: */
	jumpFailClass = genoperand(JumpNonZero, ((sqInt)0));
	genGetDoubleValueOfinto(Arg0Reg, DPFPReg1);
	/* begin Label */
	doOp = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	if (!(preOpCheckOrNil == null)) {
		jumpFailCheck = preOpCheckOrNil(DPFPReg0, DPFPReg1);
	}
	genoperandoperand(arithmeticOperator, DPFPReg1, DPFPReg0);
	jumpFailAlloc = genAllocFloatValueintoscratchRegscratchReg(DPFPReg0, SendNumArgsReg, ClassReg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	jmpTarget(jumpFailClass, gLabel());
	if (!(preOpCheckOrNil == null)) {
		jmpTarget(jumpFailCheck, getJmpTarget(jumpFailClass));
	}
	genPushRegisterArgsForNumArgsscratchReg(backEnd, methodOrBlockNumArgs, SendNumArgsReg);
	/* begin Jump: */
	jumpFailClass = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpImmediate, gLabel());
	jumpNonInt = genJumpNotSmallInteger(Arg0Reg);

	genConvertSmallIntegerToIntegerInReg(ClassReg);
	/* begin ConvertR:Rd: */
	genoperandoperand(ConvertRRd, ClassReg, DPFPReg1);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)doOp));
	jmpTarget(jumpFailAlloc, gLabel());
	compileFallbackToInterpreterPrimitive();
	jmpTarget(jumpFailClass, gLabel());
	jmpTarget(jumpNonInt, getJmpTarget(jumpFailClass));

	return 0;
}


/*	Receiver and arg in registers.
	Stack looks like
	return address */

	/* StackToRegisterMappingCogit>>#genDoubleComparison:invert: */
static sqInt
genDoubleComparisoninvert(AbstractInstruction *(*jumpOpcodeGenerator)(void *), sqInt invertComparison)
{
    AbstractInstruction *compare;
    sqInt constant;
    AbstractInstruction *jumpCond;
    AbstractInstruction *jumpFail;
    AbstractInstruction *jumpImmediate;
    AbstractInstruction *jumpNonInt;

	genGetDoubleValueOfinto(ReceiverResultReg, DPFPReg0);
	jumpImmediate = genJumpImmediate(Arg0Reg);
	genGetCompactClassIndexNonImmOfinto(Arg0Reg, SendNumArgsReg);
	genCmpClassFloatCompactIndexR(SendNumArgsReg);
	/* begin JumpNonZero: */
	jumpFail = genoperand(JumpNonZero, ((sqInt)0));
	genGetDoubleValueOfinto(Arg0Reg, DPFPReg1);
	if (invertComparison) {

		/* May need to invert for NaNs */

		/* begin CmpRd:Rd: */
		compare = genoperandoperand(CmpRdRd, DPFPReg0, DPFPReg1);
	}
	else {
		/* begin CmpRd:Rd: */
		compare = genoperandoperand(CmpRdRd, DPFPReg1, DPFPReg0);
	}

	/* FP jumps are a little weird */

	jumpCond = jumpOpcodeGenerator(0);
	/* begin genMoveFalseR: */
	/* begin genMoveConstant:R: */
	constant = falseObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, ReceiverResultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, ReceiverResultReg));
	}
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpCond, genMoveTrueR(ReceiverResultReg));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpImmediate, gLabel());
	jumpNonInt = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);

	genConvertSmallIntegerToIntegerInReg(Arg0Reg);
	/* begin ConvertR:Rd: */
	genoperandoperand(ConvertRRd, Arg0Reg, DPFPReg1);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)compare));
	jmpTarget(jumpFail, gLabel());
	jmpTarget(jumpNonInt, getJmpTarget(jumpFail));

	return 0;
}


/*	Generates the machine code for #== in the case where the instruction is
	not followed by a branch
 */

	/* StackToRegisterMappingCogit>>#genEqualsEqualsNoBranchArgIsConstant:rcvrIsConstant:argReg:rcvrReg: */
static sqInt
genEqualsEqualsNoBranchArgIsConstantrcvrIsConstantargRegrcvrReg(sqInt argIsConstant, sqInt rcvrIsConstant, sqInt argReg, sqInt rcvrReg)
{
    sqInt constant;
    sqInt constant1;
    sqInt constant2;
    AbstractInstruction *jumpEqual;
    AbstractInstruction *jumpNotEqual;
    AbstractInstruction *label;
    sqInt resultReg;

	/* begin Label */
	label = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	/* begin genEqualsEqualsComparisonArgIsConstant:rcvrIsConstant:argReg:rcvrReg: */
	if (argIsConstant) {
		/* begin genCompConstant:R: */
		constant = ((ssTop())->constant);
		if (shouldAnnotateObjectReference(constant)) {
			annotateobjRef(gCmpCwR(constant, rcvrReg), constant);
		}
		else {
			/* begin CmpCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(constant, genoperandoperand(CmpCqR, constant, rcvrReg));
		}
	}
	else {
		if (rcvrIsConstant) {
			/* begin genCompConstant:R: */
			constant1 = ((ssValue(1))->constant);
			if (shouldAnnotateObjectReference(constant1)) {
				annotateobjRef(gCmpCwR(constant1, argReg), constant1);
			}
			else {
				/* begin CmpCq:R: */
				/* begin gen:quickConstant:operand: */
				checkQuickConstantforInstruction(constant1, genoperandoperand(CmpCqR, constant1, argReg));
			}
		}
		else {
			/* begin CmpR:R: */
			genoperandoperand(CmpRR, argReg, rcvrReg);
		}
	}
	ssPop(2);
	resultReg = (!(rcvrReg)
		? argReg
		: rcvrReg);
	/* begin JumpZero: */
	jumpEqual = genoperand(JumpZero, ((sqInt)0));
	if (!argIsConstant) {
		genEnsureOopInRegNotForwardedscratchRegjumpBackTo(argReg, TempReg, label);
	}
	if (!rcvrIsConstant) {
		genEnsureOopInRegNotForwardedscratchRegjumpBackTo(rcvrReg, TempReg, label);
	}
	/* begin genMoveFalseR: */
	/* begin genMoveConstant:R: */
	constant2 = falseObject();
	if (shouldAnnotateObjectReference(constant2)) {
		annotateobjRef(gMoveCwR(constant2, resultReg), constant2);
	}
	else {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant2, genoperandoperand(MoveCqR, constant2, resultReg));
	}
	/* begin Jump: */
	jumpNotEqual = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpEqual, genMoveTrueR(resultReg));
	jmpTarget(jumpNotEqual, gLabel());
	ssPushRegister(resultReg);
	return 0;
}


/*	Override to push the register receiver and register arguments, if any. */

	/* StackToRegisterMappingCogit>>#genExternalizePointersForPrimitiveCall */
static sqInt
genExternalizePointersForPrimitiveCall(void)
{
    sqInt address;
    sqInt address1;
    sqInt address2;
    sqInt address3;
    sqInt address4;

	genPushRegisterArgs();
	/* begin MoveR:Aw: */
	address4 = framePointerAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address4, genoperandoperand(MoveRAw, FPReg, address4));
	
	/* Set coInterpreter stackPointer to the topmost argument, skipping the return address. */

	/* begin MoveR:Aw: */
	address = stackPointerAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address, genoperandoperand(MoveRAw, SPReg, address));
	/* begin MoveR:Aw: */
	address1 = instructionPointerAddress();
	/* begin gen:operand:literal: */
	checkLiteralforInstruction(address1, genoperandoperand(MoveRAw, LinkReg, address1));

	return 0;
}


/*	Enilopmarts transfer control from C into machine code (backwards
	trampolines). 
 */
/*	Enilopmarts transfer control from C into machine code (backwards
	trampolines). Override to add version for generic and PIC-specific entry
	with reg args. */

	/* StackToRegisterMappingCogit>>#generateEnilopmarts */
static void
generateEnilopmarts(void)
{
	
#  if Debug
	/* begin genEnilopmartFor:forCall:called: */
	realCEEnterCogCodePopReceiverReg = genEnilopmartForandandforCallcalled(ReceiverResultReg, null, null, 0, "realCEEnterCogCodePopReceiverReg");
	ceEnterCogCodePopReceiverReg = enterCogCodePopReceiver;
	/* begin genEnilopmartFor:forCall:called: */
	realCECallCogCodePopReceiverReg = genEnilopmartForandandforCallcalled(ReceiverResultReg, null, null, 1, "realCEEnterCogCodePopReceiverReg");
	ceCallCogCodePopReceiverReg = callCogCodePopReceiver;
	/* begin genEnilopmartFor:and:forCall:called: */
	realCECallCogCodePopReceiverAndClassRegs = genEnilopmartForandandforCallcalled(ReceiverResultReg, ClassReg, null, 1, "realCECallCogCodePopReceiverAndClassRegs");
	ceCallCogCodePopReceiverAndClassRegs = callCogCodePopReceiverAndClassRegs;

#  else /* Debug */
	/* begin genEnilopmartFor:forCall:called: */
	ceEnterCogCodePopReceiverReg = genEnilopmartForandandforCallcalled(ReceiverResultReg, null, null, 0, "ceEnterCogCodePopReceiverReg");
	/* begin genEnilopmartFor:forCall:called: */
	ceCallCogCodePopReceiverReg = genEnilopmartForandandforCallcalled(ReceiverResultReg, null, null, 1, "ceCallCogCodePopReceiverReg");
	/* begin genEnilopmartFor:and:forCall:called: */
	ceCallCogCodePopReceiverAndClassRegs = genEnilopmartForandandforCallcalled(ReceiverResultReg, ClassReg, null, 1, "ceCallCogCodePopReceiverAndClassRegs");

#  endif /* Debug */

	genPrimReturnEnterCogCodeEnilopmart(0);
	cePrimReturnEnterCogCode = methodZoneBase;
	outputInstructionsForGeneratedRuntimeAt(cePrimReturnEnterCogCode);
	recordGeneratedRunTimeaddress("cePrimReturnEnterCogCode", cePrimReturnEnterCogCode);
	genPrimReturnEnterCogCodeEnilopmart(1);
	cePrimReturnEnterCogCodeProfiling = methodZoneBase;
	outputInstructionsForGeneratedRuntimeAt(cePrimReturnEnterCogCodeProfiling);
	recordGeneratedRunTimeaddress("cePrimReturnEnterCogCodeProfiling", cePrimReturnEnterCogCodeProfiling);
	
#  if Debug
	/* begin genEnilopmartFor:and:forCall:called: */
	realCECallCogCodePopReceiverArg0Regs = genEnilopmartForandandforCallcalled(ReceiverResultReg, Arg0Reg, null, 1, "realCECallCogCodePopReceiverArg0Regs");
	ceCallCogCodePopReceiverArg0Regs = callCogCodePopReceiverArg0Regs;
	realCECallCogCodePopReceiverArg1Arg0Regs = genEnilopmartForandandforCallcalled(ReceiverResultReg, Arg0Reg, Arg1Reg, 1, "realCECallCogCodePopReceiverArg1Arg0Regs");
	ceCallCogCodePopReceiverArg1Arg0Regs = callCogCodePopReceiverArg1Arg0Regs;

#  else /* Debug */
	/* begin genEnilopmartFor:and:forCall:called: */
	ceCallCogCodePopReceiverArg0Regs = genEnilopmartForandandforCallcalled(ReceiverResultReg, Arg0Reg, null, 1, "ceCallCogCodePopReceiverArg0Regs");
	ceCallCogCodePopReceiverArg1Arg0Regs = genEnilopmartForandandforCallcalled(ReceiverResultReg, Arg0Reg, Arg1Reg, 1, "ceCallCogCodePopReceiverArg1Arg0Regs");

#  endif /* Debug */

	ceCall0ArgsPIC = genCallPICEnilopmartNumArgs(0);
	ceCall1ArgsPIC = genCallPICEnilopmartNumArgs(1);
	ceCall2ArgsPIC = genCallPICEnilopmartNumArgs(2);
	assert((numRegArgs()) == 2);


}


/*	Generate the run-time entries for the various method and PIC entry misses
	and aborts.
	Read the class-side method trampolines for documentation on the various
	trampolines 
 */

	/* StackToRegisterMappingCogit>>#generateMissAbortTrampolines */
static void
generateMissAbortTrampolines(void)
{
    sqInt numArgs;
    sqInt numArgsLimiT;

	for (numArgs = 0, numArgsLimiT = (2 + 1); numArgs <= numArgsLimiT; numArgs += 1) {
		methodAbortTrampolines[numArgs] = (genMethodAbortTrampolineFor(numArgs));
	}
	for (numArgs = 0, numArgsLimiT = (2 + 1); numArgs <= numArgsLimiT; numArgs += 1) {
		picAbortTrampolines[numArgs] = (genPICAbortTrampolineFor(numArgs));
	}
	for (numArgs = 0, numArgsLimiT = (2 + 1); numArgs <= numArgsLimiT; numArgs += 1) {
		picMissTrampolines[numArgs] = (genPICMissTrampolineFor(numArgs));
	}
}


/*	Override to generate code to push the register arg(s) for <= numRegArg
	arity sends.
 */

	/* StackToRegisterMappingCogit>>#generateSendTrampolines */
static void
generateSendTrampolines(void)
{
    sqInt numArgs;

	for (numArgs = 0; numArgs < NumSendTrampolines; numArgs += 1) {
		ordinarySendTrampolines[numArgs] = (genSendTrampolineFornumArgscalledargargargarg(ceSendsupertonumArgs, numArgs, trampolineNamenumArgs("ceSend", numArgs), ClassReg, 0, ReceiverResultReg, (numArgs <= (NumSendTrampolines - 2)
	? numArgs
	: SendNumArgsReg)));
	}
	
	
#  if BytecodeSetHasDirectedSuperSend
	for (numArgs = 0; numArgs < NumSendTrampolines; numArgs += 1) {
		directedSuperSendTrampolines[numArgs] = (genSendTrampolineFornumArgscalledargargargarg(ceSendabovetonumArgs, numArgs, trampolineNamenumArgs("ceDirectedSuperSend", numArgs), ClassReg, TempReg, ReceiverResultReg, (numArgs <= (NumSendTrampolines - 2)
	? numArgs
	: SendNumArgsReg)));
	}

#  endif /* BytecodeSetHasDirectedSuperSend */

	for (numArgs = 0; numArgs < NumSendTrampolines; numArgs += 1) {
		superSendTrampolines[numArgs] = (genSendTrampolineFornumArgscalledargargargarg(ceSendsupertonumArgs, numArgs, trampolineNamenumArgs("ceSuperSend", numArgs), ClassReg, 1, ReceiverResultReg, (numArgs <= (NumSendTrampolines - 2)
	? numArgs
	: SendNumArgsReg)));
	}
	firstSend = ordinarySendTrampolines[0];
	lastSend = superSendTrampolines[NumSendTrampolines - 1];
}


/*	Generate trampolines for tracing. In the simulator we can save a lot of
	time and avoid noise instructions in the lastNInstructions log by
	short-cutting these
	trampolines, but we need them in the real vm. */

	/* StackToRegisterMappingCogit>>#generateTracingTrampolines */
static void
generateTracingTrampolines(void)
{
	ceTraceLinkedSendTrampoline = genSafeTrampolineForcalledarg(ceTraceLinkedSend, "ceTraceLinkedSendTrampoline", ReceiverResultReg);
	ceTraceBlockActivationTrampoline = genTrampolineForcalled(ceTraceBlockActivation, "ceTraceBlockActivationTrampoline");
	ceTraceStoreTrampoline = genSafeTrampolineForcalledargarg(ceTraceStoreOfinto, "ceTraceStoreTrampoline", TempReg, ReceiverResultReg);
	null;
}

	/* StackToRegisterMappingCogit>>#genJumpBackTo: */
static sqInt
genJumpBackTo(sqInt targetBytecodePC)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    sqInt address;
    void *jumpTarget;
    void *jumpTarget1;

	ssFlushTo(simStackPtr);
	/* begin MoveAw:R: */
	address = stackLimitAddress();
	/* begin gen:literal:operand: */
	checkLiteralforInstruction(address, genoperandoperand(MoveAwR, address, TempReg));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, TempReg, SPReg);
	/* begin JumpAboveOrEqual: */
	jumpTarget = fixupAt(targetBytecodePC - initialPC);
	genoperand(JumpAboveOrEqual, ((sqInt)jumpTarget));
	/* begin CallRT: */
	/* begin annotateCall: */
	/* begin Call: */
	abstractInstruction1 = genoperand(Call, ceCheckForInterruptTrampoline);
	(abstractInstruction1->annotation = IsRelativeCall);
	abstractInstruction1;
	/* begin annotateBytecode: */
	/* begin Label */
	abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	(abstractInstruction->annotation = HasBytecodePC);
	abstractInstruction;
	/* begin Jump: */
	jumpTarget1 = fixupAt(targetBytecodePC - initialPC);
	genoperand(Jump, ((sqInt)jumpTarget1));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genJumpIf:to: */
static sqInt
genJumpIfto(sqInt boolean, sqInt targetBytecodePC)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    AbstractInstruction *abstractInstruction2;
    sqInt callTarget;
    CogSimStackEntry *desc;
    BytecodeFixup *fixup;
    void *jumpTarget;
    AbstractInstruction *ok;
    sqInt quickConstant;

	ssFlushTo(simStackPtr - 1);
	desc = ssTop();
	ssPop(1);
	if ((((desc->type)) == SSConstant)
	 && ((((desc->constant)) == (trueObject()))
	 || (((desc->constant)) == (falseObject())))) {

		/* Must arrange there's a fixup at the target whether it is jumped to or
		   not so that the simStackPtr can be kept correct. */


		/* Must enter any annotatedConstants into the map */

		fixup = ensureFixupAt(targetBytecodePC - initialPC);
		if ((desc->annotateUse)) {
			/* begin annotateBytecode: */
			if (prevInstIsPCAnnotated()) {
				/* begin Nop */
				abstractInstruction = gen(Nop);
			}
			else {
				/* begin Label */
				abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
			}
			(abstractInstruction->annotation = HasBytecodePC);
			abstractInstruction;
		}
		/* begin annotateBytecode: */
		if (((desc->constant)) == boolean) {
			/* begin Jump: */
			abstractInstruction1 = genoperand(Jump, ((sqInt)fixup));
		}
		else {
			if (prevInstIsPCAnnotated()) {
				/* begin Nop */
				abstractInstruction1 = gen(Nop);
			}
			else {
				/* begin Label */
				abstractInstruction1 = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
			}
		}
		(abstractInstruction1->annotation = HasBytecodePC);
		abstractInstruction1;
		return 0;
	}
	popToReg(desc, TempReg);
	assert((objectAfter(falseObject())) == (trueObject()));
	annotateobjRef(gSubCwR(boolean, TempReg), boolean);
	/* begin JumpZero: */
	jumpTarget = ensureFixupAt(targetBytecodePC - initialPC);
	genoperand(JumpZero, ((sqInt)jumpTarget));
	/* begin CmpCq:R: */
	quickConstant = (boolean == (falseObject())
		? (trueObject()) - (falseObject())
		: (falseObject()) - (trueObject()));
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, TempReg));
	/* begin JumpZero: */
	ok = genoperand(JumpZero, ((sqInt)0));
	/* begin CallRT: */
	callTarget = (boolean == (falseObject())
		? ceSendMustBeBooleanAddFalseTrampoline
		: ceSendMustBeBooleanAddTrueTrampoline);
	/* begin annotateCall: */
	/* begin Call: */
	abstractInstruction2 = genoperand(Call, callTarget);
	(abstractInstruction2->annotation = IsRelativeCall);
	abstractInstruction2;
	jmpTarget(ok, annotateBytecode(gLabel()));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genJumpTo: */
static sqInt
genJumpTo(sqInt targetBytecodePC)
{
    void *jumpTarget;

	ssFlushTo(simStackPtr);
	/* begin Jump: */
	jumpTarget = ensureFixupAt(targetBytecodePC - initialPC);
	genoperand(Jump, ((sqInt)jumpTarget));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genMarshalledSend:numArgs:sendTable: */
static sqInt
genMarshalledSendnumArgssendTable(sqInt selector, sqInt numArgs, sqInt *sendTable)
{
    AbstractInstruction *anInstruction;
    sqInt annotation;
    sqInt tempOop;

	if (isYoung(selector)) {
		hasYoungReferent = 1;
	}
	assert(needsFrame);
	/* begin annotationForSendTable: */
	;
	
	
	
	
	if (sendTable == superSendTrampolines) {
		annotation = IsSuperSend;
		goto l1;
	}
	assert(sendTable == ordinarySendTrampolines);
	annotation = IsSendCall;
l1:	/* end annotationForSendTable: */;
	if ((annotation == IsSuperSend)
	 || (0)) {
		genEnsureOopInRegNotForwardedscratchReg(ReceiverResultReg, TempReg);
	}
	if (numArgs >= (NumSendTrampolines - 1)) {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(numArgs, genoperandoperand(MoveCqR, numArgs, SendNumArgsReg));
	}
	
	/* begin MoveUniqueCw:R: */
	/* begin gen:uniqueLiteral:operand: */
	/* begin uniqueLiteral:forInstruction: */
	anInstruction = genoperandoperand(MoveCwR, selector, ClassReg);
	assert(usesOutOfLineLiteral(anInstruction));
	(anInstruction->dependent = allocateLiteral(selector));
	anInstruction;
	((gCall(sendTable[((numArgs < (NumSendTrampolines - 1)) ? numArgs : (NumSendTrampolines - 1))]))->annotation = annotation);
	(optStatus.isReceiverResultRegLive = 0);
	return ssPushRegister(ReceiverResultReg);
}


/*	Generate the abort for a method. This abort performs either a call of
	ceSICMiss: to handle a single-in-line cache miss or a call of
	ceStackOverflow: to handle a
	stack overflow. It distinguishes the two by testing ResultReceiverReg. If
	the register is zero then this is a stack-overflow because a) the receiver
	has already
	been pushed and so can be set to zero before calling the abort, and b) the
	receiver must always contain an object (and hence be non-zero) on SIC
	miss.  */

	/* StackToRegisterMappingCogit>>#genMethodAbortTrampolineFor: */
static sqInt
genMethodAbortTrampolineFor(sqInt numArgs)
{
    AbstractInstruction *jumpSICMiss;

	zeroOpcodeIndex();
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, ReceiverResultReg));
	/* begin JumpNonZero: */
	jumpSICMiss = genoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveR:Mw:r: */
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveRMwr, LinkReg, 0, SPReg));

	compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(ceStackOverflow, 1, SendNumArgsReg, null, null, null, 0, 0, null);
	jmpTarget(jumpSICMiss, gLabel());
	genPushRegisterArgsForAbortMissNumArgs(backEnd, numArgs);
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceSICMiss, trampolineNamenumRegArgs("ceMethodAbort", numArgs), 1, ReceiverResultReg, null, null, null, 0, 0, null, 1);
}


/*	Nullary inline primitives. */
/*	SistaV1: 248		11111000 iiiiiiii		mjjjjjjj		Call Primitive #iiiiiiii +
	(jjjjjjj * 256) m=1 means inlined primitive, no hard return after
	execution. See EncoderForSistaV1's class comment and
	StackInterpreter>>#nullaryInlinePrimitive: 
 */

	/* StackToRegisterMappingCogit>>#genNullaryInlinePrimitive: */
static sqInt
genNullaryInlinePrimitive(sqInt prim)
{
	return EncounteredUnknownBytecode;
}


/*	Generate the abort for a PIC. This abort performs either a call of
	ceInterpretMethodFromPIC:receiver: to handle invoking an uncogged
	target or a call of ceMNUFromPICMNUMethod:receiver: to handle an
	MNU dispatch in a closed PIC. It distinguishes the two by testing
	ClassReg. If the register is zero then this is an MNU. */

	/* StackToRegisterMappingCogit>>#genPICAbortTrampolineFor: */
static sqInt
genPICAbortTrampolineFor(sqInt numArgs)
{
	zeroOpcodeIndex();
	genPushRegisterArgsForAbortMissNumArgs(backEnd, numArgs);
	return genInnerPICAbortTrampoline(trampolineNamenumRegArgs("cePICAbort", numArgs));
}

	/* StackToRegisterMappingCogit>>#genPICMissTrampolineFor: */
static sqInt
genPICMissTrampolineFor(sqInt numArgs)
{
    sqInt startAddress;

	startAddress = methodZoneBase;
	zeroOpcodeIndex();
	genPushRegisterArgsForNumArgsscratchReg(backEnd, numArgs, SendNumArgsReg);
	genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceCPICMissreceiver, trampolineNamenumRegArgs("cePICMiss", numArgs), 2, ClassReg, ReceiverResultReg, null, null, 0, 1, null, 1);
	return startAddress;
}

	/* StackToRegisterMappingCogit>>#genPopStackBytecode */
static sqInt
genPopStackBytecode(void)
{
	annotateBytecodeIfAnnotated(ssTop());
	if (((ssTop())->spilled)) {
		/* begin AddCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(BytesPerWord, genoperandoperand(AddCqR, BytesPerWord, SPReg));
	}
	ssPop(1);
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPrimitiveAdd */
static sqInt
genPrimitiveAdd(void)
{
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOvfl;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	jumpNotSI = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	genRemoveSmallIntegerTagsInScratchReg(ClassReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, ReceiverResultReg, ClassReg);
	/* begin JumpOverflow: */
	jumpOvfl = genoperand(JumpOverflow, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOvfl, jmpTarget(jumpNotSI, gLabel()));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPrimitiveAsCharacter */
static sqInt
genPrimitiveAsCharacter(void)
{
    sqInt na;
    sqInt r;

	na = argumentCountOf(methodObj);
	if (na <= 1) {
		if (((r = genInnerPrimitiveAsCharacterinReg(0, (na == 0
	? ReceiverResultReg
	: Arg0Reg)))) < 0) {
			return r;
		}
	}
	return compileFallbackToInterpreterPrimitive();
}

	/* StackToRegisterMappingCogit>>#genPrimitiveAsFloat */
static sqInt
genPrimitiveAsFloat(void)
{
    AbstractInstruction *jumpFailAlloc;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	/* begin ConvertR:Rd: */
	genoperandoperand(ConvertRRd, TempReg, DPFPReg0);
	jumpFailAlloc = genAllocFloatValueintoscratchRegscratchReg(DPFPReg0, SendNumArgsReg, ClassReg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpFailAlloc, gLabel());
	return compileFallbackToInterpreterPrimitive();
}

	/* StackToRegisterMappingCogit>>#genPrimitiveAt */
static sqInt
genPrimitiveAt(void)
{
    sqInt r;

	assert((numRegArgs()) >= 1);
	if (((r = genInnerPrimitiveAt(0))) < 0) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

	/* StackToRegisterMappingCogit>>#genPrimitiveAtPut */
static sqInt
genPrimitiveAtPut(void)
{
    sqInt r;

	if ((((r = genInnerPrimitiveAtPut(0))) < 0)
	 && (r != UnimplementedPrimitive)) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

	/* StackToRegisterMappingCogit>>#genPrimitiveBitAnd */
static sqInt
genPrimitiveBitAnd(void)
{
    AbstractInstruction *jumpNotSI;


	/* Whether the SmallInteger tags are zero or non-zero, oring them together will preserve them. */

	jumpNotSI = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	/* begin AndR:R: */
	genoperandoperand(AndRR, Arg0Reg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotSI, gLabel());
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPrimitiveBitOr */
static sqInt
genPrimitiveBitOr(void)
{
    AbstractInstruction *jumpNotSI;


	/* Whether the SmallInteger tags are zero or non-zero, oring them together will preserve them. */

	jumpNotSI = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	/* begin OrR:R: */
	genoperandoperand(OrRR, Arg0Reg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotSI, gLabel());
	return 0;
}


/*	Receiver and arg in registers.
	Stack looks like
	return address
	
	rTemp := rArg0
	rClass := tTemp
	rTemp := rTemp & 1
	jz nonInt
	rClass >>= 1
	cmp 0,rClass
	jge neg
	cmp 31,rClass // numSmallIntegerBits, jge for sign
	jge tooBig
	rTemp := rReceiver
	rTemp <<= rClass
	rTemp >>= rClass (arithmetic)
	cmp rTemp,rReceiver
	jnz ovfl
	rReceiver := rReceiver - 1
	rReceiver := rReceiver <<= rClass
	rReceiver := rReceiver + 1
	ret
	neg:
	rClass := 0 - rClass
	cmp 31,rClass
	jge inRange
	rClass := 31
	inRange
	rReceiver := rReceiver >>= rClass.
	rReceiver := rReceiver | 1.
	ret
	ovfl
	tooBig
	nonInt:
	fail
 */

	/* StackToRegisterMappingCogit>>#genPrimitiveBitShift */
static sqInt
genPrimitiveBitShift(void)
{
    AbstractInstruction *jumpInRange;
    AbstractInstruction *jumpNegative;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOvfl;
    AbstractInstruction *jumpTooBig;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;

	assert((numRegArgs()) >= 1);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	jumpNotSI = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	genConvertSmallIntegerToIntegerInReg(ClassReg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpNegative))) {
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, ClassReg));
	}
	/* begin JumpNegative: */
	jumpNegative = genoperand(JumpNegative, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant = numSmallIntegerBits();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, ClassReg));
	/* begin JumpGreaterOrEqual: */
	jumpTooBig = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	/* begin LogicalShiftLeftR:R: */
	genoperandoperand(LogicalShiftLeftRR, ClassReg, TempReg);
	/* begin ArithmeticShiftRightR:R: */
	genoperandoperand(ArithmeticShiftRightRR, ClassReg, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, TempReg, ReceiverResultReg);
	/* begin JumpNonZero: */
	jumpOvfl = genoperand(JumpNonZero, ((sqInt)0));
	genRemoveSmallIntegerTagsInScratchReg(ReceiverResultReg);
	/* begin LogicalShiftLeftR:R: */
	genoperandoperand(LogicalShiftLeftRR, ClassReg, ReceiverResultReg);
	genAddSmallIntegerTagsTo(ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNegative, gNegateR(ClassReg));
	/* begin CmpCq:R: */
	quickConstant1 = numSmallIntegerBits();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant1, genoperandoperand(CmpCqR, quickConstant1, ClassReg));
	/* begin JumpLessOrEqual: */
	jumpInRange = genoperand(JumpLessOrEqual, ((sqInt)0));
	/* begin MoveCq:R: */
	quickConstant2 = numSmallIntegerBits();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant2, genoperandoperand(MoveCqR, quickConstant2, ClassReg));
	jmpTarget(jumpInRange, gArithmeticShiftRightRR(ClassReg, ReceiverResultReg));
	genSetSmallIntegerTagsIn(ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotSI, jmpTarget(jumpTooBig, jmpTarget(jumpOvfl, gLabel())));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPrimitiveBitXor */
static sqInt
genPrimitiveBitXor(void)
{
    AbstractInstruction *jumpNotSI;


	/* Clear one or the other tag so that xoring will preserve them. */

	jumpNotSI = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	genRemoveSmallIntegerTagsInScratchReg(Arg0Reg);
	/* begin XorR:R: */
	genoperandoperand(XorRR, Arg0Reg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotSI, gLabel());
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPrimitiveCharacterValue */
static sqInt
genPrimitiveCharacterValue(void)
{
    sqInt r;

	if (((r = genInnerPrimitiveCharacterValue(0))) < 0) {
		return r;
	}
	return (r == UnfailingPrimitive
		? 0
		: compileFallbackToInterpreterPrimitive());
}


/*	Primitive class must be variadic for objectClass: */

	/* StackToRegisterMappingCogit>>#genPrimitiveClass */
static sqInt
genPrimitiveClass(void)
{
    sqInt reg;

	if (methodOrBlockNumArgs > 0) {
		if (methodOrBlockNumArgs > 1) {
			return compileFallbackToInterpreterPrimitive();
		}
		reg = Arg0Reg;
	}
	else {
		reg = ReceiverResultReg;
	}
	if ((genGetClassObjectOfintoscratchReginstRegIsReceiver(reg, ReceiverResultReg, TempReg, methodOrBlockNumArgs == 0)) == BadRegisterSet) {
		genGetClassObjectOfintoscratchReginstRegIsReceiver(reg, ClassReg, TempReg, methodOrBlockNumArgs == 0);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	}
	/* begin RetN: */
	genoperand(RetN, 0);
	return 0;
}


/*	Check the argument count. Fail if wrong.
	Get the method from the outerContext and see if it is cogged. If so, jump
	to the
	block entry or the no-context-switch entry, as appropriate, and we're
	done. If not,
	invoke the interpreter primitive. */
/*	Check the argument count. Fail if wrong.
	Get the method from the outerContext and see if it is cogged. If so, jump
	to the
	block entry or the no-context-switch entry, as appropriate, and we're
	done. If not,
	invoke the interpreter primitive.
	Override to push the register args first. */

	/* StackToRegisterMappingCogit>>#genPrimitiveClosureValue */
static sqInt
genPrimitiveClosureValue(void)
{
    AbstractInstruction *jumpBCMethod;
    AbstractInstruction *jumpFail1;
    AbstractInstruction *jumpFail2;
    AbstractInstruction *jumpFail3;
    AbstractInstruction *jumpFail4;
    AbstractInstruction *jumpFailNArgs;
    sqInt offset;
    void (*primitiveRoutine)();
    sqInt quickConstant;
    sqInt result;

	genPushRegisterArgs();
	genLoadSlotsourceRegdestReg(ClosureNumArgsIndex, ReceiverResultReg, TempReg);
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(((methodOrBlockNumArgs << 1) | 1), genoperandoperand(CmpCqR, ((methodOrBlockNumArgs << 1) | 1), TempReg));
	/* begin JumpNonZero: */
	jumpFailNArgs = genoperand(JumpNonZero, ((sqInt)0));
	genLoadSlotsourceRegdestReg(ClosureOuterContextIndex, ReceiverResultReg, ClassReg);
	jumpFail1 = genJumpImmediate(ClassReg);
	genGetCompactClassIndexNonImmOfinto(ClassReg, TempReg);
	genCmpClassMethodContextCompactIndexR(TempReg);
	/* begin JumpNonZero: */
	jumpFail2 = genoperand(JumpNonZero, ((sqInt)0));
	
	genLoadSlotsourceRegdestReg(MethodIndex, ClassReg, SendNumArgsReg);
	jumpFail3 = genJumpImmediate(SendNumArgsReg);
	genGetFormatOfinto(SendNumArgsReg, TempReg);
	/* begin CmpCq:R: */
	quickConstant = firstCompiledMethodFormat();
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, TempReg));
	/* begin JumpLess: */
	jumpFail4 = genoperand(JumpLess, ((sqInt)0));
	genLoadSlotsourceRegdestReg(HeaderIndex, SendNumArgsReg, ClassReg);
	jumpBCMethod = genJumpSmallInteger(ClassReg);
	/* begin MoveM16:r:R: */
	offset = offsetof(CogMethod, blockEntryOffset);
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveM16rR, offset, ClassReg, TempReg));
	/* begin AddR:R: */
	genoperandoperand(AddRR, ClassReg, TempReg);
	primitiveRoutine = functionPointerForCompiledMethodprimitiveIndex(methodObj, primitiveIndex);
	if (primitiveRoutine == primitiveClosureValueNoContextSwitch) {
		if (blockNoContextSwitchOffset == null) {
			return NotFullyInitialized;
		}
		/* begin SubCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(blockNoContextSwitchOffset, genoperandoperand(SubCqR, blockNoContextSwitchOffset, TempReg));
	}
	/* begin JumpR: */
	genoperand(JumpR, TempReg);
	jmpTarget(jumpBCMethod, jmpTarget(jumpFail1, jmpTarget(jumpFail2, jmpTarget(jumpFail3, jmpTarget(jumpFail4, gLabel())))));
	if (((result = compileInterpreterPrimitive(primitiveRoutine))) < 0) {
		return result;
	}
	jmpTarget(jumpFailNArgs, gLabel());
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPrimitiveDiv */
static sqInt
genPrimitiveDiv(void)
{
    AbstractInstruction *convert;
    AbstractInstruction *jumpExact;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpSameSign;
    AbstractInstruction *jumpZero;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, Arg1Reg);

	/* We must shift away the tags, not just subtract them, so that the
	   overflow case doesn't actually overflow the machine instruction. */

	jumpNotSI = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(ClassReg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpZero))) {
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, ClassReg));
	}
	/* begin JumpZero: */
	jumpZero = genoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(TempReg);
	gDivRRQuoRem(ClassReg, TempReg, TempReg, ClassReg);
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, ClassReg));
	/* begin JumpZero: */
	jumpExact = genoperand(JumpZero, ((sqInt)0));
	/* begin XorR:R: */
	genoperandoperand(XorRR, ClassReg, Arg1Reg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpZero))) {
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, Arg1Reg));
	}
	/* begin JumpGreaterOrEqual: */
	jumpSameSign = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin SubCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(1, genoperandoperand(SubCqR, 1, TempReg));
	jmpTarget(jumpSameSign, (convert = gLabel()));
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpExact, gCmpCqR(1 << ((numSmallIntegerBits()) - 1), TempReg));
	/* begin JumpLess: */
	genoperand(JumpLess, ((sqInt)convert));
	jmpTarget(jumpZero, jmpTarget(jumpNotSI, gLabel()));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPrimitiveDivide */
static sqInt
genPrimitiveDivide(void)
{
    AbstractInstruction *jumpInexact;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOverflow;
    AbstractInstruction *jumpZero;
    sqInt quickConstant;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);

	/* We must shift away the tags, not just subtract them, so that the
	   overflow case doesn't actually overflow the machine instruction. */

	jumpNotSI = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(ClassReg);
	/* begin JumpZero: */
	jumpZero = genoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(TempReg);
	gDivRRQuoRem(ClassReg, TempReg, TempReg, ClassReg);
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, ClassReg));
	/* begin JumpNonZero: */
	jumpInexact = genoperand(JumpNonZero, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant = 1 << ((numSmallIntegerBits()) - 1);
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, TempReg));
	/* begin JumpGreaterOrEqual: */
	jumpOverflow = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOverflow, jmpTarget(jumpInexact, jmpTarget(jumpZero, jmpTarget(jumpNotSI, gLabel()))));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPrimitiveFloatSquareRoot */
static sqInt
genPrimitiveFloatSquareRoot(void)
{
    AbstractInstruction *jumpFailAlloc;

	genGetDoubleValueOfinto(ReceiverResultReg, DPFPReg0);
	/* begin SqrtRd: */
	genoperand(SqrtRd, DPFPReg0);
	jumpFailAlloc = genAllocFloatValueintoscratchRegscratchReg(DPFPReg0, SendNumArgsReg, ClassReg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpFailAlloc, gLabel());
	return compileFallbackToInterpreterPrimitive();
}


/*	Receiver and arg in registers.
	Stack looks like
	return address */

	/* StackToRegisterMappingCogit>>#genPrimitiveIdentical */
static sqInt
genPrimitiveIdentical(void)
{
	return genInnerPrimitiveIdenticalorNotIf(0, 0);
}

	/* StackToRegisterMappingCogit>>#genPrimitiveIdentityHash */
static sqInt
genPrimitiveIdentityHash(void)
{
    sqInt r;

	if (((r = genInnerPrimitiveIdentityHash(0))) < 0) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

	/* StackToRegisterMappingCogit>>#genPrimitiveMod */
static sqInt
genPrimitiveMod(void)
{
    AbstractInstruction *jumpExact;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpSameSign;
    AbstractInstruction *jumpZero;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	jumpNotSI = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	genRemoveSmallIntegerTagsInScratchReg(ClassReg);
	/* begin JumpZero: */
	jumpZero = genoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, Arg1Reg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genRemoveSmallIntegerTagsInScratchReg(TempReg);
	gDivRRQuoRem(ClassReg, TempReg, TempReg, ClassReg);
	/* begin CmpCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, ClassReg));
	/* begin JumpZero: */
	jumpExact = genoperand(JumpZero, ((sqInt)0));
	/* begin XorR:R: */
	genoperandoperand(XorRR, ClassReg, Arg1Reg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpZero))) {
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, Arg1Reg));
	}
	/* begin JumpGreaterOrEqual: */
	jumpSameSign = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin XorR:R: */
	genoperandoperand(XorRR, ClassReg, Arg1Reg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, Arg1Reg, ClassReg);
	jmpTarget(jumpSameSign, jmpTarget(jumpExact, gLabel()));
	genSetSmallIntegerTagsIn(ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpZero, jmpTarget(jumpNotSI, gLabel()));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPrimitiveMultiply */
static sqInt
genPrimitiveMultiply(void)
{
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOvfl;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, Arg1Reg);
	jumpNotSI = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(ClassReg);
	genRemoveSmallIntegerTagsInScratchReg(Arg1Reg);
	gMulRR(Arg1Reg, ClassReg);
	/* begin JumpOverflow: */
	jumpOvfl = genoperand(JumpOverflow, ((sqInt)0));
	genSetSmallIntegerTagsIn(ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOvfl, jmpTarget(jumpNotSI, gLabel()));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPrimitiveNew */
static sqInt
genPrimitiveNew(void)
{
    sqInt numArgs;
    sqInt r;

	if ((((r = genInnerPrimitiveNew(0))) < 0)
	 && (r != UnimplementedPrimitive)) {
		return r;
	}

	return compileFallbackToInterpreterPrimitive();
}

	/* StackToRegisterMappingCogit>>#genPrimitiveNewMethod */
static sqInt
genPrimitiveNewMethod(void)
{
    sqInt r;

	if ((((r = genInnerPrimitiveNewMethod(0))) < 0)
	 && (r != UnimplementedPrimitive)) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

	/* StackToRegisterMappingCogit>>#genPrimitiveNewWithArg */
static sqInt
genPrimitiveNewWithArg(void)
{
    sqInt numArgs;
    sqInt r;

	if ((((r = genInnerPrimitiveNewWithArg(0))) < 0)
	 && (r != UnimplementedPrimitive)) {
		return r;
	}

	return compileFallbackToInterpreterPrimitive();
}


/*	Receiver and arg in registers.
	Stack looks like
	return address */

	/* StackToRegisterMappingCogit>>#genPrimitiveNotIdentical */
static sqInt
genPrimitiveNotIdentical(void)
{
	return genInnerPrimitiveIdenticalorNotIf(0, 1);
}

	/* StackToRegisterMappingCogit>>#genPrimitiveQuo */
static sqInt
genPrimitiveQuo(void)
{
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOverflow;
    AbstractInstruction *jumpZero;
    sqInt quickConstant;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);

	/* We must shift away the tags, not just subtract them, so that the
	   overflow case doesn't actually overflow the machine instruction. */

	jumpNotSI = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(ClassReg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpZero))) {
		/* begin CmpCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(0, genoperandoperand(CmpCqR, 0, ClassReg));
	}
	/* begin JumpZero: */
	jumpZero = genoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(TempReg);
	gDivRRQuoRem(ClassReg, TempReg, TempReg, ClassReg);
	/* begin CmpCq:R: */
	quickConstant = 1 << ((numSmallIntegerBits()) - 1);
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(quickConstant, genoperandoperand(CmpCqR, quickConstant, TempReg));
	/* begin JumpGreaterOrEqual: */
	jumpOverflow = genoperand(JumpGreaterOrEqual, ((sqInt)0));
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOverflow, jmpTarget(jumpZero, jmpTarget(jumpNotSI, gLabel())));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPrimitiveSize */
static sqInt
genPrimitiveSize(void)
{
    sqInt r;

	if (((r = genInnerPrimitiveSize(0))) < 0) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

	/* StackToRegisterMappingCogit>>#genPrimitiveStringAt */
static sqInt
genPrimitiveStringAt(void)
{
    sqInt r;

	assert((numRegArgs()) >= 1);
	if (((r = genInnerPrimitiveStringAt(0))) < 0) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

	/* StackToRegisterMappingCogit>>#genPrimitiveStringAtPut */
static sqInt
genPrimitiveStringAtPut(void)
{
    sqInt r;

	if ((((r = genInnerPrimitiveStringAtPut(0))) < 0)
	 && (r != UnimplementedPrimitive)) {
		return r;
	}
	return compileFallbackToInterpreterPrimitive();
}

	/* StackToRegisterMappingCogit>>#genPrimitiveSubtract */
static sqInt
genPrimitiveSubtract(void)
{
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOvfl;

	jumpNotSI = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, Arg0Reg, TempReg);
	/* begin JumpOverflow: */
	jumpOvfl = genoperand(JumpOverflow, ((sqInt)0));
	genAddSmallIntegerTagsTo(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOvfl, jmpTarget(jumpNotSI, gLabel()));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPushActiveContextBytecode */
static sqInt
genPushActiveContextBytecode(void)
{
	assert(needsFrame);
	(optStatus.isReceiverResultRegLive = 0);
	ssAllocateCallRegandand(ReceiverResultReg, SendNumArgsReg, ClassReg);

	genGetActiveContextNumArgslargeinBlock(methodOrBlockNumArgs, methodNeedsLargeContext(methodObj), inBlock);
	return ssPushRegister(ReceiverResultReg);
}


/*	Block compilation. At this point in the method create the block. Note its
	start and defer generating code for it until after the method and any
	other preceeding
	blocks. The block's actual code will be compiled later. */
/*	143 10001111 llllkkkk jjjjjjjj iiiiiiii	Push Closure Num Copied llll Num
	Args kkkk BlockSize jjjjjjjjiiiiiiii */

	/* StackToRegisterMappingCogit>>#genPushClosureCopyCopiedValuesBytecode */
static sqInt
genPushClosureCopyCopiedValuesBytecode(void)
{
    sqInt i;
    sqInt numArgs;
    sqInt numCopied;
    sqInt reg;
    sqInt startpc;

	assert(needsFrame);
	startpc = bytecodePC + (((generatorAt(byte0))->numBytes));
	addBlockStartAtnumArgsnumCopiedspan(startpc, (numArgs = byte1 & 15), (numCopied = ((usqInt) byte1) >> 4), (byte2 << 8) + byte3);
	/* begin genInlineClosure:numArgs:numCopied: */
	assert(getActiveContextAllocatesInMachineCode());
	(optStatus.isReceiverResultRegLive = 0);
	ssAllocateCallRegandand(ReceiverResultReg, SendNumArgsReg, ClassReg);
	genNoPopCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(startpc + 1, numArgs, numCopied, methodOrBlockNumArgs, methodNeedsLargeContext(methodObj), inBlock);
	for (i = 1; i <= numCopied; i += 1) {
		reg = ssStorePoptoPreferredReg(1, TempReg);
		genStoreSourceRegslotIndexintoNewObjectInDestReg(reg, (ClosureFirstCopiedValueIndex + numCopied) - i, ReceiverResultReg);
	}
	ssPushRegister(ReceiverResultReg);

	return 0;
}

	/* StackToRegisterMappingCogit>>#genPushLiteralVariable: */
static sqInt
genPushLiteralVariable(sqInt literalIndex)
{
    sqInt association;
    sqInt freeReg;

	freeReg = allocateRegNotConflictingWith(0);

	/* N.B. Do _not_ use ReceiverResultReg to avoid overwriting receiver in assignment in frameless methods. */
	/* So far descriptors are not rich enough to describe the entire dereference so generate the register
	   load but don't push the result.  There is an order-of-evaluation issue if we defer the dereference. */

	association = getLiteral(literalIndex);
	/* begin genMoveConstant:R: */
	if (shouldAnnotateObjectReference(association)) {
		annotateobjRef(gMoveCwR(association, TempReg), association);
	}
	else {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(association, genoperandoperand(MoveCqR, association, TempReg));
	}
	genEnsureObjInRegNotForwardedscratchReg(TempReg, freeReg);
	genLoadSlotsourceRegdestReg(ValueIndex, TempReg, freeReg);
	ssPushRegister(freeReg);
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPushLiteral: */
static sqInt
genPushLiteral(sqInt literal)
{
	return ssPushConstant(literal);
}

	/* StackToRegisterMappingCogit>>#genPushMaybeContextReceiverVariable: */
static sqInt
genPushMaybeContextReceiverVariable(sqInt slotIndex)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    AbstractInstruction *jmpDone;
    AbstractInstruction *jmpSingle;

	assert(needsFrame);
	ssAllocateCallRegand(ReceiverResultReg, SendNumArgsReg);
	ensureReceiverResultRegContainsSelf();
	if (callerSavedRegMask & (registerMaskFor(ReceiverResultReg))) {

		/* We have no way of reloading ReceiverResultReg since we need the inst var value as the result. */

		(optStatus.isReceiverResultRegLive = 0);
	}
	if (slotIndex == InstructionPointerIndex) {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(slotIndex, genoperandoperand(MoveCqR, slotIndex, SendNumArgsReg));
		/* begin CallRT: */
		/* begin annotateCall: */
		/* begin Call: */
		abstractInstruction = genoperand(Call, ceFetchContextInstVarTrampoline);
		(abstractInstruction->annotation = IsRelativeCall);
		abstractInstruction;
		return ssPushRegister(SendNumArgsReg);
	}
	genLoadSlotsourceRegdestReg(SenderIndex, ReceiverResultReg, TempReg);
	jmpSingle = genJumpNotSmallIntegerInScratchReg(TempReg);
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(slotIndex, genoperandoperand(MoveCqR, slotIndex, SendNumArgsReg));
	/* begin CallRT: */
	/* begin annotateCall: */
	/* begin Call: */
	abstractInstruction1 = genoperand(Call, ceFetchContextInstVarTrampoline);
	(abstractInstruction1->annotation = IsRelativeCall);
	abstractInstruction1;
	/* begin Jump: */
	jmpDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jmpSingle, gLabel());
	genLoadSlotsourceRegdestReg(slotIndex, ReceiverResultReg, SendNumArgsReg);
	jmpTarget(jmpDone, gLabel());
	return ssPushRegister(SendNumArgsReg);
}

	/* StackToRegisterMappingCogit>>#genPushNewArrayBytecode */
static sqInt
genPushNewArrayBytecode(void)
{
    sqInt i;
    sqInt popValues;
    sqInt size;

	assert(needsFrame);
	(optStatus.isReceiverResultRegLive = 0);
	if ((popValues = byte1 > 0x7F)) {
		ssFlushTo(simStackPtr);
	}
	else {
		ssAllocateCallRegand(SendNumArgsReg, ReceiverResultReg);
	}
	size = byte1 & 0x7F;
	if (!popValues) {
		if (tryCollapseTempVectorInitializationOfSize(size)) {
			return 0;
		}
	}
	genNewArrayOfSizeinitialized(size, !popValues);
	if (popValues) {
		for (i = (size - 1); i >= 0; i += -1) {
			/* begin PopR: */
			genoperand(PopR, TempReg);
			genStoreSourceRegslotIndexintoNewObjectInDestReg(TempReg, i, ReceiverResultReg);
		}
		ssPop(size);
	}
	return ssPushRegister(ReceiverResultReg);
}

	/* StackToRegisterMappingCogit>>#genPushReceiverBytecode */
static sqInt
genPushReceiverBytecode(void)
{
	if ((optStatus.isReceiverResultRegLive)) {
		return ssPushRegister(ReceiverResultReg);
	}
	return ssPushDesc(simSelf);
}

	/* StackToRegisterMappingCogit>>#genPushReceiverVariable: */
static sqInt
genPushReceiverVariable(sqInt index)
{
	ensureReceiverResultRegContainsSelf();
	return ssPushBaseoffset(ReceiverResultReg, slotOffsetOfInstVarIndex(index));
}


/*	Ensure that the register args are pushed before the retpc for methods with
	arity <= self numRegArgs.
 */
/*	This won't be as clumsy on a RISC. But putting the receiver and
	args above the return address means the CoInterpreter has a
	single machine-code frame format which saves us a lot of work. */

	/* StackToRegisterMappingCogit>>#genPushRegisterArgs */
static void
genPushRegisterArgs(void)
{
	if (!(regArgsHaveBeenPushed
		 || (methodOrBlockNumArgs > 2))) {
		genPushRegisterArgsForNumArgsscratchReg(backEnd, methodOrBlockNumArgs, SendNumArgsReg);
		regArgsHaveBeenPushed = 1;
	}
}

	/* StackToRegisterMappingCogit>>#genPushRemoteTempLongBytecode */
static sqInt
genPushRemoteTempLongBytecode(void)
{
    sqInt offset;
    sqInt regMask;
    sqInt remoteTempReg;
    sqInt tempVectReg;

	tempVectReg = allocateRegNotConflictingWith(0);
	/* begin MoveMw:r:R: */
	offset = frameOffsetOfTemporary(byte2);
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveMwrR, offset, FPReg, tempVectReg));
	/* begin availableRegOrNilNotConflictingWith: */
	regMask = registerMaskFor(tempVectReg);
	remoteTempReg = availableRegisterOrNilFor(backEnd, (liveRegisters()) | regMask);
	if (!(remoteTempReg)) {
		remoteTempReg = tempVectReg;
	}
	genLoadSlotsourceRegdestReg(byte1, tempVectReg, remoteTempReg);
	return ssPushRegister(remoteTempReg);
}


/*	If a frameless method (not a block), only argument temps can be accessed.
	This is assured by the use of needsFrameIfMod16GENumArgs: in pushTemp. */

	/* StackToRegisterMappingCogit>>#genPushTemporaryVariable: */
static sqInt
genPushTemporaryVariable(sqInt index)
{
	assert(inBlock
	 || (needsFrame
	 || (index < methodOrBlockNumArgs)));
	return ssPushDesc(simStack[index]);
}


/*	In a frameless method ReceiverResultReg already contains self.
	In a frameful method, ReceiverResultReg /may/ contain self. */

	/* StackToRegisterMappingCogit>>#genReturnReceiver */
static sqInt
genReturnReceiver(void)
{
	if (needsFrame) {
		if (!((optStatus.isReceiverResultRegLive))) {
			storeToReg((&simSelf), ReceiverResultReg);
		}
	}
	return genUpArrowReturn();
}

	/* StackToRegisterMappingCogit>>#genReturnTopFromBlock */
static sqInt
genReturnTopFromBlock(void)
{
	assert(inBlock);
	popToReg(ssTop(), ReceiverResultReg);
	ssPop(1);
	return genBlockReturn();
}

	/* StackToRegisterMappingCogit>>#genReturnTopFromMethod */
static sqInt
genReturnTopFromMethod(void)
{
	popToReg(ssTop(), ReceiverResultReg);
	ssPop(1);
	return genUpArrowReturn();
}

	/* StackToRegisterMappingCogit>>#genSendSuper:numArgs: */
static sqInt
genSendSupernumArgs(sqInt selector, sqInt numArgs)
{
	marshallSendArguments(numArgs);
	return genMarshalledSendnumArgssendTable(selector, numArgs, superSendTrampolines);
}


/*	Generate a trampoline with four arguments.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

	/* StackToRegisterMappingCogit>>#genSendTrampolineFor:numArgs:called:arg:arg:arg:arg: */
static sqInt
genSendTrampolineFornumArgscalledargargargarg(void *aRoutine, sqInt numArgs, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3)
{
    sqInt startAddress;

	startAddress = methodZoneBase;
	zeroOpcodeIndex();
	genPushRegisterArgsForNumArgsscratchReg(backEnd, numArgs, SendNumArgsReg);
	genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 4, regOrConst0, regOrConst1, regOrConst2, regOrConst3, 0, 1, null, 1);
	return startAddress;
}

	/* StackToRegisterMappingCogit>>#genSend:numArgs: */
static sqInt
genSendnumArgs(sqInt selector, sqInt numArgs)
{
	marshallSendArguments(numArgs);
	return genMarshalledSendnumArgssendTable(selector, numArgs, ordinarySendTrampolines);
}

	/* StackToRegisterMappingCogit>>#genSmallIntegerComparison: */
static sqInt
genSmallIntegerComparison(sqInt jumpOpcode)
{
    sqInt constant;
    AbstractInstruction *jumpFail;
    AbstractInstruction *jumpTrue;

	jumpFail = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ReceiverResultReg);
	jumpTrue = gen(jumpOpcode);
	/* begin genMoveFalseR: */
	/* begin genMoveConstant:R: */
	constant = falseObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, ReceiverResultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, ReceiverResultReg));
	}
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpTrue, genMoveTrueR(ReceiverResultReg));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpFail, gLabel());
	return 0;
}


/*	Stack looks like
	return address */

	/* StackToRegisterMappingCogit>>#genSmallIntegerComparison:orDoubleComparison: */
static sqInt
genSmallIntegerComparisonorDoubleComparison(sqInt jumpOpcode, AbstractInstruction *(*jumpFPOpcodeGenerator)(void *))
{
    sqInt constant;
    sqInt constant1;
    AbstractInstruction *jumpCond;
    AbstractInstruction *jumpDouble;
    AbstractInstruction *jumpFail;
    AbstractInstruction *jumpNonInt;
    AbstractInstruction *jumpTrue;

	
	jumpDouble = genJumpNotSmallIntegerscratchReg(Arg0Reg, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ReceiverResultReg);
	jumpTrue = gen(jumpOpcode);
	/* begin genMoveFalseR: */
	/* begin genMoveConstant:R: */
	constant = falseObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, ReceiverResultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant, genoperandoperand(MoveCqR, constant, ReceiverResultReg));
	}
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpTrue, genMoveTrueR(ReceiverResultReg));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpDouble, gLabel());
	jumpNonInt = genJumpImmediate(Arg0Reg);

	genGetCompactClassIndexNonImmOfinto(Arg0Reg, SendNumArgsReg);
	genCmpClassFloatCompactIndexR(SendNumArgsReg);
	/* begin JumpNonZero: */
	jumpFail = genoperand(JumpNonZero, ((sqInt)0));
	genConvertSmallIntegerToIntegerInReg(ReceiverResultReg);
	/* begin ConvertR:Rd: */
	genoperandoperand(ConvertRRd, ReceiverResultReg, DPFPReg0);
	genGetDoubleValueOfinto(Arg0Reg, DPFPReg1);
	/* begin CmpRd:Rd: */
	genoperandoperand(CmpRdRd, DPFPReg1, DPFPReg0);

	/* FP jumps are a little weird */

	jumpCond = jumpFPOpcodeGenerator(0);
	/* begin genMoveFalseR: */
	/* begin genMoveConstant:R: */
	constant1 = falseObject();
	if (shouldAnnotateObjectReference(constant1)) {
		annotateobjRef(gMoveCwR(constant1, ReceiverResultReg), constant1);
	}
	else {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(constant1, genoperandoperand(MoveCqR, constant1, ReceiverResultReg));
	}
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpCond, genMoveTrueR(ReceiverResultReg));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNonInt, jmpTarget(jumpFail, gLabel()));

	return 0;
}

	/* StackToRegisterMappingCogit>>#genSpecialSelectorArithmetic */
static sqInt
genSpecialSelectorArithmetic(void)
{
    char annotateInst;
    sqInt argInt;
    sqInt argIsConst;
    sqInt argIsInt;
    AbstractInstruction *instToAnnotate;
    AbstractInstruction *jumpContinue;
    AbstractInstruction *jumpNotSmallInts;
    BytecodeDescriptor *primDescriptor;
    sqInt rcvrInt;
    sqInt rcvrIsConst;
    sqInt rcvrIsInt;
    sqInt result;

	annotateInst = 0;
	primDescriptor = generatorAt(byte0);
	argIsInt = ((argIsConst = (((ssTop())->type)) == SSConstant))
	 && ((((argInt = ((ssTop())->constant))) & 1));
	rcvrIsInt = ((rcvrIsConst = (((ssValue(1))->type)) == SSConstant))
	 && ((((rcvrInt = ((ssValue(1))->constant))) & 1));
	if (argIsInt
	 && (rcvrIsInt)) {
		rcvrInt = (rcvrInt >> 1);
		argInt = (argInt >> 1);
		
		switch ((primDescriptor->opcode)) {
		case AddRR:
			result = rcvrInt + argInt;
			break;
		case SubRR:
			result = rcvrInt - argInt;
			break;
		case AndRR:
			result = rcvrInt & argInt;
			break;
		case OrRR:
			result = rcvrInt | argInt;
			break;
		default:
			error("Case not found and no otherwise clause");
		}
		if (isIntegerValue(result)) {

			/* Must enter any annotatedConstants into the map */

			annotateBytecodeIfAnnotated(ssValue(1));
			annotateBytecodeIfAnnotated(ssTop());
			return (ssPop(2),
			ssPushAnnotatedConstant(((result << 1) | 1)));
		}
		return genSpecialSelectorSend();
	}
	if ((rcvrIsConst
	 && (!rcvrIsInt))
	 || (argIsConst
	 && (!argIsInt))) {
		return genSpecialSelectorSend();
	}
	if (!(argIsInt
		 || (rcvrIsInt))) {
		return genSpecialSelectorSend();
	}
	if (argIsInt) {
		ssFlushTo(simStackPtr - 2);
		popToReg(ssValue(1), ReceiverResultReg);
		annotateInst = ((ssTop())->annotateUse);
		ssPop(2);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	}
	else {
		marshallSendArguments(1);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, Arg0Reg, TempReg);
		if (!rcvrIsInt) {
			/* begin AndR:R: */
			genoperandoperand(AndRR, ReceiverResultReg, TempReg);

		}
	}
	jumpNotSmallInts = genJumpNotSmallIntegerInScratchReg(TempReg);
	
	switch ((primDescriptor->opcode)) {
	case AddRR:
		if (argIsInt) {
			/* begin AddCq:R: */
			/* begin gen:quickConstant:operand: */
			instToAnnotate = checkQuickConstantforInstruction(argInt - ConstZero, genoperandoperand(AddCqR, argInt - ConstZero, ReceiverResultReg));
			/* begin JumpNoOverflow: */
			jumpContinue = genoperand(JumpNoOverflow, ((sqInt)0));
			/* begin SubCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(argInt - ConstZero, genoperandoperand(SubCqR, argInt - ConstZero, ReceiverResultReg));
		}
		else {
			genRemoveSmallIntegerTagsInScratchReg(ReceiverResultReg);
			/* begin AddR:R: */
			genoperandoperand(AddRR, Arg0Reg, ReceiverResultReg);
			/* begin JumpNoOverflow: */
			jumpContinue = genoperand(JumpNoOverflow, ((sqInt)0));
			if (rcvrIsInt) {
				/* begin MoveCq:R: */
				/* begin gen:quickConstant:operand: */
				checkQuickConstantforInstruction(rcvrInt, genoperandoperand(MoveCqR, rcvrInt, ReceiverResultReg));
			}
			else {
				/* begin SubR:R: */
				genoperandoperand(SubRR, Arg0Reg, ReceiverResultReg);
				genSetSmallIntegerTagsIn(ReceiverResultReg);
			}
		}
		break;
	case SubRR:
		if (argIsInt) {
			/* begin SubCq:R: */
			/* begin gen:quickConstant:operand: */
			instToAnnotate = checkQuickConstantforInstruction(argInt - ConstZero, genoperandoperand(SubCqR, argInt - ConstZero, ReceiverResultReg));
			/* begin JumpNoOverflow: */
			jumpContinue = genoperand(JumpNoOverflow, ((sqInt)0));
			/* begin AddCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(argInt - ConstZero, genoperandoperand(AddCqR, argInt - ConstZero, ReceiverResultReg));
		}
		else {
			genRemoveSmallIntegerTagsInScratchReg(Arg0Reg);
			/* begin SubR:R: */
			genoperandoperand(SubRR, Arg0Reg, ReceiverResultReg);
			/* begin JumpNoOverflow: */
			jumpContinue = genoperand(JumpNoOverflow, ((sqInt)0));
			/* begin AddR:R: */
			genoperandoperand(AddRR, Arg0Reg, ReceiverResultReg);
			genSetSmallIntegerTagsIn(Arg0Reg);
		}
		break;
	case AndRR:
		if (argIsInt) {
			/* begin AndCq:R: */
			/* begin gen:quickConstant:operand: */
			instToAnnotate = checkQuickConstantforInstruction(argInt, genoperandoperand(AndCqR, argInt, ReceiverResultReg));
		}
		else {
			/* begin AndR:R: */
			genoperandoperand(AndRR, Arg0Reg, ReceiverResultReg);
		}
		/* begin Jump: */
		jumpContinue = genoperand(Jump, ((sqInt)0));
		break;
	case OrRR:
		if (argIsInt) {
			/* begin OrCq:R: */
			/* begin gen:quickConstant:operand: */
			instToAnnotate = checkQuickConstantforInstruction(argInt, genoperandoperand(OrCqR, argInt, ReceiverResultReg));
		}
		else {
			/* begin OrR:R: */
			genoperandoperand(OrRR, Arg0Reg, ReceiverResultReg);
		}
		/* begin Jump: */
		jumpContinue = genoperand(Jump, ((sqInt)0));
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	jmpTarget(jumpNotSmallInts, gLabel());
	if (argIsInt) {
		if (annotateInst) {
			/* begin annotateBytecode: */
			(instToAnnotate->annotation = HasBytecodePC);
			instToAnnotate;
		}
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(argInt, genoperandoperand(MoveCqR, argInt, Arg0Reg));
	}
	genMarshalledSendnumArgssendTable(specialSelector(byte0 - (FirstSpecialSelector)), 1, ordinarySendTrampolines);
	jmpTarget(jumpContinue, gLabel());
	return 0;
}

	/* StackToRegisterMappingCogit>>#genSpecialSelectorClass */
static sqInt
genSpecialSelectorClass(void)
{
    sqInt topReg;

	topReg = registerOrNil(ssTop());
	ssPop(1);
	if ((topReg == null)
	 || (topReg == ClassReg)) {
		ssAllocateRequiredRegand((topReg = SendNumArgsReg), ClassReg);
	}
	else {
		ssAllocateRequiredReg(ClassReg);
	}
	ssPush(1);
	popToReg(ssTop(), topReg);
	genGetClassObjectOfintoscratchReginstRegIsReceiver(topReg, ClassReg, TempReg, 0);
	return (ssPop(1),
	ssPushRegister(ClassReg));
}

	/* StackToRegisterMappingCogit>>#genSpecialSelectorComparison */
static sqInt
genSpecialSelectorComparison(void)
{
    AbstractInstruction *abstractInstruction;
    char annotateInst;
    sqInt argInt;
    sqInt argIsInt;
    BytecodeDescriptor *branchDescriptor;
    BytecodeDescriptor *branchDescriptor1;
    sqInt descr;
    sqInt inlineCAB;
    AbstractInstruction *jumpNotSmallInts;
    void *jumpTarget;
    sqInt nExts;
    sqInt next;
    sqInt nextPC;
    sqInt nextPC1;
    sqInt postBranch;
    sqInt postBranchPC;
    sqInt postBranchPC1;
    BytecodeDescriptor *primDescriptor;
    BytecodeDescriptor *primDescriptor1;
    sqInt rcvrIsInt;
    sqInt target;
    sqInt targetBytecodePC;
    sqInt targetBytecodePC1;

	annotateInst = 0;
	ssFlushTo(simStackPtr - 2);
	primDescriptor = generatorAt(byte0);
	argIsInt = ((((ssTop())->type)) == SSConstant)
	 && ((((argInt = ((ssTop())->constant))) & 1));
	rcvrIsInt = ((((ssValue(1))->type)) == SSConstant)
	 && (((((ssValue(1))->constant)) & 1));
	if (argIsInt
	 && (rcvrIsInt)) {
		return genStaticallyResolvedSpecialSelectorComparison();
	}
	/* begin extractMaybeBranchDescriptorInto: */
	primDescriptor1 = generatorAt(byte0);
	nextPC1 = bytecodePC + ((primDescriptor1->numBytes));
	nExts = 0;
	while (1) {
		branchDescriptor1 = generatorAt((fetchByteofObject(nextPC1, methodObj)) + bytecodeSetOffset);
		if (!((branchDescriptor1->isExtension))) break;
		nExts += 1;
		nextPC1 += (branchDescriptor1->numBytes);
	}
	targetBytecodePC1 = (postBranchPC1 = 0);
	if (((branchDescriptor1->isBranchTrue))
	 || ((branchDescriptor1->isBranchFalse))) {
		targetBytecodePC1 = (nextPC1 + ((branchDescriptor1->numBytes))) + (((branchDescriptor1->spanFunction))(branchDescriptor1, nextPC1, nExts, methodObj));
		postBranchPC1 = nextPC1 + ((branchDescriptor1->numBytes));
	}
	branchDescriptor = branchDescriptor1;
	nextPC = nextPC1;
	postBranchPC = postBranchPC1;
	targetBytecodePC = targetBytecodePC1;


	/* Further, only interested in inlining = and ~= if there's a SmallInteger constant involved.
	   The relational operators successfully statically predict SmallIntegers; the equality operators do not. */

	inlineCAB = ((branchDescriptor->isBranchTrue))
	 || ((branchDescriptor->isBranchFalse));
	if (inlineCAB
	 && ((((primDescriptor->opcode)) == JumpZero)
	 || (((primDescriptor->opcode)) == JumpNonZero))) {
		inlineCAB = argIsInt
		 || (rcvrIsInt);
	}
	if (!inlineCAB) {
		return genSpecialSelectorSend();
	}
	if (argIsInt) {
		popToReg(ssValue(1), ReceiverResultReg);
		annotateInst = ((ssTop())->annotateUse);
		ssPop(2);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	}
	else {
		marshallSendArguments(1);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, Arg0Reg, TempReg);
		if (!rcvrIsInt) {
			/* begin AndR:R: */
			genoperandoperand(AndRR, ReceiverResultReg, TempReg);

		}
	}
	jumpNotSmallInts = genJumpNotSmallIntegerInScratchReg(TempReg);
	if (argIsInt) {
		if (annotateInst) {
			/* begin annotateBytecode: */
			/* begin CmpCq:R: */
			/* begin gen:quickConstant:operand: */
			abstractInstruction = checkQuickConstantforInstruction(argInt, genoperandoperand(CmpCqR, argInt, ReceiverResultReg));
			(abstractInstruction->annotation = HasBytecodePC);
			abstractInstruction;
		}
		else {
			/* begin CmpCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(argInt, genoperandoperand(CmpCqR, argInt, ReceiverResultReg));
		}
	}
	else {
		/* begin CmpR:R: */
		genoperandoperand(CmpRR, Arg0Reg, ReceiverResultReg);
	}
	genoperand(((branchDescriptor->isBranchTrue)
		? (primDescriptor->opcode)
		: inverseBranchFor((primDescriptor->opcode))), ((usqInt)(ensureNonMergeFixupAt(targetBytecodePC - initialPC))));
	/* begin Jump: */
	jumpTarget = ensureNonMergeFixupAt(postBranchPC - initialPC);
	genoperand(Jump, ((sqInt)jumpTarget));
	jmpTarget(jumpNotSmallInts, gLabel());
	if (argIsInt) {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(argInt, genoperandoperand(MoveCqR, argInt, Arg0Reg));
	}
	return genMarshalledSendnumArgssendTable(specialSelector(byte0 - (FirstSpecialSelector)), 1, ordinarySendTrampolines);
}


/*	Decompose code generation for #== into a common constant-folding version,
	followed by a double dispatch throguh the objectRepresentation to a
	version that doesn't deal with forwarders and a version that does. */

	/* StackToRegisterMappingCogit>>#genSpecialSelectorEqualsEquals */
static sqInt
genSpecialSelectorEqualsEquals(void)
{
    BytecodeDescriptor *primDescriptor;
    sqInt result;

	primDescriptor = generatorAt(byte0);
	if ((isUnannotatableConstant(ssTop()))
	 && (isUnannotatableConstant(ssValue(1)))) {
		assert(!((primDescriptor->isMapped)));
		result = ((((ssTop())->constant)) == (((ssValue(1))->constant))
			? trueObject()
			: falseObject());
		ssPop(2);
		return ssPushConstant(result);
	}
	return genSpecialSelectorEqualsEqualsWithForwarders();
}

	/* StackToRegisterMappingCogit>>#genSpecialSelectorEqualsEqualsWithForwarders */
static sqInt
genSpecialSelectorEqualsEqualsWithForwarders(void)
{
    sqInt arg;
    sqInt argReg;
    sqInt argReg1;
    BytecodeDescriptor *branchDescriptor;
    BytecodeDescriptor *branchDescriptor1;
    sqInt constant;
    sqInt constant1;
    sqInt descr;
    AbstractInstruction *finished;
    AbstractInstruction *finished1;
    usqInt fixup;
    AbstractInstruction *imm;
    AbstractInstruction *imm1;
    void *jumpTarget;
    void *jumpTarget1;
    AbstractInstruction *label;
    sqInt nExts;
    sqInt next;
    sqInt nextPC;
    sqInt nextPC1;
    AbstractInstruction *ok;
    AbstractInstruction *ok1;
    sqInt postBranch;
    sqInt postBranchPC;
    sqInt postBranchPC1;
    BytecodeDescriptor *primDescriptor;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt rcvr;
    sqInt rcvrReg;
    sqInt rcvrReg1;
    sqInt rNext;
    sqInt rNext1;
    sqInt rTop;
    sqInt rTop1;
    sqInt target;
    sqInt targetBytecodePC;
    sqInt targetBytecodePC1;
    sqInt topRegistersMask;
    sqInt unforwardArg;
    sqInt unforwardRcvr;

	argReg1 = 0;
	rNext1 = 0;
	rTop1 = 0;
	rcvrReg1 = 0;
	/* begin extractMaybeBranchDescriptorInto: */
	primDescriptor = generatorAt(byte0);
	nextPC1 = bytecodePC + ((primDescriptor->numBytes));
	nExts = 0;
	while (1) {
		branchDescriptor1 = generatorAt((fetchByteofObject(nextPC1, methodObj)) + bytecodeSetOffset);
		if (!((branchDescriptor1->isExtension))) break;
		nExts += 1;
		nextPC1 += (branchDescriptor1->numBytes);
	}
	targetBytecodePC1 = (postBranchPC1 = 0);
	if (((branchDescriptor1->isBranchTrue))
	 || ((branchDescriptor1->isBranchFalse))) {
		targetBytecodePC1 = (nextPC1 + ((branchDescriptor1->numBytes))) + (((branchDescriptor1->spanFunction))(branchDescriptor1, nextPC1, nExts, methodObj));
		postBranchPC1 = nextPC1 + ((branchDescriptor1->numBytes));
	}
	branchDescriptor = branchDescriptor1;
	nextPC = nextPC1;
	postBranchPC = postBranchPC1;
	targetBytecodePC = targetBytecodePC1;

	unforwardRcvr = !(isUnannotatableConstant(ssValue(1)));
	unforwardArg = !(isUnannotatableConstant(ssTop()));
	/* begin allocateEqualsEqualsRegistersArgNeedsReg:rcvrNeedsReg:into: */
	assert(unforwardArg
	 || (unforwardRcvr));
	if (unforwardArg) {
		if (unforwardRcvr) {
			/* begin allocateRegForStackTopTwoEntriesInto: */
			topRegistersMask = 0;
			if ((((ssTop())->type)) == SSRegister) {
				rTop1 = ((ssTop())->registerr);
			}
			if ((((ssValue(1))->type)) == SSRegister) {
				topRegistersMask = registerMaskFor((rNext1 = ((ssValue(1))->registerr)));
			}
			if (!(rTop1)) {
				rTop1 = allocateRegNotConflictingWith(topRegistersMask);
			}
			if (!(rNext1)) {
				rNext1 = allocateRegNotConflictingWith(registerMaskFor(rTop1));
			}
			argReg1 = rTop1;
			rcvrReg1 = rNext1;

			popToReg(ssTop(), argReg1);
			popToReg(ssValue(1), rcvrReg1);
		}
		else {
			argReg1 = allocateRegForStackEntryAtnotConflictingWith(0, 0);
			popToReg(ssTop(), argReg1);
			if (((ssValue(1))->spilled)) {
				/* begin AddCq:R: */
				/* begin gen:quickConstant:operand: */
				checkQuickConstantforInstruction(BytesPerWord, genoperandoperand(AddCqR, BytesPerWord, SPReg));
			}
		}
	}
	else {
		assert(unforwardRcvr);
		assert(!((((ssTop())->spilled))));
		rcvrReg1 = allocateRegForStackEntryAtnotConflictingWith(1, 0);
		popToReg(ssValue(1), rcvrReg1);
	}
	assert((!unforwardArg)
	 || (argReg1 != null));
	assert((!unforwardRcvr)
	 || (rcvrReg1 != null));
	rcvrReg = rcvrReg1;
	argReg = argReg1;

	if (!(((branchDescriptor->isBranchTrue))
		 || ((branchDescriptor->isBranchFalse)))) {
		return genEqualsEqualsNoBranchArgIsConstantrcvrIsConstantargRegrcvrReg(!unforwardArg, !unforwardRcvr, argReg, rcvrReg);
	}
	ssFlushTo(simStackPtr - 2);
	/* begin Label */
	label = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	/* begin genEqualsEqualsComparisonArgIsConstant:rcvrIsConstant:argReg:rcvrReg: */
	if (!unforwardArg) {
		/* begin genCompConstant:R: */
		constant = ((ssTop())->constant);
		if (shouldAnnotateObjectReference(constant)) {
			annotateobjRef(gCmpCwR(constant, rcvrReg), constant);
		}
		else {
			/* begin CmpCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(constant, genoperandoperand(CmpCqR, constant, rcvrReg));
		}
	}
	else {
		if (!unforwardRcvr) {
			/* begin genCompConstant:R: */
			constant1 = ((ssValue(1))->constant);
			if (shouldAnnotateObjectReference(constant1)) {
				annotateobjRef(gCmpCwR(constant1, argReg), constant1);
			}
			else {
				/* begin CmpCq:R: */
				/* begin gen:quickConstant:operand: */
				checkQuickConstantforInstruction(constant1, genoperandoperand(CmpCqR, constant1, argReg));
			}
		}
		else {
			/* begin CmpR:R: */
			genoperandoperand(CmpRR, argReg, rcvrReg);
		}
	}
	ssPop(2);
	if ((((fixupAt(nextPC - initialPC))->targetInstruction)) == 0) {

		/* The next instruction is dead.  we can skip it. */

		deadCode = 1;
		ensureFixupAt(targetBytecodePC - initialPC);
		ensureFixupAt(postBranchPC - initialPC);
	}
	else {
		ssPushConstant(trueObject());
	}
	assert(unforwardArg
	 || (unforwardRcvr));
	if ((branchDescriptor->isBranchTrue)) {
		fixup = ((usqInt)(ensureNonMergeFixupAt(postBranchPC - initialPC)));
		/* begin JumpZero: */
		jumpTarget = ((void *) (((usqInt)(ensureNonMergeFixupAt(targetBytecodePC - initialPC)))));
		genoperand(JumpZero, ((sqInt)jumpTarget));
	}
	else {

		/* branchDescriptor is branchFalse */

		fixup = ((usqInt)(ensureNonMergeFixupAt(targetBytecodePC - initialPC)));
		/* begin JumpZero: */
		jumpTarget1 = ((void *) (((usqInt)(ensureNonMergeFixupAt(postBranchPC - initialPC)))));
		genoperand(JumpZero, ((sqInt)jumpTarget1));
	}
	if (unforwardArg) {
		if (unforwardRcvr) {
			genEnsureOopInRegNotForwardedscratchRegjumpBackTo(argReg, TempReg, label);
		}
		else {
			/* begin genEnsureOopInRegNotForwarded:scratchReg:ifForwarder:ifNotForwarder: */
			assert(argReg != TempReg);

			/* notionally
			   self genGetClassIndexOfNonImm: reg into: scratch.
			   cogit CmpCq: objectMemory isForwardedObjectClassIndexPun R: TempReg.
			   but the following is an instruction shorter: */

			imm = genJumpImmediate(argReg);
			/* begin MoveMw:r:R: */
			/* begin gen:quickConstant:operand:operand: */
			checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveMwrR, 0, argReg, TempReg));
			/* begin AndCq:R: */
			quickConstant = (classIndexMask()) - (isForwardedObjectClassIndexPun());
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(quickConstant, genoperandoperand(AndCqR, quickConstant, TempReg));
			/* begin JumpNonZero: */
			ok = genoperand(JumpNonZero, ((sqInt)0));
			genLoadSlotsourceRegdestReg(0, argReg, argReg);
			/* begin Jump: */
			genoperand(Jump, ((sqInt)(((void *) label))));
			if (fixup == 0) {
				/* begin Label */
				finished = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
			}
			else {
				finished = ((AbstractInstruction *) fixup);
			}
			jmpTarget(imm, jmpTarget(ok, finished));
			0;
		}
	}
	if (unforwardRcvr) {
		/* begin genEnsureOopInRegNotForwarded:scratchReg:ifForwarder:ifNotForwarder: */
		assert(rcvrReg != TempReg);

		/* notionally
		   self genGetClassIndexOfNonImm: reg into: scratch.
		   cogit CmpCq: objectMemory isForwardedObjectClassIndexPun R: TempReg.
		   but the following is an instruction shorter: */

		imm1 = genJumpImmediate(rcvrReg);
		/* begin MoveMw:r:R: */
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(0, genoperandoperandoperand(MoveMwrR, 0, rcvrReg, TempReg));
		/* begin AndCq:R: */
		quickConstant1 = (classIndexMask()) - (isForwardedObjectClassIndexPun());
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(quickConstant1, genoperandoperand(AndCqR, quickConstant1, TempReg));
		/* begin JumpNonZero: */
		ok1 = genoperand(JumpNonZero, ((sqInt)0));
		genLoadSlotsourceRegdestReg(0, rcvrReg, rcvrReg);
		/* begin Jump: */
		genoperand(Jump, ((sqInt)(((void *) label))));
		if (fixup == 0) {
			/* begin Label */
			finished1 = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		}
		else {
			finished1 = ((AbstractInstruction *) fixup);
		}
		jmpTarget(imm1, jmpTarget(ok1, finished1));
		0;
	}
	return 0;
}


/*	Assumes both operands are ints */

	/* StackToRegisterMappingCogit>>#genStaticallyResolvedSpecialSelectorComparison */
static sqInt
genStaticallyResolvedSpecialSelectorComparison(void)
{
    sqInt argInt;
    BytecodeDescriptor *primDescriptor;
    sqInt rcvrInt;
    sqInt result;

	primDescriptor = generatorAt(byte0);
	argInt = ((ssTop())->constant);
	rcvrInt = ((ssValue(1))->constant);
	
	
	switch ((primDescriptor->opcode)) {
	case JumpLess:
		result = rcvrInt < argInt;
		break;
	case JumpLessOrEqual:
		result = rcvrInt <= argInt;
		break;
	case JumpGreater:
		result = rcvrInt > argInt;
		break;
	case JumpGreaterOrEqual:
		result = rcvrInt >= argInt;
		break;
	case JumpZero:
		result = rcvrInt == argInt;
		break;
	case JumpNonZero:
		result = rcvrInt != argInt;
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	annotateBytecodeIfAnnotated(ssValue(1));
	annotateBytecodeIfAnnotated(ssTop());
	ssPop(2);
	return ssPushAnnotatedConstant((result
		? trueObject()
		: falseObject()));
}


/*	The only reason we assert needsFrame here is that in a frameless method
	ReceiverResultReg must and does contain only self, but the ceStoreCheck
	trampoline expects the target of the store to be in ReceiverResultReg. So
	in a frameless method we would have a conflict between the receiver and
	the literal store, unless we we smart enough to realise that
	ReceiverResultReg was unused after the literal variable store, unlikely
	given that methods
	return self by default. */

	/* StackToRegisterMappingCogit>>#genStorePop:LiteralVariable: */
static sqInt
genStorePopLiteralVariable(sqInt popBoolean, sqInt litVarIndex)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    sqInt association;
    sqInt assocReg;
    sqInt topReg;

	assert(needsFrame);

	/* Avoid store check for immediate values */

	association = getLiteral(litVarIndex);
	if (isUnannotatableConstant(ssTop())) {
		assocReg = allocateRegNotConflictingWith(0);
		/* begin genMoveConstant:R: */
		if (shouldAnnotateObjectReference(association)) {
			annotateobjRef(gMoveCwR(association, assocReg), association);
		}
		else {
			/* begin MoveCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(association, genoperandoperand(MoveCqR, association, assocReg));
		}
		genEnsureObjInRegNotForwardedscratchReg(assocReg, TempReg);
		ssStorePoptoReg(popBoolean, TempReg);
		if (traceStores > 0) {
			if (!(assocReg == ReceiverResultReg)) {
				ssAllocateRequiredReg(ReceiverResultReg);
				(optStatus.isReceiverResultRegLive = 0);
				/* begin MoveR:R: */
				genoperandoperand(MoveRR, assocReg, ReceiverResultReg);
			}
			/* begin CallRT: */
			/* begin annotateCall: */
			/* begin Call: */
			abstractInstruction = genoperand(Call, ceTraceStoreTrampoline);
			(abstractInstruction->annotation = IsRelativeCall);
			abstractInstruction;
		}
		return genStoreImmediateInSourceRegslotIndexdestReg(TempReg, ValueIndex, assocReg);
	}
	topReg = allocateRegForStackEntryAtnotConflictingWith(0, registerMaskFor(ReceiverResultReg));
	ssStorePoptoReg(popBoolean, topReg);
	(optStatus.isReceiverResultRegLive = 0);
	ssAllocateRequiredReg(ReceiverResultReg);
	/* begin genMoveConstant:R: */
	if (shouldAnnotateObjectReference(association)) {
		annotateobjRef(gMoveCwR(association, ReceiverResultReg), association);
	}
	else {
		/* begin MoveCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(association, genoperandoperand(MoveCqR, association, ReceiverResultReg));
	}
	genEnsureObjInRegNotForwardedscratchReg(ReceiverResultReg, TempReg);
	if (traceStores > 0) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, topReg, TempReg);
		/* begin CallRT: */
		/* begin annotateCall: */
		/* begin Call: */
		abstractInstruction1 = genoperand(Call, ceTraceStoreTrampoline);
		(abstractInstruction1->annotation = IsRelativeCall);
		abstractInstruction1;
	}
	return genStoreSourceRegslotIndexdestRegscratchReginFrame(topReg, ValueIndex, ReceiverResultReg, TempReg, needsFrame);
}

	/* StackToRegisterMappingCogit>>#genStorePop:MaybeContextReceiverVariable: */
static sqInt
genStorePopMaybeContextReceiverVariable(sqInt popBoolean, sqInt slotIndex)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    AbstractInstruction *jmpDone;
    AbstractInstruction *jmpSingle;
    sqInt valueReg;


	/* The reason we need a frame here is that assigning to an inst var of a context may
	   involve wholesale reorganization of stack pages, and the only way to preserve the
	   execution state of an activation in that case is if it has a frame. */

	assert(needsFrame);
	ssFlushUpThroughReceiverVariable(slotIndex);
	ensureReceiverResultRegContainsSelf();
	ssPop(1);
	ssAllocateCallRegand(ClassReg, SendNumArgsReg);
	ssPush(1);
	genLoadSlotsourceRegdestReg(SenderIndex, ReceiverResultReg, TempReg);
	valueReg = ssStorePoptoPreferredReg(popBoolean, ClassReg);
	if (valueReg != ClassReg) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, valueReg, ClassReg);
	}
	jmpSingle = genJumpNotSmallIntegerInScratchReg(TempReg);
	/* begin MoveCq:R: */
	/* begin gen:quickConstant:operand: */
	checkQuickConstantforInstruction(slotIndex, genoperandoperand(MoveCqR, slotIndex, SendNumArgsReg));
	/* begin CallRT: */
	/* begin annotateCall: */
	/* begin Call: */
	abstractInstruction1 = genoperand(Call, ceStoreContextInstVarTrampoline);
	(abstractInstruction1->annotation = IsRelativeCall);
	abstractInstruction1;
	/* begin Jump: */
	jmpDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jmpSingle, gLabel());
	if (traceStores > 0) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, ClassReg, TempReg);
		/* begin CallRT: */
		/* begin annotateCall: */
		/* begin Call: */
		abstractInstruction = genoperand(Call, ceTraceStoreTrampoline);
		(abstractInstruction->annotation = IsRelativeCall);
		abstractInstruction;
	}
	genStoreSourceRegslotIndexdestRegscratchReginFrame(ClassReg, slotIndex, ReceiverResultReg, TempReg, 1);
	jmpTarget(jmpDone, gLabel());
	return 0;
}

	/* StackToRegisterMappingCogit>>#genStorePop:ReceiverVariable: */
static sqInt
genStorePopReceiverVariable(sqInt popBoolean, sqInt slotIndex)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    AbstractInstruction * inst;
    sqInt topReg;
    sqInt topReg1;

	return (needsFrame
		? (/* begin genStorePop:ReceiverVariable:traceBlock:inFrame: */
			ssFlushUpThroughReceiverVariable(slotIndex),
			(isUnannotatableConstant(ssTop())
					? (ensureReceiverResultRegContainsSelf(),
						ssStorePoptoReg(popBoolean, TempReg),
						(traceStores > 0
								? (/* begin CallRT: */
									/* begin annotateCall: */
									/* begin Call: */
									(abstractInstruction = genoperand(Call, ceTraceStoreTrampoline)),
									(abstractInstruction->annotation = IsRelativeCall),
									abstractInstruction)
								: 0),
						genStoreImmediateInSourceRegslotIndexdestReg(TempReg, slotIndex, ReceiverResultReg))
					: ((topReg = allocateRegForStackEntryAtnotConflictingWith(0, registerMaskFor(ReceiverResultReg))),
						ssStorePoptoReg(popBoolean, topReg),
						ensureReceiverResultRegContainsSelf(),
						(traceStores > 0
								? (/* begin MoveR:R: */
									genoperandoperand(MoveRR, topReg, TempReg),
									(/* begin CallRT: */
										/* begin annotateCall: */
										/* begin Call: */
										(abstractInstruction = genoperand(Call, ceTraceStoreTrampoline)),
										(abstractInstruction->annotation = IsRelativeCall),
										abstractInstruction))
								: 0),
						genStoreSourceRegslotIndexdestRegscratchReginFrame(topReg, slotIndex, ReceiverResultReg, TempReg, needsFrame))))
		: (/* begin genStorePop:ReceiverVariable:traceBlock:inFrame: */
			ssFlushUpThroughReceiverVariable(slotIndex),
			(isUnannotatableConstant(ssTop())
					? (ensureReceiverResultRegContainsSelf(),
						ssStorePoptoReg(popBoolean, TempReg),
						(traceStores > 0
								? (/* begin saveAndRestoreLinkRegAround: */
									/* begin PushR: */
									(inst = genoperand(PushR, LinkReg)),
									(/* begin CallRT: */
										/* begin annotateCall: */
										/* begin Call: */
										(abstractInstruction1 = genoperand(Call, ceTraceStoreTrampoline)),
										(abstractInstruction1->annotation = IsRelativeCall),
										abstractInstruction1),
									/* begin PopR: */
									genoperand(PopR, LinkReg),
									inst)
								: 0),
						genStoreImmediateInSourceRegslotIndexdestReg(TempReg, slotIndex, ReceiverResultReg))
					: ((topReg1 = allocateRegForStackEntryAtnotConflictingWith(0, registerMaskFor(ReceiverResultReg))),
						ssStorePoptoReg(popBoolean, topReg1),
						ensureReceiverResultRegContainsSelf(),
						(traceStores > 0
								? (/* begin MoveR:R: */
									genoperandoperand(MoveRR, topReg1, TempReg),
									(/* begin saveAndRestoreLinkRegAround: */
										/* begin PushR: */
										(inst = genoperand(PushR, LinkReg)),
										(/* begin CallRT: */
											/* begin annotateCall: */
											/* begin Call: */
											(abstractInstruction1 = genoperand(Call, ceTraceStoreTrampoline)),
											(abstractInstruction1->annotation = IsRelativeCall),
											abstractInstruction1),
										/* begin PopR: */
										genoperand(PopR, LinkReg),
										inst))
								: 0),
						genStoreSourceRegslotIndexdestRegscratchReginFrame(topReg1, slotIndex, ReceiverResultReg, TempReg, needsFrame)))));
}


/*	The only reason we assert needsFrame here is that in a frameless method
	ReceiverResultReg must and does contain only self, but the ceStoreCheck
	trampoline expects the target of the store to be in ReceiverResultReg. So
	in a frameless method we would have a conflict between the receiver and
	the temote temp store, unless we we smart enough to realise that
	ReceiverResultReg was unused after the literal variable store, unlikely
	given that methods return self by default. */

	/* StackToRegisterMappingCogit>>#genStorePop:RemoteTemp:At: */
static sqInt
genStorePopRemoteTempAt(sqInt popBoolean, sqInt slotIndex, sqInt remoteTempIndex)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    sqInt offset;
    sqInt offset1;
    sqInt tempVectReg;
    sqInt topReg;
    char topSpilled;

	assert(needsFrame);
	if (isUnannotatableConstant(ssTop())) {
		tempVectReg = allocateRegNotConflictingWith(0);
		/* begin MoveMw:r:R: */
		offset = frameOffsetOfTemporary(remoteTempIndex);
		/* begin gen:quickConstant:operand:operand: */
		checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveMwrR, offset, FPReg, tempVectReg));
		ssStorePoptoReg(popBoolean, TempReg);
		if (traceStores > 0) {
			if (!(tempVectReg == ReceiverResultReg)) {
				ssAllocateRequiredReg(ReceiverResultReg);
				(optStatus.isReceiverResultRegLive = 0);
				/* begin MoveR:R: */
				genoperandoperand(MoveRR, tempVectReg, ReceiverResultReg);
			}
			/* begin CallRT: */
			/* begin annotateCall: */
			/* begin Call: */
			abstractInstruction = genoperand(Call, ceTraceStoreTrampoline);
			(abstractInstruction->annotation = IsRelativeCall);
			abstractInstruction;
		}
		return genStoreImmediateInSourceRegslotIndexdestReg(TempReg, slotIndex, tempVectReg);
	}
	topReg = allocateRegForStackEntryAtnotConflictingWith(0, registerMaskFor(ReceiverResultReg));
	topSpilled = ((ssTop())->spilled);
	ssStorePoptoReg(popBoolean
	 || (topSpilled), topReg);
	if (!popBoolean) {
		if (!topSpilled) {
			ssPop(1);
		}
		ssPushRegister(topReg);
	}
	ssAllocateRequiredReg(ReceiverResultReg);
	(optStatus.isReceiverResultRegLive = 0);
	/* begin MoveMw:r:R: */
	offset1 = frameOffsetOfTemporary(remoteTempIndex);
	/* begin gen:quickConstant:operand:operand: */
	checkQuickConstantforInstruction(offset1, genoperandoperandoperand(MoveMwrR, offset1, FPReg, ReceiverResultReg));
	if (traceStores > 0) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, topReg, TempReg);
		/* begin CallRT: */
		/* begin annotateCall: */
		/* begin Call: */
		abstractInstruction1 = genoperand(Call, ceTraceStoreTrampoline);
		(abstractInstruction1->annotation = IsRelativeCall);
		abstractInstruction1;
	}
	return genStoreSourceRegslotIndexdestRegscratchReginFrame(topReg, slotIndex, ReceiverResultReg, TempReg, needsFrame);
}

	/* StackToRegisterMappingCogit>>#genStorePop:TemporaryVariable: */
static sqInt
genStorePopTemporaryVariable(sqInt popBoolean, sqInt tempIndex)
{
    sqInt offset;
    sqInt reg;

	ssFlushUpThroughTemporaryVariable(tempIndex);
	reg = ssStorePoptoPreferredReg(popBoolean, TempReg);
	/* begin MoveR:Mw:r: */
	offset = frameOffsetOfTemporary(tempIndex);
	/* begin gen:operand:quickConstant:operand: */
	checkQuickConstantforInstruction(offset, genoperandoperandoperand(MoveRMwr, reg, offset, FPReg));
	return 0;
}


/*	Unary inline primitives. */
/*	SistaV1: 248		11111000 iiiiiiii		mjjjjjjj		Call Primitive #iiiiiiii +
	(jjjjjjj * 256) m=1 means inlined primitive, no hard return after
	execution. See EncoderForSistaV1's class comment and
	StackInterpreter>>#trinaryInlinePrimitive: 
 */
/*	The store check requires rr to be ReceiverResultReg */

	/* StackToRegisterMappingCogit>>#genTrinaryInlinePrimitive: */
static sqInt
genTrinaryInlinePrimitive(sqInt prim)
{
    sqInt adjust;
    sqInt needsStoreCheck;
    sqInt ra1;
    sqInt ra2;
    sqInt rNext;
    sqInt rNext1;
    sqInt rr;
    sqInt rThird;
    sqInt rThird1;
    sqInt rTop;
    sqInt rTop1;
    sqInt thirdIsReceiver;
    sqInt topRegistersMask;

	rNext1 = 0;
	rThird1 = 0;
	rTop1 = 0;
	needsStoreCheck = !(isUnannotatableConstant(ssTop()));
	/* begin allocateRegForStackTopThreeEntriesInto:thirdIsReceiver: */
	thirdIsReceiver = (prim == 0)
	 && (needsStoreCheck);
	topRegistersMask = 0;
	if (((((ssTop())->type)) == SSRegister)
	 && ((!thirdIsReceiver)
	 || ((((ssTop())->registerr)) != ReceiverResultReg))) {
		topRegistersMask = registerMaskFor((rTop1 = ((ssTop())->registerr)));
	}
	if (((((ssValue(1))->type)) == SSRegister)
	 && ((!thirdIsReceiver)
	 || ((((ssValue(1))->registerr)) != ReceiverResultReg))) {
		topRegistersMask = topRegistersMask | (registerMaskFor((rNext1 = ((ssValue(1))->registerr))));
	}
	if (((((ssValue(2))->type)) == SSRegister)
	 && ((!thirdIsReceiver)
	 || ((((ssValue(2))->registerr)) == ReceiverResultReg))) {
		topRegistersMask = topRegistersMask | (registerMaskFor((rThird1 = ((ssValue(2))->registerr))));
	}
	if (!(rThird1)) {
		if (thirdIsReceiver) {

			/* Free ReceiverResultReg if it was not free */

			rThird1 = ReceiverResultReg;
			ssAllocateRequiredReg(ReceiverResultReg);
			(optStatus.isReceiverResultRegLive = 0);
		}
		else {
			rThird1 = allocateRegNotConflictingWith(topRegistersMask);
		}
		topRegistersMask = topRegistersMask | (registerMaskFor(rThird1));
	}
	if (!(rTop1)) {
		rTop1 = allocateRegNotConflictingWith(topRegistersMask);
		topRegistersMask = topRegistersMask | (registerMaskFor(rTop1));
	}
	if (!(rNext1)) {
		rNext1 = allocateRegNotConflictingWith(topRegistersMask);
	}
	ra2 = rTop1;
	ra1 = rNext1;
	rr = rThird1;

	assert((rr != ra1)
	 && ((rr != ra2)
	 && (ra1 != ra2)));
	popToReg(ssTop(), ra2);
	ssPop(1);
	popToReg(ssTop(), ra1);
	ssPop(1);
	popToReg(ssTop(), rr);
	ssPop(1);
	genConvertSmallIntegerToIntegerInReg(ra1);
	
	switch (prim) {
	case 0:
		
		/* shift by baseHeaderSize and then move from 1 relative to zero relative */

		adjust = (((usqInt) BaseHeaderSize) >> (shiftForWord())) - 1;
		if (adjust != 0) {
			/* begin AddCq:R: */
			/* begin gen:quickConstant:operand: */
			checkQuickConstantforInstruction(adjust, genoperandoperand(AddCqR, adjust, ra1));
		}
		/* begin MoveR:Xwr:R: */
		genoperandoperandoperand(MoveRXwrR, ra2, ra1, rr);
		if (needsStoreCheck) {
			assert(needsFrame);
			genStoreCheckReceiverRegvalueRegscratchReginFrame(rr, ra2, TempReg, 1);
		}
		break;
	case 1:
		genConvertSmallIntegerToIntegerInReg(ra2);

		/* shift by baseHeaderSize and then move from 1 relative to zero relative */

		adjust = BaseHeaderSize - 1;
		/* begin AddCq:R: */
		/* begin gen:quickConstant:operand: */
		checkQuickConstantforInstruction(adjust, genoperandoperand(AddCqR, adjust, ra1));
		/* begin MoveR:Xbr:R: */
		genoperandoperandoperand(MoveRXbrR, ra2, ra1, rr);
		genConvertIntegerToSmallIntegerInReg(ra2);
		break;
	default:
		return EncounteredUnknownBytecode;

	}
	ssPushRegister(ra2);
	return 0;
}


/*	Unary inline primitives. */
/*	SistaV1: 248		11111000 iiiiiiii		mjjjjjjj		Call Primitive #iiiiiiii +
	(jjjjjjj * 256) m=1 means inlined primitive, no hard return after
	execution. See EncoderForSistaV1's class comment and
	StackInterpreter>>#unaryInlinePrimitive: 
 */

	/* StackToRegisterMappingCogit>>#genUnaryInlinePrimitive: */
static sqInt
genUnaryInlinePrimitive(sqInt prim)
{
    sqInt rcvrReg;
    sqInt resultReg;

	rcvrReg = allocateRegForStackEntryAtnotConflictingWith(0, 0);
	resultReg = allocateRegNotConflictingWith(registerMaskFor(rcvrReg));
	popToReg(ssTop(), rcvrReg);
	ssPop(1);
	
	switch (prim) {
	case 1:
		
		/* 01		unchecked pointer numSlots */

		genGetNumSlotsOfinto(rcvrReg, resultReg);
		genConvertIntegerToSmallIntegerInReg(resultReg);
		break;
	case 3:
		
		/* 03		unchecked byte numBytes */

		genGetNumBytesOfinto(rcvrReg, resultReg);
		genConvertIntegerToSmallIntegerInReg(resultReg);
		break;
	default:
		
		/* 04		unchecked short16Type format numShorts */
		/* 05		unchecked word32Type format numWords */
		/* 06		unchecked doubleWord64Type format numDoubleWords */

		return EncounteredUnknownBytecode;

	}
	ssPushRegister(resultReg);
	return 0;
}


/*	Generate a method return from within a method or a block.
	Frameless method activation looks like
	CISCs (x86):
	receiver
	args
	sp->	ret pc.
	RISCs (ARM):
	receiver
	args
	ret pc in LR.
	A fully framed activation is described in CoInterpreter
	class>initializeFrameIndices. Return pops receiver and arguments off the
	stack. Callee pushes the result. */

	/* StackToRegisterMappingCogit>>#genUpArrowReturn */
static sqInt
genUpArrowReturn(void)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    sqInt offset;

	if (inBlock) {
		assert(needsFrame);
		/* begin CallRT: */
		/* begin annotateCall: */
		/* begin Call: */
		abstractInstruction1 = genoperand(Call, ceNonLocalReturnTrampoline);
		(abstractInstruction1->annotation = IsRelativeCall);
		abstractInstruction1;
		/* begin annotateBytecode: */
		/* begin Label */
		abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		(abstractInstruction->annotation = HasBytecodePC);
		abstractInstruction;
		return 0;
	}
	if (needsFrame) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, FPReg, SPReg);
		/* begin PopR: */
		genoperand(PopR, FPReg);
		/* begin PopR: */
		genoperand(PopR, LinkReg);

		/* begin RetN: */
		genoperand(RetN, (methodOrBlockNumArgs + 1) * BytesPerWord);
	}
	else {
		/* begin RetN: */
		offset = ((methodOrBlockNumArgs > 2)
		 || (regArgsHaveBeenPushed)
			? (methodOrBlockNumArgs + 1) * BytesPerWord
			: 0);
		genoperand(RetN, offset);
	}
	return 0;
}


/*	Make sure there's a flagged fixup at the targetIndex (pc relative to first
	pc) in fixups.
	These are the targets of backward branches. A backward branch fixup's
	simStackPtr needs to be set when generating the code for the bytecode at
	the targetIndex.
	Initially a fixup's target is just a flag. Later on it is replaced with a
	proper instruction. */

	/* StackToRegisterMappingCogit>>#initializeFixupAt: */
static BytecodeFixup *
initializeFixupAt(sqInt targetIndex)
{
    BytecodeFixup *fixup;

	fixup = fixupAt(targetIndex);
	(fixup->targetInstruction = ((AbstractInstruction *) 2));
	(fixup->simStackPtr = -2);
	return fixup;
}

	/* StackToRegisterMappingCogit>>#initSimStackForFramefulMethod: */
static void
initSimStackForFramefulMethod(sqInt startpc)
{
    CogSimStackEntry *desc;
    sqInt i;

	(simSelf.type = SSBaseOffset);
	(simSelf.spilled = 1);
	(simSelf.annotateUse = 0);
	(simSelf.registerr = FPReg);
	(simSelf.offset = FoxMFReceiver);
	(optStatus.isReceiverResultRegLive = 0);
	(optStatus.ssEntry = (&simSelf));

	/* N.B. Includes num args */

	simSpillBase = methodOrBlockNumTemps;

	/* args */

	simStackPtr = simSpillBase - 1;
	for (i = 0; i < methodOrBlockNumArgs; i += 1) {
		desc = simStackAt(i);
		(desc->type = SSBaseOffset);
		(desc->spilled = 1);
		(desc->annotateUse = 0);
		(desc->registerr = FPReg);
		(desc->offset = FoxCallerSavedIP + ((methodOrBlockNumArgs - i) * BytesPerWord));
		(desc->bcptr = startpc);
	}
	for (i = methodOrBlockNumArgs; i <= simStackPtr; i += 1) {
		desc = simStackAt(i);
		(desc->type = SSBaseOffset);
		(desc->spilled = 1);
		(desc->annotateUse = 0);
		(desc->registerr = FPReg);
		(desc->offset = FoxMFReceiver - (((i - methodOrBlockNumArgs) + 1) * BytesPerWord));
		(desc->bcptr = startpc);
	}
}


/*	The register receiver (the closure itself) and args are pushed by the
	closure value primitive(s)
	and hence a frameless block has all arguments and copied values pushed to
	the stack. However,
	the method receiver (self) is put in the ReceiverResultRegister by the
	block entry. */

	/* StackToRegisterMappingCogit>>#initSimStackForFramelessBlock: */
static void
initSimStackForFramelessBlock(sqInt startpc)
{
    CogSimStackEntry *desc;
    sqInt i;

	(simSelf.type = SSRegister);
	(simSelf.spilled = 0);
	(simSelf.annotateUse = 0);
	(simSelf.registerr = ReceiverResultReg);
	(optStatus.isReceiverResultRegLive = 1);
	(optStatus.ssEntry = (&simSelf));
	assert(methodOrBlockNumTemps >= methodOrBlockNumArgs);
	for (i = 0; i < methodOrBlockNumTemps; i += 1) {
		desc = simStackAt(i);
		(desc->type = SSBaseOffset);
		(desc->spilled = 1);
		(desc->annotateUse = 0);
		(desc->registerr = SPReg);
		(desc->offset = ((methodOrBlockNumArgs - 1) - i) * BytesPerWord);
		(desc->bcptr = startpc);
	}
	simSpillBase = (simStackPtr = methodOrBlockNumTemps - 1);
}

	/* StackToRegisterMappingCogit>>#initSimStackForFramelessMethod: */
static void
initSimStackForFramelessMethod(sqInt startpc)
{
    CogSimStackEntry *desc;
    sqInt i;

	(simSelf.type = SSRegister);
	(simSelf.spilled = 0);
	(simSelf.annotateUse = 0);
	(simSelf.registerr = ReceiverResultReg);
	(optStatus.isReceiverResultRegLive = 1);
	(optStatus.ssEntry = (&simSelf));
	assert(methodOrBlockNumTemps >= methodOrBlockNumArgs);
	assert((numRegArgs()) <= 2);
	if (((methodOrBlockNumArgs >= 1) && (methodOrBlockNumArgs <= 2))) {
		desc = simStackAt(0);
		(desc->type = SSRegister);
		(desc->spilled = 0);
		(desc->annotateUse = 0);
		(desc->registerr = Arg0Reg);
		(desc->bcptr = startpc);
		if (methodOrBlockNumArgs > 1) {
			desc = simStackAt(1);
			(desc->type = SSRegister);
			(desc->spilled = 0);
			(desc->annotateUse = 0);
			(desc->registerr = Arg1Reg);
			(desc->bcptr = startpc);
		}
	}
	else {
		for (i = 0; i < methodOrBlockNumArgs; i += 1) {
			desc = simStackAt(i);
			(desc->type = SSBaseOffset);
			(desc->registerr = SPReg);
			(desc->spilled = 1);
			(desc->annotateUse = 0);
			(desc->offset = ((methodOrBlockNumArgs - 1) - i) * BytesPerWord);
			(desc->bcptr = startpc);
		}
	}
	simSpillBase = (simStackPtr = methodOrBlockNumArgs - 1);
}

	/* StackToRegisterMappingCogit>>#liveRegisters */
static sqInt
liveRegisters(void)
{
    sqInt i;
    sqInt regsSet;

	if (needsFrame) {
		regsSet = 0;
	}
	else {
		regsSet = registerMaskFor(ReceiverResultReg);
		if ((methodOrBlockNumArgs <= 2)
		 && (methodOrBlockNumArgs > 0)) {
			regsSet = regsSet | (registerMaskFor(Arg0Reg));
			if (methodOrBlockNumArgs > 1) {
				regsSet = regsSet | (registerMaskFor(Arg1Reg));
			}
		}
	}
	for (i = (((simSpillBase < 0) ? 0 : simSpillBase)); i <= simStackPtr; i += 1) {
		regsSet = regsSet | (registerMask(simStackAt(i)));
	}
	return regsSet;
}


/*	Spill everything on the simulated stack that needs spilling (that below
	receiver and arguments).
	Marshall receiver and arguments to stack and/or registers depending on arg
	count. If the args don't fit in registers push receiver and args (spill
	everything), but still assign
	the receiver to ReceiverResultReg. */

	/* StackToRegisterMappingCogit>>#marshallSendArguments: */
static void
marshallSendArguments(sqInt numArgs)
{
    sqInt anyRefs;
    CogSimStackEntry * cascade0;
    sqInt numSpilled;

	ssFlushTo((simStackPtr - numArgs) - 1);
	if (numArgs > 2) {

		/* If there are no spills and no references to ReceiverResultReg
		   the fetch of ReceiverResultReg from the stack can be avoided
		   by assigning directly to ReceiverResultReg and pushing it. */

		numSpilled = numberOfSpillsInTopNItems(numArgs + 1);
		anyRefs = anyReferencesToRegisterinTopNItems(ReceiverResultReg, numArgs + 1);
		if ((numSpilled > 0)
		 || (anyRefs)) {
			ssFlushTo(simStackPtr);
			storeToReg(simStackAt(simStackPtr - numArgs), ReceiverResultReg);
		}
		else {
			cascade0 = simStackAt(simStackPtr - numArgs);
			storeToReg(cascade0, ReceiverResultReg);
			(cascade0->type = SSRegister);
			(cascade0->registerr = ReceiverResultReg);
			ssFlushTo(simStackPtr);
		}
	}
	else {

		/* Move the args to the register arguments, being careful to do
		   so last to first so e.g. previous contents don't get overwritten.
		   Also check for any arg registers in use by other args. */

		if (numArgs > 0) {
			if (numArgs > 1) {
				ssAllocateRequiredRegupThrough(Arg0Reg, simStackPtr - 2);
				ssAllocateRequiredRegupThrough(Arg1Reg, simStackPtr - 1);
			}
			else {
				ssAllocateRequiredRegupThrough(Arg0Reg, simStackPtr - 1);
			}
		}
		if (numArgs > 1) {
			popToReg(simStackAt(simStackPtr), Arg1Reg);
		}
		if (numArgs > 0) {
			popToReg(simStackAt((simStackPtr - numArgs) + 1), Arg0Reg);
		}
		popToReg(simStackAt(simStackPtr - numArgs), ReceiverResultReg);
	}
	ssPop(numArgs + 1);
}


/*	Merge control flow at a fixup. The fixup holds the simStackPtr at the jump
	to this target.
	See stackToRegisterMapping on the class side for a full description. */

	/* StackToRegisterMappingCogit>>#merge:afterContinuation: */
static void
mergeafterContinuation(BytecodeFixup *fixup, sqInt mergeWithContinuation)
{
    sqInt i;

	traceMerge(fixup);
	(optStatus.isReceiverResultRegLive = 0);
	if (!mergeWithContinuation) {
		assert((((usqInt)((fixup->targetInstruction)))) >= 2);
		simStackPtr = (fixup->simStackPtr);
	}
	if ((((usqInt)((fixup->targetInstruction)))) <= 2) {

		/* This is either a forward or backward branch target.
		   The stack must be flushed. */

		ssFlushTo(simStackPtr);
		if (((fixup->simStackPtr)) <= -2) {

			/* This is the target of a backward branch.  It doesn't have a simStackPtr yet. */

			(fixup->simStackPtr = simStackPtr);
		}
		(fixup->targetInstruction = gLabel());
	}
	assert(simStackPtr >= ((fixup->simStackPtr)));
	
	simStackPtr = (fixup->simStackPtr);

	/* For now throw away all type information for values on the stack, but sometime consider
	   the more sophisticated merge described in the class side stackToRegisterMapping. */

	simSpillBase = methodOrBlockNumTemps;
	for (i = methodOrBlockNumTemps; i <= simStackPtr; i += 1) {
		mergeAtfrom(simStackAt(i), FoxMFReceiver - (((i - methodOrBlockNumArgs) + 1) * BytesPerOop), FPReg);
	}
}

	/* StackToRegisterMappingCogit>>#methodAbortTrampolineFor: */
static sqInt
methodAbortTrampolineFor(sqInt numArgs)
{
	return methodAbortTrampolines[((numArgs < (2 + 1)) ? numArgs : (2 + 1))];
}

	/* StackToRegisterMappingCogit>>#needsFrameIfMod16GENumArgs: */
static sqInt
needsFrameIfMod16GENumArgs(sqInt stackDelta)
{
	return (byte0 % 16) >= methodOrBlockNumArgs;
}


/*	As of August 2013, the code generator can't deal with spills in frameless
	methods (the
	issue is to do with the stack offset to get at an argument, which is
	changed when there's a spill).
	In e.g. TextColor>>#dominates: other ^other class == self class the second
	send of class
	needs also rto allocate a register that the first one used, but the first
	one's register can't be
	spilled. So avoid this by only allowing class to be sent if the stack
	contains a single element. */

	/* StackToRegisterMappingCogit>>#needsFrameIfStackGreaterThanOne: */
static sqInt
needsFrameIfStackGreaterThanOne(sqInt stackDelta)
{
	return stackDelta > 1;
}

	/* StackToRegisterMappingCogit>>#numberOfSpillsInTopNItems: */
static sqInt
numberOfSpillsInTopNItems(sqInt n)
{
    sqInt i;

	for (i = simStackPtr; i >= ((simStackPtr - n) + 1); i += -1) {
		if ((((simStackAt(i))->type)) == SSSpill) {
			return n - (simStackPtr - i);
		}
	}
	return 0;
}

	/* StackToRegisterMappingCogit>>#picAbortTrampolineFor: */
static sqInt
picAbortTrampolineFor(sqInt numArgs)
{
	return picAbortTrampolines[((numArgs < (2 + 1)) ? numArgs : (2 + 1))];
}

	/* StackToRegisterMappingCogit>>#prevInstIsPCAnnotated */
static sqInt
prevInstIsPCAnnotated(void)
{
    sqInt prevIndex;
    AbstractInstruction *prevInst;

	if (!(opcodeIndex > 0)) {
		return 0;
	}
	prevIndex = opcodeIndex - 1;
	while (1) {
		if (prevIndex <= 0) {
			return 0;
		}
		prevInst = abstractInstructionAt(prevIndex);
		if (isPCMappedAnnotation((!((prevInst->annotation))
			? 0
			: (prevInst->annotation)))) {
			return 1;
		}
		if (!(((prevInst->opcode)) == Label)) break;
		prevIndex -= 1;
	}
	return 0;
}

	/* StackToRegisterMappingCogit>>#pushNilSize:numInitialNils: */
static sqInt
pushNilSizenumInitialNils(sqInt aMethodObj, sqInt numInitialNils)
{
    sqInt (* const pushNilSizeFunction)(sqInt,sqInt) = v3PushNilSizenumInitialNils;

	return pushNilSizeFunction(aMethodObj, numInitialNils);
}


/*	When a block must be recompiled due to overestimating the
	numInitialNils fixups must be restored, which means rescannning
	since backward branches need their targets initialized. */

	/* StackToRegisterMappingCogit>>#reinitializeFixupsFrom:through: */
static void
reinitializeFixupsFromthrough(sqInt start, sqInt end)
{
    BytecodeFixup * cascade0;
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt nExts;
    sqInt pc;
    sqInt targetPC;

	pc = start;
	nExts = 0;
	while (pc <= end) {
		cascade0 = fixupAt(pc - initialPC);
		(cascade0->targetInstruction = 0);
		(cascade0->simStackPtr = null);
		byte0 = (fetchByteofObject(pc, methodObj)) + bytecodeSetOffset;
		descriptor = generatorAt(byte0);
		if ((isBranch(descriptor))
		 && (isBackwardBranchatextsin(descriptor, pc, nExts, methodObj))) {
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj);
			targetPC = (pc + ((descriptor->numBytes))) + distance;
			initializeFixupAt(targetPC - initialPC);
		}
		if ((descriptor->isBlockCreation)) {
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj);
			pc = (pc + ((descriptor->numBytes))) + distance;
		}
		else {
			pc += (descriptor->numBytes);
		}
		nExts = ((descriptor->isExtension)
			? nExts + 1
			: 0);
	}
}


/*	Scan the block to determine if the block needs a frame or not */

	/* StackToRegisterMappingCogit>>#scanBlock: */
static void
scanBlock(BlockStart *blockStart)
{
    BytecodeDescriptor *descriptor;
    sqInt end;
    sqInt framelessStackDelta;
    sqInt nExts;
    sqInt numPushNils;
    sqInt (* const numPushNilsFunction)(struct _BytecodeDescriptor *,sqInt,sqInt,sqInt) = v3NumPushNils;
    sqInt pc;
    sqInt pushingNils;

	needsFrame = 0;
	prevBCDescriptor = null;
	methodOrBlockNumArgs = (blockStart->numArgs);
	inBlock = 1;
	pc = (blockStart->startpc);
	end = ((blockStart->startpc)) + ((blockStart->span));
	framelessStackDelta = (nExts = (extA = (extB = 0)));
	pushingNils = 1;
	while (pc < end) {
		byte0 = (fetchByteofObject(pc, methodObj)) + bytecodeSetOffset;
		descriptor = generatorAt(byte0);
		if ((descriptor->isExtension)) {
			loadSubsequentBytesForDescriptorat(descriptor, pc);
			((descriptor->generator))();
		}
		if (!needsFrame) {
			if ((((descriptor->needsFrameFunction)) == null)
			 || (((descriptor->needsFrameFunction))(framelessStackDelta))) {
				needsFrame = 1;
			}
			else {
				framelessStackDelta += (descriptor->stackDelta);
			}
		}
		/* begin maybeNoteDescriptor:blockStart: */
		if ((descriptor->isInstVarRef)) {
			(blockStart->hasInstVarRef = 1);
		}
		if (pushingNils
		 && (!((descriptor->isExtension)))) {

			/* Count the initial number of pushed nils acting as temp initializers.  We can't tell
			   whether an initial pushNil is an operand reference or a temp initializer, except
			   when the pushNil is a jump target (has a fixup), which never happens:
			   self systemNavigation browseAllSelect:
			   [:m| | ebc |
			   (ebc := m embeddedBlockClosures
			   select: [:ea| ea decompile statements first isMessage]
			   thenCollect: [:ea| ea decompile statements first selector]) notEmpty
			   and: [(#(whileTrue whileFalse whileTrue: whileFalse:) intersection: ebc) notEmpty]]
			   or if the bytecode set has a push multiple nils bytecode.  We simply count initial nils.
			   Rarely we may end up over-estimating.  We will correct by checking the stack depth
			   at the end of the block in compileBlockBodies. */

			if (((numPushNils = numPushNilsFunction(descriptor, pc, nExts, methodObj))) > 0) {
				assert((((descriptor->numBytes)) == 1)
				 || (((descriptor->generator)) == genPushClosureTempsBytecode));
				(blockStart->numInitialNils = ((blockStart->numInitialNils)) + numPushNils);
			}
			else {
				pushingNils = 0;
			}
		}
		pc = (pc + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj)
	: 0));
		if ((descriptor->isExtension)) {
			nExts += 1;
		}
		else {
			nExts = (extA = (extB = 0));
		}
		prevBCDescriptor = descriptor;
	}
	if (!needsFrame) {
		assert((framelessStackDelta >= 0)
		 && (((blockStart->numInitialNils)) >= framelessStackDelta));
		(blockStart->numInitialNils = ((blockStart->numInitialNils)) - framelessStackDelta);
	}
}


/*	Scan the method (and all embedded blocks) to determine
	- what the last bytecode is; extra bytes at the end of a method are used
	to encode things like source pointers or temp names
	- if the method needs a frame or not
	- what are the targets of any backward branches.
	- how many blocks it creates
	Answer the block count or on error a negative error code */

	/* StackToRegisterMappingCogit>>#scanMethod */
static sqInt
scanMethod(void)
{
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt framelessStackDelta;
    sqInt latestContinuation;
    sqInt nExts;
    sqInt numBlocks;
    sqInt pc;
    sqInt targetPC;

	needsFrame = 0;
	inBlock = 0;
	prevBCDescriptor = null;
	
#  if NewspeakVM
	numIRCs = 0;

#  endif /* NewspeakVM */

	if ((primitiveIndex > 0)
	 && (isQuickPrimitiveIndex(primitiveIndex))) {
		return 0;
	}
	pc = (latestContinuation = initialPC);
	numBlocks = (framelessStackDelta = (nExts = (extA = (extB = 0))));
	while (pc <= endPC) {
		byte0 = (fetchByteofObject(pc, methodObj)) + bytecodeSetOffset;
		descriptor = generatorAt(byte0);
		if ((descriptor->isExtension)) {
			if (((descriptor->opcode)) == Nop) {

				/* unknown bytecode tag; see Cogit class>>#generatorTableFrom: */

				return EncounteredUnknownBytecode;
			}
			loadSubsequentBytesForDescriptorat(descriptor, pc);
			((descriptor->generator))();
		}
		if (((descriptor->isReturn))
		 && (pc >= latestContinuation)) {
			endPC = pc;
		}
		if (!needsFrame) {
			if ((((descriptor->needsFrameFunction)) == null)
			 || (((descriptor->needsFrameFunction))(framelessStackDelta))) {
				needsFrame = 1;
			}
			else {
				framelessStackDelta += (descriptor->stackDelta);
			}
		}
		if (isBranch(descriptor)) {
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj);
			targetPC = (pc + ((descriptor->numBytes))) + distance;
			if (isBackwardBranchatextsin(descriptor, pc, nExts, methodObj)) {
				initializeFixupAt(targetPC - initialPC);
			}
			else {
				latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
			}
		}
		if ((descriptor->isBlockCreation)) {
			numBlocks += 1;
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj);
			targetPC = (pc + ((descriptor->numBytes))) + distance;
			latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
		}
		
#    if NewspeakVM
		if ((descriptor->hasIRC)) {
			numIRCs += 1;
		}

#    endif /* NewspeakVM */

		pc += (descriptor->numBytes);
		if ((descriptor->isExtension)) {
			nExts += 1;
		}
		else {
			nExts = (extA = (extB = 0));
		}
		prevBCDescriptor = descriptor;
	}
	return numBlocks;
}


/*	Allocate a register needed in a run-time call (i.e. flush uses of the
	register to the real stack). Since the run-time can smash any and
	all caller-saved registers also flush all caller-saved registers. */

	/* StackToRegisterMappingCogit>>#ssAllocateCallReg: */
static void
ssAllocateCallReg(sqInt requiredReg)
{
	ssAllocateRequiredRegMaskupThrough(callerSavedRegMask | (registerMaskFor(requiredReg)), simStackPtr);
}


/*	Allocate registers needed in a run-time call (i.e. flush uses of the
	registers to the real stack). Since the run-time can smash any and
	all caller-saved registers also flush all caller-saved registers. */

	/* StackToRegisterMappingCogit>>#ssAllocateCallReg:and: */
static void
ssAllocateCallRegand(sqInt requiredReg1, sqInt requiredReg2)
{
	ssAllocateRequiredRegMaskupThrough(callerSavedRegMask | ((registerMaskFor(requiredReg1)) | (registerMaskFor(requiredReg2))), simStackPtr);
}


/*	Allocate registers needed in a run-time call (i.e. flush uses of the
	registers to the real stack). Since the run-time can smash any and
	all caller-saved registers also flush all caller-saved registers. */

	/* StackToRegisterMappingCogit>>#ssAllocateCallReg:and:and: */
static void
ssAllocateCallRegandand(sqInt requiredReg1, sqInt requiredReg2, sqInt requiredReg3)
{
	ssAllocateRequiredRegMaskupThrough(callerSavedRegMask | ((registerMaskFor(requiredReg1)) | ((registerMaskFor(requiredReg2)) | (registerMaskFor(requiredReg3)))), simStackPtr);
}

	/* StackToRegisterMappingCogit>>#ssAllocateRequiredRegMask:upThrough: */
static void
ssAllocateRequiredRegMaskupThrough(sqInt requiredRegsMask, sqInt stackPtr)
{
    sqInt i;
    sqInt lastRequired;
    sqInt liveRegs;


	/* compute live regs while noting the last occurrence of required regs.
	   If these are not free we must spill from simSpillBase to last occurrence.
	   Note we are conservative here; we could allocate FPReg in frameless methods. */

	lastRequired = -1;
	liveRegs = registerMaskForand(FPReg, SPReg);
	for (i = (((simSpillBase < 0) ? 0 : simSpillBase)); i <= stackPtr; i += 1) {
		liveRegs = liveRegs | (registerMask(simStackAt(i)));
		if (((registerMask(simStackAt(i))) & requiredRegsMask) != 0) {
			lastRequired = i;
		}
	}
	if (!((liveRegs & requiredRegsMask) == 0)) {

		/* Some live, must spill */

		ssFlushTo(lastRequired);
		assert(((liveRegisters()) & requiredRegsMask) == 0);
	}
}

	/* StackToRegisterMappingCogit>>#ssAllocateRequiredReg: */
static void
ssAllocateRequiredReg(sqInt requiredReg)
{
	ssAllocateRequiredRegMaskupThrough(registerMaskFor(requiredReg), simStackPtr);
}

	/* StackToRegisterMappingCogit>>#ssAllocateRequiredReg:and: */
static void
ssAllocateRequiredRegand(sqInt requiredReg1, sqInt requiredReg2)
{
	ssAllocateRequiredRegMaskupThrough((registerMaskFor(requiredReg1)) | (registerMaskFor(requiredReg2)), simStackPtr);
}

	/* StackToRegisterMappingCogit>>#ssAllocateRequiredReg:upThrough: */
static void
ssAllocateRequiredRegupThrough(sqInt requiredReg, sqInt stackPtr)
{
	ssAllocateRequiredRegMaskupThrough(registerMaskFor(requiredReg), stackPtr);
}

	/* StackToRegisterMappingCogit>>#ssFlushTo: */
static void
ssFlushTo(sqInt index)
{
    sqInt i;

	for (i = methodOrBlockNumTemps; i < simSpillBase; i += 1) {
		assert(((simStackAt(i))->spilled));
	}
	if (simSpillBase <= index) {
		for (i = (((simSpillBase < 0) ? 0 : simSpillBase)); i <= index; i += 1) {
			assert(needsFrame);
			ensureSpilledAtfrom(simStackAt(i), frameOffsetOfTemporary(i), FPReg);
		}
		simSpillBase = index + 1;
	}
}


/*	Any occurrences on the stack of the value being stored (which is the top
	of stack)
	must be flushed, and hence any values colder than them stack. */

	/* StackToRegisterMappingCogit>>#ssFlushUpThroughReceiverVariable: */
static void
ssFlushUpThroughReceiverVariable(sqInt slotIndex)
{
    CogSimStackEntry *desc;
    sqInt index;

	/* begin ssFlushUpThrough: */
	for (index = (simStackPtr - 1); index >= (((simSpillBase < 0) ? 0 : simSpillBase)); index += -1) {
		if (((((simStackAt(index))->type)) == SSBaseOffset)
		 && (((((simStackAt(index))->registerr)) == ReceiverResultReg)
		 && ((((simStackAt(index))->offset)) == (slotOffsetOfInstVarIndex(slotIndex))))) {
			ssFlushTo(index);
			goto l1;
		}
	}
l1:	/* end ssFlushUpThrough: */;
}


/*	Any occurrences on the stack of the value being stored (which is the top
	of stack)
	must be flushed, and hence any values colder than them stack. */

	/* StackToRegisterMappingCogit>>#ssFlushUpThroughTemporaryVariable: */
static void
ssFlushUpThroughTemporaryVariable(sqInt tempIndex)
{
    CogSimStackEntry *desc;
    sqInt index;

	/* begin ssFlushUpThrough: */
	for (index = (simStackPtr - 1); index >= (((simSpillBase < 0) ? 0 : simSpillBase)); index += -1) {
		if (((((simStackAt(index))->type)) == SSBaseOffset)
		 && (((((simStackAt(index))->registerr)) == FPReg)
		 && ((((simStackAt(index))->offset)) == (frameOffsetOfTemporary(tempIndex))))) {
			ssFlushTo(index);
			goto l1;
		}
	}
l1:	/* end ssFlushUpThrough: */;
}

	/* StackToRegisterMappingCogit>>#ssPop: */
static void
ssPop(sqInt n)
{
	assert(((simStackPtr - n) >= (methodOrBlockNumTemps - 1))
	 || ((!needsFrame)
	 && ((simStackPtr - n) >= -1)));
	simStackPtr -= n;
}

	/* StackToRegisterMappingCogit>>#ssPushAnnotatedConstant: */
static sqInt
ssPushAnnotatedConstant(sqInt literal)
{
    CogSimStackEntry * cascade0;

	ssPush(1);
	updateSimSpillBase();
	cascade0 = ssTop();
	(cascade0->type = SSConstant);
	(cascade0->annotateUse = 1);
	(cascade0->spilled = 0);
	(cascade0->constant = literal);
	(cascade0->bcptr = bytecodePC);
	return 0;
}

	/* StackToRegisterMappingCogit>>#ssPushBase:offset: */
static sqInt
ssPushBaseoffset(sqInt reg, sqInt offset)
{
    CogSimStackEntry * cascade0;

	ssPush(1);
	updateSimSpillBase();
	cascade0 = ssTop();
	(cascade0->type = SSBaseOffset);
	(cascade0->spilled = 0);
	(cascade0->annotateUse = 0);
	(cascade0->registerr = reg);
	(cascade0->offset = offset);
	(cascade0->bcptr = bytecodePC);
	return 0;
}

	/* StackToRegisterMappingCogit>>#ssPushConstant: */
static sqInt
ssPushConstant(sqInt literal)
{
    CogSimStackEntry * cascade0;

	ssPush(1);
	updateSimSpillBase();
	cascade0 = ssTop();
	(cascade0->type = SSConstant);
	(cascade0->spilled = 0);
	(cascade0->annotateUse = 0);
	(cascade0->constant = literal);
	(cascade0->bcptr = bytecodePC);
	return 0;
}

	/* StackToRegisterMappingCogit>>#ssPushDesc: */
static sqInt
ssPushDesc(CogSimStackEntry simStackEntry)
{
	if (((simStackEntry.type)) == SSSpill) {
		(simStackEntry.type = SSBaseOffset);
	}
	(simStackEntry.spilled = 0);
	(simStackEntry.annotateUse = 0);
	(simStackEntry.bcptr = bytecodePC);
	simStack[(simStackPtr += 1)] = simStackEntry;
	updateSimSpillBase();
	return 0;
}

	/* StackToRegisterMappingCogit>>#ssPushRegister: */
static sqInt
ssPushRegister(sqInt reg)
{
    CogSimStackEntry * cascade0;

	ssPush(1);
	updateSimSpillBase();
	cascade0 = ssTop();
	(cascade0->type = SSRegister);
	(cascade0->spilled = 0);
	(cascade0->annotateUse = 0);
	(cascade0->registerr = reg);
	(cascade0->bcptr = bytecodePC);
	return 0;
}

	/* StackToRegisterMappingCogit>>#ssPush: */
static void
ssPush(sqInt n)
{
	simStackPtr += n;
}


/*	Store or pop the top simulated stack entry to a register.
	Use preferredReg if the entry is not itself a register.
	Answer the actual register the result ends up in. */

	/* StackToRegisterMappingCogit>>#ssStorePop:toPreferredReg: */
static sqInt
ssStorePoptoPreferredReg(sqInt popBoolean, sqInt preferredReg)
{
    sqInt actualReg;

	actualReg = preferredReg;
	if ((((ssTop())->type)) == SSRegister) {
		assert(!(((ssTop())->annotateUse)));
		assert(!(((ssTop())->spilled)));
		actualReg = ((ssTop())->registerr);
	}
	ssStorePoptoReg(popBoolean, actualReg);
	return actualReg;
}


/*	Store or pop the top simulated stack entry to a register.
	N.B.: popToReg: and storeToReg: does not generate anything if 
	it moves a register to the same register. */

	/* StackToRegisterMappingCogit>>#ssStorePop:toReg: */
static void
ssStorePoptoReg(sqInt popBoolean, sqInt reg)
{
	if (popBoolean) {
		popToReg(ssTop(), reg);
		ssPop(1);
	}
	else {
		storeToReg(ssTop(), reg);
	}
}

	/* StackToRegisterMappingCogit>>#ssTop */
static CogSimStackEntry *
ssTop(void)
{
	return simStackAt(simStackPtr);
}

	/* StackToRegisterMappingCogit>>#ssTopDescriptor */
static CogSimStackEntry
ssTopDescriptor(void)
{
	return simStack[simStackPtr];
}

	/* StackToRegisterMappingCogit>>#ssValue: */
static CogSimStackEntry *
ssValue(sqInt n)
{
	return simStackAt(simStackPtr - n);
}


/*	If the sequence of bytecodes is
	push: (Array new: 1)
	popIntoTemp: tempIndex
	pushConstant: const or pushTemp: n
	popIntoTemp: 0 inVectorAt: tempIndex
	collapse this into
	tempAt: tempIndex put: {const or temp}
	and answer true, otherwise answer false.
	One might think that we should look for a sequence of more than
	one pushes and pops but this is extremely rare.
	Exclude pushRcvr: n to avoid potential complications with context inst
	vars.  */

	/* StackToRegisterMappingCogit>>#tryCollapseTempVectorInitializationOfSize: */
static sqInt
tryCollapseTempVectorInitializationOfSize(sqInt slots)
{
    BytecodeDescriptor *pushArrayDesc;
    BytecodeDescriptor *pushValueDesc;
    sqInt reg;
    sqInt remoteTempIndex;
    BytecodeDescriptor *storeArrayDesc;
    BytecodeDescriptor *storeValueDesc;
    sqInt tempIndex;

	if (slots != 1) {
		return 0;
	}
	pushArrayDesc = generatorAt(bytecodeSetOffset + (fetchByteofObject(bytecodePC, methodObj)));
	assert(((pushArrayDesc->generator)) == genPushNewArrayBytecode);
	storeArrayDesc = generatorAt(bytecodeSetOffset + (fetchByteofObject(bytecodePC + ((pushArrayDesc->numBytes)), methodObj)));
	if (((storeArrayDesc->generator)) == genStoreAndPopTemporaryVariableBytecode) {
		tempIndex = (fetchByteofObject(bytecodePC + ((pushArrayDesc->numBytes)), methodObj)) & 7;
	}
	else {
		if (!(((storeArrayDesc->generator)) == genLongStoreAndPopTemporaryVariableBytecode)) {
			return 0;
		}
		tempIndex = fetchByteofObject((bytecodePC + ((pushArrayDesc->numBytes))) + 1, methodObj);
	}
	pushValueDesc = generatorAt(bytecodeSetOffset + (fetchByteofObject((bytecodePC + ((pushArrayDesc->numBytes))) + ((storeArrayDesc->numBytes)), methodObj)));
	if (!((((pushValueDesc->generator)) == genPushLiteralConstantBytecode)
		 || ((((pushValueDesc->generator)) == genPushQuickIntegerConstantBytecode)
		 || (((pushValueDesc->generator)) == genPushTemporaryVariableBytecode)))) {
		return 0;
	}
	storeValueDesc = generatorAt(bytecodeSetOffset + (fetchByteofObject(((bytecodePC + ((pushArrayDesc->numBytes))) + ((storeArrayDesc->numBytes))) + ((pushValueDesc->numBytes)), methodObj)));
	remoteTempIndex = fetchByteofObject((((bytecodePC + ((pushArrayDesc->numBytes))) + ((storeArrayDesc->numBytes))) + ((pushValueDesc->numBytes))) + 2, methodObj);
	if (!((((storeValueDesc->generator)) == genStoreAndPopRemoteTempLongBytecode)
		 && (tempIndex == remoteTempIndex))) {
		return 0;
	}
	genNewArrayOfSizeinitialized(1, 0);
	evaluateat(pushValueDesc, (bytecodePC + ((pushArrayDesc->numBytes))) + ((storeArrayDesc->numBytes)));
	reg = ssStorePoptoPreferredReg(1, TempReg);
	genStoreSourceRegslotIndexintoNewObjectInDestReg(reg, 0, ReceiverResultReg);
	ssPushRegister(ReceiverResultReg);
	evaluateat(storeArrayDesc, bytecodePC + ((pushArrayDesc->numBytes)));

	/* + pushArrayDesc numBytes this gets added by nextBytecodePCFor:at:exts:in: */

	bytecodePC = ((bytecodePC + ((storeArrayDesc->numBytes))) + ((pushValueDesc->numBytes))) + ((storeValueDesc->numBytes));
	return 1;
}

	/* StackToRegisterMappingCogit>>#updateSimSpillBase */
static void
updateSimSpillBase(void)
{
	if (simSpillBase > simStackPtr) {
		simSpillBase = ((simStackPtr < 0) ? 0 : simStackPtr);
	}
}

	/* StackToRegisterMappingCogit>>#v3PushNilSize:numInitialNils: */
static sqInt
v3PushNilSizenumInitialNils(sqInt aMethodObj, sqInt numInitialNils)
{
	return numInitialNils;
}

	/* StackToRegisterMappingCogit>>#v3:Num:Push:Nils: */
static sqInt
v3NumPushNils(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	return (((descriptor->generator)) == genPushConstantNilBytecode
		? 1
		: 0);
}
